============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-09 06:32:36,025 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:32:36,030 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:32:36,034 - distributed.scheduler - INFO - State start
2024-01-09 06:32:36,181 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:32:36,183 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-09 06:32:36,185 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:32:36,185 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:32:36,356 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37269'
2024-01-09 06:32:36,383 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34539'
2024-01-09 06:32:36,386 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38165'
2024-01-09 06:32:36,395 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38075'
2024-01-09 06:32:37,213 - distributed.scheduler - INFO - Receive client connection: Client-df7bf69a-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:37,228 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58656
2024-01-09 06:32:38,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:38,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:38,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:38,259 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:38,261 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:38,262 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38231
2024-01-09 06:32:38,262 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38231
2024-01-09 06:32:38,262 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36521
2024-01-09 06:32:38,262 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:32:38,262 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,262 - distributed.worker - INFO -               Threads:                          4
2024-01-09 06:32:38,262 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-09 06:32:38,262 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-um5v0j1a
2024-01-09 06:32:38,262 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d50b3006-b79b-44e6-9fa0-260c5a880185
2024-01-09 06:32:38,262 - distributed.worker - INFO - Starting Worker plugin PreImport-a5be0d1c-dcec-42d2-b0c2-230faf22760d
2024-01-09 06:32:38,262 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:38,262 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b02a7efe-8b33-4766-8286-68513c1f9111
2024-01-09 06:32:38,262 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,263 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35221
2024-01-09 06:32:38,263 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35221
2024-01-09 06:32:38,263 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32873
2024-01-09 06:32:38,263 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:32:38,263 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,264 - distributed.worker - INFO -               Threads:                          4
2024-01-09 06:32:38,264 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-09 06:32:38,264 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-3h55cubp
2024-01-09 06:32:38,264 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6cf9e71c-732b-45f8-84da-c3c8bd342af0
2024-01-09 06:32:38,265 - distributed.worker - INFO - Starting Worker plugin PreImport-725adc69-2ea0-4603-a860-4d47764b7ade
2024-01-09 06:32:38,265 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2e399708-30a2-431c-ad6f-20747e1ed47d
2024-01-09 06:32:38,265 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:38,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:38,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:38,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:38,295 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:38,295 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:38,296 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41311
2024-01-09 06:32:38,296 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38963
2024-01-09 06:32:38,296 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41311
2024-01-09 06:32:38,296 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40979
2024-01-09 06:32:38,296 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38963
2024-01-09 06:32:38,296 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:32:38,296 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43683
2024-01-09 06:32:38,296 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,296 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:32:38,296 - distributed.worker - INFO -               Threads:                          4
2024-01-09 06:32:38,296 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,296 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-09 06:32:38,296 - distributed.worker - INFO -               Threads:                          4
2024-01-09 06:32:38,296 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-y7b7m0aq
2024-01-09 06:32:38,296 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-09 06:32:38,296 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-l4zpzopq
2024-01-09 06:32:38,296 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-61bc6e31-41a6-4c8c-9106-044e9c3fccda
2024-01-09 06:32:38,297 - distributed.worker - INFO - Starting Worker plugin PreImport-c3ac1ce8-1433-45b7-a4d8-564773af5b87
2024-01-09 06:32:38,297 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1864583f-5c2c-4309-9622-29a3e36fe377
2024-01-09 06:32:38,297 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-32743869-58aa-4dfb-8af5-d4c5154fbd82
2024-01-09 06:32:38,297 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,297 - distributed.worker - INFO - Starting Worker plugin PreImport-6885ded6-a409-42af-a710-842fd613bc79
2024-01-09 06:32:38,297 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9c6ff529-adb4-4a4e-b244-0d8ee1cc9d61
2024-01-09 06:32:38,298 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,731 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38231', status: init, memory: 0, processing: 0>
2024-01-09 06:32:38,732 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38231
2024-01-09 06:32:38,732 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58680
2024-01-09 06:32:38,733 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:38,734 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:32:38,734 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,735 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:32:38,735 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41311', status: init, memory: 0, processing: 0>
2024-01-09 06:32:38,736 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41311
2024-01-09 06:32:38,736 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58722
2024-01-09 06:32:38,737 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38963', status: init, memory: 0, processing: 0>
2024-01-09 06:32:38,737 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:38,737 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38963
2024-01-09 06:32:38,737 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58712
2024-01-09 06:32:38,737 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:32:38,737 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,738 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35221', status: init, memory: 0, processing: 0>
2024-01-09 06:32:38,738 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:38,738 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35221
2024-01-09 06:32:38,739 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58696
2024-01-09 06:32:38,739 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:32:38,739 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:32:38,739 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,739 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:38,740 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:32:38,740 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:32:38,740 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:38,742 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:32:38,766 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-09 06:32:38,766 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-09 06:32:38,766 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-09 06:32:38,766 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-09 06:32:38,771 - distributed.scheduler - INFO - Remove client Client-df7bf69a-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:38,772 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58656; closing.
2024-01-09 06:32:38,772 - distributed.scheduler - INFO - Remove client Client-df7bf69a-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:38,772 - distributed.scheduler - INFO - Close client connection: Client-df7bf69a-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:38,773 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37269'. Reason: nanny-close
2024-01-09 06:32:38,774 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34539'. Reason: nanny-close
2024-01-09 06:32:38,774 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:38,774 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38165'. Reason: nanny-close
2024-01-09 06:32:38,775 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:38,775 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38075'. Reason: nanny-close
2024-01-09 06:32:38,775 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38231. Reason: nanny-close
2024-01-09 06:32:38,775 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:38,776 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38963. Reason: nanny-close
2024-01-09 06:32:38,776 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41311. Reason: nanny-close
2024-01-09 06:32:38,777 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:32:38,777 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58680; closing.
2024-01-09 06:32:38,777 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:32:38,777 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38231', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781958.7777004')
2024-01-09 06:32:38,778 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:32:38,778 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58712; closing.
2024-01-09 06:32:38,778 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:38,778 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:38,779 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38963', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781958.7790964')
2024-01-09 06:32:38,779 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:38,779 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58722; closing.
2024-01-09 06:32:38,780 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41311', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781958.7799447')
2024-01-09 06:32:38,792 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:38,793 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35221. Reason: nanny-close
2024-01-09 06:32:38,794 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:32:38,794 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58696; closing.
2024-01-09 06:32:38,795 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35221', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781958.7950969')
2024-01-09 06:32:38,795 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:32:38,796 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:39,589 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:32:39,589 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:32:39,590 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:32:39,591 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-09 06:32:39,591 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-09 06:32:41,914 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:32:41,920 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:32:41,924 - distributed.scheduler - INFO - State start
2024-01-09 06:32:42,324 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:32:42,325 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:32:42,326 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:32:42,327 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:32:42,603 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40875'
2024-01-09 06:32:42,623 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44353'
2024-01-09 06:32:42,640 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46819'
2024-01-09 06:32:42,642 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34219'
2024-01-09 06:32:42,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37995'
2024-01-09 06:32:42,660 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40733'
2024-01-09 06:32:42,669 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46225'
2024-01-09 06:32:42,678 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44855'
2024-01-09 06:32:43,203 - distributed.scheduler - INFO - Receive client connection: Client-e2ff7854-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:43,218 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51326
2024-01-09 06:32:44,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:44,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:44,523 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:44,524 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45887
2024-01-09 06:32:44,524 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45887
2024-01-09 06:32:44,524 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38045
2024-01-09 06:32:44,524 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:44,524 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:44,525 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:44,525 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:44,525 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yzx5xh98
2024-01-09 06:32:44,525 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5ca11af4-9936-4bcb-b19e-0cf7c9023f08
2024-01-09 06:32:44,525 - distributed.worker - INFO - Starting Worker plugin PreImport-a4f70d99-0eda-45f5-9af1-42d2fc5ec7cb
2024-01-09 06:32:44,525 - distributed.worker - INFO - Starting Worker plugin RMMSetup-249a429f-3e15-426f-b513-a61ff8c6152f
2024-01-09 06:32:44,571 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:44,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:44,575 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:44,576 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38839
2024-01-09 06:32:44,576 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38839
2024-01-09 06:32:44,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:44,576 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41775
2024-01-09 06:32:44,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:44,576 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:44,576 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:44,576 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:44,577 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:44,577 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pho6mk88
2024-01-09 06:32:44,577 - distributed.worker - INFO - Starting Worker plugin RMMSetup-74f50800-9372-4207-9a27-98b8ea9973c6
2024-01-09 06:32:44,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:44,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:44,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:44,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:44,581 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:44,581 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34053
2024-01-09 06:32:44,582 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34053
2024-01-09 06:32:44,582 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38975
2024-01-09 06:32:44,582 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:44,582 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:44,582 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:44,582 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:44,582 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wygzki7j
2024-01-09 06:32:44,582 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e03f3b33-98c6-4b68-9077-7ac966e10c13
2024-01-09 06:32:44,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:44,582 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:44,584 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:44,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:44,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:44,584 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38215
2024-01-09 06:32:44,584 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38215
2024-01-09 06:32:44,585 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44081
2024-01-09 06:32:44,585 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:44,585 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:44,585 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:44,585 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:44,585 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:44,585 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sshe4jb0
2024-01-09 06:32:44,585 - distributed.worker - INFO - Starting Worker plugin PreImport-e216ae0d-0889-413d-a4d4-68cc421a56ff
2024-01-09 06:32:44,585 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eaf360d0-ffd0-4a55-87b9-63d13e608eac
2024-01-09 06:32:44,586 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35843
2024-01-09 06:32:44,586 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35843
2024-01-09 06:32:44,586 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33777
2024-01-09 06:32:44,586 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:44,586 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:44,586 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:44,586 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:44,586 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-58tex12m
2024-01-09 06:32:44,586 - distributed.worker - INFO - Starting Worker plugin RMMSetup-536fa5a9-a470-45ca-aeaf-f01f952e9d50
2024-01-09 06:32:44,586 - distributed.worker - INFO - Starting Worker plugin RMMSetup-89b635b1-f79e-4e2f-b084-646b72380a1f
2024-01-09 06:32:44,587 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:44,588 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35445
2024-01-09 06:32:44,588 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35445
2024-01-09 06:32:44,588 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43733
2024-01-09 06:32:44,588 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:44,588 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:44,588 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:44,588 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:44,588 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:44,588 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hp_ijwnl
2024-01-09 06:32:44,589 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ce014951-91d1-4c99-9e62-3919d1da8193
2024-01-09 06:32:44,589 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42589
2024-01-09 06:32:44,589 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42589
2024-01-09 06:32:44,589 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35485
2024-01-09 06:32:44,589 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:44,589 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:44,589 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:44,589 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:44,589 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ud8f7d6e
2024-01-09 06:32:44,590 - distributed.worker - INFO - Starting Worker plugin PreImport-c90c6f3a-ab9b-4e35-87d1-58dca97829d6
2024-01-09 06:32:44,590 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6f9faed1-26ea-49f5-8dde-dda355073f6a
2024-01-09 06:32:44,590 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4ddb114a-e0ab-44e5-bf41-32d3b19fa3b2
2024-01-09 06:32:44,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:44,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:44,595 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:44,596 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35747
2024-01-09 06:32:44,596 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35747
2024-01-09 06:32:44,596 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44225
2024-01-09 06:32:44,596 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:44,596 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:44,596 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:44,596 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:44,596 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zkbslxbj
2024-01-09 06:32:44,597 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab5cef5c-4eb2-4cbd-80b7-38ef93e70e4f
2024-01-09 06:32:46,968 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,001 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45887', status: init, memory: 0, processing: 0>
2024-01-09 06:32:47,003 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45887
2024-01-09 06:32:47,003 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51340
2024-01-09 06:32:47,004 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:47,005 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:47,005 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,007 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:47,054 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d9f13ddb-df6d-4e69-accd-fa2bdb1c7e3b
2024-01-09 06:32:47,055 - distributed.worker - INFO - Starting Worker plugin PreImport-cb19a527-3968-4b91-bd64-f53f301133d8
2024-01-09 06:32:47,055 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,084 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38839', status: init, memory: 0, processing: 0>
2024-01-09 06:32:47,085 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38839
2024-01-09 06:32:47,085 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51350
2024-01-09 06:32:47,086 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:47,087 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:47,087 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,088 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:47,292 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a53cf564-2f09-4143-9a8e-e873277b699e
2024-01-09 06:32:47,293 - distributed.worker - INFO - Starting Worker plugin PreImport-ec4c7f48-b8ed-44d3-989e-1f4a98460b3e
2024-01-09 06:32:47,294 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,326 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35445', status: init, memory: 0, processing: 0>
2024-01-09 06:32:47,327 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35445
2024-01-09 06:32:47,328 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51366
2024-01-09 06:32:47,329 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:47,330 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:47,331 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,333 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:47,338 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f10cdf96-d020-429c-bf3f-58f87c8a0eb4
2024-01-09 06:32:47,338 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,339 - distributed.worker - INFO - Starting Worker plugin PreImport-064a98e6-013f-4d46-b528-7cc9376e2222
2024-01-09 06:32:47,340 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,345 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c2dc4bc2-9ae7-4ca9-9586-a79b42ff0845
2024-01-09 06:32:47,346 - distributed.worker - INFO - Starting Worker plugin PreImport-4cff07b1-5044-49c4-98f1-d1c8f1f97bea
2024-01-09 06:32:47,348 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,357 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-36edabe4-64dc-4ec6-8872-85225492994a
2024-01-09 06:32:47,359 - distributed.worker - INFO - Starting Worker plugin PreImport-1aa0e2a7-f5bf-4eef-bd0a-6448f4d3b606
2024-01-09 06:32:47,360 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,367 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,370 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42589', status: init, memory: 0, processing: 0>
2024-01-09 06:32:47,371 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42589
2024-01-09 06:32:47,371 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51370
2024-01-09 06:32:47,373 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:47,374 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:47,374 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,375 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:47,377 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34053', status: init, memory: 0, processing: 0>
2024-01-09 06:32:47,378 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34053
2024-01-09 06:32:47,378 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51386
2024-01-09 06:32:47,380 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:47,380 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35747', status: init, memory: 0, processing: 0>
2024-01-09 06:32:47,381 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35747
2024-01-09 06:32:47,381 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51392
2024-01-09 06:32:47,381 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:47,381 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,382 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:47,383 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:47,383 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,383 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:47,385 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:47,393 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35843', status: init, memory: 0, processing: 0>
2024-01-09 06:32:47,394 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35843
2024-01-09 06:32:47,394 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51408
2024-01-09 06:32:47,395 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:47,396 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:47,396 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,398 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:47,400 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38215', status: init, memory: 0, processing: 0>
2024-01-09 06:32:47,401 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38215
2024-01-09 06:32:47,401 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51412
2024-01-09 06:32:47,402 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:47,404 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:47,404 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:47,407 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:47,460 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:47,460 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:47,460 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:47,460 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:47,460 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:47,460 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:47,460 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:47,461 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:47,467 - distributed.scheduler - INFO - Remove client Client-e2ff7854-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:47,467 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51326; closing.
2024-01-09 06:32:47,468 - distributed.scheduler - INFO - Remove client Client-e2ff7854-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:47,468 - distributed.scheduler - INFO - Close client connection: Client-e2ff7854-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:47,469 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40875'. Reason: nanny-close
2024-01-09 06:32:47,470 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:47,470 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44353'. Reason: nanny-close
2024-01-09 06:32:47,471 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:47,471 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46819'. Reason: nanny-close
2024-01-09 06:32:47,471 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45887. Reason: nanny-close
2024-01-09 06:32:47,471 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:47,471 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34219'. Reason: nanny-close
2024-01-09 06:32:47,471 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:47,471 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38215. Reason: nanny-close
2024-01-09 06:32:47,472 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37995'. Reason: nanny-close
2024-01-09 06:32:47,472 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42589. Reason: nanny-close
2024-01-09 06:32:47,472 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:47,472 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40733'. Reason: nanny-close
2024-01-09 06:32:47,472 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38839. Reason: nanny-close
2024-01-09 06:32:47,473 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:47,473 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46225'. Reason: nanny-close
2024-01-09 06:32:47,473 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34053. Reason: nanny-close
2024-01-09 06:32:47,473 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:47,473 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:47,474 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44855'. Reason: nanny-close
2024-01-09 06:32:47,474 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51340; closing.
2024-01-09 06:32:47,474 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35445. Reason: nanny-close
2024-01-09 06:32:47,474 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:47,474 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:47,474 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45887', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781967.4746306')
2024-01-09 06:32:47,475 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35843. Reason: nanny-close
2024-01-09 06:32:47,475 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:47,475 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35747. Reason: nanny-close
2024-01-09 06:32:47,475 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:47,475 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:47,476 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:47,476 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:47,476 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51412; closing.
2024-01-09 06:32:47,476 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:47,476 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:47,477 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:47,477 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51350; closing.
2024-01-09 06:32:47,477 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:47,478 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:47,478 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38215', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781967.4780626')
2024-01-09 06:32:47,478 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:47,478 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:47,478 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:47,478 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51370; closing.
2024-01-09 06:32:47,479 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:47,480 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38839', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781967.480028')
2024-01-09 06:32:47,480 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51386; closing.
2024-01-09 06:32:47,480 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42589', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781967.4808679')
2024-01-09 06:32:47,481 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51366; closing.
2024-01-09 06:32:47,482 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34053', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781967.482166')
2024-01-09 06:32:47,482 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35445', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781967.4827328')
2024-01-09 06:32:47,483 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51408; closing.
2024-01-09 06:32:47,483 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51392; closing.
2024-01-09 06:32:47,484 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35843', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781967.484075')
2024-01-09 06:32:47,484 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35747', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781967.4846263')
2024-01-09 06:32:47,484 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:32:48,485 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:32:48,486 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:32:48,486 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:32:48,487 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:32:48,488 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-09 06:32:50,933 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:32:50,938 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:32:50,942 - distributed.scheduler - INFO - State start
2024-01-09 06:32:50,965 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:32:50,966 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:32:50,967 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:32:50,967 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:32:51,233 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46601'
2024-01-09 06:32:51,251 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34313'
2024-01-09 06:32:51,271 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46325'
2024-01-09 06:32:51,273 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34145'
2024-01-09 06:32:51,282 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36441'
2024-01-09 06:32:51,292 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44987'
2024-01-09 06:32:51,301 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34201'
2024-01-09 06:32:51,311 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36371'
2024-01-09 06:32:52,324 - distributed.scheduler - INFO - Receive client connection: Client-e852bd4d-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:52,342 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37708
2024-01-09 06:32:53,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:53,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:53,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:53,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:53,180 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:53,180 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:53,181 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34927
2024-01-09 06:32:53,181 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34927
2024-01-09 06:32:53,181 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40255
2024-01-09 06:32:53,181 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43155
2024-01-09 06:32:53,181 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:53,181 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:53,181 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43155
2024-01-09 06:32:53,181 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:53,181 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41899
2024-01-09 06:32:53,181 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:53,181 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:53,181 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w_b1lhv4
2024-01-09 06:32:53,181 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:53,181 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:53,181 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:53,181 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jycipbeg
2024-01-09 06:32:53,181 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6c3a486b-a0b7-4bfc-b727-c1c6d32671dc
2024-01-09 06:32:53,181 - distributed.worker - INFO - Starting Worker plugin RMMSetup-557520f4-5e0e-4b06-a511-df7d0b43ec9f
2024-01-09 06:32:53,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:53,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:53,214 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:53,215 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36903
2024-01-09 06:32:53,215 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36903
2024-01-09 06:32:53,215 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35397
2024-01-09 06:32:53,215 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:53,215 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:53,215 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:53,216 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:53,216 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d5p7puon
2024-01-09 06:32:53,216 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1b6e0a05-7ebc-4f00-b2d8-63fde0044198
2024-01-09 06:32:53,242 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:53,242 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:53,246 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:53,247 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36057
2024-01-09 06:32:53,247 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36057
2024-01-09 06:32:53,247 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44185
2024-01-09 06:32:53,247 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:53,247 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:53,247 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:53,248 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:53,248 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ac3z8mom
2024-01-09 06:32:53,248 - distributed.worker - INFO - Starting Worker plugin PreImport-814c5a4b-dfc7-4283-9ccd-0dcc99b198b9
2024-01-09 06:32:53,248 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cd16fcbb-0d4a-4d1d-ad94-b4f2c80b0304
2024-01-09 06:32:53,248 - distributed.worker - INFO - Starting Worker plugin RMMSetup-64c59e22-e145-41e4-9f5c-dd35da2922e9
2024-01-09 06:32:53,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:53,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:53,267 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:53,268 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38145
2024-01-09 06:32:53,268 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38145
2024-01-09 06:32:53,268 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38457
2024-01-09 06:32:53,268 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:53,268 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:53,268 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:53,268 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:53,268 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7s4aqvt2
2024-01-09 06:32:53,269 - distributed.worker - INFO - Starting Worker plugin RMMSetup-273e2f84-f464-426a-93dc-0456201dfbfd
2024-01-09 06:32:53,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:53,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:53,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:53,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:53,274 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:53,274 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45879
2024-01-09 06:32:53,275 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45879
2024-01-09 06:32:53,275 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44603
2024-01-09 06:32:53,275 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:53,275 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:53,275 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:53,275 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:53,275 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ka8yfpw3
2024-01-09 06:32:53,275 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1ba459ad-131a-4469-9335-361ebcbc4229
2024-01-09 06:32:53,277 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:53,278 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38139
2024-01-09 06:32:53,278 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38139
2024-01-09 06:32:53,278 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41125
2024-01-09 06:32:53,278 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:53,278 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:53,278 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:53,278 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:53,278 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qh6cap8y
2024-01-09 06:32:53,278 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5ad38df9-12ae-4171-ad2f-b7236f05a4c5
2024-01-09 06:32:53,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:32:53,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:32:53,649 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:32:53,650 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33659
2024-01-09 06:32:53,650 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33659
2024-01-09 06:32:53,650 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46501
2024-01-09 06:32:53,650 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:32:53,650 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:53,650 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:32:53,650 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:32:53,650 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o0znt0e0
2024-01-09 06:32:53,650 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eb6c868e-1ca4-4166-b067-eaafd099cd7f
2024-01-09 06:32:54,410 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d5df0e6e-2da5-43ce-95bf-1e35f4b2d614
2024-01-09 06:32:54,411 - distributed.worker - INFO - Starting Worker plugin PreImport-70110773-4cf8-4c3c-969e-e95f245521b1
2024-01-09 06:32:54,412 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:54,451 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43155', status: init, memory: 0, processing: 0>
2024-01-09 06:32:54,452 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43155
2024-01-09 06:32:54,452 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37728
2024-01-09 06:32:54,454 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:54,455 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:54,455 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:54,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:55,539 - distributed.worker - INFO - Starting Worker plugin PreImport-d7bfcb1b-3d1a-4e6f-9146-6e90bae924b8
2024-01-09 06:32:55,540 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0d41edd6-bce5-423b-a1f1-8653e80e2e7a
2024-01-09 06:32:55,541 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,587 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34927', status: init, memory: 0, processing: 0>
2024-01-09 06:32:55,587 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34927
2024-01-09 06:32:55,587 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37760
2024-01-09 06:32:55,590 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:55,591 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:55,591 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,594 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:55,654 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-de5131e1-0e67-41f1-ab22-3c1cbff27319
2024-01-09 06:32:55,655 - distributed.worker - INFO - Starting Worker plugin PreImport-3407ec8f-0624-4e42-b6f7-7bef2df25ec7
2024-01-09 06:32:55,656 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,688 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36903', status: init, memory: 0, processing: 0>
2024-01-09 06:32:55,689 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36903
2024-01-09 06:32:55,689 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37770
2024-01-09 06:32:55,690 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:55,691 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:55,691 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,692 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:55,697 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,708 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-632ab4c8-1eea-47e2-8032-609e51e95a6a
2024-01-09 06:32:55,709 - distributed.worker - INFO - Starting Worker plugin PreImport-7bde7b7a-629e-46d3-81e1-91e9a89fe787
2024-01-09 06:32:55,709 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,733 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36057', status: init, memory: 0, processing: 0>
2024-01-09 06:32:55,734 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36057
2024-01-09 06:32:55,734 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37774
2024-01-09 06:32:55,736 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38145', status: init, memory: 0, processing: 0>
2024-01-09 06:32:55,736 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:55,736 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38145
2024-01-09 06:32:55,736 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37790
2024-01-09 06:32:55,737 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:55,737 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,737 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:55,738 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:55,738 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,739 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:55,739 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:55,743 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a3b1c406-6d57-4341-98d9-7bf291b102b1
2024-01-09 06:32:55,743 - distributed.worker - INFO - Starting Worker plugin PreImport-faa71811-9398-40a3-86fe-7318bdb8d030
2024-01-09 06:32:55,744 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,760 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd945d5e-68be-402f-8b07-384d98b67705
2024-01-09 06:32:55,761 - distributed.worker - INFO - Starting Worker plugin PreImport-34565ddb-ceac-4d99-b59b-e16e2764de95
2024-01-09 06:32:55,762 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,769 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38139', status: init, memory: 0, processing: 0>
2024-01-09 06:32:55,770 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38139
2024-01-09 06:32:55,770 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37796
2024-01-09 06:32:55,771 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:55,771 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:55,772 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,773 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:55,787 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45879', status: init, memory: 0, processing: 0>
2024-01-09 06:32:55,788 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45879
2024-01-09 06:32:55,788 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37798
2024-01-09 06:32:55,789 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:55,789 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-35682141-caff-4b58-a4c9-1fd5a6ca1663
2024-01-09 06:32:55,789 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:55,790 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,791 - distributed.worker - INFO - Starting Worker plugin PreImport-f3c38d6f-0257-4eb4-a169-68ac04b08654
2024-01-09 06:32:55,791 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:55,792 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,836 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33659', status: init, memory: 0, processing: 0>
2024-01-09 06:32:55,837 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33659
2024-01-09 06:32:55,837 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37802
2024-01-09 06:32:55,839 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:32:55,841 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:32:55,841 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:32:55,844 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:32:55,926 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:55,926 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:55,926 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:55,926 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:55,926 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:55,926 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:55,927 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:55,927 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:32:55,931 - distributed.scheduler - INFO - Remove client Client-e852bd4d-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:55,932 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37708; closing.
2024-01-09 06:32:55,932 - distributed.scheduler - INFO - Remove client Client-e852bd4d-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:55,932 - distributed.scheduler - INFO - Close client connection: Client-e852bd4d-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:32:55,933 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46601'. Reason: nanny-close
2024-01-09 06:32:55,934 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:55,934 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34313'. Reason: nanny-close
2024-01-09 06:32:55,934 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:55,934 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46325'. Reason: nanny-close
2024-01-09 06:32:55,935 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34927. Reason: nanny-close
2024-01-09 06:32:55,935 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:55,935 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34145'. Reason: nanny-close
2024-01-09 06:32:55,935 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33659. Reason: nanny-close
2024-01-09 06:32:55,935 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:55,935 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36441'. Reason: nanny-close
2024-01-09 06:32:55,935 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36903. Reason: nanny-close
2024-01-09 06:32:55,936 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:55,936 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44987'. Reason: nanny-close
2024-01-09 06:32:55,936 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38145. Reason: nanny-close
2024-01-09 06:32:55,936 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:55,936 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34201'. Reason: nanny-close
2024-01-09 06:32:55,937 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43155. Reason: nanny-close
2024-01-09 06:32:55,937 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:55,937 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36371'. Reason: nanny-close
2024-01-09 06:32:55,937 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:55,937 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36057. Reason: nanny-close
2024-01-09 06:32:55,937 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:32:55,937 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37760; closing.
2024-01-09 06:32:55,937 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38139. Reason: nanny-close
2024-01-09 06:32:55,937 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:55,937 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34927', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781975.9378254')
2024-01-09 06:32:55,938 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:55,938 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45879. Reason: nanny-close
2024-01-09 06:32:55,938 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:55,938 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37770; closing.
2024-01-09 06:32:55,939 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:55,939 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:55,939 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:55,939 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:55,939 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:55,939 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36903', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781975.9396157')
2024-01-09 06:32:55,940 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37790; closing.
2024-01-09 06:32:55,940 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:55,940 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37802; closing.
2024-01-09 06:32:55,940 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:55,940 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:55,941 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37728; closing.
2024-01-09 06:32:55,941 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38145', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781975.9412506')
2024-01-09 06:32:55,941 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:32:55,941 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:55,941 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:55,941 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33659', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781975.9415927')
2024-01-09 06:32:55,942 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43155', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781975.9423797')
2024-01-09 06:32:55,942 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37796; closing.
2024-01-09 06:32:55,943 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37798; closing.
2024-01-09 06:32:55,943 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37774; closing.
2024-01-09 06:32:55,943 - distributed.nanny - INFO - Worker closed
2024-01-09 06:32:55,943 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38139', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781975.9435241')
2024-01-09 06:32:55,943 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45879', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781975.9439144')
2024-01-09 06:32:55,944 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36057', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781975.9441817')
2024-01-09 06:32:55,944 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:32:58,152 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:32:58,152 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:32:58,153 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:32:58,154 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:32:58,154 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-09 06:33:00,582 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:00,587 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44513 instead
  warnings.warn(
2024-01-09 06:33:00,593 - distributed.scheduler - INFO - State start
2024-01-09 06:33:00,619 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:00,620 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:33:00,621 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44513/status
2024-01-09 06:33:00,622 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:33:00,932 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39351'
2024-01-09 06:33:00,949 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43345'
2024-01-09 06:33:00,958 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44745'
2024-01-09 06:33:00,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39365'
2024-01-09 06:33:00,975 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32927'
2024-01-09 06:33:00,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46457'
2024-01-09 06:33:00,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45655'
2024-01-09 06:33:01,002 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42223'
2024-01-09 06:33:01,972 - distributed.scheduler - INFO - Receive client connection: Client-ee0e0b37-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:33:01,989 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33276
2024-01-09 06:33:02,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:02,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:02,858 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:02,859 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41285
2024-01-09 06:33:02,859 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41285
2024-01-09 06:33:02,859 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36933
2024-01-09 06:33:02,859 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:02,859 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:02,859 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:02,859 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:02,859 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ge6xl6_1
2024-01-09 06:33:02,859 - distributed.worker - INFO - Starting Worker plugin RMMSetup-becd8360-e61c-45bd-8aea-0d9e6c2e67ac
2024-01-09 06:33:02,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:02,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:02,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:02,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:02,897 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:02,897 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:02,898 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38813
2024-01-09 06:33:02,898 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38117
2024-01-09 06:33:02,898 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38117
2024-01-09 06:33:02,898 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38813
2024-01-09 06:33:02,898 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45209
2024-01-09 06:33:02,898 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37647
2024-01-09 06:33:02,898 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:02,898 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:02,898 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:02,898 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:02,898 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:02,898 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:02,898 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:02,898 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:02,898 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p6ax1q_4
2024-01-09 06:33:02,898 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ivkt4jvi
2024-01-09 06:33:02,899 - distributed.worker - INFO - Starting Worker plugin PreImport-40dce3cc-f3f1-4c02-bdfa-c08a20f0753b
2024-01-09 06:33:02,899 - distributed.worker - INFO - Starting Worker plugin RMMSetup-94709ea1-45c0-4364-b81f-b631c2343c0e
2024-01-09 06:33:02,899 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-61214a16-e19a-4dd6-8aac-70ccb50c98df
2024-01-09 06:33:02,899 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b13f6680-7f25-4904-873d-dbea1435100b
2024-01-09 06:33:02,906 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:02,906 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:02,910 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:02,911 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42025
2024-01-09 06:33:02,911 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42025
2024-01-09 06:33:02,911 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39889
2024-01-09 06:33:02,911 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:02,911 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:02,911 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:02,911 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:02,911 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z34p55rs
2024-01-09 06:33:02,912 - distributed.worker - INFO - Starting Worker plugin RMMSetup-40681d27-7862-42ea-9f41-aead121ed96d
2024-01-09 06:33:02,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:02,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:02,918 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:02,918 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42599
2024-01-09 06:33:02,918 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42599
2024-01-09 06:33:02,918 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46081
2024-01-09 06:33:02,919 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:02,919 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:02,919 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:02,919 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:02,919 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wwy57ona
2024-01-09 06:33:02,919 - distributed.worker - INFO - Starting Worker plugin RMMSetup-abd41121-67df-4c76-af0e-1055a41a626b
2024-01-09 06:33:03,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:03,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:03,133 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:03,134 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42959
2024-01-09 06:33:03,134 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42959
2024-01-09 06:33:03,134 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34089
2024-01-09 06:33:03,134 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:03,134 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:03,134 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:03,134 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:03,134 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rfr7lap9
2024-01-09 06:33:03,134 - distributed.worker - INFO - Starting Worker plugin PreImport-ee5ed022-4f2e-4737-8cc7-c89bed0cee1f
2024-01-09 06:33:03,134 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f1de5b06-558f-4809-91d8-58c01b2e99fb
2024-01-09 06:33:03,135 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e83f98a3-8aeb-441f-8eea-206019f1f9ae
2024-01-09 06:33:03,141 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:03,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:03,146 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:03,147 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40073
2024-01-09 06:33:03,147 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40073
2024-01-09 06:33:03,147 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38441
2024-01-09 06:33:03,147 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:03,147 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:03,147 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:03,147 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:03,148 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rq_444ya
2024-01-09 06:33:03,148 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b3ac0b36-2b81-4741-a438-0b949fca41dc
2024-01-09 06:33:03,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:03,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:03,165 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:03,166 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42999
2024-01-09 06:33:03,166 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42999
2024-01-09 06:33:03,166 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36131
2024-01-09 06:33:03,166 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:03,166 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:03,166 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:03,166 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:03,166 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4lxc2z82
2024-01-09 06:33:03,167 - distributed.worker - INFO - Starting Worker plugin RMMSetup-92a1bf78-45fa-4bb5-8155-3c049d2ee73e
2024-01-09 06:33:04,592 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f89ae7cd-a8a0-4b3b-9aef-8d61fc689d04
2024-01-09 06:33:04,592 - distributed.worker - INFO - Starting Worker plugin PreImport-e2e9c5ad-315b-4b98-babf-6428f6f413f2
2024-01-09 06:33:04,593 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:04,785 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41285', status: init, memory: 0, processing: 0>
2024-01-09 06:33:04,786 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41285
2024-01-09 06:33:04,786 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33290
2024-01-09 06:33:04,788 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:04,790 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:04,790 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:04,792 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:07,385 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0516ac90-c605-472a-a788-effab9fd0427
2024-01-09 06:33:07,386 - distributed.worker - INFO - Starting Worker plugin PreImport-163f2bb9-9591-486b-a71f-534e3c1e1e45
2024-01-09 06:33:07,386 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,399 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-73b69f11-c5b6-4b61-9596-27db3845c24e
2024-01-09 06:33:07,399 - distributed.worker - INFO - Starting Worker plugin PreImport-04ba5da8-de08-40d8-a465-3d0a0026d4ae
2024-01-09 06:33:07,400 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,411 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42599', status: init, memory: 0, processing: 0>
2024-01-09 06:33:07,411 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42599
2024-01-09 06:33:07,411 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33312
2024-01-09 06:33:07,412 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:07,413 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:07,413 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,415 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:07,418 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e9171d75-d430-4e23-b05a-33264215af62
2024-01-09 06:33:07,419 - distributed.worker - INFO - Starting Worker plugin PreImport-398d3791-8d84-455f-874c-40962e72c984
2024-01-09 06:33:07,420 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,424 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38813', status: init, memory: 0, processing: 0>
2024-01-09 06:33:07,424 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38813
2024-01-09 06:33:07,424 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33324
2024-01-09 06:33:07,425 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:07,426 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:07,426 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,427 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:07,454 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-84c66247-879c-4572-8102-b5489983238c
2024-01-09 06:33:07,455 - distributed.worker - INFO - Starting Worker plugin PreImport-9ce9c993-ecd5-40e6-9768-d9a8fb606981
2024-01-09 06:33:07,455 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42025', status: init, memory: 0, processing: 0>
2024-01-09 06:33:07,456 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42025
2024-01-09 06:33:07,456 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33340
2024-01-09 06:33:07,456 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,457 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:07,458 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:07,458 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,461 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:07,467 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,489 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40073', status: init, memory: 0, processing: 0>
2024-01-09 06:33:07,490 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40073
2024-01-09 06:33:07,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33342
2024-01-09 06:33:07,492 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:07,493 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:07,493 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,495 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:07,502 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38117', status: init, memory: 0, processing: 0>
2024-01-09 06:33:07,503 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38117
2024-01-09 06:33:07,503 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33356
2024-01-09 06:33:07,504 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:07,505 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:07,505 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,508 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:07,540 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8b10f019-fb94-404a-8233-75218cdbeb13
2024-01-09 06:33:07,541 - distributed.worker - INFO - Starting Worker plugin PreImport-97ba4c78-444c-44c7-86c6-06981cec3aca
2024-01-09 06:33:07,541 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,563 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,567 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42999', status: init, memory: 0, processing: 0>
2024-01-09 06:33:07,568 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42999
2024-01-09 06:33:07,568 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33370
2024-01-09 06:33:07,569 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:07,570 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:07,570 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,571 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:07,589 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42959', status: init, memory: 0, processing: 0>
2024-01-09 06:33:07,589 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42959
2024-01-09 06:33:07,589 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33378
2024-01-09 06:33:07,590 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:07,591 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:07,591 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:07,593 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:07,611 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:33:07,611 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:33:07,612 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:33:07,612 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:33:07,612 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:33:07,612 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:33:07,612 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:33:07,612 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:33:07,624 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:33:07,624 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:33:07,624 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:33:07,625 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:33:07,625 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:33:07,625 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:33:07,625 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:33:07,625 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:33:07,802 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:33:07,804 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:33:07,806 - distributed.scheduler - INFO - Remove client Client-ee0e0b37-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:33:07,807 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33276; closing.
2024-01-09 06:33:07,807 - distributed.scheduler - INFO - Remove client Client-ee0e0b37-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:33:07,807 - distributed.scheduler - INFO - Close client connection: Client-ee0e0b37-aeb8-11ee-b596-d8c49764f6bb
2024-01-09 06:33:07,808 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39351'. Reason: nanny-close
2024-01-09 06:33:07,809 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:07,809 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43345'. Reason: nanny-close
2024-01-09 06:33:07,810 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:07,810 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44745'. Reason: nanny-close
2024-01-09 06:33:07,810 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:07,810 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39365'. Reason: nanny-close
2024-01-09 06:33:07,810 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41285. Reason: nanny-close
2024-01-09 06:33:07,811 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:07,811 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38117. Reason: nanny-close
2024-01-09 06:33:07,811 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32927'. Reason: nanny-close
2024-01-09 06:33:07,811 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42959. Reason: nanny-close
2024-01-09 06:33:07,811 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:07,811 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46457'. Reason: nanny-close
2024-01-09 06:33:07,812 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42599. Reason: nanny-close
2024-01-09 06:33:07,812 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:07,812 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45655'. Reason: nanny-close
2024-01-09 06:33:07,812 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:07,812 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42025. Reason: nanny-close
2024-01-09 06:33:07,812 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42223'. Reason: nanny-close
2024-01-09 06:33:07,812 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:07,813 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40073. Reason: nanny-close
2024-01-09 06:33:07,813 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38813. Reason: nanny-close
2024-01-09 06:33:07,813 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:07,813 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:07,813 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33290; closing.
2024-01-09 06:33:07,813 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42999. Reason: nanny-close
2024-01-09 06:33:07,813 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33356; closing.
2024-01-09 06:33:07,814 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41285', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781987.813991')
2024-01-09 06:33:07,814 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:07,814 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38117', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781987.8145401')
2024-01-09 06:33:07,814 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:07,815 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:07,815 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:07,815 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:07,815 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:07,815 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:07,815 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:07,816 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:07,816 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:07,816 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33340; closing.
2024-01-09 06:33:07,816 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33378; closing.
2024-01-09 06:33:07,816 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:07,817 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33312; closing.
2024-01-09 06:33:07,817 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:07,817 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:07,817 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:07,817 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42025', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781987.8176627')
2024-01-09 06:33:07,818 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42959', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781987.8180318')
2024-01-09 06:33:07,818 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33342; closing.
2024-01-09 06:33:07,818 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33324; closing.
2024-01-09 06:33:07,818 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42599', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781987.8187547')
2024-01-09 06:33:07,819 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33370; closing.
2024-01-09 06:33:07,819 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40073', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781987.8194327')
2024-01-09 06:33:07,819 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38813', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781987.819793')
2024-01-09 06:33:07,820 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42999', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781987.8201766')
2024-01-09 06:33:07,820 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:33:08,975 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:33:08,975 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:33:08,976 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:33:08,977 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:33:08,978 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-09 06:33:11,324 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:11,329 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41141 instead
  warnings.warn(
2024-01-09 06:33:11,332 - distributed.scheduler - INFO - State start
2024-01-09 06:33:11,356 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:11,356 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-09 06:33:11,357 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:33:11,358 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-09 06:33:11,590 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33193'
2024-01-09 06:33:11,615 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44977'
2024-01-09 06:33:11,629 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40795'
2024-01-09 06:33:11,647 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36227'
2024-01-09 06:33:11,650 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37271'
2024-01-09 06:33:11,661 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33613'
2024-01-09 06:33:11,676 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41937'
2024-01-09 06:33:11,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46249'
2024-01-09 06:33:13,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:13,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:13,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:13,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:13,949 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:13,950 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36987
2024-01-09 06:33:13,950 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36987
2024-01-09 06:33:13,950 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40281
2024-01-09 06:33:13,950 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:13,950 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:13,950 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:13,950 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:13,950 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-65t06jih
2024-01-09 06:33:13,950 - distributed.worker - INFO - Starting Worker plugin PreImport-2956713f-ea37-4534-b153-ba992a4a4ba3
2024-01-09 06:33:13,950 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-22cb99c9-7bdd-496b-af50-882e3b57ab4b
2024-01-09 06:33:13,951 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6533fdb9-e4cc-404a-b9ec-8d85a65491b7
2024-01-09 06:33:13,951 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:13,952 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41561
2024-01-09 06:33:13,952 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41561
2024-01-09 06:33:13,952 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44121
2024-01-09 06:33:13,952 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:13,952 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:13,952 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:13,952 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:13,953 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y8zpyf81
2024-01-09 06:33:13,953 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c0d8ef96-c46b-4240-8fdb-2925233776ce
2024-01-09 06:33:13,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:13,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:13,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:13,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:13,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:13,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:13,959 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:13,960 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:13,960 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39325
2024-01-09 06:33:13,961 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39325
2024-01-09 06:33:13,961 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44451
2024-01-09 06:33:13,961 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:13,961 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:13,961 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:13,961 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36299
2024-01-09 06:33:13,961 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:13,961 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36299
2024-01-09 06:33:13,961 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4bv8w43j
2024-01-09 06:33:13,961 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36223
2024-01-09 06:33:13,961 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:13,961 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:13,961 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:13,961 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a0ecac73-8d45-4905-9a69-239d0deabd62
2024-01-09 06:33:13,961 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:13,961 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-igy93bhg
2024-01-09 06:33:13,961 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f6de86e0-0bb1-4d61-90d7-4832c7c69d75
2024-01-09 06:33:13,964 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:13,965 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41497
2024-01-09 06:33:13,965 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41497
2024-01-09 06:33:13,965 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41915
2024-01-09 06:33:13,965 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:13,965 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:13,965 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:13,965 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:13,965 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-039p1b6t
2024-01-09 06:33:13,965 - distributed.worker - INFO - Starting Worker plugin RMMSetup-10bc7787-897b-4fca-8ee7-0e402bd6e8fe
2024-01-09 06:33:13,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:13,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:13,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:13,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:13,973 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:13,974 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44953
2024-01-09 06:33:13,975 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44953
2024-01-09 06:33:13,975 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43937
2024-01-09 06:33:13,975 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:13,975 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:13,975 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:13,975 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:13,975 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e16m7nzt
2024-01-09 06:33:13,975 - distributed.worker - INFO - Starting Worker plugin PreImport-a703047c-7691-47cc-b1f4-c3c5da0edb00
2024-01-09 06:33:13,975 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-17f2a47c-c54d-4216-bca7-411eb44de9d8
2024-01-09 06:33:13,975 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a11732e6-d7c3-43c8-a310-05b299ff47af
2024-01-09 06:33:13,977 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:13,978 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36851
2024-01-09 06:33:13,979 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36851
2024-01-09 06:33:13,979 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42937
2024-01-09 06:33:13,979 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:13,979 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:13,979 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:13,979 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:13,979 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vw056q2d
2024-01-09 06:33:13,979 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c8db431b-d386-4fe3-a2d6-90013954c126
2024-01-09 06:33:14,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:14,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:14,012 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:14,013 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36217
2024-01-09 06:33:14,013 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36217
2024-01-09 06:33:14,013 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36155
2024-01-09 06:33:14,013 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:14,013 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:14,013 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:14,013 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:14,013 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6zeklb7c
2024-01-09 06:33:14,013 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8d7aa6fc-3f3a-49ce-917f-aec22a535ebe
2024-01-09 06:33:19,083 - distributed.worker - INFO - Starting Worker plugin PreImport-be9072aa-d8a0-499a-be56-9798416bd8ab
2024-01-09 06:33:19,083 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6baa3fff-d5fd-409a-acc8-62f53ca6cda9
2024-01-09 06:33:19,085 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,104 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,121 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9042c9f7-b1f6-4a1e-bb0e-ae1bc6fa09a6
2024-01-09 06:33:19,122 - distributed.worker - INFO - Starting Worker plugin PreImport-ad318041-deb4-4147-9613-eae508b493d7
2024-01-09 06:33:19,122 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,135 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:19,136 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:19,136 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,138 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:19,143 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,147 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:19,148 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33193'. Reason: nanny-close
2024-01-09 06:33:19,148 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-769f3e76-b0ae-4f5c-baf0-298a7606ced1
2024-01-09 06:33:19,149 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:19,149 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,149 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44977'. Reason: nanny-close
2024-01-09 06:33:19,149 - distributed.worker - INFO - Starting Worker plugin PreImport-73f90cd1-b823-45c6-b124-354ff296bac8
2024-01-09 06:33:19,149 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40795'. Reason: nanny-close
2024-01-09 06:33:19,149 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36227'. Reason: nanny-close
2024-01-09 06:33:19,149 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37271'. Reason: nanny-close
2024-01-09 06:33:19,149 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,150 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33613'. Reason: nanny-close
2024-01-09 06:33:19,150 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41937'. Reason: nanny-close
2024-01-09 06:33:19,150 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46249'. Reason: nanny-close
2024-01-09 06:33:19,151 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:19,157 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:19,157 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:19,157 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,159 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:19,165 - distributed.worker - INFO - Starting Worker plugin PreImport-feed3f3e-3845-483b-b76e-04889b175bc6
2024-01-09 06:33:19,166 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-335ebb61-7f2e-4e20-88c2-64b52f612143
2024-01-09 06:33:19,168 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,170 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-521b2f1c-3277-46ba-aee4-32eaf757da7c
2024-01-09 06:33:19,170 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f3cf0595-52f4-4692-8f3d-6b3892187e9d
2024-01-09 06:33:19,171 - distributed.worker - INFO - Starting Worker plugin PreImport-ddb7caad-5c64-4c48-a68d-d0af5b0a3635
2024-01-09 06:33:19,171 - distributed.worker - INFO - Starting Worker plugin PreImport-611c7ff5-a477-417e-97f1-8045095b4f50
2024-01-09 06:33:19,171 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:19,171 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,172 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:19,172 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,173 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,174 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:19,179 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:19,180 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:19,180 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:19,180 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,180 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:19,181 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:19,181 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:19,181 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41561. Reason: nanny-close
2024-01-09 06:33:19,182 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44953. Reason: nanny-close
2024-01-09 06:33:19,182 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:19,182 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36987. Reason: nanny-close
2024-01-09 06:33:19,182 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36217. Reason: nanny-close
2024-01-09 06:33:19,183 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:19,183 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:19,184 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:19,184 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:19,184 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:19,185 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:19,186 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:19,186 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:19,198 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:19,199 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:19,199 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,201 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:19,209 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:19,210 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:19,210 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,213 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:19,223 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:19,225 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:19,225 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:19,228 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:19,232 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:19,232 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:19,232 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:19,233 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41497. Reason: nanny-close
2024-01-09 06:33:19,233 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36299. Reason: nanny-close
2024-01-09 06:33:19,234 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36851. Reason: nanny-close
2024-01-09 06:33:19,235 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:19,235 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:19,237 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:19,237 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:19,238 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:19,240 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:19,241 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39325. Reason: nanny-close
2024-01-09 06:33:19,241 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:19,244 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:19,246 - distributed.nanny - INFO - Worker closed
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-09 06:33:23,085 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:23,090 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34281 instead
  warnings.warn(
2024-01-09 06:33:23,094 - distributed.scheduler - INFO - State start
2024-01-09 06:33:23,138 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:23,139 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-09 06:33:23,140 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:33:23,141 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-09 06:33:23,714 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44867'
2024-01-09 06:33:23,734 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36443'
2024-01-09 06:33:23,737 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45717'
2024-01-09 06:33:23,747 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34683'
2024-01-09 06:33:23,761 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34629'
2024-01-09 06:33:23,772 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39639'
2024-01-09 06:33:23,784 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39837'
2024-01-09 06:33:23,792 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36717'
2024-01-09 06:33:25,662 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:25,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:25,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:25,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:25,667 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:25,668 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37465
2024-01-09 06:33:25,668 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37465
2024-01-09 06:33:25,668 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36293
2024-01-09 06:33:25,668 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:25,668 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:25,668 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:25,668 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:25,668 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-99c7v5nx
2024-01-09 06:33:25,669 - distributed.worker - INFO - Starting Worker plugin RMMSetup-00809804-d581-4c7c-a93e-323dbdb32a68
2024-01-09 06:33:25,669 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:25,670 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41489
2024-01-09 06:33:25,670 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41489
2024-01-09 06:33:25,670 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43033
2024-01-09 06:33:25,670 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:25,670 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:25,670 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:25,670 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:25,670 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e4zamaup
2024-01-09 06:33:25,671 - distributed.worker - INFO - Starting Worker plugin RMMSetup-347cddf6-4fbd-4584-ae9c-3497ca3eef53
2024-01-09 06:33:25,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:25,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:25,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:25,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:25,676 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:25,676 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:25,677 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36587
2024-01-09 06:33:25,677 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33763
2024-01-09 06:33:25,677 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36587
2024-01-09 06:33:25,677 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33763
2024-01-09 06:33:25,677 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39297
2024-01-09 06:33:25,677 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37307
2024-01-09 06:33:25,677 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:25,677 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:25,677 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:25,677 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:25,677 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:25,677 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:25,677 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:25,677 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qlaqnt4w
2024-01-09 06:33:25,677 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:25,677 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qpp7uz6l
2024-01-09 06:33:25,677 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dbe2cdca-bfa2-44c2-8389-0d2f3a5f00e5
2024-01-09 06:33:25,677 - distributed.worker - INFO - Starting Worker plugin PreImport-06299629-99ef-47ae-8314-8003fe04b4ee
2024-01-09 06:33:25,678 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b8bc2992-dfc1-4b81-894b-83a30448c6f6
2024-01-09 06:33:25,678 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a555a3c9-af7e-4c5a-aaa3-2d70a722e888
2024-01-09 06:33:25,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:25,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:25,751 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:25,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:25,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:25,752 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34065
2024-01-09 06:33:25,752 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34065
2024-01-09 06:33:25,752 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41275
2024-01-09 06:33:25,752 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:25,752 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:25,752 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:25,752 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:25,752 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ddrm2vh3
2024-01-09 06:33:25,753 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8ab7ae09-a4ac-4e35-81b4-8508505c1ad1
2024-01-09 06:33:25,756 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:25,756 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41757
2024-01-09 06:33:25,756 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41757
2024-01-09 06:33:25,757 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44321
2024-01-09 06:33:25,757 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:25,757 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:25,757 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:25,757 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:25,757 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dhf3ug7v
2024-01-09 06:33:25,757 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3dcad4c0-4457-456e-a90c-e14329bedd5b
2024-01-09 06:33:25,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:25,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:25,763 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:25,764 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33205
2024-01-09 06:33:25,764 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33205
2024-01-09 06:33:25,764 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40993
2024-01-09 06:33:25,764 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:25,764 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:25,764 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:25,764 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:25,764 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p70_dulw
2024-01-09 06:33:25,764 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0b7bd10-d5e2-46d3-a75c-470f4cc2d1b9
2024-01-09 06:33:25,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:25,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:25,847 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:25,848 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46291
2024-01-09 06:33:25,848 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46291
2024-01-09 06:33:25,849 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44481
2024-01-09 06:33:25,849 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:25,849 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:25,849 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:25,849 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:33:25,849 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ejbokhzu
2024-01-09 06:33:25,849 - distributed.worker - INFO - Starting Worker plugin PreImport-4d5d5797-b3b1-4bc9-8053-5dbf349852a6
2024-01-09 06:33:25,849 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d6c73978-19b6-4f71-b0ee-643da319a67f
2024-01-09 06:33:25,850 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8a65184b-5777-440a-97be-b5cafc8dbb84
2024-01-09 06:33:29,900 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:29,924 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:29,925 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:29,925 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:29,926 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:30,007 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4d066bff-4cf0-4171-8bf1-c9b14cf479c5
2024-01-09 06:33:30,010 - distributed.worker - INFO - Starting Worker plugin PreImport-2442b823-1738-43c3-934e-7ac34a1bd2e7
2024-01-09 06:33:30,011 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,019 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-23061c69-b009-40d1-b9d0-d1b44b8df84b
2024-01-09 06:33:30,019 - distributed.worker - INFO - Starting Worker plugin PreImport-f3881467-ad84-4e39-8131-e11dd953ccbd
2024-01-09 06:33:30,020 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,027 - distributed.worker - INFO - Starting Worker plugin PreImport-c25fc21a-b5d3-4e4b-a974-db472113adc7
2024-01-09 06:33:30,028 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ba38a9f4-6ac1-47cf-83a1-e0d6092cccae
2024-01-09 06:33:30,028 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,042 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,043 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:30,045 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:30,045 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,046 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:30,046 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:30,047 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:30,048 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,050 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:30,052 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:30,052 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:30,053 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,054 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:30,061 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-81223c92-af14-438c-8c54-5a8af43b1396
2024-01-09 06:33:30,062 - distributed.worker - INFO - Starting Worker plugin PreImport-7c61891e-3978-48c4-bf5b-61355d921b6d
2024-01-09 06:33:30,062 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d834535e-64a7-4ac1-9ca3-4e1b86ca4680
2024-01-09 06:33:30,062 - distributed.worker - INFO - Starting Worker plugin PreImport-52193d14-8316-45e6-8454-7d283a69507e
2024-01-09 06:33:30,062 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,063 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,069 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d9458f0c-42b4-495d-90be-12eccee7901a
2024-01-09 06:33:30,070 - distributed.worker - INFO - Starting Worker plugin PreImport-d778fcc3-c15a-496f-ae22-c5cdda8f4182
2024-01-09 06:33:30,070 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,078 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:30,079 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:30,079 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,081 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:30,086 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:30,088 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:30,088 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,090 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:30,102 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:30,103 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:30,103 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,106 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:30,106 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:30,107 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:30,107 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:30,109 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:39,475 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44867'. Reason: nanny-close
2024-01-09 06:33:39,477 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:39,477 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36443'. Reason: nanny-close
2024-01-09 06:33:39,478 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:39,478 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45717'. Reason: nanny-close
2024-01-09 06:33:39,478 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:39,478 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36587. Reason: nanny-close
2024-01-09 06:33:39,478 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34683'. Reason: nanny-close
2024-01-09 06:33:39,478 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:39,479 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34629'. Reason: nanny-close
2024-01-09 06:33:39,479 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41489. Reason: nanny-close
2024-01-09 06:33:39,479 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37465. Reason: nanny-close
2024-01-09 06:33:39,479 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:39,479 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39639'. Reason: nanny-close
2024-01-09 06:33:39,479 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33763. Reason: nanny-close
2024-01-09 06:33:39,479 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:39,480 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39837'. Reason: nanny-close
2024-01-09 06:33:39,480 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:39,480 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46291. Reason: nanny-close
2024-01-09 06:33:39,480 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36717'. Reason: nanny-close
2024-01-09 06:33:39,480 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:39,481 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:39,481 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33205. Reason: nanny-close
2024-01-09 06:33:39,481 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41757. Reason: nanny-close
2024-01-09 06:33:39,481 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34065. Reason: nanny-close
2024-01-09 06:33:39,482 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:39,482 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:39,482 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:39,482 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:39,483 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:39,483 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:39,483 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:39,483 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:39,484 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:39,484 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:39,484 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:39,484 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:39,485 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:39,485 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:39,488 - distributed.nanny - INFO - Worker closed
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-09 06:33:43,689 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:43,693 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:33:43,697 - distributed.scheduler - INFO - State start
2024-01-09 06:33:43,719 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:43,720 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:33:43,721 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:33:43,721 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:33:44,000 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37389'
2024-01-09 06:33:44,320 - distributed.scheduler - INFO - Receive client connection: Client-08622148-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:33:44,336 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55440
2024-01-09 06:33:44,587 - distributed.scheduler - INFO - Receive client connection: Client-07d03e03-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:33:44,587 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55462
2024-01-09 06:33:45,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:45,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:46,481 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:46,482 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33827
2024-01-09 06:33:46,482 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33827
2024-01-09 06:33:46,482 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-09 06:33:46,482 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:46,482 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:46,482 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:46,482 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:33:46,482 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g_31ebsh
2024-01-09 06:33:46,482 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dcac2184-e9e8-4957-a00e-a4ba73418275
2024-01-09 06:33:46,483 - distributed.worker - INFO - Starting Worker plugin PreImport-b919066d-9579-4bfd-8698-3ef519dcc0f4
2024-01-09 06:33:46,483 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cc960f38-f76f-4006-bc69-6572c1023472
2024-01-09 06:33:46,483 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:47,780 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33827', status: init, memory: 0, processing: 0>
2024-01-09 06:33:47,781 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33827
2024-01-09 06:33:47,781 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55542
2024-01-09 06:33:47,782 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:47,782 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:47,783 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:47,784 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:47,801 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:33:47,803 - distributed.scheduler - INFO - Remove client Client-07d03e03-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:33:47,804 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55462; closing.
2024-01-09 06:33:47,804 - distributed.scheduler - INFO - Remove client Client-07d03e03-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:33:47,804 - distributed.scheduler - INFO - Close client connection: Client-07d03e03-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:33:47,805 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37389'. Reason: nanny-close
2024-01-09 06:33:47,805 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:47,806 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33827. Reason: nanny-close
2024-01-09 06:33:47,808 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:47,808 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55542; closing.
2024-01-09 06:33:47,808 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33827', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782027.8085127')
2024-01-09 06:33:47,808 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:33:47,809 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:48,771 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:33:48,772 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:33:48,772 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:33:48,774 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:33:48,775 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-09 06:33:53,457 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:53,461 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37197 instead
  warnings.warn(
2024-01-09 06:33:53,465 - distributed.scheduler - INFO - State start
2024-01-09 06:33:53,488 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:33:53,489 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:33:53,490 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37197/status
2024-01-09 06:33:53,490 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:33:53,802 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44535', status: init, memory: 0, processing: 0>
2024-01-09 06:33:53,817 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44535
2024-01-09 06:33:53,817 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35462
2024-01-09 06:33:53,819 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41749'
2024-01-09 06:33:53,836 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35462; closing.
2024-01-09 06:33:53,836 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44535', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782033.8367603')
2024-01-09 06:33:53,837 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:33:54,064 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43427', status: init, memory: 0, processing: 0>
2024-01-09 06:33:54,065 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43427
2024-01-09 06:33:54,065 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35470
2024-01-09 06:33:54,090 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35470; closing.
2024-01-09 06:33:54,091 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43427', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782034.0911064')
2024-01-09 06:33:54,091 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:33:54,412 - distributed.scheduler - INFO - Receive client connection: Client-0dadc411-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:33:54,413 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35496
2024-01-09 06:33:55,363 - distributed.scheduler - INFO - Receive client connection: Client-08622148-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:33:55,364 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35516
2024-01-09 06:33:55,824 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:33:55,824 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:33:56,348 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:33:56,349 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45981
2024-01-09 06:33:56,349 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45981
2024-01-09 06:33:56,349 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43157
2024-01-09 06:33:56,349 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:33:56,349 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:56,349 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:33:56,349 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:33:56,349 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yyhr3q7_
2024-01-09 06:33:56,349 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d74ef4d6-bd47-4118-83b4-8b37f04b2498
2024-01-09 06:33:56,349 - distributed.worker - INFO - Starting Worker plugin PreImport-86723da9-bb60-4162-9aaa-e2046227d6c1
2024-01-09 06:33:56,350 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2a2c1286-3674-416b-bca3-9f68373ff2aa
2024-01-09 06:33:56,350 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:57,342 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45981', status: init, memory: 0, processing: 0>
2024-01-09 06:33:57,342 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45981
2024-01-09 06:33:57,342 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35536
2024-01-09 06:33:57,343 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:33:57,344 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:33:57,344 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:33:57,345 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:33:57,349 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:33:57,352 - distributed.scheduler - INFO - Remove client Client-0dadc411-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:33:57,352 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35496; closing.
2024-01-09 06:33:57,352 - distributed.scheduler - INFO - Remove client Client-0dadc411-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:33:57,353 - distributed.scheduler - INFO - Close client connection: Client-0dadc411-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:33:57,354 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41749'. Reason: nanny-close
2024-01-09 06:33:57,357 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:33:57,358 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45981. Reason: nanny-close
2024-01-09 06:33:57,359 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35536; closing.
2024-01-09 06:33:57,360 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:33:57,360 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45981', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782037.3601782')
2024-01-09 06:33:57,360 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:33:57,361 - distributed.nanny - INFO - Worker closed
2024-01-09 06:33:58,119 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:33:58,119 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:33:58,120 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:33:58,121 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:33:58,121 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-09 06:34:00,491 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:00,496 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46171 instead
  warnings.warn(
2024-01-09 06:34:00,501 - distributed.scheduler - INFO - State start
2024-01-09 06:34:00,525 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:00,526 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:34:00,527 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46171/status
2024-01-09 06:34:00,528 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:34:01,063 - distributed.scheduler - INFO - Receive client connection: Client-08622148-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:34:01,080 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49166
2024-01-09 06:34:01,084 - distributed.scheduler - INFO - Remove client Client-08622148-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:34:01,085 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49166; closing.
2024-01-09 06:34:01,085 - distributed.scheduler - INFO - Remove client Client-08622148-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:34:01,085 - distributed.scheduler - INFO - Close client connection: Client-08622148-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:34:01,238 - distributed.scheduler - INFO - Receive client connection: Client-136064b7-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:34:01,239 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49188
2024-01-09 06:34:03,566 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:49152'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 969, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4428, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:49152>: Stream is closed
2024-01-09 06:34:03,987 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:34:03,987 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:34:03,987 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:34:03,989 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:34:03,989 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-09 06:34:06,442 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:06,449 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45977 instead
  warnings.warn(
2024-01-09 06:34:06,454 - distributed.scheduler - INFO - State start
2024-01-09 06:34:06,481 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:06,482 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-09 06:34:06,483 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45977/status
2024-01-09 06:34:06,484 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:34:06,498 - distributed.scheduler - INFO - Receive client connection: Client-15543d8e-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:06,515 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37922
2024-01-09 06:34:06,578 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34379'
2024-01-09 06:34:08,419 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:08,419 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:08,423 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:08,423 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34297
2024-01-09 06:34:08,424 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34297
2024-01-09 06:34:08,424 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35059
2024-01-09 06:34:08,424 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:34:08,424 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:08,424 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:08,424 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:34:08,424 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-ilt74s50
2024-01-09 06:34:08,424 - distributed.worker - INFO - Starting Worker plugin RMMSetup-17fb1649-37ab-41a1-b22a-5e66fdebd9a9
2024-01-09 06:34:08,424 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-23bef16f-8852-4e0a-aabc-c69c70cdcb97
2024-01-09 06:34:08,424 - distributed.worker - INFO - Starting Worker plugin PreImport-276cffbc-0575-4c39-a356-f2cafcd7f498
2024-01-09 06:34:08,425 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:08,492 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34297', status: init, memory: 0, processing: 0>
2024-01-09 06:34:08,493 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34297
2024-01-09 06:34:08,493 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37940
2024-01-09 06:34:08,494 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:08,495 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:34:08,495 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:08,496 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:34:08,559 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:08,563 - distributed.scheduler - INFO - Remove client Client-15543d8e-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:08,563 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37922; closing.
2024-01-09 06:34:08,563 - distributed.scheduler - INFO - Remove client Client-15543d8e-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:08,563 - distributed.scheduler - INFO - Close client connection: Client-15543d8e-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:08,564 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34379'. Reason: nanny-close
2024-01-09 06:34:08,565 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:08,566 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34297. Reason: nanny-close
2024-01-09 06:34:08,568 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37940; closing.
2024-01-09 06:34:08,568 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:34:08,568 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34297', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782048.5683148')
2024-01-09 06:34:08,568 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:34:08,569 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:09,235 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:34:09,235 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:34:09,236 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:34:09,236 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-09 06:34:09,237 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-09 06:34:11,449 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:11,454 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42307 instead
  warnings.warn(
2024-01-09 06:34:11,458 - distributed.scheduler - INFO - State start
2024-01-09 06:34:11,484 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:11,485 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:34:11,486 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42307/status
2024-01-09 06:34:11,486 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:34:11,760 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44831'
2024-01-09 06:34:11,778 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37821'
2024-01-09 06:34:11,788 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33575'
2024-01-09 06:34:11,803 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45491'
2024-01-09 06:34:11,805 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35065'
2024-01-09 06:34:11,814 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45609'
2024-01-09 06:34:11,823 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37059'
2024-01-09 06:34:11,833 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35829'
2024-01-09 06:34:11,883 - distributed.scheduler - INFO - Receive client connection: Client-1882c9e8-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:11,902 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56038
2024-01-09 06:34:13,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:13,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:13,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:13,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:13,706 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:13,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:13,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:13,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:13,707 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:13,707 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:13,708 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37713
2024-01-09 06:34:13,708 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37713
2024-01-09 06:34:13,708 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36033
2024-01-09 06:34:13,708 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33795
2024-01-09 06:34:13,708 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36033
2024-01-09 06:34:13,708 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:13,708 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:13,708 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41915
2024-01-09 06:34:13,708 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:13,708 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:13,708 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:13,708 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:34:13,708 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:13,708 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8komwr7q
2024-01-09 06:34:13,708 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:34:13,709 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6jyjw_ci
2024-01-09 06:34:13,709 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0bb27eee-173d-454e-83d2-57a5c81816a0
2024-01-09 06:34:13,709 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ebd6b1c5-12c2-49c9-b1d0-41530371c896
2024-01-09 06:34:13,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:13,709 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:13,710 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:13,711 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40477
2024-01-09 06:34:13,711 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40477
2024-01-09 06:34:13,711 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39069
2024-01-09 06:34:13,711 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:13,711 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:13,711 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:13,711 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:13,711 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:34:13,711 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tedqaco9
2024-01-09 06:34:13,712 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3e76ffcf-f511-44e8-8f41-8bb414c21074
2024-01-09 06:34:13,712 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43887
2024-01-09 06:34:13,712 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43887
2024-01-09 06:34:13,712 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40329
2024-01-09 06:34:13,712 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:13,712 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:13,712 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:13,712 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:34:13,712 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xrwfjxwu
2024-01-09 06:34:13,713 - distributed.worker - INFO - Starting Worker plugin PreImport-d0931aec-67d2-4330-9ce7-ee19c1506561
2024-01-09 06:34:13,713 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f74346bf-939c-4d2b-a9cc-8ece9dc29f86
2024-01-09 06:34:13,713 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2d2425c8-88cc-465b-a723-048cc998e8d4
2024-01-09 06:34:13,713 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:13,714 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44311
2024-01-09 06:34:13,714 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44311
2024-01-09 06:34:13,714 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40811
2024-01-09 06:34:13,714 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:13,714 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:13,714 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:13,714 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:34:13,715 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bnedy9v6
2024-01-09 06:34:13,715 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d5287a92-bceb-4013-b210-bf54a6de988e
2024-01-09 06:34:13,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:13,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:13,759 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:13,760 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41853
2024-01-09 06:34:13,760 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41853
2024-01-09 06:34:13,760 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35689
2024-01-09 06:34:13,760 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:13,760 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:13,760 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:13,760 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:34:13,760 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-66nu8fmn
2024-01-09 06:34:13,761 - distributed.worker - INFO - Starting Worker plugin PreImport-8757b60c-7695-46d9-ab06-da561a2d1c1c
2024-01-09 06:34:13,761 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b14e76b4-ddb3-404d-bc67-22b929823f78
2024-01-09 06:34:13,761 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a8890350-b242-45fa-aa2f-ce4175a6d3ac
2024-01-09 06:34:13,790 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:13,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:13,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:13,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:13,795 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:13,796 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34059
2024-01-09 06:34:13,796 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34059
2024-01-09 06:34:13,796 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38513
2024-01-09 06:34:13,796 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:13,796 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:13,796 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:13,796 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:34:13,796 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jfutxdrq
2024-01-09 06:34:13,797 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3eb21e53-5d18-4d45-ba0d-e008565ad0f6
2024-01-09 06:34:13,797 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:13,798 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35837
2024-01-09 06:34:13,798 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35837
2024-01-09 06:34:13,798 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45875
2024-01-09 06:34:13,798 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:13,798 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:13,798 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:13,798 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:34:13,799 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-38kp4m3z
2024-01-09 06:34:13,799 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8b5ce6da-9b52-42a3-9ec6-44110e521648
2024-01-09 06:34:14,697 - distributed.scheduler - INFO - Receive client connection: Client-136064b7-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:34:14,697 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56100
2024-01-09 06:34:15,846 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:15,871 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43887', status: init, memory: 0, processing: 0>
2024-01-09 06:34:15,872 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43887
2024-01-09 06:34:15,872 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56122
2024-01-09 06:34:15,873 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:15,874 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:15,874 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:15,874 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f239b1d0-85b4-487d-9951-c2a67175cc5b
2024-01-09 06:34:15,875 - distributed.worker - INFO - Starting Worker plugin PreImport-d5604aec-6755-40ac-bc4d-6f31e20e72f6
2024-01-09 06:34:15,875 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:15,875 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:15,877 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0105fb50-3ee6-485f-8745-b6ceb608b08b
2024-01-09 06:34:15,878 - distributed.worker - INFO - Starting Worker plugin PreImport-07ed230e-8cf6-425c-b58c-394a2a685c13
2024-01-09 06:34:15,879 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:15,902 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36033', status: init, memory: 0, processing: 0>
2024-01-09 06:34:15,903 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36033
2024-01-09 06:34:15,903 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56124
2024-01-09 06:34:15,904 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:15,905 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:15,905 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:15,907 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:15,918 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37713', status: init, memory: 0, processing: 0>
2024-01-09 06:34:15,919 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37713
2024-01-09 06:34:15,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56138
2024-01-09 06:34:15,919 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cbeeea17-6b0b-4d7e-b72b-bda34580dc02
2024-01-09 06:34:15,920 - distributed.worker - INFO - Starting Worker plugin PreImport-22dde606-8647-4f6b-9d40-e427f1377fb1
2024-01-09 06:34:15,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:15,921 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:15,922 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:15,922 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:15,924 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:15,953 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5394010f-ee65-4fc0-b568-3d91e3c6ecfd
2024-01-09 06:34:15,954 - distributed.worker - INFO - Starting Worker plugin PreImport-b4c6708a-f28c-4614-a251-f339715a2443
2024-01-09 06:34:15,955 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:15,961 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40477', status: init, memory: 0, processing: 0>
2024-01-09 06:34:15,961 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40477
2024-01-09 06:34:15,961 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56144
2024-01-09 06:34:15,963 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:15,964 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:15,964 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:15,966 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:15,998 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44311', status: init, memory: 0, processing: 0>
2024-01-09 06:34:15,998 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44311
2024-01-09 06:34:15,999 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56150
2024-01-09 06:34:16,000 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:16,002 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:16,002 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:16,004 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:16,198 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:16,218 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-59ddb7c8-b14b-470e-851f-3bdf6b0cb3e0
2024-01-09 06:34:16,219 - distributed.worker - INFO - Starting Worker plugin PreImport-b5c99e74-fc18-41e1-b443-828b82213b90
2024-01-09 06:34:16,219 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:16,223 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-46a769ca-7555-4b0c-8061-2afe4370e6fc
2024-01-09 06:34:16,223 - distributed.worker - INFO - Starting Worker plugin PreImport-f0ba3188-54fd-4fe4-b1de-0af5d4c8b2d2
2024-01-09 06:34:16,224 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:16,235 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41853', status: init, memory: 0, processing: 0>
2024-01-09 06:34:16,235 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41853
2024-01-09 06:34:16,236 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56176
2024-01-09 06:34:16,237 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:16,239 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:16,239 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:16,241 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:16,246 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34059', status: init, memory: 0, processing: 0>
2024-01-09 06:34:16,246 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34059
2024-01-09 06:34:16,247 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56178
2024-01-09 06:34:16,247 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35837', status: init, memory: 0, processing: 0>
2024-01-09 06:34:16,247 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:16,248 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35837
2024-01-09 06:34:16,248 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56182
2024-01-09 06:34:16,249 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:16,249 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:16,249 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:16,250 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:16,250 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:16,251 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:16,252 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:16,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:34:16,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:34:16,312 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:34:16,313 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:34:16,313 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:34:16,313 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:34:16,313 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:34:16,314 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:34:16,327 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:16,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:16,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:16,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:16,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:16,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:16,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:16,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:16,333 - distributed.scheduler - INFO - Remove client Client-1882c9e8-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:16,333 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56038; closing.
2024-01-09 06:34:16,333 - distributed.scheduler - INFO - Remove client Client-1882c9e8-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:16,334 - distributed.scheduler - INFO - Close client connection: Client-1882c9e8-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:16,334 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44831'. Reason: nanny-close
2024-01-09 06:34:16,335 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:16,335 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37821'. Reason: nanny-close
2024-01-09 06:34:16,336 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:16,336 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33575'. Reason: nanny-close
2024-01-09 06:34:16,336 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40477. Reason: nanny-close
2024-01-09 06:34:16,336 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:16,336 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45491'. Reason: nanny-close
2024-01-09 06:34:16,337 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41853. Reason: nanny-close
2024-01-09 06:34:16,337 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:16,337 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35065'. Reason: nanny-close
2024-01-09 06:34:16,337 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43887. Reason: nanny-close
2024-01-09 06:34:16,337 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:16,337 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45609'. Reason: nanny-close
2024-01-09 06:34:16,337 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36033. Reason: nanny-close
2024-01-09 06:34:16,337 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:16,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37059'. Reason: nanny-close
2024-01-09 06:34:16,338 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37713. Reason: nanny-close
2024-01-09 06:34:16,338 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:16,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35829'. Reason: nanny-close
2024-01-09 06:34:16,338 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44311. Reason: nanny-close
2024-01-09 06:34:16,338 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:16,338 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:16,338 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34059. Reason: nanny-close
2024-01-09 06:34:16,338 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56122; closing.
2024-01-09 06:34:16,339 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:16,339 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:16,339 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43887', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782056.3392665')
2024-01-09 06:34:16,339 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:16,339 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35837. Reason: nanny-close
2024-01-09 06:34:16,339 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56144; closing.
2024-01-09 06:34:16,340 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:16,340 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40477', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782056.3404336')
2024-01-09 06:34:16,340 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:16,340 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:16,340 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56176; closing.
2024-01-09 06:34:16,340 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:16,340 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:16,340 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56124; closing.
2024-01-09 06:34:16,340 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:16,341 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:16,341 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:16,341 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41853', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782056.3418775')
2024-01-09 06:34:16,342 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:16,342 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:16,342 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36033', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782056.3422644')
2024-01-09 06:34:16,342 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:16,342 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:16,343 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:56144>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-09 06:34:16,344 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56138; closing.
2024-01-09 06:34:16,344 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56150; closing.
2024-01-09 06:34:16,345 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56178; closing.
2024-01-09 06:34:16,345 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37713', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782056.3455014')
2024-01-09 06:34:16,345 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44311', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782056.345852')
2024-01-09 06:34:16,346 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34059', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782056.3461924')
2024-01-09 06:34:16,346 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56182; closing.
2024-01-09 06:34:16,347 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35837', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782056.3469388')
2024-01-09 06:34:16,347 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:34:17,164 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39269', status: init, memory: 0, processing: 0>
2024-01-09 06:34:17,165 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39269
2024-01-09 06:34:17,165 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56198
2024-01-09 06:34:17,222 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40291', status: init, memory: 0, processing: 0>
2024-01-09 06:34:17,223 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40291
2024-01-09 06:34:17,223 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56216
2024-01-09 06:34:17,224 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33443', status: init, memory: 0, processing: 0>
2024-01-09 06:34:17,225 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33443
2024-01-09 06:34:17,225 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56206
2024-01-09 06:34:17,451 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:34:17,452 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:34:17,452 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:34:17,454 - distributed.core - INFO - Connection to tcp://127.0.0.1:56198 has been closed.
2024-01-09 06:34:17,454 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39269', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782057.4542503')
2024-01-09 06:34:17,454 - distributed.core - INFO - Connection to tcp://127.0.0.1:56216 has been closed.
2024-01-09 06:34:17,455 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40291', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782057.4549222')
2024-01-09 06:34:17,455 - distributed.core - INFO - Connection to tcp://127.0.0.1:56206 has been closed.
2024-01-09 06:34:17,455 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33443', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782057.4554176')
2024-01-09 06:34:17,455 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:34:17,458 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:34:17,458 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-09 06:34:19,788 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:19,792 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46861 instead
  warnings.warn(
2024-01-09 06:34:19,796 - distributed.scheduler - INFO - State start
2024-01-09 06:34:19,877 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:19,878 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:34:19,879 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46861/status
2024-01-09 06:34:19,879 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:34:19,903 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42039', status: init, memory: 0, processing: 0>
2024-01-09 06:34:19,922 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42039
2024-01-09 06:34:19,922 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56714
2024-01-09 06:34:19,941 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56714; closing.
2024-01-09 06:34:19,941 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42039', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782059.9415007')
2024-01-09 06:34:19,941 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:34:19,963 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38765'
2024-01-09 06:34:21,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:21,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:21,690 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:21,691 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42175
2024-01-09 06:34:21,691 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42175
2024-01-09 06:34:21,691 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41193
2024-01-09 06:34:21,691 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:21,692 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:21,692 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:21,692 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:34:21,692 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h9_6g2xp
2024-01-09 06:34:21,692 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-257d19c9-b146-441e-8600-649f747c2974
2024-01-09 06:34:21,692 - distributed.worker - INFO - Starting Worker plugin PreImport-b85d6cdb-7430-4f69-ae92-378e913f62e7
2024-01-09 06:34:21,692 - distributed.worker - INFO - Starting Worker plugin RMMSetup-793c96af-494e-4652-b6b2-e5659dd7ec37
2024-01-09 06:34:22,032 - distributed.scheduler - INFO - Receive client connection: Client-1d4c4116-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:22,033 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44212
2024-01-09 06:34:22,189 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:22,247 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42175', status: init, memory: 0, processing: 0>
2024-01-09 06:34:22,247 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42175
2024-01-09 06:34:22,247 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44218
2024-01-09 06:34:22,248 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:22,249 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:22,249 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:22,251 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:22,345 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:34:22,350 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:22,351 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:22,354 - distributed.scheduler - INFO - Remove client Client-1d4c4116-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:22,354 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44212; closing.
2024-01-09 06:34:22,355 - distributed.scheduler - INFO - Remove client Client-1d4c4116-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:22,355 - distributed.scheduler - INFO - Close client connection: Client-1d4c4116-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:22,356 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38765'. Reason: nanny-close
2024-01-09 06:34:22,356 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:22,357 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42175. Reason: nanny-close
2024-01-09 06:34:22,359 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:22,359 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44218; closing.
2024-01-09 06:34:22,359 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42175', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782062.3597279')
2024-01-09 06:34:22,359 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:34:22,361 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:22,763 - distributed.scheduler - INFO - Receive client connection: Client-136064b7-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:34:22,763 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44224
2024-01-09 06:34:22,971 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:34:22,972 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:34:22,972 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:34:22,974 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:34:22,974 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-09 06:34:25,176 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:25,181 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33355 instead
  warnings.warn(
2024-01-09 06:34:25,185 - distributed.scheduler - INFO - State start
2024-01-09 06:34:25,207 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:34:25,208 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:34:25,208 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33355/status
2024-01-09 06:34:25,209 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:34:25,273 - distributed.scheduler - INFO - Receive client connection: Client-20a4d127-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:25,288 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44456
2024-01-09 06:34:25,570 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45271'
2024-01-09 06:34:26,138 - distributed.scheduler - INFO - Receive client connection: Client-2237d631-aeb9-11ee-b9fd-d8c49764f6bb
2024-01-09 06:34:26,139 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44500
2024-01-09 06:34:27,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:34:27,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:34:27,520 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:34:27,521 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44319
2024-01-09 06:34:27,521 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44319
2024-01-09 06:34:27,521 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42295
2024-01-09 06:34:27,521 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:34:27,521 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:27,521 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:34:27,521 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:34:27,522 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k8nj046h
2024-01-09 06:34:27,522 - distributed.worker - INFO - Starting Worker plugin RMMSetup-182aa8e4-2967-4cb0-8cd7-8d997b502948
2024-01-09 06:34:27,828 - distributed.worker - INFO - Starting Worker plugin PreImport-f6966172-e75f-478f-b431-8bb469006015
2024-01-09 06:34:27,829 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-efdcb302-5657-453a-bf34-0795f8a2eb2a
2024-01-09 06:34:27,829 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:27,887 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44319', status: init, memory: 0, processing: 0>
2024-01-09 06:34:27,889 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44319
2024-01-09 06:34:27,889 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44520
2024-01-09 06:34:27,890 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:34:27,892 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:34:27,892 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:34:27,893 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:34:27,941 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-09 06:34:27,946 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:34:27,951 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:27,953 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:34:27,955 - distributed.scheduler - INFO - Remove client Client-20a4d127-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:27,955 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44456; closing.
2024-01-09 06:34:27,956 - distributed.scheduler - INFO - Remove client Client-20a4d127-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:27,956 - distributed.scheduler - INFO - Close client connection: Client-20a4d127-aeb9-11ee-b596-d8c49764f6bb
2024-01-09 06:34:27,957 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45271'. Reason: nanny-close
2024-01-09 06:34:27,957 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:34:27,958 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44319. Reason: nanny-close
2024-01-09 06:34:27,961 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44520; closing.
2024-01-09 06:34:27,961 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44319', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704782067.9615479')
2024-01-09 06:34:27,961 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:34:27,961 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:34:27,963 - distributed.nanny - INFO - Worker closed
2024-01-09 06:34:28,672 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:34:28,672 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:34:28,673 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:34:28,675 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:34:28,676 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34121 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37771 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36213 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43541 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46193 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39177 instead
  warnings.warn(
2024-01-09 06:35:32,148 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 737, in wait
  File "libucxx.pyx", line 722, in wait_yield
  File "libucxx.pyx", line 717, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] [1704782235.613604] [dgx13:69412:0]            sock.c:481  UCX  ERROR bind(fd=161 addr=0.0.0.0:56961) failed: Address already in use
2024-01-09 06:37:18,072 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 737, in wait
  File "libucxx.pyx", line 722, in wait_yield
  File "libucxx.pyx", line 717, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-09 06:37:18,077 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 737, in wait
  File "libucxx.pyx", line 722, in wait_yield
  File "libucxx.pyx", line 717, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
2024-01-09 06:37:18,078 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 737, in wait
  File "libucxx.pyx", line 722, in wait_yield
  File "libucxx.pyx", line 717, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39955 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40717 instead
  warnings.warn(
[1704782250.717899] [dgx13:69717:0]            sock.c:481  UCX  ERROR bind(fd=133 addr=0.0.0.0:46350) failed: Address already in use
[1704782252.360565] [dgx13:69818:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:34359) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] [1704782263.374209] [dgx13:69887:0]            sock.c:481  UCX  ERROR bind(fd=158 addr=0.0.0.0:48502) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36717 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38297 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45597 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39191 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42043 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32979 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41565 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36933 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46831 instead
  warnings.warn(
[1704782514.843975] [dgx13:74339:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:47362) failed: Address already in use
[1704782518.287654] [dgx13:74329:0]            sock.c:481  UCX  ERROR bind(fd=130 addr=0.0.0.0:48397) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] [1704782565.772347] [dgx13:74984:0]            sock.c:481  UCX  ERROR bind(fd=121 addr=0.0.0.0:37378) failed: Address already in use
[1704782568.562098] [dgx13:74984:0]            sock.c:481  UCX  ERROR bind(fd=153 addr=0.0.0.0:48892) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43077 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33889 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39507 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44105 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37151 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34915 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46001 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45837 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37301 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35103 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35669 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42457 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40741 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46587 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39109 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46401 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40475 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45235 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39613 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39189 instead
  warnings.warn(
[1704783122.828451] [dgx13:83164:0]            sock.c:481  UCX  ERROR bind(fd=155 addr=0.0.0.0:38010) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35649 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41337 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37829 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35329 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37451 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35705 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35373 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44671 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41907 instead
  warnings.warn(
[1704783245.178215] [dgx13:85013:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:45881) failed: Address already in use
2024-01-09 06:54:06,880 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-09 06:54:06,880 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37291 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38979 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38033 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40601 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39821 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44517 instead
  warnings.warn(
[1704783349.569244] [dgx13:86268:0]            sock.c:481  UCX  ERROR bind(fd=155 addr=0.0.0.0:50546) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36153 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42955 instead
  warnings.warn(
[1704783385.065322] [dgx13:86576:0]            sock.c:481  UCX  ERROR bind(fd=157 addr=0.0.0.0:48822) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43615 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37929 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36275 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43673 instead
  warnings.warn(
[1704783463.657415] [dgx13:87642:0]            sock.c:481  UCX  ERROR bind(fd=161 addr=0.0.0.0:60340) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_lock_workers PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucx] [1704783487.102225] [dgx13:62870:0]            sock.c:481  UCX  ERROR bind(fd=175 addr=0.0.0.0:41222) failed: Address already in use
[1704783492.318300] [dgx13:88036:0]            sock.c:481  UCX  ERROR bind(fd=162 addr=0.0.0.0:48722) failed: Address already in use
2024-01-09 06:58:13,647 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-09 06:58:13,651 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-09 06:58:13,651 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-09 06:58:13,652 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-09 06:58:13,651 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-09 06:58:13,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-01-09 06:58:13,685 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1563, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1673, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1675, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucxx] PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[tcp] PASSED
dask_cuda/tests/test_gds.py::test_gds[True-cupy] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-cudf] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-numba.cuda] SKIPPED (GDS ...)
dask_cuda/tests/test_gds.py::test_gds[False-cupy] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-cudf] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-numba.cuda] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45347 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43365 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37259 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33833 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39537 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37813 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34133 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40781 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_local_cuda_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_with_subset_of_cuda_visible_devices PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucxx] [1704783596.954029] [dgx13:62870:1]            sock.c:481  UCX  ERROR bind(fd=251 addr=0.0.0.0:48348) failed: Address already in use
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_n_workers PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_threads_per_worker_and_memory_limit PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cudaworker 2024-01-09 07:00:19,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:00:19,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:00:19,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:00:19,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:00:19,953 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:00:19,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:00:19,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:00:19,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:00:20,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:00:20,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:00:20,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:00:20,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:00:20,154 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:00:20,154 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:00:20,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:00:20,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:00:20,548 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:00:20,549 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34183
2024-01-09 07:00:20,549 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34183
2024-01-09 07:00:20,549 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44419
2024-01-09 07:00:20,549 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,549 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,549 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:00:20,549 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-88xq3gap
2024-01-09 07:00:20,550 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd5a7eba-22eb-49aa-8669-f1481db47fdc
2024-01-09 07:00:20,550 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-308df68b-170f-4cd4-8cb3-08d20b23f756
2024-01-09 07:00:20,550 - distributed.worker - INFO - Starting Worker plugin PreImport-c2317a97-a501-4c16-bdd3-fd1de682c546
2024-01-09 07:00:20,550 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,583 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:00:20,584 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38039
2024-01-09 07:00:20,585 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38039
2024-01-09 07:00:20,585 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45125
2024-01-09 07:00:20,585 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,585 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,585 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:00:20,585 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-izi7ywwv
2024-01-09 07:00:20,585 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f763b26b-acee-4ee1-a144-ea805380cfec
2024-01-09 07:00:20,585 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e59872f4-2582-40f6-be41-b04d231ed1f3
2024-01-09 07:00:20,585 - distributed.worker - INFO - Starting Worker plugin PreImport-a95948f9-9b6b-49b6-8073-e62fb6fe506e
2024-01-09 07:00:20,586 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,601 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:00:20,602 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43051
2024-01-09 07:00:20,602 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43051
2024-01-09 07:00:20,602 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34315
2024-01-09 07:00:20,602 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,602 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,602 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:00:20,602 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uuin8a05
2024-01-09 07:00:20,602 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0e410a04-4bc0-4a6d-8380-6657d655a079
2024-01-09 07:00:20,602 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-19c9e78c-b0d2-4a1e-9f1d-cef18d7dd182
2024-01-09 07:00:20,603 - distributed.worker - INFO - Starting Worker plugin PreImport-2608fd47-a2c7-4c4d-a8f5-92401dc27738
2024-01-09 07:00:20,603 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,642 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:00:20,643 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35197
2024-01-09 07:00:20,643 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35197
2024-01-09 07:00:20,643 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36039
2024-01-09 07:00:20,643 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,644 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,644 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:00:20,644 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ki6dn0kh
2024-01-09 07:00:20,644 - distributed.worker - INFO - Starting Worker plugin RMMSetup-732257ab-22c6-4576-bbf9-f6edf542b0dd
2024-01-09 07:00:20,644 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-15b745b2-c07f-4b81-8ef2-30a98744ec22
2024-01-09 07:00:20,644 - distributed.worker - INFO - Starting Worker plugin PreImport-0df289d0-6bf5-416e-af5f-a349ca9a1586
2024-01-09 07:00:20,644 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,648 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:00:20,649 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,649 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41515
2024-01-09 07:00:20,663 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:00:20,663 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39947
2024-01-09 07:00:20,664 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39947
2024-01-09 07:00:20,664 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37983
2024-01-09 07:00:20,664 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,664 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,664 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:00:20,664 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s0wm1b1t
2024-01-09 07:00:20,664 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bdfdf579-9c93-4df8-8ece-c42f0be10880
2024-01-09 07:00:20,664 - distributed.worker - INFO - Starting Worker plugin RMMSetup-808c117d-f56f-49cf-a4a0-51e4a7a1774c
2024-01-09 07:00:20,665 - distributed.worker - INFO - Starting Worker plugin PreImport-553b37ce-6d08-4eaa-9613-21b949884e46
2024-01-09 07:00:20,665 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,715 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:00:20,716 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,716 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41515
2024-01-09 07:00:20,746 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:00:20,747 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,747 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,748 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41515
2024-01-09 07:00:20,751 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:00:20,752 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43005
2024-01-09 07:00:20,752 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43005
2024-01-09 07:00:20,752 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44733
2024-01-09 07:00:20,752 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,752 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,752 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:00:20,752 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5ajy7s05
2024-01-09 07:00:20,753 - distributed.worker - INFO - Starting Worker plugin RMMSetup-54018123-852f-4d8e-ba04-b103b5a9562a
2024-01-09 07:00:20,753 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-898f7192-4cc0-499c-9908-ba9ed2f020d4
2024-01-09 07:00:20,753 - distributed.worker - INFO - Starting Worker plugin PreImport-ea06b1e0-7991-4326-ae31-6360163a19f2
2024-01-09 07:00:20,753 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,793 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:00:20,794 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,794 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,795 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41515
2024-01-09 07:00:20,805 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:00:20,806 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,806 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,808 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41515
2024-01-09 07:00:20,828 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:00:20,830 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38117
2024-01-09 07:00:20,830 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38117
2024-01-09 07:00:20,830 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42177
2024-01-09 07:00:20,830 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,830 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,830 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:00:20,830 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-24hdq9tp
2024-01-09 07:00:20,831 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7d7aedf6-bf4a-4dba-8ece-40cc7b8964d1
2024-01-09 07:00:20,831 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-de3f465d-d16d-4d51-8f17-13422e5bf66d
2024-01-09 07:00:20,832 - distributed.worker - INFO - Starting Worker plugin PreImport-b93246cc-41bb-4bdd-9f3c-01657cbda674
2024-01-09 07:00:20,832 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,836 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:00:20,837 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37969
2024-01-09 07:00:20,837 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37969
2024-01-09 07:00:20,837 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34757
2024-01-09 07:00:20,837 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,837 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,837 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:00:20,837 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_t7_x5x2
2024-01-09 07:00:20,837 - distributed.worker - INFO - Starting Worker plugin PreImport-b3566d32-1acc-4f76-ba7f-c12a00081db6
2024-01-09 07:00:20,837 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-05416b51-3cd0-4d12-8714-d8b017751988
2024-01-09 07:00:20,838 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aea8d57f-6e13-4446-8e9e-b309af016894
2024-01-09 07:00:20,838 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,843 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:00:20,843 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,843 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,845 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41515
2024-01-09 07:00:20,957 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:00:20,958 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,958 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,959 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41515
2024-01-09 07:00:20,959 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:00:20,960 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:41515
2024-01-09 07:00:20,960 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:20,962 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41515
2024-01-09 07:00:21,003 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 07:00:21,003 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 07:00:21,003 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 07:00:21,003 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 07:00:21,003 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 07:00:21,004 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 07:00:21,004 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 07:00:21,004 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 07:00:21,010 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34183. Reason: nanny-close
2024-01-09 07:00:21,011 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43051. Reason: nanny-close
2024-01-09 07:00:21,011 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35197. Reason: nanny-close
2024-01-09 07:00:21,012 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38039. Reason: nanny-close
2024-01-09 07:00:21,013 - distributed.core - INFO - Connection to tcp://127.0.0.1:41515 has been closed.
2024-01-09 07:00:21,013 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39947. Reason: nanny-close
2024-01-09 07:00:21,013 - distributed.core - INFO - Connection to tcp://127.0.0.1:41515 has been closed.
2024-01-09 07:00:21,013 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43005. Reason: nanny-close
2024-01-09 07:00:21,014 - distributed.core - INFO - Connection to tcp://127.0.0.1:41515 has been closed.
2024-01-09 07:00:21,014 - distributed.core - INFO - Connection to tcp://127.0.0.1:41515 has been closed.
2024-01-09 07:00:21,014 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37969. Reason: nanny-close
2024-01-09 07:00:21,014 - distributed.nanny - INFO - Worker closed
2024-01-09 07:00:21,015 - distributed.nanny - INFO - Worker closed
2024-01-09 07:00:21,015 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38117. Reason: nanny-close
2024-01-09 07:00:21,015 - distributed.nanny - INFO - Worker closed
2024-01-09 07:00:21,016 - distributed.core - INFO - Connection to tcp://127.0.0.1:41515 has been closed.
2024-01-09 07:00:21,016 - distributed.nanny - INFO - Worker closed
2024-01-09 07:00:21,016 - distributed.core - INFO - Connection to tcp://127.0.0.1:41515 has been closed.
2024-01-09 07:00:21,016 - distributed.core - INFO - Connection to tcp://127.0.0.1:41515 has been closed.
2024-01-09 07:00:21,017 - distributed.nanny - INFO - Worker closed
2024-01-09 07:00:21,017 - distributed.core - INFO - Connection to tcp://127.0.0.1:41515 has been closed.
2024-01-09 07:00:21,017 - distributed.nanny - INFO - Worker closed
2024-01-09 07:00:21,018 - distributed.nanny - INFO - Worker closed
2024-01-09 07:00:21,018 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_all_to_all PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_pool PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_maximum_poolsize_without_poolsize_error PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_managed PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async_with_maximum_pool_size PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_logging PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import_not_found 2024-01-09 07:00:57,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:00:57,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:00:57,962 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:00:57,963 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36689
2024-01-09 07:00:57,963 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36689
2024-01-09 07:00:57,963 - distributed.worker - INFO -           Worker name:                          0
2024-01-09 07:00:57,963 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38881
2024-01-09 07:00:57,963 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44815
2024-01-09 07:00:57,963 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:00:57,963 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:00:57,963 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 07:00:57,964 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hbgup8oc
2024-01-09 07:00:57,964 - distributed.worker - INFO - Starting Worker plugin PreImport-fb5a2cc8-11bf-4ae7-9669-11291a9d560f
2024-01-09 07:00:57,967 - distributed.worker - ERROR - No module named 'my_module'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'
2024-01-09 07:00:57,967 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7833c7b3-6820-48b6-9c5c-5c4f0682f7da
2024-01-09 07:00:57,968 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a9afe494-bf3f-4b93-a2f2-81b95a92238a
2024-01-09 07:00:57,968 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36689. Reason: failure-to-start-<class 'ModuleNotFoundError'>
2024-01-09 07:00:57,968 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2024-01-09 07:00:57,970 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
XFAIL
dask_cuda/tests/test_local_cuda_cluster.py::test_cluster_worker 2024-01-09 07:01:02,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:01:02,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:01:02,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:01:02,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:01:02,443 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:01:02,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:01:02,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:01:02,538 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:01:02,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:01:02,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:01:02,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:01:02,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:01:02,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:01:02,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:01:02,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 07:01:02,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 07:01:03,000 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:01:03,000 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35941
2024-01-09 07:01:03,000 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35941
2024-01-09 07:01:03,001 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40141
2024-01-09 07:01:03,001 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,001 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,001 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:01:03,001 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 07:01:03,001 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mfhajdpm
2024-01-09 07:01:03,001 - distributed.worker - INFO - Starting Worker plugin PreImport-9a541974-feca-4461-a246-b8ef8c88cfa4
2024-01-09 07:01:03,001 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f938457c-0193-48e0-a912-2f9dd22d1a9f
2024-01-09 07:01:03,001 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5fc49943-1c29-43dc-a7b5-837d0274fd51
2024-01-09 07:01:03,002 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,019 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:01:03,020 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45623
2024-01-09 07:01:03,020 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45623
2024-01-09 07:01:03,020 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33191
2024-01-09 07:01:03,020 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,020 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,020 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:01:03,020 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 07:01:03,020 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t3wt2mvw
2024-01-09 07:01:03,021 - distributed.worker - INFO - Starting Worker plugin RMMSetup-24888f24-1b9a-4328-9a45-0bbd5a347d15
2024-01-09 07:01:03,021 - distributed.worker - INFO - Starting Worker plugin PreImport-b8cc23cd-1301-487d-9c12-402b2aef4679
2024-01-09 07:01:03,021 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-57c75bb9-003a-4092-8152-59bf6b0f71df
2024-01-09 07:01:03,021 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,051 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:01:03,052 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39421
2024-01-09 07:01:03,052 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39421
2024-01-09 07:01:03,052 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34495
2024-01-09 07:01:03,052 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,052 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,052 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:01:03,052 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 07:01:03,052 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kc0cu414
2024-01-09 07:01:03,052 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-281df9ed-bfa7-4761-9dc5-7ba55c1d39dc
2024-01-09 07:01:03,053 - distributed.worker - INFO - Starting Worker plugin PreImport-b432621f-6101-45bf-b036-e6eaaa37367d
2024-01-09 07:01:03,053 - distributed.worker - INFO - Starting Worker plugin RMMSetup-92e495d6-1e3b-4773-a8fc-d720ceda0197
2024-01-09 07:01:03,053 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,093 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:01:03,094 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,094 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,096 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36403
2024-01-09 07:01:03,120 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:01:03,121 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,121 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,122 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36403
2024-01-09 07:01:03,139 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:01:03,140 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,140 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,141 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36403
2024-01-09 07:01:03,175 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:01:03,176 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43921
2024-01-09 07:01:03,176 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43921
2024-01-09 07:01:03,176 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34525
2024-01-09 07:01:03,176 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,176 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,176 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:01:03,176 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 07:01:03,176 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wp31v0g5
2024-01-09 07:01:03,177 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b32f691f-7af6-421f-b7f6-e46897653ae1
2024-01-09 07:01:03,177 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4973c275-432d-47ef-8793-cc313cde02c5
2024-01-09 07:01:03,177 - distributed.worker - INFO - Starting Worker plugin PreImport-53e4c44a-1c19-4e3b-ac96-053b9a1c5f25
2024-01-09 07:01:03,177 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,184 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:01:03,185 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43451
2024-01-09 07:01:03,185 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43451
2024-01-09 07:01:03,185 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35143
2024-01-09 07:01:03,185 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,185 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,185 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:01:03,185 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 07:01:03,185 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zrqk6i9y
2024-01-09 07:01:03,186 - distributed.worker - INFO - Starting Worker plugin PreImport-eceaa385-6c17-483f-95aa-d711ffe618e0
2024-01-09 07:01:03,186 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6719c4e3-b256-4e92-af9c-8d01b0050026
2024-01-09 07:01:03,186 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a822fb22-6359-443a-9984-b50dd3240171
2024-01-09 07:01:03,186 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,196 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:01:03,197 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38249
2024-01-09 07:01:03,197 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38249
2024-01-09 07:01:03,197 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41873
2024-01-09 07:01:03,197 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,198 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,198 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:01:03,198 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 07:01:03,198 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-popsou4d
2024-01-09 07:01:03,198 - distributed.worker - INFO - Starting Worker plugin PreImport-22b0668d-7c6c-4acc-aea5-d029ba21ee8f
2024-01-09 07:01:03,198 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2299022e-cebd-4fb7-a926-61f38b797ed9
2024-01-09 07:01:03,199 - distributed.worker - INFO - Starting Worker plugin RMMSetup-79ec16d4-d06f-41a5-b7be-5b6a313bc0ce
2024-01-09 07:01:03,199 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,270 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:01:03,271 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,271 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,272 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36403
2024-01-09 07:01:03,297 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:01:03,298 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46473
2024-01-09 07:01:03,298 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46473
2024-01-09 07:01:03,298 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35271
2024-01-09 07:01:03,298 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,298 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,299 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:01:03,299 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 07:01:03,299 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lus6v7dc
2024-01-09 07:01:03,299 - distributed.worker - INFO - Starting Worker plugin PreImport-6f43a1a4-a95d-4622-bd17-6a25db0f8a4c
2024-01-09 07:01:03,299 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2233d0c5-65c9-4342-90c2-ae6c4ac5de85
2024-01-09 07:01:03,299 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-867545d1-449d-47f2-8a45-9d3dfc3c0388
2024-01-09 07:01:03,299 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,300 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:01:03,301 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,301 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,303 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36403
2024-01-09 07:01:03,307 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 07:01:03,307 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:01:03,307 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,307 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,308 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38759
2024-01-09 07:01:03,308 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38759
2024-01-09 07:01:03,308 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39427
2024-01-09 07:01:03,308 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,308 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,308 - distributed.worker - INFO -               Threads:                          1
2024-01-09 07:01:03,308 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 07:01:03,308 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5dn_ybvp
2024-01-09 07:01:03,308 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c449bbc2-2197-4a62-b7d3-bd962752eff3
2024-01-09 07:01:03,308 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36403
2024-01-09 07:01:03,309 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a048c10e-220e-4db8-9157-8793a883efd4
2024-01-09 07:01:03,309 - distributed.worker - INFO - Starting Worker plugin PreImport-850dd243-1f62-42ff-a22b-ba5ebccdbf65
2024-01-09 07:01:03,309 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,385 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:01:03,386 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,386 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,387 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36403
2024-01-09 07:01:03,390 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 07:01:03,390 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:36403
2024-01-09 07:01:03,391 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 07:01:03,392 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36403
2024-01-09 07:01:03,417 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35941. Reason: nanny-close
2024-01-09 07:01:03,418 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45623. Reason: nanny-close
2024-01-09 07:01:03,418 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39421. Reason: nanny-close
2024-01-09 07:01:03,419 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43921. Reason: nanny-close
2024-01-09 07:01:03,419 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38249. Reason: nanny-close
2024-01-09 07:01:03,420 - distributed.core - INFO - Connection to tcp://127.0.0.1:36403 has been closed.
2024-01-09 07:01:03,420 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43451. Reason: nanny-close
2024-01-09 07:01:03,420 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46473. Reason: nanny-close
2024-01-09 07:01:03,420 - distributed.core - INFO - Connection to tcp://127.0.0.1:36403 has been closed.
2024-01-09 07:01:03,420 - distributed.core - INFO - Connection to tcp://127.0.0.1:36403 has been closed.
2024-01-09 07:01:03,421 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38759. Reason: nanny-close
2024-01-09 07:01:03,421 - distributed.core - INFO - Connection to tcp://127.0.0.1:36403 has been closed.
2024-01-09 07:01:03,421 - distributed.nanny - INFO - Worker closed
2024-01-09 07:01:03,422 - distributed.core - INFO - Connection to tcp://127.0.0.1:36403 has been closed.
2024-01-09 07:01:03,422 - distributed.nanny - INFO - Worker closed
2024-01-09 07:01:03,422 - distributed.nanny - INFO - Worker closed
2024-01-09 07:01:03,422 - distributed.core - INFO - Connection to tcp://127.0.0.1:36403 has been closed.
2024-01-09 07:01:03,422 - distributed.core - INFO - Connection to tcp://127.0.0.1:36403 has been closed.
2024-01-09 07:01:03,422 - distributed.nanny - INFO - Worker closed
2024-01-09 07:01:03,423 - distributed.core - INFO - Connection to tcp://127.0.0.1:36403 has been closed.
2024-01-09 07:01:03,423 - distributed.nanny - INFO - Worker closed
2024-01-09 07:01:03,423 - distributed.nanny - INFO - Worker closed
2024-01-09 07:01:03,424 - distributed.nanny - INFO - Worker closed
2024-01-09 07:01:03,424 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_available_mig_workers SKIPPED
dask_cuda/tests/test_local_cuda_cluster.py::test_gpu_uuid PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_track_allocations PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_get_cluster_configuration PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_worker_fraction_limits PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_death_timeout_raises XFAIL
dask_cuda/tests/test_proxify_host_file.py::test_one_dev_item_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_one_item_host_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_spill_on_demand FAILED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_dataframes_share_dev_mem PASSED
dask_cuda/tests/test_proxify_host_file.py::test_cudf_get_device_memory_objects PASSED
dask_cuda/tests/test_proxify_host_file.py::test_externals PASSED
dask_cuda/tests/test_proxify_host_file.py::test_incompatible_types PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_worker_force_spill_to_disk /opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
