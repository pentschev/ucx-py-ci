[1710315283.460783] [dgx13:80261:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_2: LRU push returned Unsupported operation
[dgx13:80261:0:80261]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  80261) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f0c3f03007d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f0c3f02dc21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f0c3f02ddbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f0c3f0d89f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f0c3f0afd8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f0c3f0ebafd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f0c3f0f09ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f0c3f0f172f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f0c3f19f6f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56399a39e04c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56399a3843f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56399a37efb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56399a390469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56399a381042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56399a37efb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56399a390469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56399a381042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56399a4336d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56399a385c10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56399a4336d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56399a385c10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56399a4336d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56399a385c10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56399a4336d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56399a385c10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56399a4336d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x56399a385c10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x56399a4336d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f0c721b61e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f0c721b6aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56399a3886ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x56399a3433ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x56399a387723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x56399a385929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56399a390712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56399a3804e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56399a390712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56399a3804e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56399a390712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56399a3804e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56399a390712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56399a3804e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56399a37efb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56399a390469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x56399a381042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56399a37efb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x56399a39d8cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56399a39e04c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x56399a46180e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56399a3886ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56399a3843f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56399a390712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x56399a39d9ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x56399a3843f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56399a390712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56399a3804e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56399a37efb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56399a390469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56399a3804e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x56399a390712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x56399a380232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x56399a37efb4]
=================================
2024-03-13 07:34:45,295 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60091
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f0c1c520240, tag: 0x7e6c0a9b79708055, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f0c1c520240, tag: 0x7e6c0a9b79708055, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-03-13 07:34:45,295 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60091
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f42ecb66200, tag: 0xfd40ee42e2ef47bb, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f42ecb66200, tag: 0xfd40ee42e2ef47bb, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-1126' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:140> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 155, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 55, in exchange_peer_info
    await asyncio.wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2024-03-13 07:34:45,295 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60091
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7fbc9148b100, tag: 0xeb9f6c20ef0b8869, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7fbc9148b100, tag: 0xeb9f6c20ef0b8869, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-03-13 07:34:45,296 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60091
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fa90077f240, tag: 0x41edb177188dc98d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fa90077f240, tag: 0x41edb177188dc98d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-03-13 07:34:45,297 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60091
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fa45070c1c0, tag: 0x2d5fa8237908fdb4, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fa45070c1c0, tag: 0x2d5fa8237908fdb4, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-03-13 07:34:45,298 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60091
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f09fc0011c0, tag: 0x7ae6852e7b679d54, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f09fc0011c0, tag: 0x7ae6852e7b679d54, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-03-13 07:34:45,298 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60091
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f582dda7140, tag: 0x2de211af77439806, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f582dda7140, tag: 0x2de211af77439806, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
[1710315286.779779] [dgx13:80265:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:80265:0:80265]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  80265) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fa45dce407d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7fa45dce1c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7fa45dce1dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7fa45dd8c9f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7fa45dd63d8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7fa45dd9fafd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7fa45dda49ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7fa45dda572f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7fa45de536f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55935810704c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5593580ed3f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5593580e7fb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5593580f9469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5593580ea042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5593580e7fb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5593580f9469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5593580ea042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55935819c6d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5593580eec10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55935819c6d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5593580eec10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55935819c6d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5593580eec10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55935819c6d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5593580eec10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55935819c6d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x5593580eec10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55935819c6d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7fa484e661e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7fa484e66aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5593580f16ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x5593580ac3ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x5593580f0723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x5593580ee929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5593580f9712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5593580e94e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5593580f9712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5593580e94e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5593580f9712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5593580e94e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5593580f9712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5593580e94e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5593580e7fb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5593580f9469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x5593580ea042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5593580e7fb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x5593581068cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55935810704c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x5593581ca80e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5593580f16ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5593580ed3f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5593580f9712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x5593581069ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x5593580ed3f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5593580f9712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5593580e94e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5593580e7fb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5593580f9469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5593580e94e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x5593580f9712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x5593580e9232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x5593580e7fb4]
=================================
2024-03-13 07:34:48,647 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38259
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #034] ep: 0x7fa90077f180, tag: 0xe3105af9add2da3f, nbytes: 400027468, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #034] ep: 0x7fa90077f180, tag: 0xe3105af9add2da3f, nbytes: 400027468, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-03-13 07:34:48,650 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38259
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #032] ep: 0x7f09fc001280, tag: 0xb8e4e7e627027bb2, nbytes: 799955512, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #032] ep: 0x7f09fc001280, tag: 0xb8e4e7e627027bb2, nbytes: 799955512, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
[1710315289.346438] [dgx13:80243:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_0: LRU push returned Unsupported operation
[dgx13:80243:0:80243]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  80243) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f587807507d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f5878072c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f5878072dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f5861fa59f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f5861f7cd8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f5861fb8afd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f5861fbd9ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f5861fbe72f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f58781166f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55658f67804c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55658f65e3f6]
11  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55658f658fb4]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55658f66a469]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55658f65b042]
14  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55658f658fb4]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55658f66a469]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55658f65b042]
17  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55658f70d6d2]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55658f65fc10]
19  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55658f70d6d2]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55658f65fc10]
21  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55658f70d6d2]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55658f65fc10]
23  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55658f70d6d2]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55658f65fc10]
25  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55658f70d6d2]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5dc0) [0x55658f65fc10]
27  /opt/conda/envs/gdf/bin/python(+0x1e26d2) [0x55658f70d6d2]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f588d1251e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f588d125aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55658f6626ac]
31  /opt/conda/envs/gdf/bin/python(+0xf23ff) [0x55658f61d3ff]
32  /opt/conda/envs/gdf/bin/python(+0x136723) [0x55658f661723]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ad9) [0x55658f65f929]
34  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55658f66a712]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55658f65a4e6]
36  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55658f66a712]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55658f65a4e6]
38  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55658f66a712]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55658f65a4e6]
40  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55658f66a712]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55658f65a4e6]
42  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55658f658fb4]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55658f66a469]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f2) [0x55658f65b042]
45  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55658f658fb4]
46  /opt/conda/envs/gdf/bin/python(+0x14c8cb) [0x55658f6778cb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55658f67804c]
48  /opt/conda/envs/gdf/bin/python(+0x21080e) [0x55658f73b80e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55658f6626ac]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55658f65e3f6]
51  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55658f66a712]
52  /opt/conda/envs/gdf/bin/python(+0x14c9ac) [0x55658f6779ac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x45a6) [0x55658f65e3f6]
54  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55658f66a712]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55658f65a4e6]
56  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55658f658fb4]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55658f66a469]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55658f65a4e6]
59  /opt/conda/envs/gdf/bin/python(+0x13f712) [0x55658f66a712]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55658f65a232]
61  /opt/conda/envs/gdf/bin/python(+0x12dfb4) [0x55658f658fb4]
=================================
2024-03-13 07:34:50,021 - distributed.nanny - WARNING - Restarting worker
2024-03-13 07:34:51,225 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38881
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #045] ep: 0x7f42ecb66100, tag: 0x587a4fe550d96d41, nbytes: 99987120, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #045] ep: 0x7f42ecb66100, tag: 0x587a4fe550d96d41, nbytes: 99987120, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-03-13 07:34:51,225 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38881
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 392, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #033] ep: 0x7f0c1c520280, tag: 0xa83e617ce30f906e, nbytes: 99965160, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 398, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #033] ep: 0x7f0c1c520280, tag: 0xa83e617ce30f906e, nbytes: 99965160, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2024-03-13 07:34:51,620 - distributed.comm.ucx - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:424: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:424: Maximum pool size exceeded
2024-03-13 07:34:51,620 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:424: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2056, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2860, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 374, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 167, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:424: Maximum pool size exceeded
2024-03-13 07:34:51,938 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-03f7cb961bc271045f61fb8e929802fd', 3)
Function:  shuffle_group
args:      (                 key   payload  _partitions
0         1118863339  99051695            0
1         1152208751  78953234            4
2          639778035  81293845            2
3         1153618300  74974697            4
4         1102090160  62919800            4
...              ...       ...          ...
99999995    37713713  72068972            4
99999996  1149206659  33160153            7
99999997  1159655348  40095643            5
99999998  1152540937  33956372            0
99999999  1112812172  90324512            3

[100000000 rows x 3 columns], '_partitions', 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:424: Maximum pool size exceeded')"

2024-03-13 07:34:51,940 - distributed.worker - WARNING - Compute Failed
Key:       ('assign-105d6b45e9ac946e8c11e3f14b6522bb', 4)
Function:  subgraph_callable-12df8fff-fb5a-4f61-8b52-9fca7306
args:      (               key   payload
shuffle                     
4            11942  45783728
4            40657  68145645
4            11943  27835325
4            40669  49185928
4            11949  61644859
...            ...       ...
4        799966902  81374440
4        799966911  78552986
4        799966955  10007894
4        799966959  64839749
4        799966974  80045211

[100000000 rows x 2 columns], '_partitions', 'getitem-1a29b4ce141df7e1c12a18585d818c2c', ['key'])
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:424: Maximum pool size exceeded')"

2024-03-13 07:34:51,966 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-17901c1db354ce18edb19f318a71d952', 3)
Function:  shuffle_group
args:      (                key  shuffle   payload  _partitions
0         300000000        1  48863339            1
1         300000001        6  82208751            6
2         300000002        5  23172095            5
3         300000003        3  83618300            3
4         300000004        7  32090160            7
...             ...      ...       ...          ...
99999995  399999995        4   2417575            4
99999996  399999996        3  79206659            3
99999997  399999997        4  89655348            4
99999998  399999998        0  82540937            0
99999999  399999999        1  42812172            1

[100000000 rows x 4 columns], '_partitions', 0, 8, 8, True, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:424: Maximum pool size exceeded')"

2024-03-13 07:34:52,005 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-17901c1db354ce18edb19f318a71d952', 0)
Function:  shuffle_group
args:      (               key  shuffle   payload  _partitions
0                0        1  48863339            1
1                1        6  82208751            6
2                2        5  23172095            5
3                3        3  83618300            3
4                4        7  32090160            7
...            ...      ...       ...          ...
99999995  99999995        4   2417575            4
99999996  99999996        3  79206659            3
99999997  99999997        4  89655348            4
99999998  99999998        0  82540937            0
99999999  99999999        1  42812172            1

[100000000 rows x 4 columns], '_partitions', 0, 8, 8, True, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:424: Maximum pool size exceeded')"

2024-03-13 07:34:52,137 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-03f7cb961bc271045f61fb8e929802fd', 0)
Function:  shuffle_group
args:      (                key   payload  _partitions
0         818863339  99051695            7
1         852208751  78953234            0
2         602278035  81293845            0
3         853618300  74974697            7
4         802090160  62919800            2
...             ...       ...          ...
99999995     213713  72068972            5
99999996  849206659  33160153            6
99999997  859655348  40095643            3
99999998  852540937  33956372            6
99999999  812812172  90324512            6

[100000000 rows x 3 columns], '_partitions', 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:424: Maximum pool size exceeded')"

2024-03-13 07:34:55,513 - distributed.nanny - WARNING - Restarting worker
2024-03-13 07:34:57,533 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
