============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.2, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-10-19 05:29:47,809 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:29:47,813 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-19 05:29:47,817 - distributed.scheduler - INFO - State start
2023-10-19 05:29:47,841 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:29:47,842 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-19 05:29:47,843 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-19 05:29:47,843 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:29:48,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38401'
2023-10-19 05:29:48,041 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42719'
2023-10-19 05:29:48,045 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36573'
2023-10-19 05:29:48,058 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35629'
2023-10-19 05:29:49,649 - distributed.scheduler - INFO - Receive client connection: Client-83901d9d-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:29:49,662 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36112
2023-10-19 05:29:49,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:49,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:49,932 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:49,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:49,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:49,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:49,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:49,959 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:49,962 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:50,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:50,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:50,033 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-10-19 05:29:50,595 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38751
2023-10-19 05:29:50,596 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38751
2023-10-19 05:29:50,596 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46463
2023-10-19 05:29:50,596 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-19 05:29:50,596 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:50,596 - distributed.worker - INFO -               Threads:                          4
2023-10-19 05:29:50,596 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-19 05:29:50,596 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-3482sysz
2023-10-19 05:29:50,596 - distributed.worker - INFO - Starting Worker plugin PreImport-81e034ea-249c-4f59-aef0-dd38e650b1a0
2023-10-19 05:29:50,596 - distributed.worker - INFO - Starting Worker plugin RMMSetup-21a72a81-a26f-49b9-871f-3c5d54cbe88d
2023-10-19 05:29:50,596 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ab61e239-d025-4d43-a858-2f9bd9d4e2cc
2023-10-19 05:29:50,597 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:51,854 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38751', status: init, memory: 0, processing: 0>
2023-10-19 05:29:51,856 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38751
2023-10-19 05:29:51,856 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51856
2023-10-19 05:29:51,857 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:29:51,858 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-19 05:29:51,858 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:51,860 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-19 05:29:52,926 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41305
2023-10-19 05:29:52,927 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41305
2023-10-19 05:29:52,927 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45939
2023-10-19 05:29:52,927 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-19 05:29:52,927 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:52,927 - distributed.worker - INFO -               Threads:                          4
2023-10-19 05:29:52,927 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-19 05:29:52,927 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-vp8gm4qq
2023-10-19 05:29:52,928 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4e8c0c83-ed73-4667-9fef-458f0c89c8fc
2023-10-19 05:29:52,928 - distributed.worker - INFO - Starting Worker plugin RMMSetup-205ede78-2ca0-41ae-8557-646477d23fa2
2023-10-19 05:29:52,928 - distributed.worker - INFO - Starting Worker plugin PreImport-0b878db8-4815-4bd4-8631-5cb4970a21c0
2023-10-19 05:29:52,928 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:52,930 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43573
2023-10-19 05:29:52,931 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43573
2023-10-19 05:29:52,931 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33129
2023-10-19 05:29:52,931 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-19 05:29:52,931 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:52,931 - distributed.worker - INFO -               Threads:                          4
2023-10-19 05:29:52,931 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-19 05:29:52,931 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-f0cyeqo3
2023-10-19 05:29:52,932 - distributed.worker - INFO - Starting Worker plugin PreImport-1a9d5572-69f0-4283-ba18-a874140e13b4
2023-10-19 05:29:52,932 - distributed.worker - INFO - Starting Worker plugin RMMSetup-585ba661-089f-4b29-b1fb-6f1cf3664564
2023-10-19 05:29:52,932 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-88bdd03b-b257-4d2c-b86c-b4ff4922c80e
2023-10-19 05:29:52,932 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:52,933 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40837
2023-10-19 05:29:52,936 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40837
2023-10-19 05:29:52,936 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39385
2023-10-19 05:29:52,936 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-19 05:29:52,936 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:52,936 - distributed.worker - INFO -               Threads:                          4
2023-10-19 05:29:52,937 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-19 05:29:52,937 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-fvmyedz3
2023-10-19 05:29:52,939 - distributed.worker - INFO - Starting Worker plugin PreImport-d97ac395-d4b6-4130-ae62-abe749b76294
2023-10-19 05:29:52,940 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fea2f584-0008-42da-ac37-f3bca4f66b2a
2023-10-19 05:29:52,940 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-50fc23eb-3b04-49de-8d58-69ae74bbe633
2023-10-19 05:29:52,941 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:52,952 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41305', status: init, memory: 0, processing: 0>
2023-10-19 05:29:52,952 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41305
2023-10-19 05:29:52,953 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51858
2023-10-19 05:29:52,954 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:29:52,954 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-19 05:29:52,954 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:52,956 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-19 05:29:52,956 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43573', status: init, memory: 0, processing: 0>
2023-10-19 05:29:52,957 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43573
2023-10-19 05:29:52,957 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51872
2023-10-19 05:29:52,958 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:29:52,959 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-19 05:29:52,959 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:52,960 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-19 05:29:52,983 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40837', status: init, memory: 0, processing: 0>
2023-10-19 05:29:52,984 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40837
2023-10-19 05:29:52,984 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51880
2023-10-19 05:29:52,985 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:29:52,986 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-19 05:29:52,986 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:29:52,988 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-19 05:29:53,009 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-19 05:29:53,009 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-19 05:29:53,009 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-19 05:29:53,009 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-19 05:29:53,015 - distributed.scheduler - INFO - Remove client Client-83901d9d-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:29:53,015 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36112; closing.
2023-10-19 05:29:53,015 - distributed.scheduler - INFO - Remove client Client-83901d9d-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:29:53,016 - distributed.scheduler - INFO - Close client connection: Client-83901d9d-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:29:53,016 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38401'. Reason: nanny-close
2023-10-19 05:29:53,017 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:29:53,018 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42719'. Reason: nanny-close
2023-10-19 05:29:53,018 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:29:53,018 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41305. Reason: nanny-close
2023-10-19 05:29:53,018 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36573'. Reason: nanny-close
2023-10-19 05:29:53,018 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:29:53,019 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40837. Reason: nanny-close
2023-10-19 05:29:53,019 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35629'. Reason: nanny-close
2023-10-19 05:29:53,019 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:29:53,019 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43573. Reason: nanny-close
2023-10-19 05:29:53,020 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38751. Reason: nanny-close
2023-10-19 05:29:53,020 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51858; closing.
2023-10-19 05:29:53,020 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-19 05:29:53,020 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41305', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693393.02059')
2023-10-19 05:29:53,020 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-19 05:29:53,021 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-19 05:29:53,021 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51880; closing.
2023-10-19 05:29:53,021 - distributed.nanny - INFO - Worker closed
2023-10-19 05:29:53,022 - distributed.nanny - INFO - Worker closed
2023-10-19 05:29:53,022 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40837', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693393.0223815')
2023-10-19 05:29:53,022 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51872; closing.
2023-10-19 05:29:53,023 - distributed.nanny - INFO - Worker closed
2023-10-19 05:29:53,023 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-19 05:29:53,023 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43573', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693393.0233254')
2023-10-19 05:29:53,023 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51856; closing.
2023-10-19 05:29:53,024 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38751', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693393.0240636')
2023-10-19 05:29:53,024 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:29:53,025 - distributed.nanny - INFO - Worker closed
2023-10-19 05:29:54,284 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:29:54,284 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:29:54,284 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:29:54,285 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-19 05:29:54,286 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-10-19 05:29:56,700 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:29:56,705 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-19 05:29:56,708 - distributed.scheduler - INFO - State start
2023-10-19 05:29:56,731 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:29:56,733 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:29:56,733 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-19 05:29:56,734 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:29:56,846 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40247'
2023-10-19 05:29:56,857 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37049'
2023-10-19 05:29:56,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38995'
2023-10-19 05:29:56,875 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40817'
2023-10-19 05:29:56,890 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35237'
2023-10-19 05:29:56,893 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34767'
2023-10-19 05:29:56,902 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39489'
2023-10-19 05:29:56,912 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33851'
2023-10-19 05:29:58,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:58,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:58,760 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:58,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:58,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:58,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:58,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:58,776 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:58,777 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:58,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:58,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:58,834 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:58,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:58,841 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:58,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:58,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:58,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:58,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:58,845 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:58,846 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:58,847 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:29:58,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:29:58,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:29:58,855 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:00,395 - distributed.scheduler - INFO - Receive client connection: Client-88e6df00-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:00,406 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36646
2023-10-19 05:30:01,649 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34487
2023-10-19 05:30:01,650 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34487
2023-10-19 05:30:01,650 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34789
2023-10-19 05:30:01,650 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,650 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,650 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:01,650 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:01,650 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-15fetcyx
2023-10-19 05:30:01,651 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c3b9fac4-4cdb-4a8b-a0b2-827fde3d4506
2023-10-19 05:30:01,651 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45915
2023-10-19 05:30:01,651 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45915
2023-10-19 05:30:01,652 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35029
2023-10-19 05:30:01,652 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,652 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,652 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:01,652 - distributed.worker - INFO - Starting Worker plugin PreImport-861ace46-d5ff-4c2e-80f8-67f6a1b78ae9
2023-10-19 05:30:01,652 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:01,652 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zerghch8
2023-10-19 05:30:01,652 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b2017273-01a8-43ee-962a-ff7722f26aad
2023-10-19 05:30:01,653 - distributed.worker - INFO - Starting Worker plugin RMMSetup-140bfad8-d399-4cf2-9b6a-33f870a72319
2023-10-19 05:30:01,651 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36641
2023-10-19 05:30:01,653 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36641
2023-10-19 05:30:01,653 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39343
2023-10-19 05:30:01,653 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,653 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,653 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:01,653 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:01,653 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jw7hy6_r
2023-10-19 05:30:01,654 - distributed.worker - INFO - Starting Worker plugin RMMSetup-64489505-ced2-4c03-8269-1ad70e980674
2023-10-19 05:30:01,663 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34681
2023-10-19 05:30:01,665 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34681
2023-10-19 05:30:01,665 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37633
2023-10-19 05:30:01,665 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,665 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,665 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:01,666 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:01,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2x0yhzot
2023-10-19 05:30:01,667 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5913d8c8-a8bb-449d-8975-a930b00ece3e
2023-10-19 05:30:01,734 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35643
2023-10-19 05:30:01,735 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35643
2023-10-19 05:30:01,735 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36003
2023-10-19 05:30:01,735 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,735 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,735 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:01,735 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:01,735 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zq5l246g
2023-10-19 05:30:01,736 - distributed.worker - INFO - Starting Worker plugin RMMSetup-799a73db-1b1a-4061-8af4-73277074b640
2023-10-19 05:30:01,746 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44641
2023-10-19 05:30:01,747 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44641
2023-10-19 05:30:01,747 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38889
2023-10-19 05:30:01,747 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,747 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,747 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:01,747 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:01,747 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7y7elpmy
2023-10-19 05:30:01,748 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3c13df1f-8866-4cd6-8446-f19cf2bb20fc
2023-10-19 05:30:01,759 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36817
2023-10-19 05:30:01,759 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36817
2023-10-19 05:30:01,759 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37897
2023-10-19 05:30:01,759 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,760 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,760 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:01,760 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:01,760 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qoxty3o2
2023-10-19 05:30:01,760 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43341
2023-10-19 05:30:01,760 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-99e2b8b7-9df3-4739-903a-e97acbfcb269
2023-10-19 05:30:01,760 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43341
2023-10-19 05:30:01,760 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42661
2023-10-19 05:30:01,760 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,760 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,761 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:01,761 - distributed.worker - INFO - Starting Worker plugin RMMSetup-da4ba143-5857-4c92-9908-822b39b1d53a
2023-10-19 05:30:01,761 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:01,761 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mi57aibr
2023-10-19 05:30:01,761 - distributed.worker - INFO - Starting Worker plugin RMMSetup-083fa75f-c97f-4bca-a8e9-963eb30f6e15
2023-10-19 05:30:01,802 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-401d60b3-bff9-4173-b9ae-4f595744cc3a
2023-10-19 05:30:01,802 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3235d3b0-ce74-4eb3-8eb1-2f0bc4c11e3e
2023-10-19 05:30:01,802 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c2dd074d-329a-4f2f-aecd-b7d289c8dffb
2023-10-19 05:30:01,802 - distributed.worker - INFO - Starting Worker plugin PreImport-67fe1e72-a641-4af3-8e5e-870ff8bad20e
2023-10-19 05:30:01,803 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,803 - distributed.worker - INFO - Starting Worker plugin PreImport-652c2282-f4e3-4a6a-9b20-a577e94a332c
2023-10-19 05:30:01,803 - distributed.worker - INFO - Starting Worker plugin PreImport-dca232d8-8afc-4cea-ac54-e9d79df71734
2023-10-19 05:30:01,803 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,804 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,823 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,829 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34681', status: init, memory: 0, processing: 0>
2023-10-19 05:30:01,830 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34681
2023-10-19 05:30:01,830 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36668
2023-10-19 05:30:01,831 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36641', status: init, memory: 0, processing: 0>
2023-10-19 05:30:01,831 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36641
2023-10-19 05:30:01,832 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36672
2023-10-19 05:30:01,831 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:01,832 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,832 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,833 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:01,834 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45915', status: init, memory: 0, processing: 0>
2023-10-19 05:30:01,834 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,834 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,834 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:01,834 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45915
2023-10-19 05:30:01,834 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36682
2023-10-19 05:30:01,835 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:01,836 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:01,837 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,837 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,839 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:01,857 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34487', status: init, memory: 0, processing: 0>
2023-10-19 05:30:01,857 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34487
2023-10-19 05:30:01,857 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36692
2023-10-19 05:30:01,859 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:01,860 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,861 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,863 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:01,884 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-27825751-6c0d-45b8-bb7b-ec99f55a7392
2023-10-19 05:30:01,885 - distributed.worker - INFO - Starting Worker plugin PreImport-615671c9-99a0-4643-ad0f-7f339d142d2e
2023-10-19 05:30:01,885 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,892 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c9c0714f-5744-44e2-b54d-99f5084421ec
2023-10-19 05:30:01,892 - distributed.worker - INFO - Starting Worker plugin PreImport-60ae6c6e-dde1-4dfa-b143-c3da05a5531b
2023-10-19 05:30:01,892 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-297eb15d-85c7-47a3-8a06-d2aec42c0d1e
2023-10-19 05:30:01,892 - distributed.worker - INFO - Starting Worker plugin PreImport-ded6c33f-70fe-4e5f-81cc-7f2c2caabdee
2023-10-19 05:30:01,892 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,893 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,893 - distributed.worker - INFO - Starting Worker plugin PreImport-a33d1c35-f096-43fd-8664-0124cd5f9c73
2023-10-19 05:30:01,894 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,908 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35643', status: init, memory: 0, processing: 0>
2023-10-19 05:30:01,908 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35643
2023-10-19 05:30:01,908 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36706
2023-10-19 05:30:01,910 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:01,911 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,911 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,912 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:01,914 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43341', status: init, memory: 0, processing: 0>
2023-10-19 05:30:01,915 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43341
2023-10-19 05:30:01,915 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36712
2023-10-19 05:30:01,916 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:01,917 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,917 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,918 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:01,923 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36817', status: init, memory: 0, processing: 0>
2023-10-19 05:30:01,923 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36817
2023-10-19 05:30:01,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36722
2023-10-19 05:30:01,924 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44641', status: init, memory: 0, processing: 0>
2023-10-19 05:30:01,925 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44641
2023-10-19 05:30:01,925 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36736
2023-10-19 05:30:01,925 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:01,926 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,926 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,926 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:01,927 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:01,927 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:01,928 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:01,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:01,953 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:01,953 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:01,953 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:01,953 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:01,954 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:01,954 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:01,954 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:01,954 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:01,958 - distributed.scheduler - INFO - Remove client Client-88e6df00-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:01,959 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36646; closing.
2023-10-19 05:30:01,959 - distributed.scheduler - INFO - Remove client Client-88e6df00-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:01,959 - distributed.scheduler - INFO - Close client connection: Client-88e6df00-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:01,960 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40247'. Reason: nanny-close
2023-10-19 05:30:01,961 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:01,962 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37049'. Reason: nanny-close
2023-10-19 05:30:01,962 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:01,963 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38995'. Reason: nanny-close
2023-10-19 05:30:01,963 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:01,963 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45915. Reason: nanny-close
2023-10-19 05:30:01,963 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34487. Reason: nanny-close
2023-10-19 05:30:01,963 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40817'. Reason: nanny-close
2023-10-19 05:30:01,963 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:01,964 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36641. Reason: nanny-close
2023-10-19 05:30:01,964 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35237'. Reason: nanny-close
2023-10-19 05:30:01,964 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34767'. Reason: nanny-close
2023-10-19 05:30:01,964 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43341. Reason: nanny-close
2023-10-19 05:30:01,964 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39489'. Reason: nanny-close
2023-10-19 05:30:01,964 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:01,965 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33851'. Reason: nanny-close
2023-10-19 05:30:01,965 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:01,965 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34681. Reason: nanny-close
2023-10-19 05:30:01,965 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:01,965 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36682; closing.
2023-10-19 05:30:01,966 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35643. Reason: nanny-close
2023-10-19 05:30:01,966 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45915', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693401.9660711')
2023-10-19 05:30:01,966 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:01,966 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:01,966 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:01,967 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36672; closing.
2023-10-19 05:30:01,967 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:01,967 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:01,967 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:01,967 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:01,967 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:01,968 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36641', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693401.9681025')
2023-10-19 05:30:01,968 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36712; closing.
2023-10-19 05:30:01,968 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:01,968 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36692; closing.
2023-10-19 05:30:01,968 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:01,969 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:01,969 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43341', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693401.9694076')
2023-10-19 05:30:01,969 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36668; closing.
2023-10-19 05:30:01,970 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34487', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693401.9699903')
2023-10-19 05:30:01,970 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34681', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693401.9705575')
2023-10-19 05:30:01,970 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36706; closing.
2023-10-19 05:30:01,971 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35643', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693401.9712663')
2023-10-19 05:30:01,971 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:01,972 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:01,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36817. Reason: nanny-close
2023-10-19 05:30:01,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44641. Reason: nanny-close
2023-10-19 05:30:01,974 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36722; closing.
2023-10-19 05:30:01,975 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:01,975 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36817', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693401.975223')
2023-10-19 05:30:01,975 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:01,975 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36736; closing.
2023-10-19 05:30:01,976 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44641', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693401.975963')
2023-10-19 05:30:01,976 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:30:01,976 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:01,977 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:03,477 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:30:03,478 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:30:03,479 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:30:03,480 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:30:03,480 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-10-19 05:30:05,781 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:05,785 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43269 instead
  warnings.warn(
2023-10-19 05:30:05,790 - distributed.scheduler - INFO - State start
2023-10-19 05:30:05,813 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:05,814 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:30:05,814 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43269/status
2023-10-19 05:30:05,814 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:30:05,821 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38891'
2023-10-19 05:30:05,840 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36885'
2023-10-19 05:30:05,842 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37901'
2023-10-19 05:30:05,850 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36967'
2023-10-19 05:30:05,858 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34707'
2023-10-19 05:30:05,859 - distributed.scheduler - INFO - Receive client connection: Client-8e4db661-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:05,867 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42025'
2023-10-19 05:30:05,872 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36894
2023-10-19 05:30:05,877 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39639'
2023-10-19 05:30:05,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45481'
2023-10-19 05:30:07,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:07,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:07,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:07,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:07,738 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:07,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:07,738 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:07,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:07,742 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:07,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:07,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:07,765 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:07,768 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:07,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:07,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:07,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:07,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:07,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:07,773 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:07,775 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:07,776 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:07,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:07,818 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:07,822 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:10,967 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34675
2023-10-19 05:30:10,968 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34675
2023-10-19 05:30:10,968 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45311
2023-10-19 05:30:10,968 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:10,968 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:10,968 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:10,968 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:10,968 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-omp6gk1d
2023-10-19 05:30:10,969 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5cbd22cd-4c45-4857-94aa-c52860e5069f
2023-10-19 05:30:10,969 - distributed.worker - INFO - Starting Worker plugin RMMSetup-701229f7-5996-4d29-a521-b64c7ea73813
2023-10-19 05:30:11,009 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40755
2023-10-19 05:30:11,010 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40755
2023-10-19 05:30:11,010 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33853
2023-10-19 05:30:11,010 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,011 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,011 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:11,011 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:11,011 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c6ccayit
2023-10-19 05:30:11,011 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-42acb65a-bc2e-40f4-89a5-dd95aa137ed9
2023-10-19 05:30:11,011 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8d578780-35cc-41e8-b5d7-cbc61a999c9f
2023-10-19 05:30:11,028 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38603
2023-10-19 05:30:11,029 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38603
2023-10-19 05:30:11,029 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46863
2023-10-19 05:30:11,029 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,029 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,029 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:11,030 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:11,030 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tp8bhwlm
2023-10-19 05:30:11,030 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b0b6f322-4343-41d5-a4cc-9d2e7de1f94d
2023-10-19 05:30:11,031 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cce8d9ba-ef8e-4cab-90fe-935d2650d277
2023-10-19 05:30:11,031 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38351
2023-10-19 05:30:11,032 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38351
2023-10-19 05:30:11,032 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35555
2023-10-19 05:30:11,032 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,032 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,032 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:11,032 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:11,032 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oc49ezuo
2023-10-19 05:30:11,033 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-35b37480-011b-4c39-9500-dbc5e8ff749e
2023-10-19 05:30:11,033 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2ffd765e-874e-4049-910e-4145f534fb09
2023-10-19 05:30:11,034 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38855
2023-10-19 05:30:11,034 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38855
2023-10-19 05:30:11,035 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35861
2023-10-19 05:30:11,035 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,035 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,035 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:11,035 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:11,035 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rs0v0tbq
2023-10-19 05:30:11,035 - distributed.worker - INFO - Starting Worker plugin PreImport-c3129d2f-c089-4e25-b224-1698f933e130
2023-10-19 05:30:11,036 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38c02495-7046-4c1f-8553-946224cb3340
2023-10-19 05:30:11,036 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d8b0467c-cd72-4cab-8cda-1c9a111dff65
2023-10-19 05:30:11,036 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41467
2023-10-19 05:30:11,037 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41467
2023-10-19 05:30:11,037 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39815
2023-10-19 05:30:11,037 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,037 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,037 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:11,037 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:11,037 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sxu99q53
2023-10-19 05:30:11,037 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-278b553b-28a7-4982-aa08-c0f8b6cba66b
2023-10-19 05:30:11,038 - distributed.worker - INFO - Starting Worker plugin PreImport-a0ebf463-2015-472c-8f12-29d3f67a59d2
2023-10-19 05:30:11,039 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cdd4f32a-74ec-47f9-be7b-53a842f37adb
2023-10-19 05:30:11,043 - distributed.worker - INFO - Starting Worker plugin PreImport-f95e74b3-20e0-4df3-ab6e-382d6d19525a
2023-10-19 05:30:11,043 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,053 - distributed.worker - INFO - Starting Worker plugin PreImport-66f65831-e900-4649-aea8-fd0bbea4c26e
2023-10-19 05:30:11,053 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,060 - distributed.worker - INFO - Starting Worker plugin PreImport-4f558ded-93b6-434f-9443-379a3dd30ab6
2023-10-19 05:30:11,061 - distributed.worker - INFO - Starting Worker plugin PreImport-353f9557-536c-432b-8ae3-36d85ebae5ea
2023-10-19 05:30:11,061 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,061 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,062 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,064 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,074 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34675', status: init, memory: 0, processing: 0>
2023-10-19 05:30:11,076 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34675
2023-10-19 05:30:11,076 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38540
2023-10-19 05:30:11,077 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40755', status: init, memory: 0, processing: 0>
2023-10-19 05:30:11,078 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40755
2023-10-19 05:30:11,078 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38542
2023-10-19 05:30:11,078 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:11,079 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,079 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:11,079 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,080 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,080 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,081 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:11,081 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:11,129 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38855', status: init, memory: 0, processing: 0>
2023-10-19 05:30:11,130 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38855
2023-10-19 05:30:11,130 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38574
2023-10-19 05:30:11,131 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38351', status: init, memory: 0, processing: 0>
2023-10-19 05:30:11,131 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:11,132 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38351
2023-10-19 05:30:11,132 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38548
2023-10-19 05:30:11,132 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,132 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,132 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41467', status: init, memory: 0, processing: 0>
2023-10-19 05:30:11,133 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:11,133 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41467
2023-10-19 05:30:11,133 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38586
2023-10-19 05:30:11,133 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,133 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,133 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38603', status: init, memory: 0, processing: 0>
2023-10-19 05:30:11,134 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:11,134 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38603
2023-10-19 05:30:11,134 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38562
2023-10-19 05:30:11,134 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:11,135 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:11,135 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,135 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,135 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:11,137 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,137 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,138 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:11,139 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:11,156 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39593
2023-10-19 05:30:11,157 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39593
2023-10-19 05:30:11,157 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46273
2023-10-19 05:30:11,157 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,157 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,157 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:11,157 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:11,157 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ugxsbcy4
2023-10-19 05:30:11,158 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c1079ada-7bda-4afc-a248-e88f11f38b65
2023-10-19 05:30:11,162 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41779
2023-10-19 05:30:11,164 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41779
2023-10-19 05:30:11,164 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45007
2023-10-19 05:30:11,164 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,164 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,164 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:11,164 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:11,164 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k4e216cj
2023-10-19 05:30:11,165 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5acd4765-1985-42dd-b863-159c96085e55
2023-10-19 05:30:11,166 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-964b7570-fee5-4f06-a006-3f40e9ef35f8
2023-10-19 05:30:11,166 - distributed.worker - INFO - Starting Worker plugin PreImport-e426812e-e70f-4ad4-9844-682ea2e4b892
2023-10-19 05:30:11,166 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,171 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fea050e8-152e-4b1b-a37a-a0d0d7015eca
2023-10-19 05:30:11,171 - distributed.worker - INFO - Starting Worker plugin PreImport-b07a1654-c269-4368-94b5-4ad1d3a93e25
2023-10-19 05:30:11,171 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,192 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39593', status: init, memory: 0, processing: 0>
2023-10-19 05:30:11,193 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39593
2023-10-19 05:30:11,193 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38594
2023-10-19 05:30:11,194 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:11,195 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,195 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,196 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:11,203 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41779', status: init, memory: 0, processing: 0>
2023-10-19 05:30:11,204 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41779
2023-10-19 05:30:11,204 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38600
2023-10-19 05:30:11,205 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:11,207 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:11,207 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:11,209 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:11,295 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:11,295 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:11,295 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:11,295 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:11,295 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:11,296 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:11,296 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:11,296 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:11,301 - distributed.scheduler - INFO - Remove client Client-8e4db661-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:11,301 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36894; closing.
2023-10-19 05:30:11,301 - distributed.scheduler - INFO - Remove client Client-8e4db661-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:11,302 - distributed.scheduler - INFO - Close client connection: Client-8e4db661-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:11,303 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36967'. Reason: nanny-close
2023-10-19 05:30:11,303 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:11,304 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34707'. Reason: nanny-close
2023-10-19 05:30:11,304 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:11,304 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41467. Reason: nanny-close
2023-10-19 05:30:11,305 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42025'. Reason: nanny-close
2023-10-19 05:30:11,305 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:11,305 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34675. Reason: nanny-close
2023-10-19 05:30:11,305 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39639'. Reason: nanny-close
2023-10-19 05:30:11,305 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:11,306 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39593. Reason: nanny-close
2023-10-19 05:30:11,306 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45481'. Reason: nanny-close
2023-10-19 05:30:11,306 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:11,306 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38855. Reason: nanny-close
2023-10-19 05:30:11,306 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38891'. Reason: nanny-close
2023-10-19 05:30:11,307 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:11,307 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38586; closing.
2023-10-19 05:30:11,307 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:11,307 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41779. Reason: nanny-close
2023-10-19 05:30:11,307 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41467', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693411.3076813')
2023-10-19 05:30:11,307 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36885'. Reason: nanny-close
2023-10-19 05:30:11,307 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:11,307 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:11,308 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:11,308 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38603. Reason: nanny-close
2023-10-19 05:30:11,308 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37901'. Reason: nanny-close
2023-10-19 05:30:11,308 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:11,308 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:11,308 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38351. Reason: nanny-close
2023-10-19 05:30:11,309 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40755. Reason: nanny-close
2023-10-19 05:30:11,309 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:11,309 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:11,309 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38574; closing.
2023-10-19 05:30:11,309 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38594; closing.
2023-10-19 05:30:11,309 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38540; closing.
2023-10-19 05:30:11,309 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:11,309 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:11,310 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38855', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693411.3105211')
2023-10-19 05:30:11,310 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:11,310 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:11,310 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39593', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693411.3109126')
2023-10-19 05:30:11,311 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34675', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693411.311267')
2023-10-19 05:30:11,311 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:11,312 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:11,312 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38600; closing.
2023-10-19 05:30:11,312 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:11,312 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:11,312 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:11,312 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41779', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693411.3127275')
2023-10-19 05:30:11,313 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38548; closing.
2023-10-19 05:30:11,313 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38562; closing.
2023-10-19 05:30:11,313 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38542; closing.
2023-10-19 05:30:11,313 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38351', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693411.3137653')
2023-10-19 05:30:11,314 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38603', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693411.3141384')
2023-10-19 05:30:11,314 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:11,314 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40755', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693411.3144996')
2023-10-19 05:30:11,314 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:30:12,821 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:30:12,821 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:30:12,822 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:30:12,823 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:30:12,824 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-10-19 05:30:14,956 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:14,960 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45353 instead
  warnings.warn(
2023-10-19 05:30:14,965 - distributed.scheduler - INFO - State start
2023-10-19 05:30:14,986 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:14,987 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:30:14,987 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45353/status
2023-10-19 05:30:14,988 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:30:15,117 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35267'
2023-10-19 05:30:15,130 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44509'
2023-10-19 05:30:15,143 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40485'
2023-10-19 05:30:15,153 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36659'
2023-10-19 05:30:15,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44869'
2023-10-19 05:30:15,163 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44447'
2023-10-19 05:30:15,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44637'
2023-10-19 05:30:15,182 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34505'
2023-10-19 05:30:16,881 - distributed.scheduler - INFO - Receive client connection: Client-93dc8cd4-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:16,901 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38786
2023-10-19 05:30:17,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:17,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:17,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:17,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:17,062 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:17,063 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:17,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:17,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:17,092 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:17,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:17,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:17,142 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:17,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:17,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:17,152 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:17,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:17,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:17,169 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:17,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:17,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:17,180 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:17,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:17,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:17,190 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:21,375 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38271
2023-10-19 05:30:21,376 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38271
2023-10-19 05:30:21,376 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45689
2023-10-19 05:30:21,376 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:21,376 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:21,376 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:21,376 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:21,376 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wilz07yt
2023-10-19 05:30:21,374 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46829
2023-10-19 05:30:21,376 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46829
2023-10-19 05:30:21,376 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36029
2023-10-19 05:30:21,376 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37311
2023-10-19 05:30:21,376 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36029
2023-10-19 05:30:21,376 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:21,376 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41257
2023-10-19 05:30:21,377 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:21,377 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:21,377 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ee9fbb41-f847-4343-9395-e51c878fddb5
2023-10-19 05:30:21,377 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:21,377 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:21,377 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:21,377 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:21,377 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:21,377 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b_1563fw
2023-10-19 05:30:21,377 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-10034kk7
2023-10-19 05:30:21,377 - distributed.worker - INFO - Starting Worker plugin PreImport-ebd14057-6122-4948-b8e0-af16d5f15a6a
2023-10-19 05:30:21,378 - distributed.worker - INFO - Starting Worker plugin RMMSetup-97ef5f10-3a6c-4dc2-9a7a-218405d1e0b6
2023-10-19 05:30:21,378 - distributed.worker - INFO - Starting Worker plugin RMMSetup-88ea27be-b986-4a65-982b-6fc3a8a03023
2023-10-19 05:30:21,376 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43681
2023-10-19 05:30:21,379 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43681
2023-10-19 05:30:21,379 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41253
2023-10-19 05:30:21,379 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:21,379 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:21,379 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:21,379 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:21,379 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dzv_i8g4
2023-10-19 05:30:21,381 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ca55e2f9-3073-4614-95ba-645b267803e8
2023-10-19 05:30:21,623 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36423
2023-10-19 05:30:21,624 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36423
2023-10-19 05:30:21,624 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41805
2023-10-19 05:30:21,624 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:21,624 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:21,624 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:21,624 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:21,624 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_md9yp__
2023-10-19 05:30:21,625 - distributed.worker - INFO - Starting Worker plugin RMMSetup-53fdd50f-fc19-4506-8d7e-e2c9c05228a5
2023-10-19 05:30:21,642 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40259
2023-10-19 05:30:21,644 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40259
2023-10-19 05:30:21,644 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40235
2023-10-19 05:30:21,644 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:21,644 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:21,644 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:21,644 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:21,644 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7g96og80
2023-10-19 05:30:21,646 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-20acfde9-27cb-4cda-9c75-d33dbe28401c
2023-10-19 05:30:21,646 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4c110432-ba0e-4bc5-9960-88b85b418e5d
2023-10-19 05:30:21,645 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39951
2023-10-19 05:30:21,647 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39951
2023-10-19 05:30:21,647 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39633
2023-10-19 05:30:21,647 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:21,647 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:21,647 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:21,647 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:21,647 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f_9qp4xm
2023-10-19 05:30:21,649 - distributed.worker - INFO - Starting Worker plugin RMMSetup-657a786d-1a10-45e6-afba-b1b151878d19
2023-10-19 05:30:21,662 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36893
2023-10-19 05:30:21,664 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36893
2023-10-19 05:30:21,664 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46631
2023-10-19 05:30:21,664 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:21,664 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:21,664 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:21,664 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:21,664 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hw5z4vg3
2023-10-19 05:30:21,665 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cf39bf08-7584-4110-8193-ef89929f3b4d
2023-10-19 05:30:22,095 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a3ec5c0d-dd56-4338-a9aa-625b907c0591
2023-10-19 05:30:22,096 - distributed.worker - INFO - Starting Worker plugin PreImport-2531f926-0e4c-428b-9386-9ecd38bf6e19
2023-10-19 05:30:22,097 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,100 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d73f08f7-4801-4e20-b942-b2c1969a7a1a
2023-10-19 05:30:22,101 - distributed.worker - INFO - Starting Worker plugin PreImport-4a8f15b0-03e0-48d3-8ac8-71b660afce67
2023-10-19 05:30:22,102 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,106 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-790475c5-378f-41cd-aeb3-5fe5f72d30de
2023-10-19 05:30:22,108 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,111 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-60c88436-66f2-4f82-91f1-7cbea021e3ca
2023-10-19 05:30:22,112 - distributed.worker - INFO - Starting Worker plugin PreImport-3a458b28-472c-44b3-a91b-4b009dd7824a
2023-10-19 05:30:22,113 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,129 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46829', status: init, memory: 0, processing: 0>
2023-10-19 05:30:22,131 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46829
2023-10-19 05:30:22,131 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34784
2023-10-19 05:30:22,132 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:22,133 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:22,133 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,135 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:22,148 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36029', status: init, memory: 0, processing: 0>
2023-10-19 05:30:22,148 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36029
2023-10-19 05:30:22,149 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34798
2023-10-19 05:30:22,150 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:22,152 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:22,152 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43681', status: init, memory: 0, processing: 0>
2023-10-19 05:30:22,152 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,152 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43681
2023-10-19 05:30:22,152 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34800
2023-10-19 05:30:22,153 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38271', status: init, memory: 0, processing: 0>
2023-10-19 05:30:22,153 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:22,154 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38271
2023-10-19 05:30:22,154 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34786
2023-10-19 05:30:22,154 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:22,155 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:22,155 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,156 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:22,156 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:22,157 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:22,157 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,160 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:22,161 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-94f12b9b-3103-42d9-9eef-91bcdc036e02
2023-10-19 05:30:22,161 - distributed.worker - INFO - Starting Worker plugin PreImport-efdbc86a-b749-4aa8-8717-f273cbfd611b
2023-10-19 05:30:22,162 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,171 - distributed.worker - INFO - Starting Worker plugin PreImport-3932d26a-4db7-47c8-b5fc-c73c29eb2fc4
2023-10-19 05:30:22,171 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6864a06b-9878-4817-8dc2-920bf0f730e1
2023-10-19 05:30:22,171 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,172 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cc5dacc1-1878-46d2-b076-bda083ee4847
2023-10-19 05:30:22,172 - distributed.worker - INFO - Starting Worker plugin PreImport-44fd227d-e7d1-4b59-bcd5-b674d3cd03ce
2023-10-19 05:30:22,172 - distributed.worker - INFO - Starting Worker plugin PreImport-75f6b009-153d-4837-b35d-be8b9835cf0c
2023-10-19 05:30:22,172 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,172 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,506 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40259', status: init, memory: 0, processing: 0>
2023-10-19 05:30:22,507 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40259
2023-10-19 05:30:22,507 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34828
2023-10-19 05:30:22,508 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36423', status: init, memory: 0, processing: 0>
2023-10-19 05:30:22,508 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36423
2023-10-19 05:30:22,509 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34812
2023-10-19 05:30:22,508 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:22,509 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39951', status: init, memory: 0, processing: 0>
2023-10-19 05:30:22,510 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39951
2023-10-19 05:30:22,510 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:22,510 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,510 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34830
2023-10-19 05:30:22,510 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:22,510 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36893', status: init, memory: 0, processing: 0>
2023-10-19 05:30:22,511 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:22,511 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,511 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36893
2023-10-19 05:30:22,511 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34818
2023-10-19 05:30:22,511 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:22,512 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:22,512 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:22,512 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,513 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:22,513 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:22,514 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:22,514 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:22,515 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:22,516 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:22,554 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:22,554 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:22,554 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:22,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:22,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:22,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:22,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:22,555 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:22,567 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:22,568 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:22,568 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:22,568 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:22,568 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:22,568 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:22,568 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:22,568 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:22,576 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:22,578 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:22,580 - distributed.scheduler - INFO - Remove client Client-93dc8cd4-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:22,581 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38786; closing.
2023-10-19 05:30:22,581 - distributed.scheduler - INFO - Remove client Client-93dc8cd4-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:22,582 - distributed.scheduler - INFO - Close client connection: Client-93dc8cd4-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:22,582 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35267'. Reason: nanny-close
2023-10-19 05:30:22,583 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:22,584 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44509'. Reason: nanny-close
2023-10-19 05:30:22,584 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:22,584 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36029. Reason: nanny-close
2023-10-19 05:30:22,585 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40485'. Reason: nanny-close
2023-10-19 05:30:22,585 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:22,585 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36659'. Reason: nanny-close
2023-10-19 05:30:22,585 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38271. Reason: nanny-close
2023-10-19 05:30:22,585 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:22,586 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44869'. Reason: nanny-close
2023-10-19 05:30:22,586 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43681. Reason: nanny-close
2023-10-19 05:30:22,586 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:22,586 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44447'. Reason: nanny-close
2023-10-19 05:30:22,586 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46829. Reason: nanny-close
2023-10-19 05:30:22,587 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:22,587 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34798; closing.
2023-10-19 05:30:22,587 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40259. Reason: nanny-close
2023-10-19 05:30:22,587 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:22,587 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44637'. Reason: nanny-close
2023-10-19 05:30:22,587 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36029', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693422.5876865')
2023-10-19 05:30:22,587 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:22,587 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39951. Reason: nanny-close
2023-10-19 05:30:22,588 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:22,588 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34505'. Reason: nanny-close
2023-10-19 05:30:22,588 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:22,588 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36423. Reason: nanny-close
2023-10-19 05:30:22,588 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:22,588 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:22,589 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36893. Reason: nanny-close
2023-10-19 05:30:22,589 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:22,589 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34800; closing.
2023-10-19 05:30:22,589 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:22,589 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:22,589 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34786; closing.
2023-10-19 05:30:22,590 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:22,590 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:22,590 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:22,590 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43681', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693422.590699')
2023-10-19 05:30:22,591 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:22,591 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34784; closing.
2023-10-19 05:30:22,591 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38271', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693422.591326')
2023-10-19 05:30:22,591 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:22,592 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:22,592 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46829', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693422.592357')
2023-10-19 05:30:22,592 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:22,592 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:22,592 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34828; closing.
2023-10-19 05:30:22,592 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34830; closing.
2023-10-19 05:30:22,593 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40259', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693422.5935388')
2023-10-19 05:30:22,593 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:22,593 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39951', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693422.593868')
2023-10-19 05:30:22,594 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34812; closing.
2023-10-19 05:30:22,594 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36423', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693422.5947251')
2023-10-19 05:30:22,595 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34818; closing.
2023-10-19 05:30:22,595 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36893', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693422.5954983')
2023-10-19 05:30:22,595 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:30:24,401 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:30:24,401 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:30:24,402 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:30:24,403 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:30:24,403 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-10-19 05:30:26,704 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:26,709 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-19 05:30:26,713 - distributed.scheduler - INFO - State start
2023-10-19 05:30:26,783 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:26,784 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:30:26,786 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-19 05:30:26,786 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:30:27,017 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37241'
2023-10-19 05:30:27,031 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40417'
2023-10-19 05:30:27,049 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38677'
2023-10-19 05:30:27,051 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41911'
2023-10-19 05:30:27,061 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34999'
2023-10-19 05:30:27,070 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43229'
2023-10-19 05:30:27,079 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40475'
2023-10-19 05:30:27,091 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44097'
2023-10-19 05:30:28,971 - distributed.scheduler - INFO - Receive client connection: Client-9abbd7e6-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:28,984 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34958
2023-10-19 05:30:28,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:28,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:28,999 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:29,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:29,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:29,012 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:29,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:29,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:29,016 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:29,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:29,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:29,029 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:29,068 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:29,068 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:29,076 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:29,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:29,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:29,103 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:29,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:29,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:29,133 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:29,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:29,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:29,144 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:32,175 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38183
2023-10-19 05:30:32,176 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38183
2023-10-19 05:30:32,176 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33863
2023-10-19 05:30:32,176 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,176 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,176 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:32,176 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:32,177 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bxcbld8z
2023-10-19 05:30:32,177 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1b831d73-147a-473f-bd4e-ac8a02a57b93
2023-10-19 05:30:32,306 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a24f9cca-989b-40e3-b4f4-a0cbddffa2f8
2023-10-19 05:30:32,306 - distributed.worker - INFO - Starting Worker plugin PreImport-b0663553-c462-480c-b028-66aa5338290e
2023-10-19 05:30:32,306 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,336 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38183', status: init, memory: 0, processing: 0>
2023-10-19 05:30:32,337 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38183
2023-10-19 05:30:32,337 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60128
2023-10-19 05:30:32,338 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:32,339 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,339 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,340 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:32,369 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33563
2023-10-19 05:30:32,370 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33563
2023-10-19 05:30:32,370 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34979
2023-10-19 05:30:32,370 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,370 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,370 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:32,371 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:32,371 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ju5_j3w3
2023-10-19 05:30:32,371 - distributed.worker - INFO - Starting Worker plugin PreImport-3fc28992-fd56-43f1-b2cf-977f8b8e8e94
2023-10-19 05:30:32,371 - distributed.worker - INFO - Starting Worker plugin RMMSetup-145cefb8-a48e-4626-8509-ecbf41662af5
2023-10-19 05:30:32,407 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43505
2023-10-19 05:30:32,408 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43505
2023-10-19 05:30:32,408 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38585
2023-10-19 05:30:32,408 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,408 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,408 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:32,409 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:32,409 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f_ph6v_9
2023-10-19 05:30:32,409 - distributed.worker - INFO - Starting Worker plugin RMMSetup-de64c412-865c-48eb-a949-ece8daf9acbe
2023-10-19 05:30:32,421 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40695
2023-10-19 05:30:32,421 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40695
2023-10-19 05:30:32,422 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44061
2023-10-19 05:30:32,422 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,422 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,422 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:32,422 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:32,422 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kmw5cypa
2023-10-19 05:30:32,422 - distributed.worker - INFO - Starting Worker plugin RMMSetup-578cc37b-9d5c-4e2b-938b-97f556eb2c53
2023-10-19 05:30:32,430 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37405
2023-10-19 05:30:32,432 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37405
2023-10-19 05:30:32,432 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45441
2023-10-19 05:30:32,432 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,432 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,432 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:32,433 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:32,433 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9iogh2sa
2023-10-19 05:30:32,434 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5328ad70-e6ee-40cb-906e-617c79950f4e
2023-10-19 05:30:32,441 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42629
2023-10-19 05:30:32,442 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42629
2023-10-19 05:30:32,442 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37329
2023-10-19 05:30:32,442 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,442 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,442 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:32,442 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:32,442 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0stmi6_s
2023-10-19 05:30:32,443 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4ced8c3d-0dd2-4cae-919a-001ba9df9642
2023-10-19 05:30:32,446 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36195
2023-10-19 05:30:32,447 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36195
2023-10-19 05:30:32,447 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42881
2023-10-19 05:30:32,447 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,447 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,447 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:32,447 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:32,447 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rnhtf6d7
2023-10-19 05:30:32,448 - distributed.worker - INFO - Starting Worker plugin RMMSetup-56c40137-0ff1-4eb5-8c4b-82e12021bce9
2023-10-19 05:30:32,451 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44495
2023-10-19 05:30:32,452 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44495
2023-10-19 05:30:32,452 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40503
2023-10-19 05:30:32,452 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,452 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,452 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:32,453 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:32,453 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ibx8seck
2023-10-19 05:30:32,453 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4fc43339-483d-4a20-94a0-64e2b0b19c2b
2023-10-19 05:30:32,455 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d10ac9cc-06b8-4ce6-90a1-43f60bf74a3a
2023-10-19 05:30:32,572 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f314b49e-fab6-42ee-92cb-fdbb006680f6
2023-10-19 05:30:32,573 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,620 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33563', status: init, memory: 0, processing: 0>
2023-10-19 05:30:32,621 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33563
2023-10-19 05:30:32,621 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60138
2023-10-19 05:30:32,623 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:32,624 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,624 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,626 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1222055e-aa4a-4739-aa8f-b1ea764cac98
2023-10-19 05:30:32,626 - distributed.worker - INFO - Starting Worker plugin PreImport-35a2fb3d-9969-4809-9c7e-5d7db29788da
2023-10-19 05:30:32,627 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,627 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:32,652 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43505', status: init, memory: 0, processing: 0>
2023-10-19 05:30:32,654 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43505
2023-10-19 05:30:32,654 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60148
2023-10-19 05:30:32,655 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:32,655 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,655 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,657 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:32,660 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a636558e-ef04-4e8c-9b68-e339f1ed3848
2023-10-19 05:30:32,661 - distributed.worker - INFO - Starting Worker plugin PreImport-919e45dc-91fe-4f36-a717-c66e90281c89
2023-10-19 05:30:32,661 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,675 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f6118c34-3859-427f-8e9f-7692b89d1f51
2023-10-19 05:30:32,675 - distributed.worker - INFO - Starting Worker plugin PreImport-bbde571f-ed54-4d84-9ba1-be42d6b0eb38
2023-10-19 05:30:32,676 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,678 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-79a2444e-47cb-4de1-82f5-7080b0e26482
2023-10-19 05:30:32,678 - distributed.worker - INFO - Starting Worker plugin PreImport-27eafee1-fc71-409c-b573-8c5783bb1250
2023-10-19 05:30:32,679 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,699 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36195', status: init, memory: 0, processing: 0>
2023-10-19 05:30:32,700 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36195
2023-10-19 05:30:32,700 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60164
2023-10-19 05:30:32,700 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-afa09d98-406c-4043-883f-56a32e7b4945
2023-10-19 05:30:32,701 - distributed.worker - INFO - Starting Worker plugin PreImport-cb43e559-80e8-4e1b-8253-03d9740fbe00
2023-10-19 05:30:32,701 - distributed.worker - INFO - Starting Worker plugin PreImport-895d3940-92c2-4de7-89f7-ab6b24aa9087
2023-10-19 05:30:32,701 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40695', status: init, memory: 0, processing: 0>
2023-10-19 05:30:32,701 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,701 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:32,701 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,701 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40695
2023-10-19 05:30:32,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60150
2023-10-19 05:30:32,702 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,702 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,703 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:32,703 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:32,705 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,705 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,707 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:32,713 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42629', status: init, memory: 0, processing: 0>
2023-10-19 05:30:32,714 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42629
2023-10-19 05:30:32,714 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60180
2023-10-19 05:30:32,715 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:32,717 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,717 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,719 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:32,729 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37405', status: init, memory: 0, processing: 0>
2023-10-19 05:30:32,730 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37405
2023-10-19 05:30:32,730 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60184
2023-10-19 05:30:32,731 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:32,732 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,732 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,734 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:32,735 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44495', status: init, memory: 0, processing: 0>
2023-10-19 05:30:32,736 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44495
2023-10-19 05:30:32,736 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60190
2023-10-19 05:30:32,737 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:32,738 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:32,739 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:32,741 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:32,922 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,922 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,922 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,922 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,922 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,923 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,923 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,923 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,935 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:32,935 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:32,935 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:32,935 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:32,935 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:32,935 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:32,936 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:32,936 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:30:32,943 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,944 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:32,947 - distributed.scheduler - INFO - Remove client Client-9abbd7e6-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:32,947 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34958; closing.
2023-10-19 05:30:32,947 - distributed.scheduler - INFO - Remove client Client-9abbd7e6-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:32,948 - distributed.scheduler - INFO - Close client connection: Client-9abbd7e6-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:32,949 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37241'. Reason: nanny-close
2023-10-19 05:30:32,950 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:32,951 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40417'. Reason: nanny-close
2023-10-19 05:30:32,951 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:32,951 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33563. Reason: nanny-close
2023-10-19 05:30:32,952 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38677'. Reason: nanny-close
2023-10-19 05:30:32,952 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:32,952 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40695. Reason: nanny-close
2023-10-19 05:30:32,953 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41911'. Reason: nanny-close
2023-10-19 05:30:32,953 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:32,953 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38183. Reason: nanny-close
2023-10-19 05:30:32,954 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:32,954 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60138; closing.
2023-10-19 05:30:32,953 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34999'. Reason: nanny-close
2023-10-19 05:30:32,954 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43505. Reason: nanny-close
2023-10-19 05:30:32,954 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:32,954 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33563', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693432.9546998')
2023-10-19 05:30:32,955 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43229'. Reason: nanny-close
2023-10-19 05:30:32,955 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:32,955 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:32,955 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44495. Reason: nanny-close
2023-10-19 05:30:32,955 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:32,955 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40475'. Reason: nanny-close
2023-10-19 05:30:32,956 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:32,956 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:32,956 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:32,956 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60150; closing.
2023-10-19 05:30:32,956 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44097'. Reason: nanny-close
2023-10-19 05:30:32,956 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:32,956 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42629. Reason: nanny-close
2023-10-19 05:30:32,957 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:32,957 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37405. Reason: nanny-close
2023-10-19 05:30:32,957 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:32,958 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:32,958 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40695', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693432.9581738')
2023-10-19 05:30:32,958 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36195. Reason: nanny-close
2023-10-19 05:30:32,958 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:32,958 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60128; closing.
2023-10-19 05:30:32,960 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:32,960 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:32,960 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:32,961 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:32,961 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:32,962 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:32,959 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:60150>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:60150>: Stream is closed
2023-10-19 05:30:32,963 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38183', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693432.9638608')
2023-10-19 05:30:32,964 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60148; closing.
2023-10-19 05:30:32,965 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43505', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693432.9650948')
2023-10-19 05:30:32,965 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:32,965 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60190; closing.
2023-10-19 05:30:32,966 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44495', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693432.9664328')
2023-10-19 05:30:32,966 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60184; closing.
2023-10-19 05:30:32,966 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60164; closing.
2023-10-19 05:30:32,967 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60180; closing.
2023-10-19 05:30:32,967 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37405', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693432.9677007')
2023-10-19 05:30:32,968 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36195', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693432.9680898')
2023-10-19 05:30:32,968 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42629', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693432.9685254')
2023-10-19 05:30:32,968 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:30:32,968 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:60164>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-19 05:30:32,969 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:60184>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-19 05:30:32,969 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:60180>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-19 05:30:34,617 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:30:34,617 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:30:34,618 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:30:34,619 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:30:34,620 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-10-19 05:30:36,992 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:36,997 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-19 05:30:37,001 - distributed.scheduler - INFO - State start
2023-10-19 05:30:37,025 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:37,027 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:30:37,028 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-19 05:30:37,028 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:30:37,189 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45509'
2023-10-19 05:30:37,204 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42389'
2023-10-19 05:30:37,214 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46691'
2023-10-19 05:30:37,228 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40857'
2023-10-19 05:30:37,230 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45323'
2023-10-19 05:30:37,241 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41199'
2023-10-19 05:30:37,252 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37067'
2023-10-19 05:30:37,260 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33825'
2023-10-19 05:30:37,786 - distributed.scheduler - INFO - Receive client connection: Client-a0e9db7f-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:37,798 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60374
2023-10-19 05:30:39,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:39,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:39,372 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:39,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:39,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:39,723 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:39,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:39,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:39,735 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:39,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:39,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:39,748 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:39,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:39,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:39,754 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:39,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:39,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:39,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:39,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:39,761 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:39,761 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:39,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:39,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:39,766 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:43,640 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43849
2023-10-19 05:30:43,640 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43849
2023-10-19 05:30:43,641 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42527
2023-10-19 05:30:43,641 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:43,641 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:43,641 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:43,641 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:43,641 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-272kyvb0
2023-10-19 05:30:43,641 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43201
2023-10-19 05:30:43,641 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43201
2023-10-19 05:30:43,641 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33355
2023-10-19 05:30:43,641 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:43,642 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:43,642 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5cc3f5c6-495c-4c67-b1c2-a712ff9a609f
2023-10-19 05:30:43,642 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:43,642 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:43,642 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p5vy6w2f
2023-10-19 05:30:43,642 - distributed.worker - INFO - Starting Worker plugin RMMSetup-724daa82-b467-460a-85ff-9dee55ce1b01
2023-10-19 05:30:43,760 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43039
2023-10-19 05:30:43,761 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43039
2023-10-19 05:30:43,761 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41869
2023-10-19 05:30:43,761 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:43,761 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:43,761 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:43,761 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:43,761 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ycgmlv8_
2023-10-19 05:30:43,762 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-85429ed8-2d9f-4811-a34e-0ec477e80e3b
2023-10-19 05:30:43,762 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cf5c6ddf-f277-454e-9741-e1128b6aa264
2023-10-19 05:30:43,767 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38501
2023-10-19 05:30:43,768 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38501
2023-10-19 05:30:43,768 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33551
2023-10-19 05:30:43,768 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:43,768 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:43,768 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:43,769 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:43,769 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5cjjzhu4
2023-10-19 05:30:43,769 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ca153f6c-8910-4fad-86fc-247eb19d2603
2023-10-19 05:30:43,773 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40245
2023-10-19 05:30:43,774 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40245
2023-10-19 05:30:43,774 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37575
2023-10-19 05:30:43,774 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:43,774 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:43,774 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:43,774 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:43,774 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ikejewla
2023-10-19 05:30:43,775 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1f759d44-f5b4-42b7-8051-e6df5a0684ce
2023-10-19 05:30:43,792 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43565
2023-10-19 05:30:43,793 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43565
2023-10-19 05:30:43,793 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37765
2023-10-19 05:30:43,793 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:43,793 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:43,793 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:43,793 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:43,793 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w_v0p_ei
2023-10-19 05:30:43,794 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3932e295-2d44-4ff8-9c50-0f74c155ae7e
2023-10-19 05:30:43,793 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39595
2023-10-19 05:30:43,794 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39595
2023-10-19 05:30:43,794 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41277
2023-10-19 05:30:43,794 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:43,795 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:43,794 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35853
2023-10-19 05:30:43,795 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35853
2023-10-19 05:30:43,795 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:43,795 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:43,795 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37015
2023-10-19 05:30:43,795 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pbi5hdtt
2023-10-19 05:30:43,795 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:43,795 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:43,795 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:43,795 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:30:43,795 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8194316c-ab15-4024-b6d4-c01b1d3378ec
2023-10-19 05:30:43,795 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t873b8aa
2023-10-19 05:30:43,796 - distributed.worker - INFO - Starting Worker plugin PreImport-fa130278-fc66-4179-b48d-7b84b66f8063
2023-10-19 05:30:43,796 - distributed.worker - INFO - Starting Worker plugin RMMSetup-618faa09-b756-43ed-8b36-81850780d96c
2023-10-19 05:30:43,796 - distributed.worker - INFO - Starting Worker plugin RMMSetup-44a41d28-3a7c-4137-9983-1c956ab81e6a
2023-10-19 05:30:44,176 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7b6e555f-d2a1-4c87-b0ae-b8e88d53af8f
2023-10-19 05:30:44,178 - distributed.worker - INFO - Starting Worker plugin PreImport-3c7cb8e3-4ba7-4b0c-8b0b-32a9194f16ff
2023-10-19 05:30:44,179 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,196 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d79fc70c-643e-4a1d-b900-d46e253efb07
2023-10-19 05:30:44,199 - distributed.worker - INFO - Starting Worker plugin PreImport-6e5fac66-64bd-446b-9fa4-3ebeb4d9bc63
2023-10-19 05:30:44,200 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,211 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43849', status: init, memory: 0, processing: 0>
2023-10-19 05:30:44,214 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43849
2023-10-19 05:30:44,214 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42674
2023-10-19 05:30:44,216 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:44,217 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:44,217 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,219 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:44,232 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43201', status: init, memory: 0, processing: 0>
2023-10-19 05:30:44,232 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43201
2023-10-19 05:30:44,232 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42686
2023-10-19 05:30:44,234 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:44,235 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:44,235 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,237 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:44,263 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-976e7fef-9ff3-48f1-b2e8-98e61bc92afb
2023-10-19 05:30:44,263 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c380830d-7c58-4858-b030-d436ca36aee0
2023-10-19 05:30:44,263 - distributed.worker - INFO - Starting Worker plugin PreImport-99e3b16e-3231-45cc-bae5-b5159cb43457
2023-10-19 05:30:44,264 - distributed.worker - INFO - Starting Worker plugin PreImport-0ca4a2a0-5d32-45ff-8d31-cc377b4b3da0
2023-10-19 05:30:44,264 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,264 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,272 - distributed.worker - INFO - Starting Worker plugin PreImport-b6aa0020-dca5-4c9a-99e2-b21500f2ff93
2023-10-19 05:30:44,272 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0e82014b-8cc3-426d-b7f6-d61cfb9a338c
2023-10-19 05:30:44,272 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b31a84d9-7688-452a-aede-9b8a45d06f81
2023-10-19 05:30:44,272 - distributed.worker - INFO - Starting Worker plugin PreImport-7b29be55-8041-4e65-a9af-9ced2633cc72
2023-10-19 05:30:44,273 - distributed.worker - INFO - Starting Worker plugin PreImport-a48875b6-93c1-45cf-a540-8c6536024d82
2023-10-19 05:30:44,273 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,273 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,273 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,295 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,297 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35853', status: init, memory: 0, processing: 0>
2023-10-19 05:30:44,298 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35853
2023-10-19 05:30:44,298 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42730
2023-10-19 05:30:44,299 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:44,299 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43565', status: init, memory: 0, processing: 0>
2023-10-19 05:30:44,300 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:44,300 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,300 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43565
2023-10-19 05:30:44,300 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42720
2023-10-19 05:30:44,301 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43039', status: init, memory: 0, processing: 0>
2023-10-19 05:30:44,301 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43039
2023-10-19 05:30:44,301 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:44,301 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42732
2023-10-19 05:30:44,301 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:44,302 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:44,302 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,302 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40245', status: init, memory: 0, processing: 0>
2023-10-19 05:30:44,302 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:44,302 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40245
2023-10-19 05:30:44,302 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42712
2023-10-19 05:30:44,303 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:44,303 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38501', status: init, memory: 0, processing: 0>
2023-10-19 05:30:44,303 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:44,303 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,304 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38501
2023-10-19 05:30:44,304 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42698
2023-10-19 05:30:44,304 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:44,305 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:44,305 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:44,306 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:44,306 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,307 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:44,307 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,308 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:44,309 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:44,320 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39595', status: init, memory: 0, processing: 0>
2023-10-19 05:30:44,320 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39595
2023-10-19 05:30:44,320 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42744
2023-10-19 05:30:44,321 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:44,322 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:44,322 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:44,324 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:44,391 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:44,391 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:44,391 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:44,391 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:44,392 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:44,392 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:44,392 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:44,392 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:30:44,397 - distributed.scheduler - INFO - Remove client Client-a0e9db7f-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:44,397 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60374; closing.
2023-10-19 05:30:44,397 - distributed.scheduler - INFO - Remove client Client-a0e9db7f-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:44,398 - distributed.scheduler - INFO - Close client connection: Client-a0e9db7f-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:44,399 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45509'. Reason: nanny-close
2023-10-19 05:30:44,399 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:44,400 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42389'. Reason: nanny-close
2023-10-19 05:30:44,400 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:44,400 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39595. Reason: nanny-close
2023-10-19 05:30:44,400 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46691'. Reason: nanny-close
2023-10-19 05:30:44,401 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:44,401 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35853. Reason: nanny-close
2023-10-19 05:30:44,401 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40857'. Reason: nanny-close
2023-10-19 05:30:44,401 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:44,401 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43849. Reason: nanny-close
2023-10-19 05:30:44,402 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45323'. Reason: nanny-close
2023-10-19 05:30:44,402 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:44,402 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38501. Reason: nanny-close
2023-10-19 05:30:44,402 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:44,402 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42744; closing.
2023-10-19 05:30:44,402 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41199'. Reason: nanny-close
2023-10-19 05:30:44,402 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:44,402 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39595', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693444.4028676')
2023-10-19 05:30:44,403 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43039. Reason: nanny-close
2023-10-19 05:30:44,403 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37067'. Reason: nanny-close
2023-10-19 05:30:44,403 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:44,403 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:44,403 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33825'. Reason: nanny-close
2023-10-19 05:30:44,403 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43565. Reason: nanny-close
2023-10-19 05:30:44,404 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:44,404 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42730; closing.
2023-10-19 05:30:44,404 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:44,404 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43201. Reason: nanny-close
2023-10-19 05:30:44,404 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:44,404 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:44,404 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40245. Reason: nanny-close
2023-10-19 05:30:44,405 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:44,405 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:44,405 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35853', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693444.4050374')
2023-10-19 05:30:44,406 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:44,406 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:44,406 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:44,406 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:44,406 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:44,407 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:44,407 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:44,405 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:42730>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:42730>: Stream is closed
2023-10-19 05:30:44,408 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42674; closing.
2023-10-19 05:30:44,408 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42698; closing.
2023-10-19 05:30:44,408 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:44,408 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43849', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693444.4088464')
2023-10-19 05:30:44,409 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38501', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693444.4091396')
2023-10-19 05:30:44,409 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:44,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42732; closing.
2023-10-19 05:30:44,410 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43039', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693444.4101372')
2023-10-19 05:30:44,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42720; closing.
2023-10-19 05:30:44,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42686; closing.
2023-10-19 05:30:44,411 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43565', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693444.411259')
2023-10-19 05:30:44,411 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43201', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693444.4116602')
2023-10-19 05:30:44,412 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42712; closing.
2023-10-19 05:30:44,412 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40245', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693444.4125004')
2023-10-19 05:30:44,412 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:30:44,412 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:42712>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-19 05:30:46,217 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:30:46,218 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:30:46,219 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:30:46,220 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:30:46,221 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-10-19 05:30:48,759 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:48,764 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-19 05:30:48,768 - distributed.scheduler - INFO - State start
2023-10-19 05:30:48,827 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:48,828 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:30:48,829 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-19 05:30:48,829 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:30:49,070 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38337'
2023-10-19 05:30:49,718 - distributed.scheduler - INFO - Receive client connection: Client-a7d5a235-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:49,736 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42816
2023-10-19 05:30:50,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:50,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:30:51,478 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:30:52,303 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33173
2023-10-19 05:30:52,303 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33173
2023-10-19 05:30:52,303 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-10-19 05:30:52,303 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:30:52,304 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:52,304 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:30:52,304 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-19 05:30:52,304 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b0lm02nb
2023-10-19 05:30:52,304 - distributed.worker - INFO - Starting Worker plugin RMMSetup-83c300e1-8b46-4225-81cf-c15e536f77ce
2023-10-19 05:30:52,304 - distributed.worker - INFO - Starting Worker plugin PreImport-273db9be-630a-4aeb-b45f-104d416e7524
2023-10-19 05:30:52,305 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a81d59ee-1a31-4c01-bed7-6b1aba0f6a33
2023-10-19 05:30:52,305 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:52,334 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33173', status: init, memory: 0, processing: 0>
2023-10-19 05:30:52,336 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33173
2023-10-19 05:30:52,336 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45136
2023-10-19 05:30:52,337 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:30:52,337 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:30:52,337 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:30:52,339 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:30:52,393 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:30:52,396 - distributed.scheduler - INFO - Remove client Client-a7d5a235-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:52,396 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42816; closing.
2023-10-19 05:30:52,397 - distributed.scheduler - INFO - Remove client Client-a7d5a235-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:52,397 - distributed.scheduler - INFO - Close client connection: Client-a7d5a235-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:30:52,398 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38337'. Reason: nanny-close
2023-10-19 05:30:52,398 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:30:52,399 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33173. Reason: nanny-close
2023-10-19 05:30:52,401 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:30:52,401 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45136; closing.
2023-10-19 05:30:52,402 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33173', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693452.4019961')
2023-10-19 05:30:52,402 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:30:52,403 - distributed.nanny - INFO - Worker closed
2023-10-19 05:30:53,415 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:30:53,415 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:30:53,415 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:30:53,416 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:30:53,416 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-10-19 05:30:57,786 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:57,790 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-19 05:30:57,794 - distributed.scheduler - INFO - State start
2023-10-19 05:30:57,820 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:30:57,821 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:30:57,822 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-19 05:30:57,822 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:30:57,944 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37967'
2023-10-19 05:30:59,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:30:59,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:00,408 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:01,128 - distributed.scheduler - INFO - Receive client connection: Client-ad505cae-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:01,139 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41840
2023-10-19 05:31:01,282 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41481
2023-10-19 05:31:01,282 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41481
2023-10-19 05:31:01,283 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41381
2023-10-19 05:31:01,283 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:01,283 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:01,283 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:01,283 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-19 05:31:01,283 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jo4ua0ft
2023-10-19 05:31:01,283 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1e87fa8e-56c9-4474-8bb4-1b9628dae016
2023-10-19 05:31:01,283 - distributed.worker - INFO - Starting Worker plugin PreImport-7302efc6-de19-411e-906f-c5b21256762f
2023-10-19 05:31:01,285 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cab9036b-0a8c-421a-a3d2-819569f0a558
2023-10-19 05:31:01,285 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:01,306 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41481', status: init, memory: 0, processing: 0>
2023-10-19 05:31:01,307 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41481
2023-10-19 05:31:01,307 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41852
2023-10-19 05:31:01,308 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:01,309 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:01,309 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:01,311 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:01,350 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:01,352 - distributed.scheduler - INFO - Remove client Client-ad505cae-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:01,352 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41840; closing.
2023-10-19 05:31:01,353 - distributed.scheduler - INFO - Remove client Client-ad505cae-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:01,353 - distributed.scheduler - INFO - Close client connection: Client-ad505cae-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:01,354 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37967'. Reason: nanny-close
2023-10-19 05:31:01,354 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:01,355 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41481. Reason: nanny-close
2023-10-19 05:31:01,357 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:01,357 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41852; closing.
2023-10-19 05:31:01,357 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41481', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693461.357771')
2023-10-19 05:31:01,358 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:31:01,358 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:02,371 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:31:02,371 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:31:02,372 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:31:02,372 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:31:02,373 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-10-19 05:31:04,701 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:04,706 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-19 05:31:04,710 - distributed.scheduler - INFO - State start
2023-10-19 05:31:04,734 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:04,735 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:31:04,736 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-19 05:31:04,736 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:31:09,224 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:41854'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:41854>: Stream is closed
2023-10-19 05:31:09,522 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:31:09,522 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:31:09,523 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:31:09,524 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:31:09,524 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-10-19 05:31:11,738 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:11,742 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-19 05:31:11,746 - distributed.scheduler - INFO - State start
2023-10-19 05:31:11,782 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:11,783 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-19 05:31:11,784 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-19 05:31:11,784 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:31:11,919 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39521'
2023-10-19 05:31:12,880 - distributed.scheduler - INFO - Receive client connection: Client-b59fc9fa-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:12,897 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60178
2023-10-19 05:31:13,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:13,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:13,778 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:14,646 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37453
2023-10-19 05:31:14,646 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37453
2023-10-19 05:31:14,646 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33007
2023-10-19 05:31:14,646 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-19 05:31:14,646 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:14,646 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:14,647 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-19 05:31:14,647 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-yrq7yvo7
2023-10-19 05:31:14,647 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6c580c93-65f8-449c-b28d-37eddffd6ac1
2023-10-19 05:31:14,647 - distributed.worker - INFO - Starting Worker plugin PreImport-02cf8079-ca54-4237-8d3c-40e21b24a740
2023-10-19 05:31:14,647 - distributed.worker - INFO - Starting Worker plugin RMMSetup-47bc8d92-a86e-4afb-8687-868be6ba4651
2023-10-19 05:31:14,648 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:14,675 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37453', status: init, memory: 0, processing: 0>
2023-10-19 05:31:14,676 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37453
2023-10-19 05:31:14,676 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60200
2023-10-19 05:31:14,677 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:14,678 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-19 05:31:14,678 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:14,680 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-19 05:31:14,742 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:14,744 - distributed.scheduler - INFO - Remove client Client-b59fc9fa-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:14,745 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60178; closing.
2023-10-19 05:31:14,745 - distributed.scheduler - INFO - Remove client Client-b59fc9fa-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:14,745 - distributed.scheduler - INFO - Close client connection: Client-b59fc9fa-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:14,746 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39521'. Reason: nanny-close
2023-10-19 05:31:14,747 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:14,748 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37453. Reason: nanny-close
2023-10-19 05:31:14,750 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60200; closing.
2023-10-19 05:31:14,750 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-19 05:31:14,750 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37453', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693474.7504532')
2023-10-19 05:31:14,750 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:31:14,751 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:15,663 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:31:15,663 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:31:15,664 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:31:15,666 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-19 05:31:15,666 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-10-19 05:31:17,918 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:17,923 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-19 05:31:17,926 - distributed.scheduler - INFO - State start
2023-10-19 05:31:17,957 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:17,958 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:31:17,959 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-19 05:31:17,959 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:31:18,073 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44541'
2023-10-19 05:31:18,097 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36349'
2023-10-19 05:31:18,099 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45145'
2023-10-19 05:31:18,108 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35629'
2023-10-19 05:31:18,120 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43577'
2023-10-19 05:31:18,129 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45941'
2023-10-19 05:31:18,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41039'
2023-10-19 05:31:18,147 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36675'
2023-10-19 05:31:18,946 - distributed.scheduler - INFO - Receive client connection: Client-b94ee9fb-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:18,959 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47994
2023-10-19 05:31:19,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:19,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:19,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:19,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:19,826 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:19,826 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:20,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:20,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:20,137 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:20,137 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:20,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:20,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:20,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:20,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:20,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:20,141 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:20,143 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:20,144 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:20,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:20,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:20,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:20,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:20,154 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:20,156 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:21,846 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45387
2023-10-19 05:31:21,846 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45387
2023-10-19 05:31:21,846 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43343
2023-10-19 05:31:21,846 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:21,846 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:21,847 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:21,847 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:31:21,847 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ynyexcuq
2023-10-19 05:31:21,847 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0bad8e89-a23d-4fae-8acf-9c3ba60782b9
2023-10-19 05:31:21,879 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41225
2023-10-19 05:31:21,879 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41225
2023-10-19 05:31:21,880 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33091
2023-10-19 05:31:21,880 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:21,880 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:21,880 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:21,880 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:31:21,880 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zjtux8nl
2023-10-19 05:31:21,880 - distributed.worker - INFO - Starting Worker plugin PreImport-c629a8ab-e279-4387-bf2f-53ae88b1714e
2023-10-19 05:31:21,880 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1e464b21-67e9-4208-b8f6-f8df03ce6c45
2023-10-19 05:31:22,359 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a2276cbb-c8c1-4f62-95da-0f3a4eddc160
2023-10-19 05:31:22,360 - distributed.worker - INFO - Starting Worker plugin PreImport-d5d148d9-2858-4029-99fb-993283845624
2023-10-19 05:31:22,361 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:22,396 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8e047661-0f98-475d-9271-b1c7eea733e3
2023-10-19 05:31:22,397 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:22,405 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45387', status: init, memory: 0, processing: 0>
2023-10-19 05:31:22,407 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45387
2023-10-19 05:31:22,407 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45062
2023-10-19 05:31:22,409 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:22,410 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:22,411 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:22,413 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:22,436 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41225', status: init, memory: 0, processing: 0>
2023-10-19 05:31:22,437 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41225
2023-10-19 05:31:22,437 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45066
2023-10-19 05:31:22,440 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:22,441 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:22,441 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:22,443 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:23,233 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38903
2023-10-19 05:31:23,234 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38903
2023-10-19 05:31:23,234 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43351
2023-10-19 05:31:23,234 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,234 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,234 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:23,234 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:31:23,234 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aiogvu7_
2023-10-19 05:31:23,235 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4af46803-ace8-42f6-98eb-ff1e9769d932
2023-10-19 05:31:23,263 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44129
2023-10-19 05:31:23,264 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44129
2023-10-19 05:31:23,264 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46807
2023-10-19 05:31:23,264 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,264 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,264 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:23,265 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:31:23,265 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g5xhd11f
2023-10-19 05:31:23,265 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0733837f-029e-4098-b2f5-c1d4db3c3f57
2023-10-19 05:31:23,270 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45689
2023-10-19 05:31:23,271 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45689
2023-10-19 05:31:23,272 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41783
2023-10-19 05:31:23,272 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,272 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,272 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:23,272 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:31:23,272 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7n6tvgm6
2023-10-19 05:31:23,272 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34651
2023-10-19 05:31:23,273 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34651
2023-10-19 05:31:23,273 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34215
2023-10-19 05:31:23,273 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,273 - distributed.worker - INFO - Starting Worker plugin PreImport-ed6a4e69-4d79-48c7-8e93-56871f1306c1
2023-10-19 05:31:23,273 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,273 - distributed.worker - INFO - Starting Worker plugin RMMSetup-074b7142-15de-4457-81c7-8d586fc0c220
2023-10-19 05:31:23,273 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:23,274 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:31:23,274 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-shgl7dua
2023-10-19 05:31:23,274 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-95de848d-9919-4af6-8580-dbdd042af739
2023-10-19 05:31:23,274 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5be1e11e-11d6-4edc-8f4b-280a5e556990
2023-10-19 05:31:23,274 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40215
2023-10-19 05:31:23,275 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40215
2023-10-19 05:31:23,275 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43485
2023-10-19 05:31:23,275 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,276 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,276 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:23,276 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:31:23,276 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zszc2z8t
2023-10-19 05:31:23,276 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37677
2023-10-19 05:31:23,276 - distributed.worker - INFO - Starting Worker plugin RMMSetup-63d1f486-a69e-4369-a0cb-15f76f1fdeec
2023-10-19 05:31:23,276 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37677
2023-10-19 05:31:23,276 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39183
2023-10-19 05:31:23,277 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,277 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,277 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:23,277 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-19 05:31:23,277 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o8qugq73
2023-10-19 05:31:23,277 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f6b7bd53-0e17-445b-b59c-4bcf0494a378
2023-10-19 05:31:23,394 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-66342c62-d18d-4cc2-8848-f4469460e398
2023-10-19 05:31:23,394 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-27837508-a393-46b4-b95e-27e779c7fac0
2023-10-19 05:31:23,394 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,394 - distributed.worker - INFO - Starting Worker plugin PreImport-e29ba2f5-36e9-476c-bb4b-794fb917c68b
2023-10-19 05:31:23,395 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,398 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8acee963-48a0-480a-a752-108c7882341a
2023-10-19 05:31:23,399 - distributed.worker - INFO - Starting Worker plugin PreImport-cbc351d0-c0a2-4be7-a383-72c2ebbbcac2
2023-10-19 05:31:23,400 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,403 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1807b562-a28a-4a1d-8e14-f0678816dea9
2023-10-19 05:31:23,403 - distributed.worker - INFO - Starting Worker plugin PreImport-3fe49172-45a1-4e1a-92cd-b107d00eb99f
2023-10-19 05:31:23,403 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,407 - distributed.worker - INFO - Starting Worker plugin PreImport-24ce8dc0-4e9b-41b6-ab86-cd0f0f5dc886
2023-10-19 05:31:23,408 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,408 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9dd5d431-03ea-4160-9caa-a5a6e97d722e
2023-10-19 05:31:23,408 - distributed.worker - INFO - Starting Worker plugin PreImport-477b52fc-43a9-4f95-818a-0b4df4814c7f
2023-10-19 05:31:23,408 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,425 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45689', status: init, memory: 0, processing: 0>
2023-10-19 05:31:23,425 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45689
2023-10-19 05:31:23,425 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45080
2023-10-19 05:31:23,427 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:23,428 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,428 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,429 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34651', status: init, memory: 0, processing: 0>
2023-10-19 05:31:23,430 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34651
2023-10-19 05:31:23,430 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45122
2023-10-19 05:31:23,430 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:23,431 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:23,432 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,432 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,433 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44129', status: init, memory: 0, processing: 0>
2023-10-19 05:31:23,433 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44129
2023-10-19 05:31:23,433 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45106
2023-10-19 05:31:23,433 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:23,434 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:23,435 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,436 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,437 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40215', status: init, memory: 0, processing: 0>
2023-10-19 05:31:23,437 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40215
2023-10-19 05:31:23,437 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45132
2023-10-19 05:31:23,438 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:23,438 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:23,438 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38903', status: init, memory: 0, processing: 0>
2023-10-19 05:31:23,439 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,439 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,439 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38903
2023-10-19 05:31:23,439 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45090
2023-10-19 05:31:23,440 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:23,441 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:23,442 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,442 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,444 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:23,449 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37677', status: init, memory: 0, processing: 0>
2023-10-19 05:31:23,449 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37677
2023-10-19 05:31:23,449 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45136
2023-10-19 05:31:23,451 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:23,452 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:23,452 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:23,454 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:23,476 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:31:23,476 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:31:23,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:31:23,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:31:23,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:31:23,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:31:23,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:31:23,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-19 05:31:23,490 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:23,490 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:23,490 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:23,491 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:23,491 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:23,491 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:23,491 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:23,491 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:23,495 - distributed.scheduler - INFO - Remove client Client-b94ee9fb-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:23,495 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47994; closing.
2023-10-19 05:31:23,496 - distributed.scheduler - INFO - Remove client Client-b94ee9fb-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:23,496 - distributed.scheduler - INFO - Close client connection: Client-b94ee9fb-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:23,497 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44541'. Reason: nanny-close
2023-10-19 05:31:23,498 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:23,498 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36349'. Reason: nanny-close
2023-10-19 05:31:23,499 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:23,499 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41225. Reason: nanny-close
2023-10-19 05:31:23,499 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45145'. Reason: nanny-close
2023-10-19 05:31:23,499 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:23,500 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45387. Reason: nanny-close
2023-10-19 05:31:23,500 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35629'. Reason: nanny-close
2023-10-19 05:31:23,500 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:23,500 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37677. Reason: nanny-close
2023-10-19 05:31:23,500 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43577'. Reason: nanny-close
2023-10-19 05:31:23,501 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:23,501 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44129. Reason: nanny-close
2023-10-19 05:31:23,501 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45941'. Reason: nanny-close
2023-10-19 05:31:23,501 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:23,501 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45066; closing.
2023-10-19 05:31:23,501 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34651. Reason: nanny-close
2023-10-19 05:31:23,501 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:23,502 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41225', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693483.5020278')
2023-10-19 05:31:23,502 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41039'. Reason: nanny-close
2023-10-19 05:31:23,502 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:23,502 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:23,502 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40215. Reason: nanny-close
2023-10-19 05:31:23,502 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36675'. Reason: nanny-close
2023-10-19 05:31:23,502 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:23,503 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:23,503 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45136; closing.
2023-10-19 05:31:23,503 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38903. Reason: nanny-close
2023-10-19 05:31:23,503 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:23,503 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:23,503 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45689. Reason: nanny-close
2023-10-19 05:31:23,504 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37677', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693483.50405')
2023-10-19 05:31:23,504 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:23,504 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:23,504 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45062; closing.
2023-10-19 05:31:23,505 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:23,505 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:23,505 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45387', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693483.5054083')
2023-10-19 05:31:23,505 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:23,505 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:23,505 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45106; closing.
2023-10-19 05:31:23,506 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45122; closing.
2023-10-19 05:31:23,506 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44129', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693483.506474')
2023-10-19 05:31:23,506 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:23,506 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34651', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693483.5068736')
2023-10-19 05:31:23,507 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:23,507 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45132; closing.
2023-10-19 05:31:23,508 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:23,508 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40215', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693483.508345')
2023-10-19 05:31:23,508 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45090; closing.
2023-10-19 05:31:23,508 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:23,509 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45080; closing.
2023-10-19 05:31:23,509 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38903', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693483.5093272')
2023-10-19 05:31:23,509 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45689', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693483.5097911')
2023-10-19 05:31:23,510 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:31:23,510 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:25,065 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:31:25,066 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:31:25,066 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:31:25,067 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:31:25,068 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-10-19 05:31:27,348 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:27,353 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34597 instead
  warnings.warn(
2023-10-19 05:31:27,357 - distributed.scheduler - INFO - State start
2023-10-19 05:31:27,381 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:27,382 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:31:27,383 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34597/status
2023-10-19 05:31:27,383 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:31:27,543 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46355'
2023-10-19 05:31:29,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:29,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:29,243 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:30,210 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34147
2023-10-19 05:31:30,210 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34147
2023-10-19 05:31:30,210 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41245
2023-10-19 05:31:30,210 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:30,210 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:30,211 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:30,211 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-19 05:31:30,211 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vvhycw9e
2023-10-19 05:31:30,211 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-acb8a15c-614f-4807-b925-cf89785e163c
2023-10-19 05:31:30,211 - distributed.worker - INFO - Starting Worker plugin PreImport-e01d1e21-3db0-47f8-a169-50fe30894969
2023-10-19 05:31:30,212 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2275073d-d198-4394-a844-b86de8c2f0d4
2023-10-19 05:31:30,317 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:30,343 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34147', status: init, memory: 0, processing: 0>
2023-10-19 05:31:30,356 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34147
2023-10-19 05:31:30,356 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34248
2023-10-19 05:31:30,357 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-19 05:31:30,358 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-19 05:31:30,358 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:30,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-19 05:31:31,725 - distributed.scheduler - INFO - Receive client connection: Client-bee3ea89-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:31,725 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34264
2023-10-19 05:31:31,731 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-19 05:31:31,734 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:31,736 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-19 05:31:31,739 - distributed.scheduler - INFO - Remove client Client-bee3ea89-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:31,739 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34264; closing.
2023-10-19 05:31:31,739 - distributed.scheduler - INFO - Remove client Client-bee3ea89-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:31,740 - distributed.scheduler - INFO - Close client connection: Client-bee3ea89-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:31,740 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46355'. Reason: nanny-close
2023-10-19 05:31:31,741 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-19 05:31:31,742 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34147. Reason: nanny-close
2023-10-19 05:31:31,743 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34248; closing.
2023-10-19 05:31:31,744 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-19 05:31:31,744 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34147', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697693491.744286')
2023-10-19 05:31:31,744 - distributed.scheduler - INFO - Lost all workers
2023-10-19 05:31:31,745 - distributed.nanny - INFO - Worker closed
2023-10-19 05:31:32,656 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:31:32,656 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:31:32,657 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:31:32,658 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:31:32,658 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-10-19 05:31:34,701 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:34,706 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39815 instead
  warnings.warn(
2023-10-19 05:31:34,710 - distributed.scheduler - INFO - State start
2023-10-19 05:31:34,733 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-19 05:31:34,734 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-19 05:31:34,734 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39815/status
2023-10-19 05:31:34,734 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-19 05:31:34,828 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33895'
2023-10-19 05:31:36,274 - distributed.scheduler - INFO - Receive client connection: Client-c35b9e4e-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:36,290 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34374
2023-10-19 05:31:36,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-19 05:31:36,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-19 05:31:36,571 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-19 05:31:37,415 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38365
2023-10-19 05:31:37,415 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38365
2023-10-19 05:31:37,415 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36707
2023-10-19 05:31:37,416 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-19 05:31:37,416 - distributed.worker - INFO - -------------------------------------------------
2023-10-19 05:31:37,416 - distributed.worker - INFO -               Threads:                          1
2023-10-19 05:31:37,416 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-19 05:31:37,416 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yx0ftoua
2023-10-19 05:31:37,416 - distributed.worker - INFO - Starting Worker plugin PreImport-50d32349-ef38-46af-b8d5-f41e569276d7
2023-10-19 05:31:37,417 - distributed.worker - INFO - Starting Worker plugin RMMSetup-be2f7aba-e027-4db5-a8bd-974f7c4ab2fe
std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
2023-10-19 05:31:37,688 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1d60bdf5-deee-4d94-8c84-9e3bbd67c5db
2023-10-19 05:31:37,688 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38365. Reason: failure-to-start-<class 'MemoryError'>
2023-10-19 05:31:37,688 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2023-10-19 05:31:37,690 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1476, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 953, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 630, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
2023-10-19 05:31:37,713 - distributed.nanny - ERROR - Failed to start process
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1476, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 953, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 630, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
2023-10-19 05:31:37,716 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33895'. Reason: nanny-instantiate-failed
2023-10-19 05:31:37,716 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-instantiate-failed
2023-10-19 05:31:38,081 - distributed.nanny - INFO - Worker process 61970 was killed by signal 15
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1476, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 362, in start_unsafe
    response = await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 953, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 630, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-10-19 05:31:38,082 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:34364'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:34364>: Stream is closed
2023-10-19 05:31:46,334 - distributed.scheduler - INFO - Remove client Client-c35b9e4e-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:46,334 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34374; closing.
2023-10-19 05:31:46,334 - distributed.scheduler - INFO - Remove client Client-c35b9e4e-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:46,335 - distributed.scheduler - INFO - Close client connection: Client-c35b9e4e-6e40-11ee-a4ff-d8c49764f6bb
2023-10-19 05:31:46,336 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-19 05:31:46,336 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-19 05:31:46,337 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-19 05:31:46,338 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-19 05:31:46,338 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44619 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36153 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46401 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44643 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34191 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33611 instead
  warnings.warn(
2023-10-19 05:32:51,783 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-10-19 05:32:51,785 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-19 05:32:51,785 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-10-19 05:32:51,788 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-10-19 05:32:51,788 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1510, in _connect
    async def _connect(self, addr: str, timeout: float | None = None) -> Comm:
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-10-19 05:32:51,790 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:49487', name: 3, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
Task exception was never retrieved
future: <Task finished name='Task-1315' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-1316' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-1314' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42031 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33253 instead
  warnings.warn(
[1697693606.281976] [dgx13:64090:0]            sock.c:470  UCX  ERROR bind(fd=137 addr=0.0.0.0:48896) failed: Address already in use
[1697693606.282247] [dgx13:64090:0]            sock.c:470  UCX  ERROR bind(fd=138 addr=0.0.0.0:59006) failed: Address already in use
[1697693606.282328] [dgx13:64090:0]            sock.c:470  UCX  ERROR bind(fd=138 addr=0.0.0.0:48784) failed: Address already in use
[1697693609.024013] [dgx13:64187:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:54176) failed: Address already in use
[1697693610.472897] [dgx13:64179:0]            sock.c:470  UCX  ERROR bind(fd=132 addr=0.0.0.0:43260) failed: Address already in use
[1697693610.472983] [dgx13:64179:0]            sock.c:470  UCX  ERROR bind(fd=132 addr=0.0.0.0:48344) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44691 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35769 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39015 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39423 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43351 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34293 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42631 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43497 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35707 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37043 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38397 instead
  warnings.warn(
2023-10-19 05:39:20,761 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-19 05:39:20,766 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:43593', name: 0, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35829 instead
  warnings.warn(
2023-10-19 05:39:59,731 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-19 05:39:59,739 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:43949'.
2023-10-19 05:39:59,740 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:43949'. Shutting down.
2023-10-19 05:39:59,742 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f187372b3d0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-19 05:40:01,745 - distributed.nanny - ERROR - Worker process died unexpectedly
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 12 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
