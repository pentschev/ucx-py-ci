============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-09 06:28:53,494 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:28:53,499 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41847 instead
  warnings.warn(
2024-01-09 06:28:53,503 - distributed.scheduler - INFO - State start
2024-01-09 06:28:53,526 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:28:53,527 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-09 06:28:53,527 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:28:53,528 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-09 06:28:53,716 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45381'
2024-01-09 06:28:53,738 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42903'
2024-01-09 06:28:53,741 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38587'
2024-01-09 06:28:53,750 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34387'
2024-01-09 06:28:55,058 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45381'. Reason: nanny-close
2024-01-09 06:28:55,059 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42903'. Reason: nanny-close
2024-01-09 06:28:55,059 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38587'. Reason: nanny-close
2024-01-09 06:28:55,059 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34387'. Reason: nanny-close
2024-01-09 06:28:55,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:28:55,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:28:55,566 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:28:55,567 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35201
2024-01-09 06:28:55,567 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35201
2024-01-09 06:28:55,567 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46655
2024-01-09 06:28:55,567 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:28:55,567 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,568 - distributed.worker - INFO -               Threads:                          4
2024-01-09 06:28:55,568 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-09 06:28:55,568 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-ydr2nhv8
2024-01-09 06:28:55,568 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cd275a47-9953-4b66-ba76-b3daf510042e
2024-01-09 06:28:55,568 - distributed.worker - INFO - Starting Worker plugin PreImport-b6ef93e4-6bfa-4171-a58f-c6104f98165b
2024-01-09 06:28:55,568 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0caaec23-8330-4a15-8c8f-935bf0aa74b3
2024-01-09 06:28:55,568 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,624 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:28:55,624 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:28:55,624 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,625 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:28:55,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:28:55,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:28:55,630 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:28:55,631 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43161
2024-01-09 06:28:55,631 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43161
2024-01-09 06:28:55,631 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46281
2024-01-09 06:28:55,632 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:28:55,632 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,632 - distributed.worker - INFO -               Threads:                          4
2024-01-09 06:28:55,632 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-09 06:28:55,632 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-4w025u55
2024-01-09 06:28:55,632 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0cfa3f49-ed2d-4c97-a46b-7a2e76e66406
2024-01-09 06:28:55,632 - distributed.worker - INFO - Starting Worker plugin PreImport-f7579777-8787-44b6-b8cb-217b0f1b92c6
2024-01-09 06:28:55,633 - distributed.worker - INFO - Starting Worker plugin RMMSetup-43aa97e5-b354-44e6-b16e-7c2897b6c030
2024-01-09 06:28:55,633 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,636 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:28:55,637 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35201. Reason: nanny-close
2024-01-09 06:28:55,638 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:28:55,640 - distributed.nanny - INFO - Worker closed
2024-01-09 06:28:55,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:28:55,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:28:55,656 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:28:55,657 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40487
2024-01-09 06:28:55,657 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40487
2024-01-09 06:28:55,657 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39855
2024-01-09 06:28:55,657 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:28:55,657 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,657 - distributed.worker - INFO -               Threads:                          4
2024-01-09 06:28:55,657 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-09 06:28:55,657 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-3t48b6tx
2024-01-09 06:28:55,657 - distributed.worker - INFO - Starting Worker plugin PreImport-17883c5f-f174-48df-b378-231df7b4ad3f
2024-01-09 06:28:55,657 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-099c927c-94ee-4714-8015-f126af4e78a1
2024-01-09 06:28:55,658 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bbb31bed-31d5-4ded-a196-e8ffed57e812
2024-01-09 06:28:55,658 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:28:55,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:28:55,696 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:28:55,697 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35367
2024-01-09 06:28:55,697 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35367
2024-01-09 06:28:55,697 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45383
2024-01-09 06:28:55,697 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:28:55,697 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,697 - distributed.worker - INFO -               Threads:                          4
2024-01-09 06:28:55,697 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-09 06:28:55,697 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-ca7f_lfo
2024-01-09 06:28:55,697 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-519231ee-ac22-4374-8e42-a6dd33c16910
2024-01-09 06:28:55,697 - distributed.worker - INFO - Starting Worker plugin PreImport-30e3d6fe-376e-4d96-b67c-b793ac874768
2024-01-09 06:28:55,697 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0de07fda-cf2d-4b7e-a892-c78148356ccf
2024-01-09 06:28:55,698 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,698 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:28:55,699 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:28:55,699 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,700 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:28:55,723 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:28:55,724 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:28:55,724 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,725 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:28:55,737 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:28:55,738 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:28:55,738 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43161. Reason: nanny-close
2024-01-09 06:28:55,739 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40487. Reason: nanny-close
2024-01-09 06:28:55,740 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:28:55,741 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:28:55,742 - distributed.nanny - INFO - Worker closed
2024-01-09 06:28:55,742 - distributed.nanny - INFO - Worker closed
2024-01-09 06:28:55,755 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:28:55,756 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:28:55,756 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:28:55,757 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:28:55,794 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:28:55,795 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35367. Reason: nanny-close
2024-01-09 06:28:55,796 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:28:55,798 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-09 06:28:58,428 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:28:58,432 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:28:58,436 - distributed.scheduler - INFO - State start
2024-01-09 06:28:58,458 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:28:58,459 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:28:58,460 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:28:58,460 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:28:58,508 - distributed.scheduler - INFO - Receive client connection: Client-5ebbec89-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:28:58,522 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49800
2024-01-09 06:28:58,767 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43923'
2024-01-09 06:28:58,795 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35955'
2024-01-09 06:28:58,813 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44153'
2024-01-09 06:28:58,824 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46399'
2024-01-09 06:28:58,835 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40541'
2024-01-09 06:28:58,850 - distributed.scheduler - INFO - Receive client connection: Client-5dcc538d-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:28:58,850 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46817'
2024-01-09 06:28:58,851 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49900
2024-01-09 06:28:58,854 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37245'
2024-01-09 06:28:58,864 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40475'
2024-01-09 06:29:00,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:00,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:00,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:00,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:00,687 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:00,688 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:00,688 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46669
2024-01-09 06:29:00,688 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46669
2024-01-09 06:29:00,688 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34591
2024-01-09 06:29:00,688 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:00,689 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:00,689 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:00,689 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:00,689 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-38cmfrai
2024-01-09 06:29:00,689 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a5f5d526-edd9-4f10-b13e-5459063780e0
2024-01-09 06:29:00,689 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32855
2024-01-09 06:29:00,689 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32855
2024-01-09 06:29:00,689 - distributed.worker - INFO - Starting Worker plugin PreImport-55ac9d79-2fe0-4867-a9d1-7d85b8becd2a
2024-01-09 06:29:00,689 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42423
2024-01-09 06:29:00,689 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c17741bc-25c2-471c-a39b-b780b7e980d0
2024-01-09 06:29:00,689 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:00,689 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:00,689 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:00,689 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:00,689 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h605jy59
2024-01-09 06:29:00,690 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aa08bd04-0d30-4a7d-b463-332616c4aa76
2024-01-09 06:29:00,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:00,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:00,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:00,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:00,728 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:00,728 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36371
2024-01-09 06:29:00,728 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36371
2024-01-09 06:29:00,728 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:00,728 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38829
2024-01-09 06:29:00,729 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:00,729 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:00,729 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:00,729 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:00,729 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2e8lzudx
2024-01-09 06:29:00,729 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1b48406a-12a4-4e0f-9c75-3e95cfa5f9a6
2024-01-09 06:29:00,729 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35307
2024-01-09 06:29:00,729 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35307
2024-01-09 06:29:00,729 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42569
2024-01-09 06:29:00,729 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:00,729 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:00,730 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:00,730 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:00,730 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bf_87nu2
2024-01-09 06:29:00,730 - distributed.worker - INFO - Starting Worker plugin PreImport-50eba4b5-0a59-4d6f-a326-a9c3a35894b3
2024-01-09 06:29:00,730 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cda07608-17b9-425f-b357-c3df64bfc107
2024-01-09 06:29:00,730 - distributed.worker - INFO - Starting Worker plugin RMMSetup-adafa915-4dab-4740-a51a-385287ed0f27
2024-01-09 06:29:00,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:00,751 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:00,755 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:00,756 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41245
2024-01-09 06:29:00,756 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41245
2024-01-09 06:29:00,756 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37257
2024-01-09 06:29:00,756 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:00,756 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:00,756 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:00,756 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:00,756 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0sv4kyla
2024-01-09 06:29:00,756 - distributed.worker - INFO - Starting Worker plugin RMMSetup-325a3e72-aadc-4303-8069-74253410cdc9
2024-01-09 06:29:00,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:00,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:00,799 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:00,800 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41221
2024-01-09 06:29:00,800 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41221
2024-01-09 06:29:00,800 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45615
2024-01-09 06:29:00,800 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:00,800 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:00,800 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:00,800 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:00,800 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ito_6t6p
2024-01-09 06:29:00,801 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eedaaa76-265e-4ec3-b340-55a81dfd8de2
2024-01-09 06:29:00,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:00,802 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:00,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:00,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:00,805 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:00,806 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41501
2024-01-09 06:29:00,806 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41501
2024-01-09 06:29:00,806 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37585
2024-01-09 06:29:00,806 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:00,807 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:00,807 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:00,807 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:00,807 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xjq4eizt
2024-01-09 06:29:00,807 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8fd4c1b5-0a83-48c5-94f0-3abfe928e8a0
2024-01-09 06:29:00,807 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:00,808 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42749
2024-01-09 06:29:00,808 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42749
2024-01-09 06:29:00,808 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42147
2024-01-09 06:29:00,808 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:00,808 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:00,808 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:00,808 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:00,808 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mg0w8_bo
2024-01-09 06:29:00,808 - distributed.worker - INFO - Starting Worker plugin PreImport-98c0c5e5-09ec-4541-b751-b3c0821bf401
2024-01-09 06:29:00,809 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-03e4d75f-2e41-4524-8d72-b64b89827cce
2024-01-09 06:29:00,810 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5074119e-6500-4928-b899-4bb7e4ce014d
2024-01-09 06:29:02,799 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:02,821 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46669', status: init, memory: 0, processing: 0>
2024-01-09 06:29:02,822 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46669
2024-01-09 06:29:02,822 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40218
2024-01-09 06:29:02,823 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:02,824 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:02,824 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:02,825 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:02,948 - distributed.worker - INFO - Starting Worker plugin PreImport-19adb6af-4356-469f-b8ad-582f135c7aa1
2024-01-09 06:29:02,948 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4cfd0a45-fc63-4cb1-92fc-aaaf9f24b1d2
2024-01-09 06:29:02,948 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:02,979 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32855', status: init, memory: 0, processing: 0>
2024-01-09 06:29:02,980 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32855
2024-01-09 06:29:02,980 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40232
2024-01-09 06:29:02,981 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:02,981 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:02,981 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:02,983 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:03,111 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2602d91f-a447-4714-a850-3dcf45e09f60
2024-01-09 06:29:03,112 - distributed.worker - INFO - Starting Worker plugin PreImport-c98cd354-7cf5-4724-b664-716cba886cf6
2024-01-09 06:29:03,112 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,123 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e4f899c9-ae5b-4802-bf38-253c14d873c1
2024-01-09 06:29:03,124 - distributed.worker - INFO - Starting Worker plugin PreImport-852ba783-ee74-427f-95e9-b4a86853c1ba
2024-01-09 06:29:03,125 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,136 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41245', status: init, memory: 0, processing: 0>
2024-01-09 06:29:03,137 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41245
2024-01-09 06:29:03,137 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40246
2024-01-09 06:29:03,138 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:03,139 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:03,139 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,140 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:03,167 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36371', status: init, memory: 0, processing: 0>
2024-01-09 06:29:03,168 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36371
2024-01-09 06:29:03,168 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40250
2024-01-09 06:29:03,170 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:03,172 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:03,172 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,174 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:03,175 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,209 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35307', status: init, memory: 0, processing: 0>
2024-01-09 06:29:03,210 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35307
2024-01-09 06:29:03,210 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40256
2024-01-09 06:29:03,212 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:03,213 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:03,213 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,215 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:03,285 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-aba6f969-511e-42d7-822c-f50d601bdafe
2024-01-09 06:29:03,286 - distributed.worker - INFO - Starting Worker plugin PreImport-df3894c2-82c7-445f-860e-a32c04246ff1
2024-01-09 06:29:03,287 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,329 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41501', status: init, memory: 0, processing: 0>
2024-01-09 06:29:03,329 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41501
2024-01-09 06:29:03,329 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40266
2024-01-09 06:29:03,332 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:03,332 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3665bb2e-dce5-490d-9300-93bc09177f84
2024-01-09 06:29:03,333 - distributed.worker - INFO - Starting Worker plugin PreImport-0f7ef0cf-d9af-4338-bacb-8ac417913a5f
2024-01-09 06:29:03,333 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,334 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:03,334 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,333 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,336 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:03,357 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41221', status: init, memory: 0, processing: 0>
2024-01-09 06:29:03,358 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41221
2024-01-09 06:29:03,358 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40276
2024-01-09 06:29:03,359 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:03,359 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:03,359 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,361 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:03,367 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42749', status: init, memory: 0, processing: 0>
2024-01-09 06:29:03,367 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42749
2024-01-09 06:29:03,367 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40290
2024-01-09 06:29:03,369 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:03,370 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:03,370 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:03,372 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:03,379 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,379 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,379 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,379 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,380 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,380 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,380 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,380 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,385 - distributed.scheduler - INFO - Remove client Client-5dcc538d-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:03,385 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49900; closing.
2024-01-09 06:29:03,385 - distributed.scheduler - INFO - Remove client Client-5dcc538d-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:03,386 - distributed.scheduler - INFO - Close client connection: Client-5dcc538d-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:03,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,394 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,395 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:03,399 - distributed.scheduler - INFO - Remove client Client-5ebbec89-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:03,399 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49800; closing.
2024-01-09 06:29:03,399 - distributed.scheduler - INFO - Remove client Client-5ebbec89-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:03,400 - distributed.scheduler - INFO - Close client connection: Client-5ebbec89-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:03,520 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43923'. Reason: nanny-close
2024-01-09 06:29:03,520 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:03,521 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35955'. Reason: nanny-close
2024-01-09 06:29:03,521 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:03,521 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44153'. Reason: nanny-close
2024-01-09 06:29:03,522 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32855. Reason: nanny-close
2024-01-09 06:29:03,522 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:03,522 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46399'. Reason: nanny-close
2024-01-09 06:29:03,522 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46669. Reason: nanny-close
2024-01-09 06:29:03,522 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:03,522 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40541'. Reason: nanny-close
2024-01-09 06:29:03,522 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35307. Reason: nanny-close
2024-01-09 06:29:03,522 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:03,523 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46817'. Reason: nanny-close
2024-01-09 06:29:03,523 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:03,523 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37245'. Reason: nanny-close
2024-01-09 06:29:03,523 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36371. Reason: nanny-close
2024-01-09 06:29:03,523 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41221. Reason: nanny-close
2024-01-09 06:29:03,523 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:03,523 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40232; closing.
2024-01-09 06:29:03,523 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:03,523 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40475'. Reason: nanny-close
2024-01-09 06:29:03,524 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41245. Reason: nanny-close
2024-01-09 06:29:03,524 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32855', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781743.5240684')
2024-01-09 06:29:03,524 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:03,524 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42749. Reason: nanny-close
2024-01-09 06:29:03,525 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:03,525 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:03,525 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41501. Reason: nanny-close
2024-01-09 06:29:03,525 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:03,525 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:03,525 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40256; closing.
2024-01-09 06:29:03,526 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:03,526 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35307', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781743.5266638')
2024-01-09 06:29:03,526 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:03,527 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:03,527 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40276; closing.
2024-01-09 06:29:03,527 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:03,527 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:03,527 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:03,527 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41221', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781743.5277002')
2024-01-09 06:29:03,527 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:03,528 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40246; closing.
2024-01-09 06:29:03,528 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40250; closing.
2024-01-09 06:29:03,528 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:03,528 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40218; closing.
2024-01-09 06:29:03,528 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:03,529 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41245', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781743.5289803')
2024-01-09 06:29:03,529 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36371', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781743.5292802')
2024-01-09 06:29:03,529 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40290; closing.
2024-01-09 06:29:03,529 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:03,529 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:03,529 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46669', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781743.5298188')
2024-01-09 06:29:03,530 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42749', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781743.530492')
2024-01-09 06:29:03,530 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40266; closing.
2024-01-09 06:29:03,531 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41501', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781743.5312955')
2024-01-09 06:29:03,531 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:05,453 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38031', status: init, memory: 0, processing: 0>
2024-01-09 06:29:05,454 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38031
2024-01-09 06:29:05,454 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40292
2024-01-09 06:29:05,506 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:29:05,506 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:29:05,507 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:29:05,508 - distributed.core - INFO - Connection to tcp://127.0.0.1:40292 has been closed.
2024-01-09 06:29:05,508 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38031', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781745.5085948')
2024-01-09 06:29:05,508 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:05,511 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:29:05,511 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-09 06:29:07,816 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:07,821 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:29:07,825 - distributed.scheduler - INFO - State start
2024-01-09 06:29:07,853 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:07,854 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:29:07,855 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:29:07,855 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:29:08,089 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33783'
2024-01-09 06:29:08,109 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39615'
2024-01-09 06:29:08,121 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39973'
2024-01-09 06:29:08,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33353'
2024-01-09 06:29:08,140 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35295'
2024-01-09 06:29:08,151 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39703'
2024-01-09 06:29:08,162 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37119'
2024-01-09 06:29:08,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45567'
2024-01-09 06:29:08,361 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38397', status: init, memory: 0, processing: 0>
2024-01-09 06:29:08,374 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38397
2024-01-09 06:29:08,374 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41046
2024-01-09 06:29:08,413 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41046; closing.
2024-01-09 06:29:08,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38397', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781748.4140246')
2024-01-09 06:29:08,414 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:08,595 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37265', status: init, memory: 0, processing: 0>
2024-01-09 06:29:08,596 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37265
2024-01-09 06:29:08,596 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41060
2024-01-09 06:29:08,609 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41060; closing.
2024-01-09 06:29:08,609 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37265', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781748.609307')
2024-01-09 06:29:08,609 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:09,596 - distributed.scheduler - INFO - Receive client connection: Client-658b5cba-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:09,597 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41072
2024-01-09 06:29:10,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:10,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:10,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:10,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:10,057 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:10,058 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34189
2024-01-09 06:29:10,058 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34189
2024-01-09 06:29:10,058 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34737
2024-01-09 06:29:10,058 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:10,058 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,058 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:10,058 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:10,058 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-krpi0mb8
2024-01-09 06:29:10,059 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4cedd64a-5b1c-4c82-b8ff-4c19a8bcc4e6
2024-01-09 06:29:10,059 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:10,060 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37847
2024-01-09 06:29:10,060 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37847
2024-01-09 06:29:10,060 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45903
2024-01-09 06:29:10,060 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:10,060 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,060 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:10,060 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:10,060 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pkgqt89s
2024-01-09 06:29:10,060 - distributed.worker - INFO - Starting Worker plugin RMMSetup-155cb260-7c70-410e-801f-4c42fc1d6af1
2024-01-09 06:29:10,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:10,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:10,122 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:10,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:10,123 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36607
2024-01-09 06:29:10,123 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36607
2024-01-09 06:29:10,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:10,123 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46177
2024-01-09 06:29:10,123 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:10,123 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,123 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:10,123 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:10,123 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wa3t6273
2024-01-09 06:29:10,124 - distributed.worker - INFO - Starting Worker plugin RMMSetup-194a19d5-f52b-43a8-872e-5f0a8b7c9046
2024-01-09 06:29:10,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:10,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:10,128 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:10,128 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39365
2024-01-09 06:29:10,129 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39365
2024-01-09 06:29:10,129 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36511
2024-01-09 06:29:10,129 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:10,129 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,129 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:10,129 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:10,129 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-il641ng8
2024-01-09 06:29:10,129 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5d2a41a0-cb6c-4438-98d7-696dac3d0994
2024-01-09 06:29:10,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:10,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:10,133 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:10,134 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43523
2024-01-09 06:29:10,134 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43523
2024-01-09 06:29:10,134 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40537
2024-01-09 06:29:10,135 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:10,135 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,135 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:10,135 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:10,135 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d488yjf_
2024-01-09 06:29:10,135 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:10,135 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0ad945b-9c66-4b94-884a-9567ddf13303
2024-01-09 06:29:10,136 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41933
2024-01-09 06:29:10,136 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41933
2024-01-09 06:29:10,136 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39029
2024-01-09 06:29:10,136 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:10,136 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,136 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:10,136 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:10,136 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bogmnqti
2024-01-09 06:29:10,136 - distributed.worker - INFO - Starting Worker plugin PreImport-7d9f6d58-f9fc-4972-8629-d0ad3dc6c63b
2024-01-09 06:29:10,137 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7c84c7b8-4c28-43ee-b4ab-5c418b44e90b
2024-01-09 06:29:10,137 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9b7e526f-119f-4aec-b34f-7c7129be55a3
2024-01-09 06:29:10,142 - distributed.scheduler - INFO - Receive client connection: Client-635da2ab-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:10,143 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57118
2024-01-09 06:29:10,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:10,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:10,151 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:10,152 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40245
2024-01-09 06:29:10,152 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40245
2024-01-09 06:29:10,152 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37863
2024-01-09 06:29:10,152 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:10,152 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,152 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:10,153 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:10,153 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gu6vgpnh
2024-01-09 06:29:10,153 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dfc3bc37-c885-4171-b445-41af17cdda88
2024-01-09 06:29:10,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:10,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:10,342 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:10,343 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42265
2024-01-09 06:29:10,343 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42265
2024-01-09 06:29:10,343 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46849
2024-01-09 06:29:10,343 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:10,343 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,345 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:10,345 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:10,345 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ornsporu
2024-01-09 06:29:10,345 - distributed.worker - INFO - Starting Worker plugin RMMSetup-77d1176c-5f41-4af5-a42c-dd09a91c07e6
2024-01-09 06:29:10,932 - distributed.worker - INFO - Starting Worker plugin PreImport-540905e2-8351-4ba8-a6e6-148d453f6795
2024-01-09 06:29:10,932 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2f1805db-3951-4ef0-b123-a079788356c9
2024-01-09 06:29:10,933 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,959 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34189', status: init, memory: 0, processing: 0>
2024-01-09 06:29:10,960 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34189
2024-01-09 06:29:10,961 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57138
2024-01-09 06:29:10,961 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:10,962 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:10,962 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:10,964 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:11,993 - distributed.worker - INFO - Starting Worker plugin PreImport-6a30ec8f-aef2-43f6-b71f-bbf2e5ecbf0a
2024-01-09 06:29:11,993 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-46d0f691-2358-4bb1-8a6b-c74e099a2a1f
2024-01-09 06:29:11,995 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,029 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37847', status: init, memory: 0, processing: 0>
2024-01-09 06:29:12,029 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37847
2024-01-09 06:29:12,029 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57156
2024-01-09 06:29:12,031 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:12,032 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:12,032 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,034 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:12,153 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dd2a20d7-b51b-4990-afe9-475b60492913
2024-01-09 06:29:12,154 - distributed.worker - INFO - Starting Worker plugin PreImport-cd0e28cc-ee02-46e0-b1f4-773606079648
2024-01-09 06:29:12,156 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,185 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36607', status: init, memory: 0, processing: 0>
2024-01-09 06:29:12,186 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36607
2024-01-09 06:29:12,186 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57160
2024-01-09 06:29:12,187 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:12,188 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:12,188 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,190 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:12,275 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,291 - distributed.worker - INFO - Starting Worker plugin PreImport-189915de-bc70-4e3e-a2b1-44b7c91d481c
2024-01-09 06:29:12,291 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3ecdbdfe-00c1-47b0-9cdb-0c904e560a11
2024-01-09 06:29:12,292 - distributed.worker - INFO - Starting Worker plugin PreImport-8aa772cd-3158-4d56-83de-d6de02193661
2024-01-09 06:29:12,292 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5952bb03-c624-4c90-ae6f-d9da0e697c55
2024-01-09 06:29:12,293 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,294 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,296 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-656901e6-4f0e-40df-93d0-a8e13d5794ed
2024-01-09 06:29:12,297 - distributed.worker - INFO - Starting Worker plugin PreImport-4f0a389b-2e45-4f96-8196-4a75a7fac525
2024-01-09 06:29:12,297 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,298 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5a4877d4-572e-493d-8cd5-ceb1d2461e10
2024-01-09 06:29:12,298 - distributed.worker - INFO - Starting Worker plugin PreImport-529a5e74-44b5-460f-9d83-ecf06ba7be96
2024-01-09 06:29:12,299 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,303 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41933', status: init, memory: 0, processing: 0>
2024-01-09 06:29:12,304 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41933
2024-01-09 06:29:12,304 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57252
2024-01-09 06:29:12,305 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:12,306 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:12,306 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,307 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:12,320 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42265', status: init, memory: 0, processing: 0>
2024-01-09 06:29:12,321 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42265
2024-01-09 06:29:12,321 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57260
2024-01-09 06:29:12,322 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:12,323 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40245', status: init, memory: 0, processing: 0>
2024-01-09 06:29:12,323 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:12,323 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,323 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40245
2024-01-09 06:29:12,324 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57274
2024-01-09 06:29:12,324 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:12,324 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:12,325 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43523', status: init, memory: 0, processing: 0>
2024-01-09 06:29:12,325 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43523
2024-01-09 06:29:12,325 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57278
2024-01-09 06:29:12,325 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:12,325 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,326 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:12,327 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:12,327 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:12,327 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,328 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39365', status: init, memory: 0, processing: 0>
2024-01-09 06:29:12,328 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39365
2024-01-09 06:29:12,328 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57268
2024-01-09 06:29:12,329 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:12,330 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:12,331 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:12,331 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:12,333 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:12,345 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,345 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,346 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,346 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,346 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,346 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,346 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,346 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,348 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,348 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,348 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,349 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:12,355 - distributed.scheduler - INFO - Remove client Client-658b5cba-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:12,355 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41072; closing.
2024-01-09 06:29:12,355 - distributed.scheduler - INFO - Remove client Client-658b5cba-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:12,358 - distributed.scheduler - INFO - Close client connection: Client-658b5cba-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:12,358 - distributed.scheduler - INFO - Remove client Client-635da2ab-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:12,358 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57118; closing.
2024-01-09 06:29:12,358 - distributed.scheduler - INFO - Remove client Client-635da2ab-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:12,359 - distributed.scheduler - INFO - Close client connection: Client-635da2ab-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:12,360 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33783'. Reason: nanny-close
2024-01-09 06:29:12,360 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:12,360 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39615'. Reason: nanny-close
2024-01-09 06:29:12,361 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:12,361 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39973'. Reason: nanny-close
2024-01-09 06:29:12,361 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:12,361 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37847. Reason: nanny-close
2024-01-09 06:29:12,361 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33353'. Reason: nanny-close
2024-01-09 06:29:12,361 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34189. Reason: nanny-close
2024-01-09 06:29:12,361 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:12,362 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35295'. Reason: nanny-close
2024-01-09 06:29:12,362 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40245. Reason: nanny-close
2024-01-09 06:29:12,362 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:12,362 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39703'. Reason: nanny-close
2024-01-09 06:29:12,362 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41933. Reason: nanny-close
2024-01-09 06:29:12,362 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:12,363 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37119'. Reason: nanny-close
2024-01-09 06:29:12,363 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:12,363 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39365. Reason: nanny-close
2024-01-09 06:29:12,363 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45567'. Reason: nanny-close
2024-01-09 06:29:12,363 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:12,363 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36607. Reason: nanny-close
2024-01-09 06:29:12,363 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:12,363 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:12,364 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57156; closing.
2024-01-09 06:29:12,364 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43523. Reason: nanny-close
2024-01-09 06:29:12,364 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42265. Reason: nanny-close
2024-01-09 06:29:12,364 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37847', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781752.3644483')
2024-01-09 06:29:12,364 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57138; closing.
2024-01-09 06:29:12,364 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:12,365 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:12,365 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:12,365 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:12,365 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:12,365 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34189', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781752.3654938')
2024-01-09 06:29:12,365 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:12,366 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:12,366 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:12,366 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57268; closing.
2024-01-09 06:29:12,366 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:12,366 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:12,366 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:12,367 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57274; closing.
2024-01-09 06:29:12,367 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:12,367 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57252; closing.
2024-01-09 06:29:12,367 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:12,368 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:12,367 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:57138>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-09 06:29:12,369 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39365', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781752.3697069')
2024-01-09 06:29:12,370 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57160; closing.
2024-01-09 06:29:12,370 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40245', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781752.3703742')
2024-01-09 06:29:12,370 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41933', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781752.3707216')
2024-01-09 06:29:12,371 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57278; closing.
2024-01-09 06:29:12,371 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36607', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781752.3716364')
2024-01-09 06:29:12,372 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43523', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781752.3720243')
2024-01-09 06:29:12,372 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57260; closing.
2024-01-09 06:29:12,372 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42265', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781752.372777')
2024-01-09 06:29:12,373 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:13,376 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:29:13,377 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:29:13,377 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:29:13,379 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:29:13,380 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-09 06:29:15,709 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:15,714 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:29:15,718 - distributed.scheduler - INFO - State start
2024-01-09 06:29:16,267 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:16,268 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:29:16,269 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:29:16,269 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:29:16,353 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40433', status: init, memory: 0, processing: 0>
2024-01-09 06:29:16,367 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40433
2024-01-09 06:29:16,367 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57464
2024-01-09 06:29:16,384 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57464; closing.
2024-01-09 06:29:16,384 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40433', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781756.3843079')
2024-01-09 06:29:16,384 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:16,482 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46489', status: init, memory: 0, processing: 0>
2024-01-09 06:29:16,483 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46489
2024-01-09 06:29:16,483 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57476
2024-01-09 06:29:16,497 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57476; closing.
2024-01-09 06:29:16,497 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46489', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781756.4976308')
2024-01-09 06:29:16,497 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:16,513 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44251'
2024-01-09 06:29:16,538 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46491'
2024-01-09 06:29:16,551 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37175'
2024-01-09 06:29:16,569 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34979'
2024-01-09 06:29:16,573 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33499'
2024-01-09 06:29:16,586 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41177'
2024-01-09 06:29:16,603 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35583'
2024-01-09 06:29:16,616 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36755'
2024-01-09 06:29:16,626 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36895', status: init, memory: 0, processing: 0>
2024-01-09 06:29:16,627 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36895
2024-01-09 06:29:16,627 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57550
2024-01-09 06:29:16,637 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57550; closing.
2024-01-09 06:29:16,637 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36895', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781756.6378906')
2024-01-09 06:29:16,638 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:16,639 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42461', status: init, memory: 0, processing: 0>
2024-01-09 06:29:16,639 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42461
2024-01-09 06:29:16,639 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57566
2024-01-09 06:29:16,644 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43647', status: init, memory: 0, processing: 0>
2024-01-09 06:29:16,645 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43647
2024-01-09 06:29:16,645 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57580
2024-01-09 06:29:16,650 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43927', status: init, memory: 0, processing: 0>
2024-01-09 06:29:16,650 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43927
2024-01-09 06:29:16,650 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57592
2024-01-09 06:29:16,652 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35129', status: init, memory: 0, processing: 0>
2024-01-09 06:29:16,652 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35129
2024-01-09 06:29:16,653 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57596
2024-01-09 06:29:16,690 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57596; closing.
2024-01-09 06:29:16,690 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35129', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781756.6905236')
2024-01-09 06:29:16,692 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57580; closing.
2024-01-09 06:29:16,692 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57566; closing.
2024-01-09 06:29:16,693 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43647', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781756.6935318')
2024-01-09 06:29:16,694 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42461', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781756.693959')
2024-01-09 06:29:16,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57592; closing.
2024-01-09 06:29:16,701 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43927', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781756.7017188')
2024-01-09 06:29:16,702 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:16,730 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45571', status: init, memory: 0, processing: 0>
2024-01-09 06:29:16,731 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45571
2024-01-09 06:29:16,731 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57612
2024-01-09 06:29:16,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:57612 has been closed.
2024-01-09 06:29:16,825 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45571', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781756.8251529')
2024-01-09 06:29:16,825 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:17,681 - distributed.scheduler - INFO - Receive client connection: Client-6a5d0235-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:17,682 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57624
2024-01-09 06:29:17,693 - distributed.scheduler - INFO - Receive client connection: Client-680d3332-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:17,694 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57646
2024-01-09 06:29:18,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:18,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:18,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:18,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:18,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:18,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:18,498 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:18,498 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:18,499 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41763
2024-01-09 06:29:18,499 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36445
2024-01-09 06:29:18,499 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41763
2024-01-09 06:29:18,499 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36445
2024-01-09 06:29:18,499 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40949
2024-01-09 06:29:18,499 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45971
2024-01-09 06:29:18,499 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:18,499 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:18,499 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:18,499 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:18,499 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:18,499 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:18,499 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:18,499 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:18,499 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i3t0i_09
2024-01-09 06:29:18,499 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pja8sefo
2024-01-09 06:29:18,499 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3c96d816-d182-4681-b84c-cea71294cf59
2024-01-09 06:29:18,499 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e6d1f0ad-4968-442e-b806-45a342358444
2024-01-09 06:29:18,500 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:18,501 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32871
2024-01-09 06:29:18,501 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32871
2024-01-09 06:29:18,501 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36493
2024-01-09 06:29:18,501 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:18,501 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:18,501 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:18,501 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:18,501 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oqd2750z
2024-01-09 06:29:18,501 - distributed.worker - INFO - Starting Worker plugin PreImport-49254cbc-a459-44cf-b9a8-503a00f63132
2024-01-09 06:29:18,502 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-707a8def-12b5-4d39-8791-04c78a15220b
2024-01-09 06:29:18,502 - distributed.worker - INFO - Starting Worker plugin RMMSetup-42e9265f-632d-43eb-8568-b8d5345dc05b
2024-01-09 06:29:18,541 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:18,541 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:18,545 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:18,546 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35161
2024-01-09 06:29:18,546 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35161
2024-01-09 06:29:18,546 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44491
2024-01-09 06:29:18,546 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:18,546 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:18,546 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:18,546 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:18,547 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1rrhmfh5
2024-01-09 06:29:18,547 - distributed.worker - INFO - Starting Worker plugin RMMSetup-231446dc-f126-480e-a70f-74bf4d08ad4c
2024-01-09 06:29:18,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:18,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:18,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:18,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:18,577 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:18,578 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41111
2024-01-09 06:29:18,578 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:18,578 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41111
2024-01-09 06:29:18,578 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35815
2024-01-09 06:29:18,578 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:18,578 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:18,578 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:18,578 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:18,578 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8j40s8su
2024-01-09 06:29:18,578 - distributed.worker - INFO - Starting Worker plugin RMMSetup-704c9385-4c37-4e26-b120-ca030fbacd33
2024-01-09 06:29:18,579 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45447
2024-01-09 06:29:18,579 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45447
2024-01-09 06:29:18,579 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43525
2024-01-09 06:29:18,579 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:18,579 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:18,579 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:18,579 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:18,579 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i1eu24hr
2024-01-09 06:29:18,579 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eb1170c1-6a10-4d9f-a7e1-03802b6c8c3c
2024-01-09 06:29:18,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:18,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:18,594 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:18,595 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36049
2024-01-09 06:29:18,595 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36049
2024-01-09 06:29:18,595 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42859
2024-01-09 06:29:18,595 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:18,595 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:18,595 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:18,595 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:18,595 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bnl_6po0
2024-01-09 06:29:18,595 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fc258c49-5eb0-453d-bf80-83730bc46992
2024-01-09 06:29:18,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:18,638 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:18,643 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:18,645 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40749
2024-01-09 06:29:18,645 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40749
2024-01-09 06:29:18,645 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39397
2024-01-09 06:29:18,645 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:18,645 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:18,645 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:18,645 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:18,645 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qprwmi8i
2024-01-09 06:29:18,645 - distributed.worker - INFO - Starting Worker plugin PreImport-61c7a163-ba25-4809-ab4a-1ea4be6196ed
2024-01-09 06:29:18,646 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-26031ea3-beea-4010-993a-53dc7887a82a
2024-01-09 06:29:18,646 - distributed.worker - INFO - Starting Worker plugin RMMSetup-56af0533-218a-470d-a9a9-6e272dd5832f
2024-01-09 06:29:20,691 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,720 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32871', status: init, memory: 0, processing: 0>
2024-01-09 06:29:20,721 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32871
2024-01-09 06:29:20,721 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35432
2024-01-09 06:29:20,722 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:20,722 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:20,722 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,724 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:20,729 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c4327ab5-90d4-4a62-b373-2fe72f7d9fa4
2024-01-09 06:29:20,729 - distributed.worker - INFO - Starting Worker plugin PreImport-af8dc91a-f48a-4546-94f5-2bb26e1a94bb
2024-01-09 06:29:20,731 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,757 - distributed.worker - INFO - Starting Worker plugin PreImport-f35e9d66-1645-45db-b388-a77469295448
2024-01-09 06:29:20,758 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c8dce291-6bc3-4d23-8a0f-05923a90d13f
2024-01-09 06:29:20,759 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,766 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41763', status: init, memory: 0, processing: 0>
2024-01-09 06:29:20,767 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41763
2024-01-09 06:29:20,767 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35442
2024-01-09 06:29:20,768 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:20,770 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:20,770 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,772 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:20,773 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0934bda2-aa17-4566-ad2e-164bc7519083
2024-01-09 06:29:20,774 - distributed.worker - INFO - Starting Worker plugin PreImport-cb8b1b34-29ad-4e72-b6c4-16739b67612e
2024-01-09 06:29:20,774 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,778 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b1c19649-8ef8-4598-83ea-ccccb948ea34
2024-01-09 06:29:20,779 - distributed.worker - INFO - Starting Worker plugin PreImport-488ec023-b00c-4942-9d22-a9dc6e316d46
2024-01-09 06:29:20,781 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,793 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-36d605ff-26b0-4aa8-b0b2-97ef0f89dd19
2024-01-09 06:29:20,794 - distributed.worker - INFO - Starting Worker plugin PreImport-ef108693-c4a0-4732-8c3f-e42133ad344a
2024-01-09 06:29:20,795 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36445', status: init, memory: 0, processing: 0>
2024-01-09 06:29:20,795 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,795 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36445
2024-01-09 06:29:20,795 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35454
2024-01-09 06:29:20,796 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c4e4e1be-27c8-46e7-9a1c-d695264b45a7
2024-01-09 06:29:20,796 - distributed.worker - INFO - Starting Worker plugin PreImport-9098a88d-1a5d-449d-ac18-603b1c8a954d
2024-01-09 06:29:20,797 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,797 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:20,798 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:20,798 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,801 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:20,803 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35161', status: init, memory: 0, processing: 0>
2024-01-09 06:29:20,803 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35161
2024-01-09 06:29:20,803 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35458
2024-01-09 06:29:20,804 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:20,805 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:20,805 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,807 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:20,816 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45447', status: init, memory: 0, processing: 0>
2024-01-09 06:29:20,816 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45447
2024-01-09 06:29:20,817 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35464
2024-01-09 06:29:20,818 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:20,819 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:20,819 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,819 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,821 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:20,822 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36049', status: init, memory: 0, processing: 0>
2024-01-09 06:29:20,823 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36049
2024-01-09 06:29:20,823 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35476
2024-01-09 06:29:20,824 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:20,824 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:20,824 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,826 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:20,831 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41111', status: init, memory: 0, processing: 0>
2024-01-09 06:29:20,831 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41111
2024-01-09 06:29:20,831 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35486
2024-01-09 06:29:20,833 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:20,834 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:20,834 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,836 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:20,846 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40749', status: init, memory: 0, processing: 0>
2024-01-09 06:29:20,846 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40749
2024-01-09 06:29:20,846 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35500
2024-01-09 06:29:20,847 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:20,848 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:20,848 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:20,850 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:20,915 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,915 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,915 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,915 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,916 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,916 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,916 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,916 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,918 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,918 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,918 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,918 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,918 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,918 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,919 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,919 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:20,932 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,932 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,933 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,933 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,933 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,933 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,933 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,933 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,937 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,937 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,937 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,937 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,937 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,937 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,937 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,938 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:20,944 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:20,945 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:20,946 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:20,948 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:20,948 - distributed.scheduler - INFO - Remove client Client-6a5d0235-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:20,948 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57624; closing.
2024-01-09 06:29:20,949 - distributed.scheduler - INFO - Remove client Client-6a5d0235-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:20,949 - distributed.scheduler - INFO - Close client connection: Client-6a5d0235-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:20,950 - distributed.scheduler - INFO - Remove client Client-680d3332-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:20,950 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57646; closing.
2024-01-09 06:29:20,950 - distributed.scheduler - INFO - Remove client Client-680d3332-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:20,951 - distributed.scheduler - INFO - Close client connection: Client-680d3332-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:20,952 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44251'. Reason: nanny-close
2024-01-09 06:29:20,952 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:20,952 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46491'. Reason: nanny-close
2024-01-09 06:29:20,953 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:20,953 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37175'. Reason: nanny-close
2024-01-09 06:29:20,953 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36445. Reason: nanny-close
2024-01-09 06:29:20,954 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:20,954 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34979'. Reason: nanny-close
2024-01-09 06:29:20,954 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41763. Reason: nanny-close
2024-01-09 06:29:20,954 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:20,954 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33499'. Reason: nanny-close
2024-01-09 06:29:20,954 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:20,954 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32871. Reason: nanny-close
2024-01-09 06:29:20,955 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41177'. Reason: nanny-close
2024-01-09 06:29:20,955 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:20,955 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35161. Reason: nanny-close
2024-01-09 06:29:20,955 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35583'. Reason: nanny-close
2024-01-09 06:29:20,955 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:20,955 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45447. Reason: nanny-close
2024-01-09 06:29:20,955 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36755'. Reason: nanny-close
2024-01-09 06:29:20,956 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:20,956 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35454; closing.
2024-01-09 06:29:20,956 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:20,956 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41111. Reason: nanny-close
2024-01-09 06:29:20,956 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36445', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781760.956287')
2024-01-09 06:29:20,956 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:20,956 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:20,956 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40749. Reason: nanny-close
2024-01-09 06:29:20,957 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:20,957 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36049. Reason: nanny-close
2024-01-09 06:29:20,957 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:20,957 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:20,958 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35458; closing.
2024-01-09 06:29:20,958 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35442; closing.
2024-01-09 06:29:20,958 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:20,958 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:20,958 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35432; closing.
2024-01-09 06:29:20,958 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:20,958 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:20,959 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35161', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781760.9590921')
2024-01-09 06:29:20,959 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:20,959 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:20,959 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41763', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781760.9594545')
2024-01-09 06:29:20,959 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:20,959 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32871', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781760.9598045')
2024-01-09 06:29:20,960 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35464; closing.
2024-01-09 06:29:20,960 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:20,960 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:20,960 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45447', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781760.960709')
2024-01-09 06:29:20,960 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:20,961 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35486; closing.
2024-01-09 06:29:20,961 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41111', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781760.961695')
2024-01-09 06:29:20,962 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35500; closing.
2024-01-09 06:29:20,962 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35476; closing.
2024-01-09 06:29:20,962 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40749', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781760.9625907')
2024-01-09 06:29:20,963 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36049', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781760.962984')
2024-01-09 06:29:20,963 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:21,967 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:29:21,968 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:29:21,968 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:29:21,970 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:29:21,971 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-09 06:29:24,375 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:24,381 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:29:24,385 - distributed.scheduler - INFO - State start
2024-01-09 06:29:24,466 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:24,468 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:29:24,469 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:29:24,469 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:29:24,729 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34141', status: init, memory: 0, processing: 0>
2024-01-09 06:29:24,759 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34141
2024-01-09 06:29:24,760 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35624
2024-01-09 06:29:24,761 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44769', status: init, memory: 0, processing: 0>
2024-01-09 06:29:24,762 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44769
2024-01-09 06:29:24,762 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35602
2024-01-09 06:29:24,763 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38967', status: init, memory: 0, processing: 0>
2024-01-09 06:29:24,763 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38967
2024-01-09 06:29:24,763 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35608
2024-01-09 06:29:24,768 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39187'
2024-01-09 06:29:24,787 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37387', status: init, memory: 0, processing: 0>
2024-01-09 06:29:24,788 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37387
2024-01-09 06:29:24,788 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35626
2024-01-09 06:29:24,792 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45243'
2024-01-09 06:29:24,798 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40649', status: init, memory: 0, processing: 0>
2024-01-09 06:29:24,799 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40649
2024-01-09 06:29:24,799 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35708
2024-01-09 06:29:24,810 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45583'
2024-01-09 06:29:24,815 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34191', status: init, memory: 0, processing: 0>
2024-01-09 06:29:24,816 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34191
2024-01-09 06:29:24,816 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35722
2024-01-09 06:29:24,817 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35708; closing.
2024-01-09 06:29:24,819 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40649', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781764.8188822')
2024-01-09 06:29:24,823 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39279'
2024-01-09 06:29:24,823 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35602; closing.
2024-01-09 06:29:24,824 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35624; closing.
2024-01-09 06:29:24,825 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44769', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781764.825433')
2024-01-09 06:29:24,826 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34141', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781764.8259413')
2024-01-09 06:29:24,826 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35626; closing.
2024-01-09 06:29:24,827 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37387', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781764.8278306')
2024-01-09 06:29:24,829 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44137', status: init, memory: 0, processing: 0>
2024-01-09 06:29:24,829 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44137
2024-01-09 06:29:24,830 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35736
2024-01-09 06:29:24,830 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35608; closing.
2024-01-09 06:29:24,831 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35624>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-09 06:29:24,834 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35626>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35626>: Stream is closed
2024-01-09 06:29:24,834 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35602>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-09 06:29:24,835 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38967', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781764.8354228')
2024-01-09 06:29:24,843 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38875'
2024-01-09 06:29:24,861 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43915'
2024-01-09 06:29:24,870 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35736; closing.
2024-01-09 06:29:24,871 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44137', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781764.8710518')
2024-01-09 06:29:24,879 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35722; closing.
2024-01-09 06:29:24,880 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34191', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781764.8801818')
2024-01-09 06:29:24,880 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:24,881 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36505', status: init, memory: 0, processing: 0>
2024-01-09 06:29:24,882 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36505
2024-01-09 06:29:24,882 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35738
2024-01-09 06:29:24,883 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35722>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-09 06:29:24,892 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46233'
2024-01-09 06:29:24,905 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42073'
2024-01-09 06:29:24,917 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35738; closing.
2024-01-09 06:29:24,917 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36505', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781764.9176586')
2024-01-09 06:29:24,918 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:26,223 - distributed.scheduler - INFO - Receive client connection: Client-6f746785-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:26,224 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35742
2024-01-09 06:29:27,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:27,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:27,567 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:27,568 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44625
2024-01-09 06:29:27,568 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44625
2024-01-09 06:29:27,569 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34589
2024-01-09 06:29:27,569 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:27,569 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:27,569 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:27,569 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:27,569 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e0wzksfb
2024-01-09 06:29:27,569 - distributed.worker - INFO - Starting Worker plugin RMMSetup-87adc57b-f735-4d1f-95c1-b483b4230242
2024-01-09 06:29:27,586 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:27,586 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:27,591 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:27,592 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34977
2024-01-09 06:29:27,592 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34977
2024-01-09 06:29:27,592 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39647
2024-01-09 06:29:27,592 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:27,592 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:27,592 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:27,592 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:27,592 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-chdsc3nh
2024-01-09 06:29:27,593 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8ef5a994-2eee-42ed-bda1-aaa0770f772e
2024-01-09 06:29:27,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:27,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:27,599 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:27,600 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33003
2024-01-09 06:29:27,600 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33003
2024-01-09 06:29:27,600 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40275
2024-01-09 06:29:27,601 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:27,601 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:27,601 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:27,601 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:27,601 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gdtn7616
2024-01-09 06:29:27,601 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d5619321-7add-43c8-a085-47c6570b0244
2024-01-09 06:29:27,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:27,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:27,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:27,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:27,618 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:27,619 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34925
2024-01-09 06:29:27,619 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34925
2024-01-09 06:29:27,619 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44925
2024-01-09 06:29:27,619 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:27,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:27,619 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:27,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:27,619 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:27,619 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:27,620 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_kcnj58u
2024-01-09 06:29:27,620 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bb8393cf-e6c2-4c16-8164-190e19340c03
2024-01-09 06:29:27,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:27,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:27,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:27,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:27,623 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:27,624 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46291
2024-01-09 06:29:27,624 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46291
2024-01-09 06:29:27,624 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43899
2024-01-09 06:29:27,624 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:27,624 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:27,624 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:27,624 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:27,624 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:27,624 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jqmzvnxv
2024-01-09 06:29:27,624 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d5b3f516-c944-4120-b4c7-b298f765a7ff
2024-01-09 06:29:27,625 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a4d84a1f-7369-4587-966e-8d5f809bef97
2024-01-09 06:29:27,625 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33699
2024-01-09 06:29:27,625 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33699
2024-01-09 06:29:27,625 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38295
2024-01-09 06:29:27,625 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:27,625 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:27,625 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:27,625 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:27,625 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:27,626 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mlc3xane
2024-01-09 06:29:27,626 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e3363de8-4175-42ff-80dc-f1267c2cbc61
2024-01-09 06:29:27,626 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33239
2024-01-09 06:29:27,626 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33239
2024-01-09 06:29:27,626 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33605
2024-01-09 06:29:27,626 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:27,627 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:27,627 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:27,627 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:27,627 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8wn10zvp
2024-01-09 06:29:27,627 - distributed.worker - INFO - Starting Worker plugin PreImport-2b18b030-3796-41a1-b45d-26b907f9e464
2024-01-09 06:29:27,627 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2273e400-d76d-49f6-9e0e-f0764dac8ca3
2024-01-09 06:29:27,627 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3afc2ac6-cbfa-49ba-a833-983ccc0c78f4
2024-01-09 06:29:27,627 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:27,628 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33931
2024-01-09 06:29:27,629 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33931
2024-01-09 06:29:27,629 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35587
2024-01-09 06:29:27,629 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:27,629 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:27,629 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:27,629 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:27,629 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-07htekj_
2024-01-09 06:29:27,629 - distributed.worker - INFO - Starting Worker plugin RMMSetup-407f118b-8771-432c-b5bc-3afda166e783
2024-01-09 06:29:28,747 - distributed.scheduler - INFO - Receive client connection: Client-6d36698d-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:28,748 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35758
2024-01-09 06:29:30,648 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6cf1dbb8-e562-476f-b682-08d995233fae
2024-01-09 06:29:30,648 - distributed.worker - INFO - Starting Worker plugin PreImport-68ad0b45-9d10-4cd2-94c2-31136a882c93
2024-01-09 06:29:30,648 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,675 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33003', status: init, memory: 0, processing: 0>
2024-01-09 06:29:30,676 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33003
2024-01-09 06:29:30,676 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44048
2024-01-09 06:29:30,677 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:30,678 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:30,678 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,680 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:30,705 - distributed.worker - INFO - Starting Worker plugin PreImport-315d19b8-d130-4947-90f3-1d9b86e84bda
2024-01-09 06:29:30,707 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,720 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9cd9714b-ff06-4c36-a433-a328ce667d85
2024-01-09 06:29:30,722 - distributed.worker - INFO - Starting Worker plugin PreImport-96189804-43cd-4645-a117-94d849529f14
2024-01-09 06:29:30,723 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,726 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,738 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8712e180-e24f-45c5-9908-f956467d1020
2024-01-09 06:29:30,739 - distributed.worker - INFO - Starting Worker plugin PreImport-590a8c8c-20ab-4871-9714-c6c8d7a2db90
2024-01-09 06:29:30,740 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46291', status: init, memory: 0, processing: 0>
2024-01-09 06:29:30,740 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,741 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46291
2024-01-09 06:29:30,741 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44058
2024-01-09 06:29:30,742 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:30,743 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:30,743 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,745 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:30,762 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33239', status: init, memory: 0, processing: 0>
2024-01-09 06:29:30,762 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33239
2024-01-09 06:29:30,762 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44064
2024-01-09 06:29:30,764 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:30,765 - distributed.worker - INFO - Starting Worker plugin PreImport-6669db84-8c67-4dd2-823f-6ae36368762b
2024-01-09 06:29:30,765 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:30,765 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,765 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9ae7c902-8b34-4415-9f02-3a23dc3a0b6b
2024-01-09 06:29:30,765 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ff37cc82-ef18-4846-99c2-e8e5793453d4
2024-01-09 06:29:30,766 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34977', status: init, memory: 0, processing: 0>
2024-01-09 06:29:30,766 - distributed.worker - INFO - Starting Worker plugin PreImport-6f0d1a2e-8222-4bec-80a8-fee034f1fa79
2024-01-09 06:29:30,767 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34977
2024-01-09 06:29:30,767 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44076
2024-01-09 06:29:30,767 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:30,767 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,769 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,770 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:30,772 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:30,772 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,774 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:30,776 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33699', status: init, memory: 0, processing: 0>
2024-01-09 06:29:30,777 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d6f9d1ac-40b1-442c-af4d-637a0e6c9daa
2024-01-09 06:29:30,777 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33699
2024-01-09 06:29:30,777 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44088
2024-01-09 06:29:30,778 - distributed.worker - INFO - Starting Worker plugin PreImport-1a34449b-3c77-47d1-822e-68f0574dfa16
2024-01-09 06:29:30,778 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,779 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:30,780 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:30,780 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,782 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:30,809 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33931', status: init, memory: 0, processing: 0>
2024-01-09 06:29:30,810 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33931
2024-01-09 06:29:30,810 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44104
2024-01-09 06:29:30,812 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:30,813 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:30,813 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,815 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:30,819 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44625', status: init, memory: 0, processing: 0>
2024-01-09 06:29:30,819 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44625
2024-01-09 06:29:30,820 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44122
2024-01-09 06:29:30,821 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:30,822 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:30,822 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,825 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:30,830 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34925', status: init, memory: 0, processing: 0>
2024-01-09 06:29:30,830 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34925
2024-01-09 06:29:30,830 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44108
2024-01-09 06:29:30,833 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:30,835 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:30,835 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:30,838 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:30,861 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,862 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,862 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,862 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,862 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,863 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,863 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,863 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,866 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,866 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,866 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,866 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,866 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,866 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,867 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,867 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,883 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,884 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,884 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,884 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,884 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,884 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,884 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,884 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,889 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,889 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,889 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,889 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,889 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,890 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,890 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,891 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:29:30,901 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,903 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,904 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,906 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:30,908 - distributed.scheduler - INFO - Remove client Client-6f746785-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:30,908 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35742; closing.
2024-01-09 06:29:30,909 - distributed.scheduler - INFO - Remove client Client-6f746785-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:30,909 - distributed.scheduler - INFO - Remove client Client-6d36698d-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:30,909 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35758; closing.
2024-01-09 06:29:30,910 - distributed.scheduler - INFO - Remove client Client-6d36698d-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:30,910 - distributed.scheduler - INFO - Close client connection: Client-6f746785-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:30,911 - distributed.scheduler - INFO - Close client connection: Client-6d36698d-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:30,911 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39187'. Reason: nanny-close
2024-01-09 06:29:30,912 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:30,912 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45243'. Reason: nanny-close
2024-01-09 06:29:30,912 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:30,913 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45583'. Reason: nanny-close
2024-01-09 06:29:30,913 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:30,913 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39279'. Reason: nanny-close
2024-01-09 06:29:30,913 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44625. Reason: nanny-close
2024-01-09 06:29:30,913 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:30,913 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38875'. Reason: nanny-close
2024-01-09 06:29:30,914 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34925. Reason: nanny-close
2024-01-09 06:29:30,914 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33003. Reason: nanny-close
2024-01-09 06:29:30,914 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:30,914 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43915'. Reason: nanny-close
2024-01-09 06:29:30,914 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:30,915 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46233'. Reason: nanny-close
2024-01-09 06:29:30,915 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33931. Reason: nanny-close
2024-01-09 06:29:30,915 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:30,915 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42073'. Reason: nanny-close
2024-01-09 06:29:30,915 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33239. Reason: nanny-close
2024-01-09 06:29:30,915 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:30,915 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34977. Reason: nanny-close
2024-01-09 06:29:30,915 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:30,916 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:30,917 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:30,917 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:30,917 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:30,917 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46291. Reason: nanny-close
2024-01-09 06:29:30,918 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:30,918 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:30,918 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33699. Reason: nanny-close
2024-01-09 06:29:30,919 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:30,919 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44122; closing.
2024-01-09 06:29:30,919 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44048; closing.
2024-01-09 06:29:30,919 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44108; closing.
2024-01-09 06:29:30,920 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:30,920 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44625', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781770.920115')
2024-01-09 06:29:30,920 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:30,920 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44104; closing.
2024-01-09 06:29:30,920 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44064; closing.
2024-01-09 06:29:30,921 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44076; closing.
2024-01-09 06:29:30,921 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33003', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781770.9212399')
2024-01-09 06:29:30,921 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34925', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781770.9216144')
2024-01-09 06:29:30,922 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33931', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781770.9223027')
2024-01-09 06:29:30,922 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33239', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781770.9226766')
2024-01-09 06:29:30,923 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34977', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781770.923035')
2024-01-09 06:29:30,923 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:30,924 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:30,923 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44064>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-09 06:29:30,924 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44104>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-09 06:29:30,924 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44076>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-09 06:29:30,925 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44058; closing.
2024-01-09 06:29:30,925 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46291', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781770.9253626')
2024-01-09 06:29:30,925 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:30,928 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:30,935 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44088; closing.
2024-01-09 06:29:30,935 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33699', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781770.9356902')
2024-01-09 06:29:30,935 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:30,935 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:30,938 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:33,530 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:29:33,531 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:29:33,531 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:29:33,534 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:29:33,534 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-09 06:29:35,861 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:35,866 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:29:35,869 - distributed.scheduler - INFO - State start
2024-01-09 06:29:35,893 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:35,894 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:29:35,895 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:29:35,895 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:29:35,928 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37591', status: init, memory: 0, processing: 0>
2024-01-09 06:29:35,943 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37591
2024-01-09 06:29:35,944 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44874
2024-01-09 06:29:35,990 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44874; closing.
2024-01-09 06:29:35,990 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37591', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781775.990634')
2024-01-09 06:29:35,991 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:36,064 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33657', status: init, memory: 0, processing: 0>
2024-01-09 06:29:36,065 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33657
2024-01-09 06:29:36,065 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44878
2024-01-09 06:29:36,091 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44878; closing.
2024-01-09 06:29:36,091 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33657', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781776.091594')
2024-01-09 06:29:36,091 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:36,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39807'
2024-01-09 06:29:36,153 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38155'
2024-01-09 06:29:36,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34597'
2024-01-09 06:29:36,181 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44503'
2024-01-09 06:29:36,184 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40783'
2024-01-09 06:29:36,195 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42235'
2024-01-09 06:29:36,204 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45703'
2024-01-09 06:29:36,211 - distributed.scheduler - INFO - Receive client connection: Client-74270d52-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:36,211 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44968
2024-01-09 06:29:36,214 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35905'
2024-01-09 06:29:37,286 - distributed.scheduler - INFO - Receive client connection: Client-760c6f99-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:37,287 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44984
2024-01-09 06:29:38,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:38,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:38,067 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:38,068 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35923
2024-01-09 06:29:38,068 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35923
2024-01-09 06:29:38,068 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38471
2024-01-09 06:29:38,068 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:38,068 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:38,068 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:38,068 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:38,068 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z3m01dc_
2024-01-09 06:29:38,068 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d5be2cf4-7b6f-41a0-94df-3f622a70c354
2024-01-09 06:29:38,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:38,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:38,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:38,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:38,090 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:38,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:38,092 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:38,093 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36117
2024-01-09 06:29:38,093 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36117
2024-01-09 06:29:38,093 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33787
2024-01-09 06:29:38,093 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:38,093 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:38,093 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:38,094 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:38,094 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r3gtkn3l
2024-01-09 06:29:38,094 - distributed.worker - INFO - Starting Worker plugin RMMSetup-96beb596-7f48-44c6-98d4-1d87e804d5b0
2024-01-09 06:29:38,094 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:38,095 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:38,095 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45991
2024-01-09 06:29:38,095 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45991
2024-01-09 06:29:38,095 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46031
2024-01-09 06:29:38,095 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:38,095 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:38,095 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:38,095 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:38,095 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-trgk67sy
2024-01-09 06:29:38,095 - distributed.worker - INFO - Starting Worker plugin RMMSetup-905b5815-8c9f-4341-9656-1d21c65fe08d
2024-01-09 06:29:38,096 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37917
2024-01-09 06:29:38,096 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37917
2024-01-09 06:29:38,096 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38745
2024-01-09 06:29:38,096 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:38,096 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:38,096 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:38,096 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:38,096 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yfpse9sn
2024-01-09 06:29:38,096 - distributed.worker - INFO - Starting Worker plugin PreImport-d32f806b-1026-45f5-a939-3c45bab701a3
2024-01-09 06:29:38,097 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-53a4b012-5709-4310-a925-e14a09415212
2024-01-09 06:29:38,097 - distributed.worker - INFO - Starting Worker plugin RMMSetup-908b47c4-d1d2-4a60-8b0e-8f389081f70c
2024-01-09 06:29:38,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:38,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:38,116 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:38,117 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36103
2024-01-09 06:29:38,117 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36103
2024-01-09 06:29:38,117 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39127
2024-01-09 06:29:38,117 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:38,117 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:38,117 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:38,117 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:38,117 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gv89h8sn
2024-01-09 06:29:38,117 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4f215876-dafb-47dd-88ec-b2872dfe6af7
2024-01-09 06:29:38,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:38,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:38,122 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:38,123 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44767
2024-01-09 06:29:38,123 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44767
2024-01-09 06:29:38,123 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43943
2024-01-09 06:29:38,123 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:38,123 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:38,123 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:38,123 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:38,123 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wd5hcw27
2024-01-09 06:29:38,124 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e7b3aca5-238e-4819-91e1-ebffedc4ba85
2024-01-09 06:29:38,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:38,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:38,190 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:38,191 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40033
2024-01-09 06:29:38,191 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40033
2024-01-09 06:29:38,191 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37967
2024-01-09 06:29:38,191 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:38,191 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:38,191 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:38,191 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:38,191 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uk45ealn
2024-01-09 06:29:38,192 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8b85885c-362f-4303-8c54-959eda27471f
2024-01-09 06:29:38,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:38,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:38,200 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:38,201 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46737
2024-01-09 06:29:38,201 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46737
2024-01-09 06:29:38,201 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35001
2024-01-09 06:29:38,201 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:38,201 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:38,201 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:38,202 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:29:38,202 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xdp69iul
2024-01-09 06:29:38,202 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b3c593d5-372b-4091-9338-581951da955b
2024-01-09 06:29:40,349 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bc9b2cea-9ff6-4041-8334-19dc42d7b5ba
2024-01-09 06:29:40,350 - distributed.worker - INFO - Starting Worker plugin PreImport-4595b0ac-0673-44e8-9c28-b56dd19c74c4
2024-01-09 06:29:40,351 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,384 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35923', status: init, memory: 0, processing: 0>
2024-01-09 06:29:40,386 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35923
2024-01-09 06:29:40,386 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47620
2024-01-09 06:29:40,387 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:40,389 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:40,389 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,391 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:40,464 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,485 - distributed.worker - INFO - Starting Worker plugin PreImport-90bfd7c5-9ec5-4422-a5bc-55d2127d0908
2024-01-09 06:29:40,486 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2a534c70-99de-4811-9849-b40b7a4de503
2024-01-09 06:29:40,487 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,487 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37917', status: init, memory: 0, processing: 0>
2024-01-09 06:29:40,488 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37917
2024-01-09 06:29:40,488 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47632
2024-01-09 06:29:40,489 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:40,490 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:40,490 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,491 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:40,515 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-855ba4d3-cb08-47d9-8149-d703a4fa1b73
2024-01-09 06:29:40,516 - distributed.worker - INFO - Starting Worker plugin PreImport-7cc64de1-fbc3-4401-abed-3e82bee3047f
2024-01-09 06:29:40,517 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,520 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45991', status: init, memory: 0, processing: 0>
2024-01-09 06:29:40,520 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-137117d4-e0be-4405-a451-87df0f346312
2024-01-09 06:29:40,521 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45991
2024-01-09 06:29:40,521 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47644
2024-01-09 06:29:40,521 - distributed.worker - INFO - Starting Worker plugin PreImport-cf6de89e-c23c-4431-923f-ba68a2751af1
2024-01-09 06:29:40,522 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,523 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:40,523 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1c1fdc99-6a59-43bd-84cc-214e5dfc305b
2024-01-09 06:29:40,524 - distributed.worker - INFO - Starting Worker plugin PreImport-fabb2ca1-5628-4667-8480-5e32b08c4801
2024-01-09 06:29:40,524 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:40,524 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,524 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,526 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:40,548 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44767', status: init, memory: 0, processing: 0>
2024-01-09 06:29:40,549 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44767
2024-01-09 06:29:40,549 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47650
2024-01-09 06:29:40,549 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36117', status: init, memory: 0, processing: 0>
2024-01-09 06:29:40,550 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36117
2024-01-09 06:29:40,550 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47670
2024-01-09 06:29:40,551 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:40,551 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:40,552 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:40,552 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,552 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:40,552 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,553 - distributed.worker - INFO - Starting Worker plugin PreImport-cc2bf258-8ce4-434b-8069-539aca6c7105
2024-01-09 06:29:40,553 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:40,553 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b8e93e10-0fba-4018-ae97-37dfa522f04d
2024-01-09 06:29:40,554 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,554 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:40,554 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36103', status: init, memory: 0, processing: 0>
2024-01-09 06:29:40,555 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36103
2024-01-09 06:29:40,555 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47660
2024-01-09 06:29:40,556 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-08c47e6d-8b69-40e6-b00f-dad04c0b607a
2024-01-09 06:29:40,556 - distributed.worker - INFO - Starting Worker plugin PreImport-fe2c9a58-9c80-483f-a278-2effb7a60a2c
2024-01-09 06:29:40,556 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:40,557 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,558 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:40,558 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,560 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:40,577 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46737', status: init, memory: 0, processing: 0>
2024-01-09 06:29:40,577 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46737
2024-01-09 06:29:40,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47674
2024-01-09 06:29:40,578 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:40,579 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40033', status: init, memory: 0, processing: 0>
2024-01-09 06:29:40,579 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:40,579 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,579 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40033
2024-01-09 06:29:40,579 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47688
2024-01-09 06:29:40,580 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:40,580 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:40,581 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:40,581 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:40,582 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:40,691 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,692 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,692 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,692 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,692 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,692 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,692 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,693 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,694 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,694 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:29:40,699 - distributed.scheduler - INFO - Remove client Client-74270d52-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:40,700 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44968; closing.
2024-01-09 06:29:40,700 - distributed.scheduler - INFO - Remove client Client-74270d52-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:40,700 - distributed.scheduler - INFO - Remove client Client-760c6f99-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:40,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44984; closing.
2024-01-09 06:29:40,701 - distributed.scheduler - INFO - Close client connection: Client-74270d52-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:40,701 - distributed.scheduler - INFO - Remove client Client-760c6f99-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:40,701 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39807'. Reason: nanny-close
2024-01-09 06:29:40,701 - distributed.scheduler - INFO - Close client connection: Client-760c6f99-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:40,702 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:40,702 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38155'. Reason: nanny-close
2024-01-09 06:29:40,703 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:40,704 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34597'. Reason: nanny-close
2024-01-09 06:29:40,704 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35923. Reason: nanny-close
2024-01-09 06:29:40,704 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:40,704 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44503'. Reason: nanny-close
2024-01-09 06:29:40,704 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45991. Reason: nanny-close
2024-01-09 06:29:40,704 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:40,705 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40783'. Reason: nanny-close
2024-01-09 06:29:40,705 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36117. Reason: nanny-close
2024-01-09 06:29:40,705 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:40,705 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42235'. Reason: nanny-close
2024-01-09 06:29:40,705 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37917. Reason: nanny-close
2024-01-09 06:29:40,705 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:40,706 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45703'. Reason: nanny-close
2024-01-09 06:29:40,706 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:40,706 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44767. Reason: nanny-close
2024-01-09 06:29:40,706 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35905'. Reason: nanny-close
2024-01-09 06:29:40,706 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:40,706 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47620; closing.
2024-01-09 06:29:40,706 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:40,706 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36103. Reason: nanny-close
2024-01-09 06:29:40,706 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:40,707 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:40,707 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35923', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781780.7070339')
2024-01-09 06:29:40,707 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40033. Reason: nanny-close
2024-01-09 06:29:40,707 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:40,707 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46737. Reason: nanny-close
2024-01-09 06:29:40,708 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47670; closing.
2024-01-09 06:29:40,708 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47644; closing.
2024-01-09 06:29:40,708 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:40,708 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:40,708 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:40,708 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:40,708 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:40,708 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:40,709 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:40,709 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36117', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781780.7092047')
2024-01-09 06:29:40,709 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:40,709 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45991', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781780.7095664')
2024-01-09 06:29:40,709 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47632; closing.
2024-01-09 06:29:40,710 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:40,710 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:40,710 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:40,710 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37917', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781780.710867')
2024-01-09 06:29:40,711 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47650; closing.
2024-01-09 06:29:40,711 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:40,711 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44767', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781780.711891')
2024-01-09 06:29:40,712 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47660; closing.
2024-01-09 06:29:40,712 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47688; closing.
2024-01-09 06:29:40,712 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47674; closing.
2024-01-09 06:29:40,712 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36103', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781780.7129326')
2024-01-09 06:29:40,713 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40033', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781780.7133052')
2024-01-09 06:29:40,713 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46737', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781780.713646')
2024-01-09 06:29:40,713 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:41,767 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:29:41,768 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:29:41,769 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:29:41,771 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:29:41,772 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-09 06:29:44,158 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:44,163 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:29:44,166 - distributed.scheduler - INFO - State start
2024-01-09 06:29:44,298 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:44,299 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:29:44,300 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:29:44,301 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:29:44,346 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45199', status: init, memory: 0, processing: 0>
2024-01-09 06:29:44,361 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45199
2024-01-09 06:29:44,362 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47812
2024-01-09 06:29:44,415 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47812; closing.
2024-01-09 06:29:44,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45199', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781784.415665')
2024-01-09 06:29:44,416 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:44,427 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40789'
2024-01-09 06:29:44,479 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44385', status: init, memory: 0, processing: 0>
2024-01-09 06:29:44,480 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44385
2024-01-09 06:29:44,480 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47842
2024-01-09 06:29:44,487 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41039', status: init, memory: 0, processing: 0>
2024-01-09 06:29:44,487 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41039
2024-01-09 06:29:44,487 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47858
2024-01-09 06:29:44,517 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38005', status: init, memory: 0, processing: 0>
2024-01-09 06:29:44,518 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38005
2024-01-09 06:29:44,518 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47874
2024-01-09 06:29:44,519 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47842; closing.
2024-01-09 06:29:44,519 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44385', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781784.5193098')
2024-01-09 06:29:44,528 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47858; closing.
2024-01-09 06:29:44,528 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41039', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781784.5285523')
2024-01-09 06:29:44,553 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41165', status: init, memory: 0, processing: 0>
2024-01-09 06:29:44,554 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41165
2024-01-09 06:29:44,554 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47888
2024-01-09 06:29:44,562 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44359', status: init, memory: 0, processing: 0>
2024-01-09 06:29:44,563 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44359
2024-01-09 06:29:44,563 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47898
2024-01-09 06:29:44,569 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47874; closing.
2024-01-09 06:29:44,569 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38005', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781784.569267')
2024-01-09 06:29:44,577 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39809', status: init, memory: 0, processing: 0>
2024-01-09 06:29:44,577 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39809
2024-01-09 06:29:44,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47904
2024-01-09 06:29:44,578 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47888; closing.
2024-01-09 06:29:44,578 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41165', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781784.5789232')
2024-01-09 06:29:44,581 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40553', status: init, memory: 0, processing: 0>
2024-01-09 06:29:44,582 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40553
2024-01-09 06:29:44,582 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47908
2024-01-09 06:29:44,619 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47904; closing.
2024-01-09 06:29:44,620 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39809', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781784.6204054')
2024-01-09 06:29:44,621 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47898; closing.
2024-01-09 06:29:44,621 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47908; closing.
2024-01-09 06:29:44,622 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44359', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781784.6219904')
2024-01-09 06:29:44,622 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40553', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781784.6223562')
2024-01-09 06:29:44,622 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:44,622 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:47898>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:47898>: Stream is closed
2024-01-09 06:29:45,488 - distributed.scheduler - INFO - Receive client connection: Client-7aeffc1d-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:45,488 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47912
2024-01-09 06:29:46,136 - distributed.scheduler - INFO - Receive client connection: Client-79105a46-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:46,137 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47920
2024-01-09 06:29:46,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:46,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:46,701 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:46,702 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46115
2024-01-09 06:29:46,702 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46115
2024-01-09 06:29:46,702 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-09 06:29:46,702 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:46,702 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:46,702 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:46,702 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:29:46,703 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7qgm6qog
2024-01-09 06:29:46,703 - distributed.worker - INFO - Starting Worker plugin RMMSetup-869c3964-641c-4553-a0de-4036d9098640
2024-01-09 06:29:46,703 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9c8ff3f4-adcf-4ac3-9a41-57ba3e283ede
2024-01-09 06:29:46,703 - distributed.worker - INFO - Starting Worker plugin PreImport-18ca3965-9eea-4810-9abd-a4d6197822c9
2024-01-09 06:29:46,704 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:46,767 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46115', status: init, memory: 0, processing: 0>
2024-01-09 06:29:46,768 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46115
2024-01-09 06:29:46,768 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47942
2024-01-09 06:29:46,769 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:46,770 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:46,770 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:46,771 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:46,815 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:46,818 - distributed.scheduler - INFO - Remove client Client-7aeffc1d-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:46,818 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47912; closing.
2024-01-09 06:29:46,818 - distributed.scheduler - INFO - Remove client Client-7aeffc1d-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:46,818 - distributed.scheduler - INFO - Close client connection: Client-7aeffc1d-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:29:46,851 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:46,854 - distributed.scheduler - INFO - Remove client Client-79105a46-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:46,854 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47920; closing.
2024-01-09 06:29:46,854 - distributed.scheduler - INFO - Remove client Client-79105a46-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:46,854 - distributed.scheduler - INFO - Close client connection: Client-79105a46-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:29:46,855 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40789'. Reason: nanny-close
2024-01-09 06:29:46,856 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:46,857 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46115. Reason: nanny-close
2024-01-09 06:29:46,859 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:46,859 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47942; closing.
2024-01-09 06:29:46,859 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46115', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781786.8595486')
2024-01-09 06:29:46,859 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:29:46,860 - distributed.nanny - INFO - Worker closed
2024-01-09 06:29:47,521 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:29:47,521 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:29:47,522 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:29:47,523 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:29:47,523 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-09 06:29:51,881 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:51,885 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46603 instead
  warnings.warn(
2024-01-09 06:29:51,889 - distributed.scheduler - INFO - State start
2024-01-09 06:29:51,909 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:51,910 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-09 06:29:51,911 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:29:51,911 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-09 06:29:51,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39277'
2024-01-09 06:29:53,696 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:29:53,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:29:54,332 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:29:54,334 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40333
2024-01-09 06:29:54,334 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40333
2024-01-09 06:29:54,334 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43443
2024-01-09 06:29:54,334 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:29:54,335 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:54,335 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:29:54,335 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:29:54,335 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bjvw7q9_
2024-01-09 06:29:54,335 - distributed.worker - INFO - Starting Worker plugin RMMSetup-05137b7b-51d1-48d3-97fc-8ebd3a98db58
2024-01-09 06:29:54,336 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5b3847dc-4f5b-4ed8-868e-8e6dd9174b46
2024-01-09 06:29:54,336 - distributed.worker - INFO - Starting Worker plugin PreImport-a7052fe5-86f7-4bfa-810b-632726c8d57c
2024-01-09 06:29:54,339 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:54,432 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:29:54,433 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:29:54,433 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:29:54,435 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:29:54,444 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:29:54,450 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39277'. Reason: nanny-close
2024-01-09 06:29:54,471 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:29:54,472 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40333. Reason: nanny-close
2024-01-09 06:29:54,474 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:29:54,476 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-09 06:29:57,690 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:57,695 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40973 instead
  warnings.warn(
2024-01-09 06:29:57,699 - distributed.scheduler - INFO - State start
2024-01-09 06:29:59,026 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:29:59,028 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-09 06:29:59,028 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:29:59,029 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-09 06:30:04,310 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:30:04,315 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32939 instead
  warnings.warn(
2024-01-09 06:30:04,319 - distributed.scheduler - INFO - State start
2024-01-09 06:30:04,342 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:30:04,342 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-09 06:30:04,343 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:30:04,344 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-09 06:30:04,637 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45823'
2024-01-09 06:30:05,234 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45823'. Reason: nanny-close
2024-01-09 06:30:06,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:06,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:06,280 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:06,281 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35135
2024-01-09 06:30:06,281 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35135
2024-01-09 06:30:06,281 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37127
2024-01-09 06:30:06,281 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-09 06:30:06,281 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:06,282 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:06,282 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:30:06,282 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-zi9q6zbs
2024-01-09 06:30:06,282 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1854f689-8622-425f-9776-cb92ec82ba05
2024-01-09 06:30:06,282 - distributed.worker - INFO - Starting Worker plugin PreImport-ff2a8dc3-7e48-493e-a7d3-d23cac63752a
2024-01-09 06:30:06,282 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bb808509-accc-49bc-8a96-c01aefa62690
2024-01-09 06:30:06,282 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:06,334 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:06,335 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-09 06:30:06,335 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:06,336 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-09 06:30:06,365 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:06,366 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35135. Reason: nanny-close
2024-01-09 06:30:06,368 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-09 06:30:06,369 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-09 06:30:08,886 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:30:08,890 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:30:08,893 - distributed.scheduler - INFO - State start
2024-01-09 06:30:08,948 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:30:08,949 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:30:08,950 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:30:08,950 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:30:09,124 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36547'
2024-01-09 06:30:09,140 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40495'
2024-01-09 06:30:09,149 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33185'
2024-01-09 06:30:09,166 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36031'
2024-01-09 06:30:09,168 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42685'
2024-01-09 06:30:09,177 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33633'
2024-01-09 06:30:09,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45009'
2024-01-09 06:30:09,199 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34957'
2024-01-09 06:30:09,681 - distributed.scheduler - INFO - Receive client connection: Client-87d6f2b4-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:30:09,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42300
2024-01-09 06:30:10,590 - distributed.scheduler - INFO - Receive client connection: Client-87d4473a-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:30:10,590 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36922
2024-01-09 06:30:11,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:11,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:11,034 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:11,035 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44317
2024-01-09 06:30:11,035 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44317
2024-01-09 06:30:11,035 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45585
2024-01-09 06:30:11,035 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:11,035 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,035 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:11,035 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:30:11,035 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bghdp9y4
2024-01-09 06:30:11,035 - distributed.worker - INFO - Starting Worker plugin PreImport-54c9fc91-e241-4b0b-b120-0377f7a352a0
2024-01-09 06:30:11,035 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8fc61dd7-4aaa-46b0-af2f-09a2289d5a90
2024-01-09 06:30:11,036 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ed91d139-a8c6-4d37-8a52-6e952008e3f2
2024-01-09 06:30:11,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:11,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:11,079 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:11,079 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40635
2024-01-09 06:30:11,080 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40635
2024-01-09 06:30:11,080 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33307
2024-01-09 06:30:11,080 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:11,080 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,080 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:11,080 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:30:11,080 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3sk3s26x
2024-01-09 06:30:11,080 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c77981f9-ea03-44b8-be9e-ce08b801a254
2024-01-09 06:30:11,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:11,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:11,085 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:11,086 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40649
2024-01-09 06:30:11,086 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40649
2024-01-09 06:30:11,086 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36509
2024-01-09 06:30:11,086 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:11,086 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,086 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:11,086 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:30:11,086 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5rgbmp11
2024-01-09 06:30:11,086 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b2c10a89-b0dc-4e44-8e31-6c3543a2849f
2024-01-09 06:30:11,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:11,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:11,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:11,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:11,285 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:11,285 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:11,286 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40171
2024-01-09 06:30:11,286 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34911
2024-01-09 06:30:11,286 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40171
2024-01-09 06:30:11,286 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34911
2024-01-09 06:30:11,286 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36975
2024-01-09 06:30:11,286 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42561
2024-01-09 06:30:11,286 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:11,286 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:11,286 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,286 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,287 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:11,287 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:11,287 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:30:11,287 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:30:11,287 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l4a0yhx3
2024-01-09 06:30:11,287 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6bwkzn6w
2024-01-09 06:30:11,287 - distributed.worker - INFO - Starting Worker plugin RMMSetup-87d4db7b-1a45-46e8-8425-3421492c6db4
2024-01-09 06:30:11,287 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d58e7ea5-b5b2-45b4-b63d-191332ca6564
2024-01-09 06:30:11,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:11,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:11,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:11,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:11,318 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:11,318 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33983
2024-01-09 06:30:11,318 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33983
2024-01-09 06:30:11,319 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40721
2024-01-09 06:30:11,319 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:11,319 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,319 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:11,319 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:30:11,319 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f6fan5ie
2024-01-09 06:30:11,319 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8fc3ccb9-31f0-46e8-ab8d-c624a135e058
2024-01-09 06:30:11,320 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:11,321 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46259
2024-01-09 06:30:11,321 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46259
2024-01-09 06:30:11,321 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39367
2024-01-09 06:30:11,321 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:11,321 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,321 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:11,321 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:30:11,321 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jm9jivq7
2024-01-09 06:30:11,322 - distributed.worker - INFO - Starting Worker plugin PreImport-0165ee2f-f3b0-4bb6-bc52-876a20b2aa9d
2024-01-09 06:30:11,322 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38148eec-8ee5-40f8-8e11-1794a6b1ff76
2024-01-09 06:30:11,322 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1dfe27b3-f769-4da7-b93b-1c2c9880ecf7
2024-01-09 06:30:11,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:11,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:11,341 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:11,342 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44915
2024-01-09 06:30:11,342 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44915
2024-01-09 06:30:11,342 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33673
2024-01-09 06:30:11,342 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:11,342 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,342 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:11,342 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:30:11,342 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wtns3jp0
2024-01-09 06:30:11,343 - distributed.worker - INFO - Starting Worker plugin RMMSetup-abc3e798-c99c-42b7-a285-9c75058641f3
2024-01-09 06:30:11,687 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,709 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44317', status: init, memory: 0, processing: 0>
2024-01-09 06:30:11,710 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44317
2024-01-09 06:30:11,710 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36938
2024-01-09 06:30:11,711 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:11,711 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:11,711 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:11,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:15,439 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9a28b3a6-66d1-4f6b-9fe9-048f9fc9f483
2024-01-09 06:30:15,440 - distributed.worker - INFO - Starting Worker plugin PreImport-61f9a990-3aa6-4d5b-8f91-3ecfec97f308
2024-01-09 06:30:15,441 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,474 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40171', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,475 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40171
2024-01-09 06:30:15,475 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36948
2024-01-09 06:30:15,476 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:15,477 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:15,477 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,479 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:15,488 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fe4d83b2-40e5-43d2-a6ea-7a337c32b49d
2024-01-09 06:30:15,489 - distributed.worker - INFO - Starting Worker plugin PreImport-036832cf-98f2-41e1-b272-eb0633e03439
2024-01-09 06:30:15,490 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,514 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40649', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,514 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40649
2024-01-09 06:30:15,514 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36962
2024-01-09 06:30:15,515 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:15,516 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:15,516 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,517 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:15,539 - distributed.worker - INFO - Starting Worker plugin PreImport-ee4e2247-66b5-4751-9292-8330aafacbd0
2024-01-09 06:30:15,540 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-aa052296-846f-4a34-8600-23ee5ebec9d2
2024-01-09 06:30:15,541 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,542 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35961', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,543 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35961
2024-01-09 06:30:15,543 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36968
2024-01-09 06:30:15,551 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39679', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,551 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39679
2024-01-09 06:30:15,551 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36974
2024-01-09 06:30:15,558 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33131', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,559 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33131
2024-01-09 06:30:15,559 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36986
2024-01-09 06:30:15,579 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40635', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,579 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40635
2024-01-09 06:30:15,580 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37002
2024-01-09 06:30:15,581 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:15,582 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:15,582 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,584 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:15,585 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38975', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,586 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38975
2024-01-09 06:30:15,586 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37018
2024-01-09 06:30:15,644 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-02b82ee4-8b2e-4b5d-b338-2e69f423fe05
2024-01-09 06:30:15,645 - distributed.worker - INFO - Starting Worker plugin PreImport-a6f19c57-2114-48f2-bf41-f1d595e04832
2024-01-09 06:30:15,647 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,651 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:30:15,651 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:30:15,651 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:30:15,652 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:30:15,652 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:30:15,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:30:15,655 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:30:15,656 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-09 06:30:15,666 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7a962bc5-9284-45fd-9d3d-06bdaf19b3d4
2024-01-09 06:30:15,667 - distributed.worker - INFO - Starting Worker plugin PreImport-5bd06518-06d5-4370-98dc-ce0d79ba4eb5
2024-01-09 06:30:15,669 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,675 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:15,675 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:15,675 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:15,675 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:15,682 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46259', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,682 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46259
2024-01-09 06:30:15,682 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37040
2024-01-09 06:30:15,683 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:15,684 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:15,684 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:15,684 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,684 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:15,684 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:15,684 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:15,685 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:15,687 - distributed.scheduler - INFO - Remove client Client-87d4473a-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:30:15,687 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36922; closing.
2024-01-09 06:30:15,688 - distributed.scheduler - INFO - Remove client Client-87d4473a-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:30:15,688 - distributed.scheduler - INFO - Close client connection: Client-87d4473a-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:30:15,689 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34911', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,689 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36547'. Reason: nanny-close
2024-01-09 06:30:15,689 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34911
2024-01-09 06:30:15,689 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37032
2024-01-09 06:30:15,690 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:15,690 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40495'. Reason: nanny-close
2024-01-09 06:30:15,690 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33185'. Reason: nanny-close
2024-01-09 06:30:15,690 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:15,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36031'. Reason: nanny-close
2024-01-09 06:30:15,691 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40635. Reason: nanny-close
2024-01-09 06:30:15,691 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:15,691 - distributed.scheduler - INFO - Remove client Client-87d6f2b4-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:30:15,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42685'. Reason: nanny-close
2024-01-09 06:30:15,691 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:15,691 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42300; closing.
2024-01-09 06:30:15,691 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44317. Reason: nanny-close
2024-01-09 06:30:15,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33633'. Reason: nanny-close
2024-01-09 06:30:15,692 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:15,692 - distributed.scheduler - INFO - Remove client Client-87d6f2b4-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:30:15,692 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40649. Reason: nanny-close
2024-01-09 06:30:15,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45009'. Reason: nanny-close
2024-01-09 06:30:15,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34957'. Reason: nanny-close
2024-01-09 06:30:15,692 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:15,692 - distributed.scheduler - INFO - Close client connection: Client-87d6f2b4-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:30:15,692 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,692 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40171. Reason: nanny-close
2024-01-09 06:30:15,693 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:15,694 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:15,694 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:15,694 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37002; closing.
2024-01-09 06:30:15,694 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36938; closing.
2024-01-09 06:30:15,695 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40635', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.69499')
2024-01-09 06:30:15,695 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:15,695 - distributed.nanny - INFO - Worker closed
2024-01-09 06:30:15,695 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:15,695 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44317', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.6955884')
2024-01-09 06:30:15,695 - distributed.nanny - INFO - Worker closed
2024-01-09 06:30:15,695 - distributed.nanny - INFO - Worker closed
2024-01-09 06:30:15,696 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36962; closing.
2024-01-09 06:30:15,697 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40649', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.6970122')
2024-01-09 06:30:15,697 - distributed.nanny - INFO - Worker closed
2024-01-09 06:30:15,698 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36948; closing.
2024-01-09 06:30:15,699 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:36962>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-09 06:30:15,701 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40171', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.7013752')
2024-01-09 06:30:15,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36974; closing.
2024-01-09 06:30:15,702 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39679', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.7024217')
2024-01-09 06:30:15,702 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36968; closing.
2024-01-09 06:30:15,702 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37018; closing.
2024-01-09 06:30:15,703 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36986; closing.
2024-01-09 06:30:15,703 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35961', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.7034996')
2024-01-09 06:30:15,703 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38975', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.7038634')
2024-01-09 06:30:15,704 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33131', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.7042246')
2024-01-09 06:30:15,705 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33983', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,706 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33983
2024-01-09 06:30:15,706 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37048
2024-01-09 06:30:15,707 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:15,708 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:15,709 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,710 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:15,714 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39307', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,715 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39307
2024-01-09 06:30:15,715 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37052
2024-01-09 06:30:15,720 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:15,720 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:15,721 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:15,721 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33983. Reason: nanny-close
2024-01-09 06:30:15,721 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46259. Reason: nanny-close
2024-01-09 06:30:15,722 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34911. Reason: nanny-close
2024-01-09 06:30:15,723 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37040; closing.
2024-01-09 06:30:15,723 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:15,723 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46259', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.723891')
2024-01-09 06:30:15,724 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:15,725 - distributed.nanny - INFO - Worker closed
2024-01-09 06:30:15,725 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37048; closing.
2024-01-09 06:30:15,725 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33983', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.7256372')
2024-01-09 06:30:15,726 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37032; closing.
2024-01-09 06:30:15,726 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:15,726 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34911', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.726385')
2024-01-09 06:30:15,726 - distributed.nanny - INFO - Worker closed
2024-01-09 06:30:15,728 - distributed.nanny - INFO - Worker closed
2024-01-09 06:30:15,729 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2d9b23af-5ab4-455c-85c4-e8bfc75a0ad0
2024-01-09 06:30:15,730 - distributed.worker - INFO - Starting Worker plugin PreImport-362a35db-a7bc-471a-913f-64cf9943d168
2024-01-09 06:30:15,730 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,750 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39917', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,750 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39917
2024-01-09 06:30:15,750 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37058
2024-01-09 06:30:15,755 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44915', status: init, memory: 0, processing: 0>
2024-01-09 06:30:15,755 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44915
2024-01-09 06:30:15,755 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37066
2024-01-09 06:30:15,756 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:15,758 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:15,758 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:15,760 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:15,766 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37052; closing.
2024-01-09 06:30:15,766 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39307', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.7667384')
2024-01-09 06:30:15,767 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37058; closing.
2024-01-09 06:30:15,768 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39917', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.7679462')
2024-01-09 06:30:15,771 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:15,772 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44915. Reason: nanny-close
2024-01-09 06:30:15,774 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37066; closing.
2024-01-09 06:30:15,774 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:15,775 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44915', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781815.7751157')
2024-01-09 06:30:15,775 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:30:15,776 - distributed.nanny - INFO - Worker closed
2024-01-09 06:30:16,001 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36551', status: init, memory: 0, processing: 0>
2024-01-09 06:30:16,001 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36551
2024-01-09 06:30:16,001 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37076
2024-01-09 06:30:16,002 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38921', status: init, memory: 0, processing: 0>
2024-01-09 06:30:16,002 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38921
2024-01-09 06:30:16,003 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37086
2024-01-09 06:30:16,020 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37076; closing.
2024-01-09 06:30:16,020 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36551', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781816.0207703')
2024-01-09 06:30:16,042 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37086; closing.
2024-01-09 06:30:16,043 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38921', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781816.0430923')
2024-01-09 06:30:16,043 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:30:18,007 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:30:18,007 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:30:18,008 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:30:18,010 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:30:18,010 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-09 06:30:20,548 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:30:20,553 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39637 instead
  warnings.warn(
2024-01-09 06:30:20,558 - distributed.scheduler - INFO - State start
2024-01-09 06:30:20,587 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:30:20,588 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-09 06:30:20,588 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:30:20,589 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-09 06:30:20,608 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46137'
2024-01-09 06:30:22,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:22,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:22,514 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:22,515 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33797
2024-01-09 06:30:22,515 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33797
2024-01-09 06:30:22,515 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37581
2024-01-09 06:30:22,515 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:22,515 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:22,515 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:22,515 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:30:22,515 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5qyfisk8
2024-01-09 06:30:22,516 - distributed.worker - INFO - Starting Worker plugin RMMSetup-725069a4-9508-472f-a9b4-429c393c669d
2024-01-09 06:30:22,830 - distributed.worker - INFO - Starting Worker plugin PreImport-44648b8f-ea29-4d0c-be78-7303aa969069
2024-01-09 06:30:22,830 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-64ccb03d-a26b-44fb-b682-0a1501d6d1ba
2024-01-09 06:30:22,831 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:22,909 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:22,910 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:22,910 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:22,912 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:33,525 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:30:33,536 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46137'. Reason: nanny-close
2024-01-09 06:30:33,536 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:33,538 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33797. Reason: nanny-close
2024-01-09 06:30:33,541 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:33,543 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-09 06:30:36,263 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:30:36,267 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-09 06:30:36,271 - distributed.scheduler - INFO - State start
2024-01-09 06:30:36,330 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-09 06:30:36,331 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-09 06:30:36,331 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-09 06:30:36,331 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-09 06:30:36,342 - distributed.scheduler - INFO - Receive client connection: Client-9864630e-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:30:36,356 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38032
2024-01-09 06:30:36,357 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46361'
2024-01-09 06:30:36,365 - distributed.scheduler - INFO - Receive client connection: Client-9811c4a4-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:30:36,366 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38060
2024-01-09 06:30:38,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:30:38,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:30:38,127 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:30:38,127 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43591
2024-01-09 06:30:38,128 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43591
2024-01-09 06:30:38,128 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43389
2024-01-09 06:30:38,128 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-09 06:30:38,128 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:38,128 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:30:38,128 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:30:38,128 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l71rcv_x
2024-01-09 06:30:38,128 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8235ad92-7a1e-4267-80df-a402dcbcbde8
2024-01-09 06:30:38,423 - distributed.worker - INFO - Starting Worker plugin PreImport-c6ae1729-779a-4245-a9a1-a6be513a3383
2024-01-09 06:30:38,424 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c5e91c19-17d6-429d-88fd-9b699119b798
2024-01-09 06:30:38,425 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:38,494 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43591', status: init, memory: 0, processing: 0>
2024-01-09 06:30:38,495 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43591
2024-01-09 06:30:38,495 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38096
2024-01-09 06:30:38,496 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:30:38,497 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-09 06:30:38,497 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:30:38,499 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-09 06:30:38,501 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-09 06:30:38,502 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-09 06:30:38,507 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:30:38,509 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-09 06:30:38,511 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:38,514 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:38,516 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:38,517 - distributed.scheduler - INFO - Remove client Client-9811c4a4-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:30:38,517 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38060; closing.
2024-01-09 06:30:38,517 - distributed.scheduler - INFO - Remove client Client-9811c4a4-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:30:38,518 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:30:38,518 - distributed.scheduler - INFO - Close client connection: Client-9811c4a4-aeb8-11ee-bd35-d8c49764f6bb
2024-01-09 06:30:38,518 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46361'. Reason: nanny-close
2024-01-09 06:30:38,520 - distributed.scheduler - INFO - Remove client Client-9864630e-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:30:38,520 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38032; closing.
2024-01-09 06:30:38,521 - distributed.scheduler - INFO - Remove client Client-9864630e-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:30:38,521 - distributed.scheduler - INFO - Close client connection: Client-9864630e-aeb8-11ee-ba91-d8c49764f6bb
2024-01-09 06:30:38,537 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-09 06:30:38,538 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43591. Reason: nanny-close
2024-01-09 06:30:38,540 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38096; closing.
2024-01-09 06:30:38,540 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-09 06:30:38,540 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43591', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781838.5407834')
2024-01-09 06:30:38,541 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:30:38,542 - distributed.nanny - INFO - Worker closed
2024-01-09 06:30:39,246 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45931', status: init, memory: 0, processing: 0>
2024-01-09 06:30:39,247 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45931
2024-01-09 06:30:39,247 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38104
2024-01-09 06:30:39,284 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-09 06:30:39,284 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-09 06:30:39,285 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-09 06:30:39,285 - distributed.core - INFO - Connection to tcp://127.0.0.1:38104 has been closed.
2024-01-09 06:30:39,285 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45931', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704781839.2857656')
2024-01-09 06:30:39,286 - distributed.scheduler - INFO - Lost all workers
2024-01-09 06:30:39,287 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-09 06:30:39,287 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45639 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37095 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45901 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43483 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37011 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33651 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45643 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39757 instead
  warnings.warn(
[1704782022.668886] [dgx13:71150:0]            sock.c:470  UCX  ERROR bind(fd=165 addr=0.0.0.0:41101) failed: Address already in use
2024-01-09 06:33:44,236 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #006] ep: 0x7f985ddb00c0, tag: 0x75e684a2f4c6a25d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #006] ep: 0x7f985ddb00c0, tag: 0x75e684a2f4c6a25d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-09 06:33:44,241 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #006] ep: 0x7fd94c1430c0, tag: 0x5c34f68338cdcead, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #006] ep: 0x7fd94c1430c0, tag: 0x5c34f68338cdcead, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2024-01-09 06:33:44,248 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 350, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 737, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #006] ep: 0x7fad345220c0, tag: 0x74986408f608b111, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 368, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #006] ep: 0x7fad345220c0, tag: 0x74986408f608b111, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] 2024-01-09 06:33:59,951 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 439, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 505, in ep
    raise CommClosedError("UCX Endpoint is closed")
distributed.comm.core.CommClosedError: UCX Endpoint is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 445, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('UCX Endpoint is closed')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39251 instead
  warnings.warn(
[1704782053.226763] [dgx13:71750:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:42817) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45237 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39959 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34003 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36493 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33533 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44951 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42663 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45401 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35801 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43949 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] [1704782242.106527] [dgx13:74961:0]            sock.c:470  UCX  ERROR bind(fd=134 addr=0.0.0.0:55518) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35569 instead
  warnings.warn(
[1704782264.665944] [dgx13:75574:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:40292) failed: Address already in use
[1704782264.666001] [dgx13:75574:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:34050) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42665 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41389 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40711 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39449 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39811 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45763 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41529 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37223 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39183 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40441 instead
  warnings.warn(
2024-01-09 06:42:26,952 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:42014 remote=tcp://127.0.0.1:39053>: Stream is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38007 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35147 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37013 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40819 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37519 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44551 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43561 instead
  warnings.warn(
[1704782684.682077] [dgx13:82005:0]            sock.c:470  UCX  ERROR bind(fd=153 addr=0.0.0.0:58984) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37499 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38291 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35553 instead
  warnings.warn(
[1704782830.581571] [dgx13:84221:0]            sock.c:470  UCX  ERROR bind(fd=159 addr=0.0.0.0:60420) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36855 instead
  warnings.warn(
[1704782861.682395] [dgx13:84513:0]            sock.c:470  UCX  ERROR bind(fd=160 addr=0.0.0.0:37758) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41971 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34525 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40687 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37813 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35427 instead
  warnings.warn(
2024-01-09 06:49:23,041 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51750 remote=tcp://127.0.0.1:41805>: Stream is closed
2024-01-09 06:49:23,041 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51788 remote=tcp://127.0.0.1:41805>: Stream is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38809 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38789 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37199 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38105 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36149 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42435 instead
  warnings.warn(
[1704783026.485297] [dgx13:87090:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:35675) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44757 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37749 instead
  warnings.warn(
[1704783052.578983] [dgx13:87382:0]            sock.c:470  UCX  ERROR bind(fd=160 addr=0.0.0.0:33756) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38399 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42401 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-4] [1704783099.831546] [dgx13:88117:0]            sock.c:470  UCX  ERROR bind(fd=163 addr=0.0.0.0:34114) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42717 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37273 instead
  warnings.warn(
[1704783147.694519] [dgx13:88733:0]            sock.c:470  UCX  ERROR bind(fd=152 addr=0.0.0.0:37262) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35723 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32775 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37343 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_lock_workers PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucx] [1704783226.384619] [dgx13:89974:0]            sock.c:470  UCX  ERROR bind(fd=165 addr=0.0.0.0:55751) failed: Address already in use
[1704783226.961029] [dgx13:89982:0]            sock.c:470  UCX  ERROR bind(fd=164 addr=0.0.0.0:55458) failed: Address already in use
PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucxx] PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[tcp] PASSED
dask_cuda/tests/test_gds.py::test_gds[True-cupy] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-cudf] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-numba.cuda] SKIPPED (GDS ...)
dask_cuda/tests/test_gds.py::test_gds[False-cupy] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-cudf] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-numba.cuda] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41983 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34689 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37241 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33849 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37823 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44767 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucx] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_local_cuda_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_with_subset_of_cuda_visible_devices PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucx] [1704783318.789039] [dgx13:64821:0]            sock.c:470  UCX  ERROR bind(fd=256 addr=0.0.0.0:56378) failed: Address already in use
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_n_workers PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_threads_per_worker_and_memory_limit PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cudaworker 2024-01-09 06:55:44,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:55:44,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:55:44,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:55:44,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:55:44,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:55:44,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:55:44,322 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:55:44,322 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:55:44,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:55:44,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:55:44,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:55:44,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:55:44,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:55:44,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:55:44,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:55:44,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:55:44,905 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:55:44,906 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43597
2024-01-09 06:55:44,906 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43597
2024-01-09 06:55:44,906 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46415
2024-01-09 06:55:44,906 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:46377
2024-01-09 06:55:44,907 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:44,907 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:55:44,907 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-88fkc_88
2024-01-09 06:55:44,907 - distributed.worker - INFO - Starting Worker plugin PreImport-cf06636f-c2f8-46d9-b5bc-1cbd1515f6ec
2024-01-09 06:55:44,907 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1021b637-86b4-4b57-afe4-767d54041586
2024-01-09 06:55:44,907 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-499f0b5b-a615-45c8-ba4c-8ef20d660218
2024-01-09 06:55:44,907 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:44,908 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:55:44,909 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40693
2024-01-09 06:55:44,909 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40693
2024-01-09 06:55:44,909 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32979
2024-01-09 06:55:44,909 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:46377
2024-01-09 06:55:44,909 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:44,909 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:55:44,909 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s2kt2b5c
2024-01-09 06:55:44,909 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f10ad171-58a4-40e4-af6a-69b0a6d68a84
2024-01-09 06:55:44,911 - distributed.worker - INFO - Starting Worker plugin PreImport-b0fbb41b-3cbc-4bcf-98aa-b5cf83ff2566
2024-01-09 06:55:44,912 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4b8403a2-cf5e-43c4-9582-398d1d705030
2024-01-09 06:55:44,912 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:44,933 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:55:44,934 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44373
2024-01-09 06:55:44,934 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44373
2024-01-09 06:55:44,934 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41853
2024-01-09 06:55:44,934 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:46377
2024-01-09 06:55:44,934 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:44,934 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:55:44,934 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6uuzrgpw
2024-01-09 06:55:44,935 - distributed.worker - INFO - Starting Worker plugin PreImport-ff57de5a-85b8-4f92-838b-1d3261b9e9ac
2024-01-09 06:55:44,935 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9fcb431f-6779-4d9b-8be0-96ef9be49124
2024-01-09 06:55:44,935 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9e3aa729-e5ef-41fc-8d28-aa2d92a8bca2
2024-01-09 06:55:44,935 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:44,938 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:55:44,939 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44477
2024-01-09 06:55:44,939 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44477
2024-01-09 06:55:44,939 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43419
2024-01-09 06:55:44,939 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:46377
2024-01-09 06:55:44,939 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:44,939 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:55:44,939 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g5nnjtpe
2024-01-09 06:55:44,940 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a71c40cc-31b2-41c1-b16b-bc1b86ee75e7
2024-01-09 06:55:44,940 - distributed.worker - INFO - Starting Worker plugin RMMSetup-21879c9d-8ab3-41f8-8398-78210f7ea44f
2024-01-09 06:55:44,940 - distributed.worker - INFO - Starting Worker plugin PreImport-e08ab1da-7eee-46a1-a59c-3251694c7be7
2024-01-09 06:55:44,940 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,020 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:55:45,021 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40769
2024-01-09 06:55:45,021 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40769
2024-01-09 06:55:45,021 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44141
2024-01-09 06:55:45,021 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:46377
2024-01-09 06:55:45,021 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,021 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:55:45,021 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-epomc8ua
2024-01-09 06:55:45,021 - distributed.worker - INFO - Starting Worker plugin RMMSetup-feba9f0e-b071-4ac9-a0a8-8505fa9b71c9
2024-01-09 06:55:45,021 - distributed.worker - INFO - Starting Worker plugin PreImport-69b0077e-27f7-4754-bc18-ce307d96ad6a
2024-01-09 06:55:45,022 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37d5a84b-67ab-418a-b6a4-11660eff088c
2024-01-09 06:55:45,022 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,087 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:55:45,087 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46181
2024-01-09 06:55:45,088 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46181
2024-01-09 06:55:45,088 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32955
2024-01-09 06:55:45,088 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:46377
2024-01-09 06:55:45,088 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,088 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:55:45,088 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p4r_90uj
2024-01-09 06:55:45,088 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3d15d176-7bdc-443e-80e3-7dbafb34c1a1
2024-01-09 06:55:45,088 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f10e0d6c-b2d7-4961-a853-4d3ef15b4575
2024-01-09 06:55:45,088 - distributed.worker - INFO - Starting Worker plugin PreImport-028493f0-c6fc-4345-a1be-c1151c34f037
2024-01-09 06:55:45,088 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,124 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:55:45,126 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33623
2024-01-09 06:55:45,126 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33623
2024-01-09 06:55:45,126 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39579
2024-01-09 06:55:45,126 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:46377
2024-01-09 06:55:45,126 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,126 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:55:45,126 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qzd0wu73
2024-01-09 06:55:45,126 - distributed.worker - INFO - Starting Worker plugin PreImport-66dbd8cd-4d45-47ec-bd4b-b379644d924d
2024-01-09 06:55:45,127 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4926fcac-cd18-4a7e-b5cb-3dbe3f2a511c
2024-01-09 06:55:45,127 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4e1ad739-7755-44ab-98e9-24d7d2c6576c
2024-01-09 06:55:45,127 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,172 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:55:45,173 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:46377
2024-01-09 06:55:45,173 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,174 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46377
2024-01-09 06:55:45,178 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:55:45,179 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37709
2024-01-09 06:55:45,179 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37709
2024-01-09 06:55:45,179 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34153
2024-01-09 06:55:45,179 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:46377
2024-01-09 06:55:45,179 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,179 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:55:45,179 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ijec7_ns
2024-01-09 06:55:45,180 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4f1ca7fb-212b-4928-8570-de1c3189fb8c
2024-01-09 06:55:45,180 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-11d20625-d5e8-457a-8ddf-5064fb725bc4
2024-01-09 06:55:45,180 - distributed.worker - INFO - Starting Worker plugin PreImport-b2dd370d-58f8-4cf5-a999-003462719c7f
2024-01-09 06:55:45,180 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,204 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:55:45,205 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:46377
2024-01-09 06:55:45,205 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,206 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46377
2024-01-09 06:55:45,356 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:55:45,357 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:46377
2024-01-09 06:55:45,357 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,358 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46377
2024-01-09 06:55:45,401 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:55:45,402 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:46377
2024-01-09 06:55:45,402 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:45,403 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46377
2024-01-09 06:55:46,293 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:55:46,294 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:46377
2024-01-09 06:55:46,294 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:46,295 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46377
2024-01-09 06:55:46,394 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:55:46,395 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:46377
2024-01-09 06:55:46,395 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:46,396 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46377
2024-01-09 06:55:46,409 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:55:46,410 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:46377
2024-01-09 06:55:46,410 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:46,411 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46377
2024-01-09 06:55:46,530 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:55:46,532 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:46377
2024-01-09 06:55:46,532 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:55:46,534 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46377
2024-01-09 06:55:46,570 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:55:46,570 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:55:46,571 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:55:46,571 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:55:46,571 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:55:46,571 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:55:46,571 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:55:46,572 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-09 06:55:46,578 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43597. Reason: nanny-close
2024-01-09 06:55:46,579 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40693. Reason: nanny-close
2024-01-09 06:55:46,580 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44477. Reason: nanny-close
2024-01-09 06:55:46,581 - distributed.core - INFO - Connection to tcp://127.0.0.1:46377 has been closed.
2024-01-09 06:55:46,581 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44373. Reason: nanny-close
2024-01-09 06:55:46,582 - distributed.core - INFO - Connection to tcp://127.0.0.1:46377 has been closed.
2024-01-09 06:55:46,582 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37709. Reason: nanny-close
2024-01-09 06:55:46,582 - distributed.nanny - INFO - Worker closed
2024-01-09 06:55:46,582 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40769. Reason: nanny-close
2024-01-09 06:55:46,583 - distributed.core - INFO - Connection to tcp://127.0.0.1:46377 has been closed.
2024-01-09 06:55:46,583 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33623. Reason: nanny-close
2024-01-09 06:55:46,583 - distributed.nanny - INFO - Worker closed
2024-01-09 06:55:46,583 - distributed.core - INFO - Connection to tcp://127.0.0.1:46377 has been closed.
2024-01-09 06:55:46,583 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46181. Reason: nanny-close
2024-01-09 06:55:46,584 - distributed.nanny - INFO - Worker closed
2024-01-09 06:55:46,585 - distributed.nanny - INFO - Worker closed
2024-01-09 06:55:46,585 - distributed.core - INFO - Connection to tcp://127.0.0.1:46377 has been closed.
2024-01-09 06:55:46,585 - distributed.core - INFO - Connection to tcp://127.0.0.1:46377 has been closed.
2024-01-09 06:55:46,585 - distributed.core - INFO - Connection to tcp://127.0.0.1:46377 has been closed.
2024-01-09 06:55:46,585 - distributed.core - INFO - Connection to tcp://127.0.0.1:46377 has been closed.
2024-01-09 06:55:46,586 - distributed.nanny - INFO - Worker closed
2024-01-09 06:55:46,586 - distributed.nanny - INFO - Worker closed
2024-01-09 06:55:46,587 - distributed.nanny - INFO - Worker closed
2024-01-09 06:55:46,587 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_all_to_all PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_pool PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_maximum_poolsize_without_poolsize_error PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_managed PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async_with_maximum_pool_size PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_logging PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import_not_found 2024-01-09 06:56:27,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:56:27,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:56:27,216 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:56:27,217 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46249
2024-01-09 06:56:27,217 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46249
2024-01-09 06:56:27,217 - distributed.worker - INFO -           Worker name:                          0
2024-01-09 06:56:27,217 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42009
2024-01-09 06:56:27,217 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:37927
2024-01-09 06:56:27,217 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:27,217 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:56:27,217 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-09 06:56:27,217 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o8l7zwh_
2024-01-09 06:56:27,217 - distributed.worker - INFO - Starting Worker plugin PreImport-fd43eda1-18a0-4f1b-aa78-df94000bd795
2024-01-09 06:56:27,221 - distributed.worker - ERROR - No module named 'my_module'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'
2024-01-09 06:56:27,221 - distributed.worker - INFO - Starting Worker plugin RMMSetup-667e32d7-595e-4604-bd85-a728369ffd55
2024-01-09 06:56:27,221 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b6fbff18-9e2d-48e5-955e-d512cbb06bdf
2024-01-09 06:56:27,222 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46249. Reason: failure-to-start-<class 'ModuleNotFoundError'>
2024-01-09 06:56:27,222 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2024-01-09 06:56:27,227 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
XFAIL
dask_cuda/tests/test_local_cuda_cluster.py::test_cluster_worker 2024-01-09 06:56:32,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:56:32,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:56:32,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:56:32,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:56:32,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:56:32,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:56:32,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:56:32,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:56:32,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:56:32,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:56:32,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:56:32,338 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:56:32,433 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:56:32,433 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:56:32,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-09 06:56:32,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-09 06:56:32,813 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:56:32,814 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38861
2024-01-09 06:56:32,814 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38861
2024-01-09 06:56:32,814 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36331
2024-01-09 06:56:32,814 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43865
2024-01-09 06:56:32,814 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,814 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:56:32,814 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:56:32,814 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6m7zxajj
2024-01-09 06:56:32,815 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b7713878-422d-4b4e-8668-2a6483532d58
2024-01-09 06:56:32,815 - distributed.worker - INFO - Starting Worker plugin PreImport-0438351c-1a19-42cc-925c-1ff36ee8a0e4
2024-01-09 06:56:32,815 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-852a329e-163d-4758-8547-0a776f830c95
2024-01-09 06:56:32,817 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,883 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:56:32,884 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33519
2024-01-09 06:56:32,884 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33519
2024-01-09 06:56:32,884 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33991
2024-01-09 06:56:32,884 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43865
2024-01-09 06:56:32,884 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,884 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:56:32,884 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:56:32,884 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:56:32,884 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r3bwzn8q
2024-01-09 06:56:32,884 - distributed.worker - INFO - Starting Worker plugin PreImport-9be0dbeb-0f10-46e4-a4e9-52ad4b79c7f6
2024-01-09 06:56:32,884 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c4c5cdfe-4a38-44ee-9903-89070de825c2
2024-01-09 06:56:32,884 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d20748a4-7969-4c43-80ef-d494d57858a3
2024-01-09 06:56:32,885 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43865
2024-01-09 06:56:32,885 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,885 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,886 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43865
2024-01-09 06:56:32,889 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:56:32,890 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33549
2024-01-09 06:56:32,890 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33549
2024-01-09 06:56:32,890 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32913
2024-01-09 06:56:32,890 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43865
2024-01-09 06:56:32,890 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,890 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:56:32,890 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:56:32,890 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_qb29zch
2024-01-09 06:56:32,890 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a972940b-6930-496b-b350-0b71556bfd40
2024-01-09 06:56:32,891 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0b15408b-654f-44cb-9164-06b6000b2691
2024-01-09 06:56:32,891 - distributed.worker - INFO - Starting Worker plugin PreImport-49e0002b-74d8-4127-8a6a-42fc59762cae
2024-01-09 06:56:32,891 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,931 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:56:32,932 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34211
2024-01-09 06:56:32,932 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34211
2024-01-09 06:56:32,932 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38151
2024-01-09 06:56:32,933 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43865
2024-01-09 06:56:32,933 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,933 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:56:32,933 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:56:32,933 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bbh8yt75
2024-01-09 06:56:32,933 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8eda1d5c-92a3-4f93-8b6c-1057eb61041d
2024-01-09 06:56:32,933 - distributed.worker - INFO - Starting Worker plugin PreImport-ad96bab1-c770-4ba3-84de-bacb95772af1
2024-01-09 06:56:32,933 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c8aa3ff5-d9b3-419f-97d8-802302a9c0e0
2024-01-09 06:56:32,933 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,965 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:56:32,967 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44791
2024-01-09 06:56:32,967 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44791
2024-01-09 06:56:32,967 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32911
2024-01-09 06:56:32,967 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43865
2024-01-09 06:56:32,967 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,967 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:56:32,967 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:56:32,967 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rr1t4loy
2024-01-09 06:56:32,968 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2ff06b25-6fc3-4689-81c6-d442f69f8560
2024-01-09 06:56:32,968 - distributed.worker - INFO - Starting Worker plugin PreImport-6b63fc93-daf5-435c-b9b0-84bbb11b0a6f
2024-01-09 06:56:32,968 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-19731318-45b9-4de0-9317-30ecb6fdf9e4
2024-01-09 06:56:32,969 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,974 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:56:32,975 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34681
2024-01-09 06:56:32,975 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34681
2024-01-09 06:56:32,975 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33609
2024-01-09 06:56:32,975 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43865
2024-01-09 06:56:32,975 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,975 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:56:32,975 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:56:32,975 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4hortemw
2024-01-09 06:56:32,975 - distributed.worker - INFO - Starting Worker plugin PreImport-27f33212-f76d-48e2-a401-6ffa615dcc20
2024-01-09 06:56:32,975 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e4cae6d9-b6c7-42ea-aef3-a1ce8279bcb7
2024-01-09 06:56:32,976 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f0dd072c-90d0-4e69-bd26-47cc8dea6bf9
2024-01-09 06:56:32,976 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:32,998 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:56:32,999 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43865
2024-01-09 06:56:32,999 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,000 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43865
2024-01-09 06:56:33,001 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:56:33,002 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43865
2024-01-09 06:56:33,002 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,003 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43865
2024-01-09 06:56:33,045 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:56:33,045 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34529
2024-01-09 06:56:33,046 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34529
2024-01-09 06:56:33,046 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33117
2024-01-09 06:56:33,046 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43865
2024-01-09 06:56:33,046 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,046 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:56:33,046 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:56:33,046 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0z97aew9
2024-01-09 06:56:33,046 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7caecf84-0830-405d-bf3c-579f6d9aa55a
2024-01-09 06:56:33,046 - distributed.worker - INFO - Starting Worker plugin PreImport-0722212d-691d-4e2c-8686-bb1b91fbf290
2024-01-09 06:56:33,046 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7d61fb13-0c02-4794-b6fe-3a3698854631
2024-01-09 06:56:33,046 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,053 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:56:33,054 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43865
2024-01-09 06:56:33,054 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,055 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43865
2024-01-09 06:56:33,080 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-09 06:56:33,081 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41963
2024-01-09 06:56:33,081 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41963
2024-01-09 06:56:33,081 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41597
2024-01-09 06:56:33,081 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:43865
2024-01-09 06:56:33,081 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,081 - distributed.worker - INFO -               Threads:                          1
2024-01-09 06:56:33,081 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-09 06:56:33,081 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xw9t4qxq
2024-01-09 06:56:33,082 - distributed.worker - INFO - Starting Worker plugin PreImport-1fbfea94-0e06-4bf2-8a96-af2a2cb97f02
2024-01-09 06:56:33,082 - distributed.worker - INFO - Starting Worker plugin RMMSetup-40b96956-92d6-4792-ba51-a7c6e816f7e3
2024-01-09 06:56:33,082 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e1cef76e-5b3e-465e-b63f-16c5e57bc699
2024-01-09 06:56:33,082 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,098 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:56:33,099 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43865
2024-01-09 06:56:33,099 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,100 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43865
2024-01-09 06:56:33,104 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:56:33,105 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43865
2024-01-09 06:56:33,105 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,106 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43865
2024-01-09 06:56:33,141 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:56:33,142 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43865
2024-01-09 06:56:33,142 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,143 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43865
2024-01-09 06:56:33,163 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-09 06:56:33,164 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:43865
2024-01-09 06:56:33,164 - distributed.worker - INFO - -------------------------------------------------
2024-01-09 06:56:33,165 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43865
2024-01-09 06:56:33,211 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38861. Reason: nanny-close
2024-01-09 06:56:33,211 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33519. Reason: nanny-close
2024-01-09 06:56:33,212 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34211. Reason: nanny-close
2024-01-09 06:56:33,213 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33549. Reason: nanny-close
2024-01-09 06:56:33,213 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34681. Reason: nanny-close
2024-01-09 06:56:33,213 - distributed.core - INFO - Connection to tcp://127.0.0.1:43865 has been closed.
2024-01-09 06:56:33,213 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44791. Reason: nanny-close
2024-01-09 06:56:33,213 - distributed.core - INFO - Connection to tcp://127.0.0.1:43865 has been closed.
2024-01-09 06:56:33,214 - distributed.core - INFO - Connection to tcp://127.0.0.1:43865 has been closed.
2024-01-09 06:56:33,214 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41963. Reason: nanny-close
2024-01-09 06:56:33,214 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34529. Reason: nanny-close
2024-01-09 06:56:33,214 - distributed.core - INFO - Connection to tcp://127.0.0.1:43865 has been closed.
2024-01-09 06:56:33,215 - distributed.nanny - INFO - Worker closed
2024-01-09 06:56:33,215 - distributed.core - INFO - Connection to tcp://127.0.0.1:43865 has been closed.
2024-01-09 06:56:33,215 - distributed.nanny - INFO - Worker closed
2024-01-09 06:56:33,215 - distributed.nanny - INFO - Worker closed
2024-01-09 06:56:33,215 - distributed.core - INFO - Connection to tcp://127.0.0.1:43865 has been closed.
2024-01-09 06:56:33,216 - distributed.core - INFO - Connection to tcp://127.0.0.1:43865 has been closed.
2024-01-09 06:56:33,216 - distributed.nanny - INFO - Worker closed
2024-01-09 06:56:33,216 - distributed.core - INFO - Connection to tcp://127.0.0.1:43865 has been closed.
2024-01-09 06:56:33,216 - distributed.nanny - INFO - Worker closed
2024-01-09 06:56:33,217 - distributed.nanny - INFO - Worker closed
2024-01-09 06:56:33,217 - distributed.nanny - INFO - Worker closed
2024-01-09 06:56:33,217 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_available_mig_workers SKIPPED
dask_cuda/tests/test_local_cuda_cluster.py::test_gpu_uuid PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_track_allocations PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_get_cluster_configuration PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_worker_fraction_limits PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucx] [1704783411.663254] [dgx13:64821:1]            sock.c:470  UCX  ERROR bind(fd=256 addr=0.0.0.0:42018) failed: Address already in use
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_death_timeout_raises XFAIL
dask_cuda/tests/test_proxify_host_file.py::test_one_dev_item_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_one_item_host_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_spill_on_demand PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_dataframes_share_dev_mem PASSED
dask_cuda/tests/test_proxify_host_file.py::test_cudf_get_device_memory_objects PASSED
dask_cuda/tests/test_proxify_host_file.py::test_externals PASSED
dask_cuda/tests/test_proxify_host_file.py::test_incompatible_types PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_worker_force_spill_to_disk PASSED
dask_cuda/tests/test_proxify_host_file.py::test_on_demand_debug_info 2024-01-09 06:58:13,298 - distributed.worker - WARNING - RMM allocation of 1.00 MiB failed, spill-on-demand couldn't find any device memory to spill.
RMM allocs: 1.00 MiB, <ProxyManager dev_limit=25.60 GiB host_limit=0.98 TiB disk=0 B(0) host=0 B(0) dev=0 B(0)>, traceback:
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 937, in _bootstrap
    self._bootstrap_inner()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/threadpoolexecutor.py", line 57, in _worker
    task.run()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/_concurrent_futures_thread.py", line 65, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1541, in <lambda>
    executor, lambda: context.run(func, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2954, in apply_function
    msg = apply_function_simple(function, args, kwargs, time_delay)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2990, in apply_function_simple
    result = function(*args, **kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_proxify_host_file.py", line 467, in task
    rmm.DeviceBuffer(size=rmm_pool_size),  # Trigger OOM
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/proxify_host_file.py", line 617, in oom
    traceback.print_stack(file=f)


2024-01-09 06:58:13,524 - distributed.worker - WARNING - Compute Failed
Key:       task-5c302f54392a5ca98adb3c55c8357b0e
Function:  task
args:      ()
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_serializer PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[numpy] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[cupy] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_name PASSED
dask_cuda/tests/test_proxy.py::test_spilling_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxy.py::test_spilling_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_to_disk[obj0] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_to_disk[obj1] PASSED
dask_cuda/tests/test_proxy.py::test_multiple_deserializations[dask] PASSED
dask_cuda/tests/test_proxy.py::test_multiple_deserializations[pickle] PASSED
dask_cuda/tests/test_proxy.py::test_multiple_deserializations[disk] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-None-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-None-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers1-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers1-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers2-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers2-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers3-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers3-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers4-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[numpy-serializers4-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-None-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-None-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers1-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers1-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers2-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers2-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers3-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers3-10000] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers4-10] PASSED
dask_cuda/tests/test_proxy.py::test_serializing_array_to_disk[cupy-serializers4-10000] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[tcp-None] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[tcp-send_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_communicating_proxy_objects[tcp-send_serializers2] /opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
