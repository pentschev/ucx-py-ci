2023-05-26 07:18:39,069 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4r7xpr5f', purging
2023-05-26 07:18:39,070 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aav4skv7', purging
2023-05-26 07:18:39,070 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wvooa9jm', purging
2023-05-26 07:18:39,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:39,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:39,117 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:39,117 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:39,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:39,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:39,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:39,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:39,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:39,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:39,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:39,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:39,218 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:39,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:39,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:39,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:41,261 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:41,451 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:41,453 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:41,464 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:41,472 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:41,480 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:41,488 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:41,591 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:42,845 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uh2qtf1f', purging
2023-05-26 07:18:42,846 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nlqsdn7e', purging
2023-05-26 07:18:42,846 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4zmyb1wi', purging
2023-05-26 07:18:42,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whnmbfey', purging
2023-05-26 07:18:42,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-glac18r8', purging
2023-05-26 07:18:42,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9byt4ah3', purging
2023-05-26 07:18:42,848 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n8m5werp', purging
2023-05-26 07:18:42,848 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bl7l2yhd', purging
2023-05-26 07:18:42,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:42,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:42,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:42,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:43,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:43,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:43,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:43,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:43,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:43,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:43,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:43,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:43,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:43,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:43,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:43,099 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:45,036 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:45,102 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:45,124 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:45,147 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:45,172 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:45,208 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:45,232 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:45,391 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:46,485 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5npizzd6', purging
2023-05-26 07:18:46,486 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z5_ppqf3', purging
2023-05-26 07:18:46,486 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_9gpxjrp', purging
2023-05-26 07:18:46,486 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-duy_zsq4', purging
2023-05-26 07:18:46,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0mp4o03s', purging
2023-05-26 07:18:46,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b2k5wdpj', purging
2023-05-26 07:18:46,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jwawwvvf', purging
2023-05-26 07:18:46,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0145m5g1', purging
2023-05-26 07:18:46,488 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:46,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:46,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:46,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:46,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:46,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:46,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:46,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:46,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:46,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:46,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:46,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:46,862 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:46,862 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:46,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:46,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:48,656 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:48,701 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:48,760 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:48,784 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:48,805 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:48,833 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:48,883 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:49,141 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:50,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ggfpyzdi', purging
2023-05-26 07:18:50,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cnbau2bm', purging
2023-05-26 07:18:50,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_t1kbk42', purging
2023-05-26 07:18:50,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8pgzva5i', purging
2023-05-26 07:18:50,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1h8otd1v', purging
2023-05-26 07:18:50,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xy5f345d', purging
2023-05-26 07:18:50,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fty5dpxj', purging
2023-05-26 07:18:50,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ke4md3v', purging
2023-05-26 07:18:50,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:50,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:50,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:50,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:50,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:50,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:50,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:50,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:50,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:50,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:50,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:50,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:50,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:50,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:50,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:50,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:52,367 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:52,400 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:52,469 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:52,494 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:52,516 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:52,542 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:52,578 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:52,797 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:53,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nmkvgot9', purging
2023-05-26 07:18:53,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9bplb5d1', purging
2023-05-26 07:18:53,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h02cj5y6', purging
2023-05-26 07:18:53,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ji1cbka5', purging
2023-05-26 07:18:53,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jzkmbpfu', purging
2023-05-26 07:18:53,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jf3kafu1', purging
2023-05-26 07:18:53,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ryhkuj8', purging
2023-05-26 07:18:53,870 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v1610lc3', purging
2023-05-26 07:18:53,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:53,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:53,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:53,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:53,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:53,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:54,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:54,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:54,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:54,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:54,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:54,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:54,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:54,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:54,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:54,302 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:56,066 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:56,127 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:56,157 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:56,177 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:56,205 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:56,230 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:56,251 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:56,442 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:57,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2h6kzy_m', purging
2023-05-26 07:18:57,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-absa2k1q', purging
2023-05-26 07:18:57,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ljfh3hju', purging
2023-05-26 07:18:57,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-79r2bkm_', purging
2023-05-26 07:18:57,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t03ggm1d', purging
2023-05-26 07:18:57,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-utdqfktf', purging
2023-05-26 07:18:57,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qroquzgy', purging
2023-05-26 07:18:57,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4m7qzkf2', purging
2023-05-26 07:18:57,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:57,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:57,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:57,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:57,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:57,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:57,727 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:57,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:57,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:57,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:57,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:57,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:57,823 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:57,823 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:18:57,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:18:57,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:59,614 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:59,662 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:59,718 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:59,739 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:59,767 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:18:59,820 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:18:59,870 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:00,096 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:01,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0t92patt', purging
2023-05-26 07:19:01,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1xr4dla7', purging
2023-05-26 07:19:01,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5endn81w', purging
2023-05-26 07:19:01,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t1dc0zz4', purging
2023-05-26 07:19:01,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dx9rr8w3', purging
2023-05-26 07:19:01,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xz4n1gs4', purging
2023-05-26 07:19:01,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s4fcxo03', purging
2023-05-26 07:19:01,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i48mh7k0', purging
2023-05-26 07:19:01,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:01,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:01,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:01,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:01,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:01,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:01,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:01,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:01,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:01,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:01,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:01,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:01,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:01,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:01,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:01,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:03,048 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:03,266 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:03,294 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:03,322 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:03,346 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:03,376 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:03,406 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:03,699 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:04,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zbl6mbfl', purging
2023-05-26 07:19:04,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pm5nd8qh', purging
2023-05-26 07:19:04,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hr_gkg8b', purging
2023-05-26 07:19:04,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j0kp_0xc', purging
2023-05-26 07:19:04,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vnw46m1x', purging
2023-05-26 07:19:04,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9u7tvy01', purging
2023-05-26 07:19:04,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yfvtc2qv', purging
2023-05-26 07:19:04,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cfv8awsw', purging
2023-05-26 07:19:04,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:04,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:04,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:04,750 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:04,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:04,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:04,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:04,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:04,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:04,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:04,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:04,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:04,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:04,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:05,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:05,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:05,368 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:06,364 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:06,790 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:06,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-27bnjtcs', purging
2023-05-26 07:19:06,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u9s4z7y1', purging
2023-05-26 07:19:06,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1g_o6yok', purging
2023-05-26 07:19:06,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f5unlbxv', purging
2023-05-26 07:19:06,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-djdnafxq', purging
2023-05-26 07:19:06,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t02__n9w', purging
2023-05-26 07:19:06,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_iz3fmqt', purging
2023-05-26 07:19:06,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:06,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:06,927 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:06,928 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:06,941 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:06,950 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:07,162 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:07,836 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:07,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-za7od3ip', purging
2023-05-26 07:19:07,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-807isbi_', purging
2023-05-26 07:19:07,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:07,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:08,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:08,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:08,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:08,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:08,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:08,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:08,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:08,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:08,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:08,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:08,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:08,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:09,018 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:09,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jz8ggrd7', purging
2023-05-26 07:19:09,268 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:09,268 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:10,100 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:10,135 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:10,322 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:10,350 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:10,406 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:10,531 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:10,548 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7u92qqk5', purging
2023-05-26 07:19:10,548 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-76_q90z2', purging
2023-05-26 07:19:10,549 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qtvfktqp', purging
2023-05-26 07:19:10,549 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cfgi2euw', purging
2023-05-26 07:19:10,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6l0az4i4', purging
2023-05-26 07:19:10,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9g55kqd5', purging
2023-05-26 07:19:10,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:10,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:10,721 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:11,380 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:11,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4dgwvymt', purging
2023-05-26 07:19:11,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b380yeof', purging
2023-05-26 07:19:11,658 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:11,658 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:11,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:11,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:11,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:11,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:11,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:11,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:11,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:11,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:12,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:12,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:12,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:12,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:12,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:12,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:13,479 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:13,693 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:13,724 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:13,792 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:13,813 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:14,091 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:14,135 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:14,297 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:14,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ij94vxqx', purging
2023-05-26 07:19:14,926 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nrn190ck', purging
2023-05-26 07:19:14,926 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qd_qufdc', purging
2023-05-26 07:19:14,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p6msste7', purging
2023-05-26 07:19:14,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-znvtsh1x', purging
2023-05-26 07:19:14,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-izj1k2to', purging
2023-05-26 07:19:14,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-phne7322', purging
2023-05-26 07:19:14,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rwk4_npw', purging
2023-05-26 07:19:14,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:14,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:15,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:15,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:15,268 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:15,268 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:15,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:15,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:15,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:15,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:15,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:15,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:15,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:15,670 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:15,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:15,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:16,279 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:16,960 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:17,132 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:17,159 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:17,185 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:17,434 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:17,461 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:17,622 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:17,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sg595be7', purging
2023-05-26 07:19:17,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f2olr76p', purging
2023-05-26 07:19:17,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r62nxtc3', purging
2023-05-26 07:19:17,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-diqtrviq', purging
2023-05-26 07:19:17,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rcgsuj5c', purging
2023-05-26 07:19:17,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oklk9w93', purging
2023-05-26 07:19:17,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s7799e9h', purging
2023-05-26 07:19:17,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vxpouhy0', purging
2023-05-26 07:19:17,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:17,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:18,505 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yaa_gktd', purging
2023-05-26 07:19:18,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:18,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:18,513 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:18,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:18,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:18,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:18,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:18,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:18,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:18,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:18,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:18,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:18,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:19,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:19,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:19,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:19,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:20,368 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:20,397 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:20,427 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:20,460 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:20,840 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:20,892 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:20,914 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:21,203 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:21,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u5i1itkt', purging
2023-05-26 07:19:21,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6mo78fxn', purging
2023-05-26 07:19:21,914 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y2n1n34s', purging
2023-05-26 07:19:21,914 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ioudwy58', purging
2023-05-26 07:19:21,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ceehicf8', purging
2023-05-26 07:19:21,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yweia1gw', purging
2023-05-26 07:19:21,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tm5l4vh8', purging
2023-05-26 07:19:21,916 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-02zvfoz8', purging
2023-05-26 07:19:21,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:21,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:21,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:21,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:21,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:21,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:22,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:22,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:22,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:22,241 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:22,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:22,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:22,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:22,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:22,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:22,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:23,541 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:23,927 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:23,955 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:23,978 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:24,161 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:24,376 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:24,410 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:24,566 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:24,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-98s81tkv', purging
2023-05-26 07:19:24,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0mxp_l84', purging
2023-05-26 07:19:24,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rw3y7j_v', purging
2023-05-26 07:19:24,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-45kr7s5c', purging
2023-05-26 07:19:24,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v52q41q5', purging
2023-05-26 07:19:24,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pmv8vh70', purging
2023-05-26 07:19:24,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4fmqdwv5', purging
2023-05-26 07:19:24,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4jm6bu75', purging
2023-05-26 07:19:24,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:24,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:25,463 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:25,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:25,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:25,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:25,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:25,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:25,719 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-503xaf5v', purging
2023-05-26 07:19:25,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:25,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:25,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:25,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:25,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:25,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:26,014 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:26,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:26,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:27,002 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:27,164 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:27,192 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:27,455 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:27,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a8zdu7bm', purging
2023-05-26 07:19:27,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wddjc9q8', purging
2023-05-26 07:19:27,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dhpl_cf5', purging
2023-05-26 07:19:27,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4mc8w3g2', purging
2023-05-26 07:19:27,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e5ufj6u3', purging
2023-05-26 07:19:27,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:27,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:27,479 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:27,525 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:27,700 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:28,386 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:28,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6z_7e3y', purging
2023-05-26 07:19:28,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x96xi3h2', purging
2023-05-26 07:19:28,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0utn3d1g', purging
2023-05-26 07:19:28,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:28,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:28,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:28,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:28,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:28,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:28,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:28,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:28,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:28,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:29,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:29,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:29,226 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:29,226 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:29,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f5ssl6u4', purging
2023-05-26 07:19:29,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:29,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:29,947 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:30,351 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:30,538 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:30,763 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:30,999 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:31,051 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:31,076 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:31,362 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:31,508 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v8ts8fkb', purging
2023-05-26 07:19:31,508 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yaahuw1e', purging
2023-05-26 07:19:31,509 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-31fwmy_8', purging
2023-05-26 07:19:31,509 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dx2yfejd', purging
2023-05-26 07:19:31,509 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ie3dkst3', purging
2023-05-26 07:19:31,510 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4a8yz4z2', purging
2023-05-26 07:19:31,510 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4o0o6p6c', purging
2023-05-26 07:19:31,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:31,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:31,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:31,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:32,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:32,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:32,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:32,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:32,354 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:32,552 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hebhoweo', purging
2023-05-26 07:19:32,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:32,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:32,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:32,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:32,615 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:32,615 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:32,834 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:32,850 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mvxlco85', purging
2023-05-26 07:19:32,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:32,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:33,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6bgjxrai', purging
2023-05-26 07:19:33,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vf1tgatf', purging
2023-05-26 07:19:33,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:33,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:33,878 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:34,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:34,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:34,486 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:34,516 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:34,542 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:34,587 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:34,899 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:35,143 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:35,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1zccsxps', purging
2023-05-26 07:19:35,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gvzuxpqf', purging
2023-05-26 07:19:35,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-povm1vmz', purging
2023-05-26 07:19:35,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-45u8ro6b', purging
2023-05-26 07:19:35,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zd68eneh', purging
2023-05-26 07:19:35,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mdqc7v_c', purging
2023-05-26 07:19:35,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:35,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:36,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:36,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:36,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:36,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:36,050 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:36,050 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:36,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:36,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:36,338 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:36,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oj3i9x3x', purging
2023-05-26 07:19:36,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:36,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:36,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:36,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:37,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:37,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:37,897 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:37,928 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:37,953 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:37,978 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:38,006 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:38,321 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:38,584 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:39,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zxtc687s', purging
2023-05-26 07:19:39,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c3v87f2l', purging
2023-05-26 07:19:39,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-by1aczv5', purging
2023-05-26 07:19:39,333 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z4rk516y', purging
2023-05-26 07:19:39,333 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_c553oi', purging
2023-05-26 07:19:39,333 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ok2d20y3', purging
2023-05-26 07:19:39,334 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nv54ajeh', purging
2023-05-26 07:19:39,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:39,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:39,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:39,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:39,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:39,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:39,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:39,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:39,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:39,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:39,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:39,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:40,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:40,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:41,060 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:41,257 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:41,286 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:41,312 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:41,340 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:41,502 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:41,662 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:42,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9qgnhbvl', purging
2023-05-26 07:19:42,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oftk2hdt', purging
2023-05-26 07:19:42,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r58489hs', purging
2023-05-26 07:19:42,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hlepwtfz', purging
2023-05-26 07:19:42,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ca4mniu', purging
2023-05-26 07:19:42,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-67pp6hli', purging
2023-05-26 07:19:42,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-poeb0xd3', purging
2023-05-26 07:19:42,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:42,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:42,696 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:42,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:42,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:42,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:42,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:42,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:42,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:42,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:43,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:43,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:43,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:43,161 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:44,289 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:44,336 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:44,525 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:44,555 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:44,582 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:44,753 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:44,937 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:45,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f8n5aagd', purging
2023-05-26 07:19:45,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f1y2jkt3', purging
2023-05-26 07:19:45,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_htq9kp', purging
2023-05-26 07:19:45,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-arpk9x1t', purging
2023-05-26 07:19:45,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i74btcmz', purging
2023-05-26 07:19:45,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s838lpmo', purging
2023-05-26 07:19:45,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_j0qlru0', purging
2023-05-26 07:19:45,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:45,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:45,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:45,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:46,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:46,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:46,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:46,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:46,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:46,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:46,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:46,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:46,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:46,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:47,767 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:47,800 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:47,842 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:47,869 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:47,897 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:48,021 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:48,189 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:49,181 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d5wba9st', purging
2023-05-26 07:19:49,182 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ryfdtxau', purging
2023-05-26 07:19:49,182 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z_a0e3v9', purging
2023-05-26 07:19:49,183 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7n4aai15', purging
2023-05-26 07:19:49,183 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yp9km9_k', purging
2023-05-26 07:19:49,183 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v2l2mvl6', purging
2023-05-26 07:19:49,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yvgz2p8d', purging
2023-05-26 07:19:49,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:49,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:49,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:49,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:49,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:49,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:49,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:49,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:49,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:49,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:49,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:49,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:49,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:49,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:50,941 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:51,122 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:51,148 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:51,182 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:51,208 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:51,234 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:51,521 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:52,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nh8qwb7h', purging
2023-05-26 07:19:52,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ok0errfi', purging
2023-05-26 07:19:52,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24eh6f9c', purging
2023-05-26 07:19:52,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x6h4sd7a', purging
2023-05-26 07:19:52,453 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-geglvz8b', purging
2023-05-26 07:19:52,453 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c9cvruhl', purging
2023-05-26 07:19:52,453 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hctytkao', purging
2023-05-26 07:19:52,454 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:52,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:52,568 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:52,568 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:52,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:52,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:52,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:52,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:52,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:52,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:52,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:52,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:53,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:53,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:54,260 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:54,468 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:54,520 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:54,546 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:54,577 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:54,617 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:54,887 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:55,797 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-geqa3hak', purging
2023-05-26 07:19:55,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_deseqta', purging
2023-05-26 07:19:55,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4cmb9q2_', purging
2023-05-26 07:19:55,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jo0nooah', purging
2023-05-26 07:19:55,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g9zhunjh', purging
2023-05-26 07:19:55,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yys_6kpw', purging
2023-05-26 07:19:55,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-34deo3ld', purging
2023-05-26 07:19:55,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:55,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:55,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:55,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:55,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:55,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:56,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:56,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:56,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:56,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:56,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:56,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:56,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:56,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:57,720 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:57,767 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:57,797 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:57,822 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:57,849 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:57,888 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:19:58,169 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:19:59,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xgjmvlik', purging
2023-05-26 07:19:59,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1pmhradw', purging
2023-05-26 07:19:59,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bpa2vyj_', purging
2023-05-26 07:19:59,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ooqssawr', purging
2023-05-26 07:19:59,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3oj7xayi', purging
2023-05-26 07:19:59,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-17dngjn2', purging
2023-05-26 07:19:59,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qiy7m5ky', purging
2023-05-26 07:19:59,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:59,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:59,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:59,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:59,309 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:59,309 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:59,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:59,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:59,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:59,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:59,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:59,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:19:59,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:19:59,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:00,693 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:00,783 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:01,019 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:01,168 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:01,197 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:01,229 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:01,411 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:02,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rso6e3ew', purging
2023-05-26 07:20:02,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-piqe_ag2', purging
2023-05-26 07:20:02,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-emgya2jy', purging
2023-05-26 07:20:02,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kmd6fg6c', purging
2023-05-26 07:20:02,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qkiyjp70', purging
2023-05-26 07:20:02,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_rznyud', purging
2023-05-26 07:20:02,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-id30gvak', purging
2023-05-26 07:20:02,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:02,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:02,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:02,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:02,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:02,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:02,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:02,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:02,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:02,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:02,794 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:02,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:02,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:02,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:03,588 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:03,625 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:04,239 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:04,287 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:04,316 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:04,347 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:04,504 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:05,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n7hzbc9i', purging
2023-05-26 07:20:05,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lp58pazs', purging
2023-05-26 07:20:05,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ya90ape', purging
2023-05-26 07:20:05,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4vsgdg0q', purging
2023-05-26 07:20:05,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c6jvmv35', purging
2023-05-26 07:20:05,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_3a2g9x6', purging
2023-05-26 07:20:05,089 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1z302gtb', purging
2023-05-26 07:20:05,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:05,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:05,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:05,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:05,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:05,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:05,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:05,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:05,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:05,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:05,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:05,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:06,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:06,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:06,188 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:06,215 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:07,116 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:07,234 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:07,323 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:07,363 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:07,556 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:07,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mp24us7j', purging
2023-05-26 07:20:07,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_mk78gne', purging
2023-05-26 07:20:07,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0z33ia3', purging
2023-05-26 07:20:07,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hhiaq9tl', purging
2023-05-26 07:20:07,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05akno0_', purging
2023-05-26 07:20:07,686 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ogqrugsa', purging
2023-05-26 07:20:07,686 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8bwmclff', purging
2023-05-26 07:20:07,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:07,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:07,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:07,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:08,602 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:08,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gjtra6e9', purging
2023-05-26 07:20:08,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:08,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:08,771 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:08,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bsz4wzxq', purging
2023-05-26 07:20:08,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:08,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:08,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:08,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:08,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:08,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:09,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:09,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:10,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:10,099 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:10,198 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:10,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3mcr1ceb', purging
2023-05-26 07:20:10,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:10,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:10,273 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:10,291 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:10,316 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:10,545 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:10,861 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:11,078 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:11,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-to966mta', purging
2023-05-26 07:20:11,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mc0t4b0m', purging
2023-05-26 07:20:11,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ab4368e5', purging
2023-05-26 07:20:11,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ndcjsz5', purging
2023-05-26 07:20:11,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_nkbx3pw', purging
2023-05-26 07:20:11,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pmi90xxy', purging
2023-05-26 07:20:11,649 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:11,649 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:11,824 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:11,824 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:11,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:11,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:11,869 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:11,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:12,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:12,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:12,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:12,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:12,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:12,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:13,204 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:13,232 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:13,265 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:13,293 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:13,833 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:13,912 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:14,081 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:14,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2msj1pyn', purging
2023-05-26 07:20:14,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rkxu2gnj', purging
2023-05-26 07:20:14,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xoj7d_5n', purging
2023-05-26 07:20:14,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cscgntaq', purging
2023-05-26 07:20:14,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tbweeg92', purging
2023-05-26 07:20:14,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pwsudgts', purging
2023-05-26 07:20:14,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p9ulprbx', purging
2023-05-26 07:20:14,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:14,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:14,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:14,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:14,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:14,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:14,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:14,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:15,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:15,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:15,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:15,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:15,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:15,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:16,290 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:16,318 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:16,529 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:16,531 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:16,781 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:16,812 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:16,985 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:17,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b0h286fq', purging
2023-05-26 07:20:17,747 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eev_jc66', purging
2023-05-26 07:20:17,747 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7j8a6lgp', purging
2023-05-26 07:20:17,747 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1qbj3bde', purging
2023-05-26 07:20:17,747 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cv7pyd5i', purging
2023-05-26 07:20:17,748 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pkign_yn', purging
2023-05-26 07:20:17,748 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-me4mqyaz', purging
2023-05-26 07:20:17,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:17,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:17,778 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:17,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:18,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:18,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:18,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:18,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:18,292 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:18,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:18,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:18,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:18,456 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:18,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:19,430 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:19,615 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:19,827 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:19,869 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:19,941 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:19,971 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:20,144 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:20,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nl_evj_p', purging
2023-05-26 07:20:20,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xtdjgurh', purging
2023-05-26 07:20:20,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qnhr_6wf', purging
2023-05-26 07:20:20,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wh9c82n8', purging
2023-05-26 07:20:20,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2h0hvqgi', purging
2023-05-26 07:20:20,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rli3_li_', purging
2023-05-26 07:20:20,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rw6fwhoj', purging
2023-05-26 07:20:20,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:20,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:21,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:21,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:21,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:21,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:21,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:21,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:21,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:21,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:21,489 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:21,489 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:21,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:21,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:21,702 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:22,471 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:22,820 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:22,903 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:22,948 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:22,976 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:23,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mv_mjiaf', purging
2023-05-26 07:20:23,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zztm27n9', purging
2023-05-26 07:20:23,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hlvi9zj_', purging
2023-05-26 07:20:23,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q1za23dm', purging
2023-05-26 07:20:23,094 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8t7123yt', purging
2023-05-26 07:20:23,094 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3bulhahr', purging
2023-05-26 07:20:23,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:23,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:23,198 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:23,857 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-173ize5d', purging
2023-05-26 07:20:23,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:23,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:23,917 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:24,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dxmi1ivk', purging
2023-05-26 07:20:24,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:24,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:24,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:24,430 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:24,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:24,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:24,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:24,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:24,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:24,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:24,725 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:25,420 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y7n07fct', purging
2023-05-26 07:20:25,420 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ktitc3n_', purging
2023-05-26 07:20:25,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:25,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:25,637 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:25,876 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:25,930 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:25,958 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:26,162 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:26,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lwzeq0n7', purging
2023-05-26 07:20:26,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_53v66i', purging
2023-05-26 07:20:26,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fgc53o1v', purging
2023-05-26 07:20:26,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y24xmgft', purging
2023-05-26 07:20:26,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:26,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:26,462 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:26,745 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:27,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-56c2333l', purging
2023-05-26 07:20:27,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-561n0if7', purging
2023-05-26 07:20:27,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:27,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:27,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:27,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:27,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:27,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:27,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:27,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:27,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:27,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:27,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:27,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:28,238 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whn6msdw', purging
2023-05-26 07:20:28,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:28,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:28,340 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:28,396 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:28,993 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:29,022 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:29,273 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:29,390 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:29,553 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:29,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a3q59837', purging
2023-05-26 07:20:29,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-suhpwz0f', purging
2023-05-26 07:20:29,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-295116ba', purging
2023-05-26 07:20:29,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j1ok2o0_', purging
2023-05-26 07:20:29,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nqmq9bqd', purging
2023-05-26 07:20:29,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b12zhs_z', purging
2023-05-26 07:20:29,790 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:29,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:29,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:29,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:30,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:30,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:30,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:30,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:30,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:30,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:30,859 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:30,883 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:30,883 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y76fsb_4', purging
2023-05-26 07:20:30,884 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l20v9oit', purging
2023-05-26 07:20:30,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:30,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:31,045 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:31,045 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:31,261 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:31,672 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:31,984 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:32,027 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:32,244 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:32,358 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mpltwayl', purging
2023-05-26 07:20:32,359 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-it_72tpu', purging
2023-05-26 07:20:32,359 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r78__2rl', purging
2023-05-26 07:20:32,359 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ves7e2h9', purging
2023-05-26 07:20:32,360 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gxuy5r9s', purging
2023-05-26 07:20:32,360 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:32,360 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:32,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:32,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:32,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:32,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:33,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:33,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:33,444 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:33,463 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:33,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mx0pkwat', purging
2023-05-26 07:20:33,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3pl8a5sj', purging
2023-05-26 07:20:33,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:33,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:33,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:33,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:33,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:33,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:34,003 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:34,053 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:34,578 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:34,614 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:34,869 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:34,889 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6imj6vvo', purging
2023-05-26 07:20:34,890 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vhhrddoi', purging
2023-05-26 07:20:34,890 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_jt7klcj', purging
2023-05-26 07:20:34,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zyx59_gb', purging
2023-05-26 07:20:34,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xfovjowo', purging
2023-05-26 07:20:34,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:34,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:34,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:34,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:35,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:35,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:35,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:35,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:36,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-blmt5cqb', purging
2023-05-26 07:20:36,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dznhpu3j', purging
2023-05-26 07:20:36,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:36,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:36,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:36,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:36,149 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:36,173 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:36,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:36,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:36,711 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:36,736 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:37,082 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:37,118 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:37,404 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:37,636 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pc3lhr1k', purging
2023-05-26 07:20:37,636 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5jwzeh5p', purging
2023-05-26 07:20:37,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25jrwmgx', purging
2023-05-26 07:20:37,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7mrij_se', purging
2023-05-26 07:20:37,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jf3sng6t', purging
2023-05-26 07:20:37,638 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:37,638 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:37,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:37,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:38,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:38,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:38,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:38,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:38,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:38,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:38,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:38,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:38,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e7m8zmda', purging
2023-05-26 07:20:38,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v8w1_fw5', purging
2023-05-26 07:20:38,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:38,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:38,888 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:38,930 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:39,471 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:39,511 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:39,840 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:39,879 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:40,052 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:40,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whf4gpqx', purging
2023-05-26 07:20:40,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ofb6u84o', purging
2023-05-26 07:20:40,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uf1_hh30', purging
2023-05-26 07:20:40,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tj77v6wq', purging
2023-05-26 07:20:40,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s88_o6qb', purging
2023-05-26 07:20:40,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:40,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:40,460 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:40,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:40,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:40,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:40,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:40,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:41,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:41,317 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:41,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:41,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:41,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:41,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:41,691 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:41,720 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:42,432 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:42,474 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:42,702 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:42,725 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:42,906 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:43,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uhl9m9qq', purging
2023-05-26 07:20:43,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0zfrjd_3', purging
2023-05-26 07:20:43,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9bs9syxu', purging
2023-05-26 07:20:43,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0cj_48ec', purging
2023-05-26 07:20:43,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cqbq_vht', purging
2023-05-26 07:20:43,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-65ka6yad', purging
2023-05-26 07:20:43,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_fdmgnx', purging
2023-05-26 07:20:43,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:43,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:43,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:43,241 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:43,997 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-temivr82', purging
2023-05-26 07:20:43,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:43,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:44,026 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:44,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:44,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:44,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:44,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:44,248 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:44,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5yo0bs8f', purging
2023-05-26 07:20:44,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:44,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:44,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:44,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:45,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:45,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:45,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:45,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:45,739 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:45,813 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:45,902 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:45,945 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:46,229 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:47,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fudjyhty', purging
2023-05-26 07:20:47,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3d3vhhxg', purging
2023-05-26 07:20:47,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6yt5fk0x', purging
2023-05-26 07:20:47,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4egx72tz', purging
2023-05-26 07:20:47,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ya8neorv', purging
2023-05-26 07:20:47,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:47,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:47,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lcqsfwhe', purging
2023-05-26 07:20:47,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:47,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:47,378 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:47,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:47,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:47,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:47,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:47,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-83p_y0kz', purging
2023-05-26 07:20:47,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:47,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:47,769 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:48,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:48,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:49,216 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:49,216 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:49,291 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:49,513 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:49,540 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:49,567 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:49,590 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:49,883 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:50,114 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:50,720 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-858mktha', purging
2023-05-26 07:20:50,720 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pl8eeph0', purging
2023-05-26 07:20:50,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-64nsfbiu', purging
2023-05-26 07:20:50,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2h5y4usl', purging
2023-05-26 07:20:50,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5jg5z2gi', purging
2023-05-26 07:20:50,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ukueeg07', purging
2023-05-26 07:20:50,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h5jh46ey', purging
2023-05-26 07:20:50,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:50,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:51,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:51,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:51,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:51,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:51,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:51,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:51,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:51,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:51,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:51,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:51,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:51,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:52,080 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:52,502 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:52,531 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:52,745 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:52,787 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:52,966 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:53,134 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:53,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-msw2j8i1', purging
2023-05-26 07:20:53,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yx3p7ef5', purging
2023-05-26 07:20:53,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xs4kxs7e', purging
2023-05-26 07:20:53,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m5ng61m0', purging
2023-05-26 07:20:53,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-14s66vrk', purging
2023-05-26 07:20:53,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g9x7pono', purging
2023-05-26 07:20:53,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4_zcmef3', purging
2023-05-26 07:20:53,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:53,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:53,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:53,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:54,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:54,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:54,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:54,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:54,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:54,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:54,314 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:54,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gesc0_hi', purging
2023-05-26 07:20:54,468 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:54,468 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:54,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:54,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:55,011 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:55,299 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:55,635 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:55,686 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:55,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zgz0ype4', purging
2023-05-26 07:20:55,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whr_pw6e', purging
2023-05-26 07:20:55,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pg1zokdb', purging
2023-05-26 07:20:55,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2nionz6', purging
2023-05-26 07:20:55,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:55,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:55,755 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:55,956 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:56,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_jyl4ye5', purging
2023-05-26 07:20:56,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-88jz4r5p', purging
2023-05-26 07:20:56,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:56,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:56,646 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:56,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i8oaki8w', purging
2023-05-26 07:20:56,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:56,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:57,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:57,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:57,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:57,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:57,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:57,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:57,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:57,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:58,015 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:58,016 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:58,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ghs6ag1', purging
2023-05-26 07:20:58,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fkl4s4_r', purging
2023-05-26 07:20:58,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:58,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:58,482 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:58,506 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:58,533 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:58,797 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:20:59,044 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:20:59,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:59,462 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a7ozefjw', purging
2023-05-26 07:20:59,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:20:59,463 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pvjesyjg', purging
2023-05-26 07:20:59,463 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2l4j1o96', purging
2023-05-26 07:20:59,463 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a98os2gv', purging
2023-05-26 07:20:59,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ade38vif', purging
2023-05-26 07:20:59,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:20:59,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:00,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:00,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:00,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:00,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:00,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:00,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:00,330 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cq9bfkq', purging
2023-05-26 07:21:00,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5_lzn0im', purging
2023-05-26 07:21:00,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:00,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:00,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:00,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:00,810 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:00,833 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:01,420 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:01,452 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:01,476 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:01,667 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:01,826 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:02,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ct_euj8p', purging
2023-05-26 07:21:02,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hsspjiy4', purging
2023-05-26 07:21:02,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-13j4wt49', purging
2023-05-26 07:21:02,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tb709nnd', purging
2023-05-26 07:21:02,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qnolp711', purging
2023-05-26 07:21:02,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:02,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:02,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:02,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:02,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:02,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:02,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:02,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:02,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:02,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:03,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:03,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:03,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:03,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:03,505 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:03,535 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:04,275 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:04,309 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:04,410 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:04,513 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:04,685 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:04,931 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r4it862q', purging
2023-05-26 07:21:04,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j612yo89', purging
2023-05-26 07:21:04,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n23i2jmf', purging
2023-05-26 07:21:04,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ajne4e_8', purging
2023-05-26 07:21:04,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mzoxf13y', purging
2023-05-26 07:21:04,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-trzerw18', purging
2023-05-26 07:21:04,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5a0pzlln', purging
2023-05-26 07:21:04,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:04,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:04,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:04,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:05,765 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:05,797 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ojkn5ods', purging
2023-05-26 07:21:05,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:05,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:05,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:05,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:05,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:05,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:05,976 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:06,013 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pvrwjgt4', purging
2023-05-26 07:21:06,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:06,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:06,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:06,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:07,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:07,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:07,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:07,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:07,665 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:07,691 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:07,720 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:07,747 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:07,772 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:08,085 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:08,253 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:09,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zfql9t0w', purging
2023-05-26 07:21:09,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-itqe8z7z', purging
2023-05-26 07:21:09,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-czpd7p2w', purging
2023-05-26 07:21:09,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eb4njwq3', purging
2023-05-26 07:21:09,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vj_6mrqn', purging
2023-05-26 07:21:09,135 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9f51du7', purging
2023-05-26 07:21:09,135 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jfe4iz9o', purging
2023-05-26 07:21:09,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:09,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:09,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:09,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:09,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:09,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:09,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:09,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:09,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:09,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:09,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:09,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:09,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:09,658 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:11,028 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:11,105 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:11,125 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:11,157 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:11,186 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:11,327 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:11,507 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:12,444 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ezmk2zh6', purging
2023-05-26 07:21:12,445 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bmpidvne', purging
2023-05-26 07:21:12,445 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lbo1wlgb', purging
2023-05-26 07:21:12,445 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vp93yn6x', purging
2023-05-26 07:21:12,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-maskq0u5', purging
2023-05-26 07:21:12,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-beqpn8xu', purging
2023-05-26 07:21:12,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ymdq6e_1', purging
2023-05-26 07:21:12,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:12,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:12,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:12,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:12,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:12,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:12,648 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:12,648 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:12,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:12,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:12,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:12,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:13,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:13,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:14,146 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:14,378 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:14,400 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:14,430 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:14,448 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:14,604 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:14,786 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:15,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5dmzsz4_', purging
2023-05-26 07:21:15,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ya60v8bi', purging
2023-05-26 07:21:15,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dyq4xua7', purging
2023-05-26 07:21:15,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wqlm32dr', purging
2023-05-26 07:21:15,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z3nh22pn', purging
2023-05-26 07:21:15,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qmejtpcg', purging
2023-05-26 07:21:15,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8sh985uc', purging
2023-05-26 07:21:15,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:15,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:15,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:15,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:15,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:15,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:15,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:15,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:15,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:15,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:16,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:16,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:16,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:16,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:16,444 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:17,594 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:17,646 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:17,717 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:17,749 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:17,869 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:17,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-me4hxiha', purging
2023-05-26 07:21:17,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hsvl9d83', purging
2023-05-26 07:21:17,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4annzl0y', purging
2023-05-26 07:21:17,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jpi9i4d6', purging
2023-05-26 07:21:17,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ri8as8mw', purging
2023-05-26 07:21:17,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h02_fq7b', purging
2023-05-26 07:21:17,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:17,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:18,056 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:18,710 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:19,183 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f_go_87j', purging
2023-05-26 07:21:19,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b3s2bqi_', purging
2023-05-26 07:21:19,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:19,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:19,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:19,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:19,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:19,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:19,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:19,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:19,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:19,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:19,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:19,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:20,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:20,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:21,080 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:21,095 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:21,132 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:21,143 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:21,184 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:21,355 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:21,537 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:22,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ni_iuhv', purging
2023-05-26 07:21:22,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-idyv7l_p', purging
2023-05-26 07:21:22,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-34rw1cg1', purging
2023-05-26 07:21:22,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7y9e7hu3', purging
2023-05-26 07:21:22,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zv21ptcq', purging
2023-05-26 07:21:22,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sg2hfqid', purging
2023-05-26 07:21:22,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-59vig1gp', purging
2023-05-26 07:21:22,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:22,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:22,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:22,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:22,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:22,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:22,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:22,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:22,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:22,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:22,790 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:22,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:23,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:23,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:24,401 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:24,444 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:24,486 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:24,498 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:24,538 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:24,554 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:24,868 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:25,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1lqv0a_q', purging
2023-05-26 07:21:25,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qdu3mfa4', purging
2023-05-26 07:21:25,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hbvyf3a4', purging
2023-05-26 07:21:25,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zhqypo9b', purging
2023-05-26 07:21:25,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-er2kjskw', purging
2023-05-26 07:21:25,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6rutuuj5', purging
2023-05-26 07:21:25,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q5btkqcz', purging
2023-05-26 07:21:25,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:25,950 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:25,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:25,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:25,970 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:25,970 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:26,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:26,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:26,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:26,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:26,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:26,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:26,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:26,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:27,910 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:27,943 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:27,981 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:27,999 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:28,034 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:28,058 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:28,214 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:29,379 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cox4dmjf', purging
2023-05-26 07:21:29,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p0fv98ra', purging
2023-05-26 07:21:29,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yzq1kwvh', purging
2023-05-26 07:21:29,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8digq86', purging
2023-05-26 07:21:29,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eivtkjg8', purging
2023-05-26 07:21:29,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ocnqc59', purging
2023-05-26 07:21:29,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8nqm19uu', purging
2023-05-26 07:21:29,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:29,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:29,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:29,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:29,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:29,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:29,542 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:29,542 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:29,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:29,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:29,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:29,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:29,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:29,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:31,333 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:31,390 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:31,423 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:31,473 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:31,495 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:31,525 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:31,678 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:32,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d9qxzcpe', purging
2023-05-26 07:21:32,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lsv0kp7c', purging
2023-05-26 07:21:32,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m1gc59w9', purging
2023-05-26 07:21:32,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9qmpau4k', purging
2023-05-26 07:21:32,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_mqx8qkr', purging
2023-05-26 07:21:32,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6xnelcjy', purging
2023-05-26 07:21:32,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-geqqzij7', purging
2023-05-26 07:21:32,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:32,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:32,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:32,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:32,911 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:32,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:32,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:32,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:33,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:33,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:33,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:33,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:33,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:33,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:34,866 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:34,921 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:34,945 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:34,969 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:34,995 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:35,033 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:35,205 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:36,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w9dqivju', purging
2023-05-26 07:21:36,300 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ewqm_ps6', purging
2023-05-26 07:21:36,300 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o2m7ylh3', purging
2023-05-26 07:21:36,301 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gxkbf8lm', purging
2023-05-26 07:21:36,301 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j0h2f7kl', purging
2023-05-26 07:21:36,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1odsz1rq', purging
2023-05-26 07:21:36,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sf45xcmg', purging
2023-05-26 07:21:36,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:36,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:36,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:36,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:36,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:36,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:36,486 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:36,486 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:36,491 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:36,491 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:36,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:36,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:36,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:36,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:38,223 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:38,283 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:38,315 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:38,363 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:38,364 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:38,410 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:38,551 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:39,694 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lf1dmu90', purging
2023-05-26 07:21:39,694 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-56b5ifj6', purging
2023-05-26 07:21:39,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-suf4j7is', purging
2023-05-26 07:21:39,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hm_oz5zw', purging
2023-05-26 07:21:39,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bdime3lt', purging
2023-05-26 07:21:39,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gjqizluy', purging
2023-05-26 07:21:39,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xb6p5xae', purging
2023-05-26 07:21:39,697 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:39,697 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:39,778 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:39,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:39,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:39,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:39,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:39,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:39,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:39,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:39,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:39,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:40,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:40,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:41,639 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:41,699 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:41,731 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:41,754 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:41,785 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:41,805 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:42,034 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:43,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9vizn02n', purging
2023-05-26 07:21:43,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fim4_jqi', purging
2023-05-26 07:21:43,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ke_1az0', purging
2023-05-26 07:21:43,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s11pc8db', purging
2023-05-26 07:21:43,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-scy_uf2z', purging
2023-05-26 07:21:43,145 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gqb4zadm', purging
2023-05-26 07:21:43,145 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_udhv0su', purging
2023-05-26 07:21:43,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:43,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:43,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:43,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:43,250 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:43,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:43,264 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:43,264 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:43,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:43,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:43,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:43,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:43,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:43,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:45,074 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:45,109 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:45,160 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:45,188 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:45,224 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:45,245 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:45,390 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:46,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gdp3_0ob', purging
2023-05-26 07:21:46,596 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ggbikw84', purging
2023-05-26 07:21:46,596 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_gtkp_eu', purging
2023-05-26 07:21:46,596 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bd_tyo2m', purging
2023-05-26 07:21:46,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rkgsqv3s', purging
2023-05-26 07:21:46,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-keigetrl', purging
2023-05-26 07:21:46,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ewukia34', purging
2023-05-26 07:21:46,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:46,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:46,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:46,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:46,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:46,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:46,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:46,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:46,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:46,737 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:46,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:46,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:46,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:46,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:48,643 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:48,688 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:48,716 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:48,739 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:48,762 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:48,790 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:48,959 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:50,164 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ox8k6qv6', purging
2023-05-26 07:21:50,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-63dozau1', purging
2023-05-26 07:21:50,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_sb7azy', purging
2023-05-26 07:21:50,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zzqmumzp', purging
2023-05-26 07:21:50,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f0fdwgpi', purging
2023-05-26 07:21:50,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4wlnzm50', purging
2023-05-26 07:21:50,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o0dptp6a', purging
2023-05-26 07:21:50,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:50,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:50,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:50,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:50,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:50,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:50,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:50,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:50,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:50,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:50,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:50,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:50,517 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:50,517 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:52,157 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:52,216 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:52,261 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:52,271 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:52,312 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:52,326 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:52,495 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:53,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0cbiw479', purging
2023-05-26 07:21:53,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2nb73u9t', purging
2023-05-26 07:21:53,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cj_hky03', purging
2023-05-26 07:21:53,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-un483vmn', purging
2023-05-26 07:21:53,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wpv8585r', purging
2023-05-26 07:21:53,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tpui669x', purging
2023-05-26 07:21:53,652 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijgr8ixd', purging
2023-05-26 07:21:53,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:53,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:53,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:53,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:53,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:53,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:53,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:53,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:53,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:53,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:53,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:53,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:54,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:54,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:55,636 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:55,687 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:55,716 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:55,747 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:55,761 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:55,792 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:55,958 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:57,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lsxtwm4f', purging
2023-05-26 07:21:57,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-crb8r0y5', purging
2023-05-26 07:21:57,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4bkfwe3q', purging
2023-05-26 07:21:57,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-keuj9_y9', purging
2023-05-26 07:21:57,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1l21qu5i', purging
2023-05-26 07:21:57,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zit4oalq', purging
2023-05-26 07:21:57,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4f4jrez0', purging
2023-05-26 07:21:57,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:57,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:57,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:57,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:57,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:57,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:57,235 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:57,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:57,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:57,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:57,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:57,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:21:57,463 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:21:57,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:21:59,092 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:59,152 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:59,174 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:59,206 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:59,228 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:59,261 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:21:59,420 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:00,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tuc1aw0l', purging
2023-05-26 07:22:00,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-59c91sra', purging
2023-05-26 07:22:00,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ibz9y7b_', purging
2023-05-26 07:22:00,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ablnmh4n', purging
2023-05-26 07:22:00,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8f9jh5ku', purging
2023-05-26 07:22:00,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iu2xvo1k', purging
2023-05-26 07:22:00,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dgio9hm2', purging
2023-05-26 07:22:00,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:00,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:00,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:00,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:00,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:00,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:00,701 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:00,701 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:00,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:00,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:00,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:00,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:00,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:00,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:02,394 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:02,424 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:02,445 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:02,473 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:02,521 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:02,563 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:02,838 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:03,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q3c6fcqk', purging
2023-05-26 07:22:03,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eo4nidgr', purging
2023-05-26 07:22:03,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-imbqz2u7', purging
2023-05-26 07:22:03,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eplso19l', purging
2023-05-26 07:22:03,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-leq3q_ut', purging
2023-05-26 07:22:03,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1lkng4d5', purging
2023-05-26 07:22:03,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3zbz9_rh', purging
2023-05-26 07:22:03,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:03,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:03,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:03,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:03,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:03,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:03,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:03,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:04,045 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:04,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:04,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:04,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:04,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:04,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:05,814 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:05,872 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:05,894 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:05,921 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:05,944 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:05,983 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:06,274 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:07,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wma0qs6n', purging
2023-05-26 07:22:07,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q1db2m88', purging
2023-05-26 07:22:07,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a5qcylnn', purging
2023-05-26 07:22:07,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wf4n0alb', purging
2023-05-26 07:22:07,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3l6_13p_', purging
2023-05-26 07:22:07,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u5_1ezdx', purging
2023-05-26 07:22:07,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nub79k4f', purging
2023-05-26 07:22:07,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:07,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:07,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:07,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:07,445 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:07,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:07,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:07,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:07,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:07,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:07,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:07,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:07,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:07,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:09,153 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:09,223 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:09,245 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:09,279 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:09,296 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:09,336 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:09,610 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:10,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nbiohrf3', purging
2023-05-26 07:22:10,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jm34wra8', purging
2023-05-26 07:22:10,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e7i0axr9', purging
2023-05-26 07:22:10,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-idk16fcw', purging
2023-05-26 07:22:10,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e_9ntlyf', purging
2023-05-26 07:22:10,567 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7cv4f89', purging
2023-05-26 07:22:10,567 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whsmmnrf', purging
2023-05-26 07:22:10,568 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:10,568 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:10,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:10,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:10,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:10,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:10,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:10,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:10,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:10,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:10,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:10,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:11,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:11,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:12,474 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:12,529 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:12,556 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:12,581 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:12,618 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:12,636 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:12,925 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:13,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zoc28j67', purging
2023-05-26 07:22:13,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f9nj2uvz', purging
2023-05-26 07:22:13,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2naj2ssd', purging
2023-05-26 07:22:13,904 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-31qej3c7', purging
2023-05-26 07:22:13,904 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_kypnnsl', purging
2023-05-26 07:22:13,904 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m7swu8m1', purging
2023-05-26 07:22:13,905 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p6jsjtlb', purging
2023-05-26 07:22:13,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:13,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:14,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:14,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:14,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:14,099 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:14,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:14,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:14,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:14,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:14,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:14,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:14,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:14,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:15,824 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:15,864 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:15,904 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:15,938 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:15,960 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:15,995 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:16,300 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:17,257 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-64fhv3pc', purging
2023-05-26 07:22:17,257 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ixxiv_x3', purging
2023-05-26 07:22:17,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0fkhotng', purging
2023-05-26 07:22:17,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6uijii5k', purging
2023-05-26 07:22:17,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j9tfobs3', purging
2023-05-26 07:22:17,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v2_c3wqm', purging
2023-05-26 07:22:17,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9hsn_vb', purging
2023-05-26 07:22:17,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:17,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:17,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:17,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:17,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:17,438 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:17,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:17,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:17,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:17,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:17,543 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:17,543 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:17,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:17,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:19,232 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:19,277 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:19,297 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:19,332 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:19,381 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 07:22:19,682 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:20,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n2pr9qvb', purging
2023-05-26 07:22:20,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o1tqx50y', purging
2023-05-26 07:22:20,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0doo54vj', purging
2023-05-26 07:22:20,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-baz5fe4b', purging
2023-05-26 07:22:20,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9lw7v4sc', purging
2023-05-26 07:22:20,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a7f1clkv', purging
2023-05-26 07:22:20,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lvnnqacz', purging
2023-05-26 07:22:20,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:20,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:20,742 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:20,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:20,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:20,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:20,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:20,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:20,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:20,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:21,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:21,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:22,366 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:22,404 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:22,433 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:22,463 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:22,480 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:22,782 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:23,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x_nbwv_s', purging
2023-05-26 07:22:23,854 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-obmik_ov', purging
2023-05-26 07:22:23,854 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kuhgoigz', purging
2023-05-26 07:22:23,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vmsgufo0', purging
2023-05-26 07:22:23,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-irvt2s56', purging
2023-05-26 07:22:23,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bnq1a0p5', purging
2023-05-26 07:22:23,856 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:23,856 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:23,869 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:23,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:23,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:23,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:23,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:23,959 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:23,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:23,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:24,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:24,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:25,581 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:25,629 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:25,651 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:25,683 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:25,702 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:25,942 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:27,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bult6gob', purging
2023-05-26 07:22:27,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ki_6w6d', purging
2023-05-26 07:22:27,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cvivste8', purging
2023-05-26 07:22:27,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25allt6e', purging
2023-05-26 07:22:27,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rqg3h3tc', purging
2023-05-26 07:22:27,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ecldoo4t', purging
2023-05-26 07:22:27,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:27,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:27,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:27,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:27,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:27,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:27,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:27,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:27,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:27,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:27,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:27,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:28,686 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:28,745 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:28,774 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:28,826 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:28,852 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:29,096 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:30,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mbsqhft_', purging
2023-05-26 07:22:30,060 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dm_3k4ee', purging
2023-05-26 07:22:30,060 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p8y0jkvk', purging
2023-05-26 07:22:30,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eify5bu4', purging
2023-05-26 07:22:30,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bdt8pxok', purging
2023-05-26 07:22:30,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y9l07i8a', purging
2023-05-26 07:22:30,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:30,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:30,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:30,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:30,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:30,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:30,330 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:30,330 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:30,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:30,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:30,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:30,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:31,600 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:31,817 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:31,870 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:31,948 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:32,188 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:32,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vzzp4gj1', purging
2023-05-26 07:22:32,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0vxkhfqi', purging
2023-05-26 07:22:32,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-co8_aol3', purging
2023-05-26 07:22:32,970 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-re7j1a7w', purging
2023-05-26 07:22:32,970 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qk0mr_r4', purging
2023-05-26 07:22:32,970 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ejlez2p9', purging
2023-05-26 07:22:32,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:32,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:33,189 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:33,189 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:33,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:33,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:33,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:33,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:33,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:33,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:34,126 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:34,156 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:34,515 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:34,558 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:34,771 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:35,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y26nsv9m', purging
2023-05-26 07:22:35,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u0z1705z', purging
2023-05-26 07:22:35,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zn4mw17t', purging
2023-05-26 07:22:35,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qrhm1dvt', purging
2023-05-26 07:22:35,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8eipah25', purging
2023-05-26 07:22:35,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:35,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:35,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:35,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:35,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:35,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:35,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:35,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:36,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:36,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:36,915 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:36,946 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:37,150 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:37,203 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:37,353 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:38,393 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oflq_be8', purging
2023-05-26 07:22:38,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xuz0if0j', purging
2023-05-26 07:22:38,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sk2kfbh9', purging
2023-05-26 07:22:38,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6qix0kxg', purging
2023-05-26 07:22:38,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7rsngq87', purging
2023-05-26 07:22:38,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:38,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:38,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:38,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:38,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:38,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:38,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:38,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:38,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:38,826 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:39,872 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:39,874 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:39,907 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:39,924 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:40,220 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:41,257 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x08gmu3a', purging
2023-05-26 07:22:41,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-saaucwtc', purging
2023-05-26 07:22:41,258 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q4rx3ds_', purging
2023-05-26 07:22:41,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6zd34xhr', purging
2023-05-26 07:22:41,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5myn_2qo', purging
2023-05-26 07:22:41,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:41,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:41,350 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:41,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:41,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:41,362 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:41,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:41,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:41,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:41,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:42,714 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:42,782 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:42,808 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:42,834 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:43,063 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:44,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jx5flm4v', purging
2023-05-26 07:22:44,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0m5rhuuo', purging
2023-05-26 07:22:44,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e4o5lgtd', purging
2023-05-26 07:22:44,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-msk2tepe', purging
2023-05-26 07:22:44,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n98y5nv9', purging
2023-05-26 07:22:44,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:44,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:44,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:44,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:44,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:44,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:44,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:44,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:44,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:44,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:45,580 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:45,632 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:45,657 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:45,685 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:45,964 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:47,020 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w9_bu7xq', purging
2023-05-26 07:22:47,020 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4oo15vs4', purging
2023-05-26 07:22:47,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a1wnnctc', purging
2023-05-26 07:22:47,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-odfr6bu9', purging
2023-05-26 07:22:47,022 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ktq6x9t', purging
2023-05-26 07:22:47,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:47,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:47,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:47,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:47,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:47,106 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:47,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:47,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:47,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:47,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:48,514 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:48,537 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:48,566 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:48,579 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:48,821 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:49,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-020nh2om', purging
2023-05-26 07:22:49,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kvjxemt7', purging
2023-05-26 07:22:49,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fagohrob', purging
2023-05-26 07:22:49,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-417t7rjt', purging
2023-05-26 07:22:49,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o8mtli7v', purging
2023-05-26 07:22:49,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:49,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:49,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:49,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:50,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:50,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:50,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:50,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:50,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:50,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:51,465 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 07:22:51,551 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:51,552 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:51,747 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:52,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_zlk3gqc', purging
2023-05-26 07:22:52,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d3kspmda', purging
2023-05-26 07:22:52,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-re_i11v3', purging
2023-05-26 07:22:52,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1dvc01m_', purging
2023-05-26 07:22:52,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5i8xyn4u', purging
2023-05-26 07:22:52,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:52,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:53,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:53,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:53,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:53,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:53,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:53,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:54,222 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:54,274 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:54,285 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:54,451 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:55,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-go_gec7a', purging
2023-05-26 07:22:55,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3chr2tj7', purging
2023-05-26 07:22:55,654 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w8bts6qr', purging
2023-05-26 07:22:55,654 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-300enn5z', purging
2023-05-26 07:22:55,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:55,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:55,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:55,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:55,697 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:55,697 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:55,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:55,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:56,901 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:56,945 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:57,065 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:57,133 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:58,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9togmd7k', purging
2023-05-26 07:22:58,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_xtjkwnj', purging
2023-05-26 07:22:58,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5wptwy9b', purging
2023-05-26 07:22:58,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xmw203mu', purging
2023-05-26 07:22:58,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:58,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:58,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:58,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:58,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:58,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:22:58,549 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:22:58,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:22:59,620 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:59,645 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:59,671 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:22:59,832 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:01,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cs3jvl3e', purging
2023-05-26 07:23:01,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oeg5g829', purging
2023-05-26 07:23:01,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e5qxgeui', purging
2023-05-26 07:23:01,049 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_llke91x', purging
2023-05-26 07:23:01,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:01,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:01,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:01,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:01,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:01,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:01,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:01,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:02,299 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:02,366 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:02,368 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:02,548 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:03,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ly2_lwk9', purging
2023-05-26 07:23:03,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dpiri_72', purging
2023-05-26 07:23:03,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0gkaf0yp', purging
2023-05-26 07:23:03,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pzv67hiz', purging
2023-05-26 07:23:03,674 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:03,674 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:03,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:03,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:03,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:03,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:03,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:03,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:04,886 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:04,912 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:04,944 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:05,175 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:06,246 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wjtz3vxk', purging
2023-05-26 07:23:06,247 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tamv3cb_', purging
2023-05-26 07:23:06,247 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_1_hqfo', purging
2023-05-26 07:23:06,247 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w8b284g9', purging
2023-05-26 07:23:06,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:06,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:06,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:06,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:06,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:06,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:06,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:06,577 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:07,514 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:07,542 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:07,563 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:07,771 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:08,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8kporjb4', purging
2023-05-26 07:23:08,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:08,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:08,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lqglnue5', purging
2023-05-26 07:23:08,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h1_wmcoo', purging
2023-05-26 07:23:08,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8tllz7nj', purging
2023-05-26 07:23:08,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:08,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:08,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:08,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:09,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:09,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:10,251 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:10,288 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:10,309 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:10,471 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:11,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-indsugdh', purging
2023-05-26 07:23:11,623 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-urn2f79i', purging
2023-05-26 07:23:11,623 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c02xdjvu', purging
2023-05-26 07:23:11,623 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uqkg0inb', purging
2023-05-26 07:23:11,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:11,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:11,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:11,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:11,727 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:11,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:11,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:11,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:12,882 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:12,911 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:12,939 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:13,092 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:14,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5s8p5iyn', purging
2023-05-26 07:23:14,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fa867jdd', purging
2023-05-26 07:23:14,266 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bcjmdvfr', purging
2023-05-26 07:23:14,266 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-672hbp_l', purging
2023-05-26 07:23:14,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:14,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:14,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:14,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:14,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:14,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:14,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:14,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:15,527 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:15,543 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:15,580 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:15,755 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:16,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uhijyy3x', purging
2023-05-26 07:23:16,920 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-muly_ikb', purging
2023-05-26 07:23:16,920 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b6i8cn0m', purging
2023-05-26 07:23:16,921 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr3jsa_v', purging
2023-05-26 07:23:16,921 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:16,921 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:16,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:16,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:16,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:16,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:17,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:17,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:18,198 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:18,227 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:18,249 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:18,431 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:19,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f7jd1plg', purging
2023-05-26 07:23:19,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8sj28709', purging
2023-05-26 07:23:19,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ve78oxmq', purging
2023-05-26 07:23:19,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9241xlbp', purging
2023-05-26 07:23:19,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:19,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:19,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:19,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:19,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:19,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:19,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:19,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:20,872 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:20,899 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:20,929 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:21,092 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:22,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lcx1qrjt', purging
2023-05-26 07:23:22,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ljn1iz9_', purging
2023-05-26 07:23:22,234 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7tni14l8', purging
2023-05-26 07:23:22,234 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7_j7t96e', purging
2023-05-26 07:23:22,235 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:22,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:22,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:22,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:22,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:22,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:22,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:22,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:23,495 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:23,541 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:23,578 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:23,741 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:24,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ppmmfarg', purging
2023-05-26 07:23:24,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-889msloz', purging
2023-05-26 07:23:24,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uqzg_6k6', purging
2023-05-26 07:23:24,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qc8a29mw', purging
2023-05-26 07:23:24,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:24,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:24,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:24,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:25,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:25,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:25,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:25,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:26,192 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:26,207 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:26,246 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:26,401 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:27,607 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xptkr5pz', purging
2023-05-26 07:23:27,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-reu1w4qu', purging
2023-05-26 07:23:27,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kijb_af6', purging
2023-05-26 07:23:27,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ccymefr', purging
2023-05-26 07:23:27,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:27,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:27,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:27,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:27,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:27,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:27,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:27,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:28,879 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:28,911 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:28,938 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:29,096 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:30,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4euyxxy6', purging
2023-05-26 07:23:30,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zs8v5ptl', purging
2023-05-26 07:23:30,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vcp96ffl', purging
2023-05-26 07:23:30,333 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7jub8usz', purging
2023-05-26 07:23:30,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:30,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:30,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:30,368 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:30,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:30,374 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:30,460 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:30,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:31,604 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:31,651 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:31,687 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:31,846 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:32,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bk15y6m8', purging
2023-05-26 07:23:32,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fg16q64l', purging
2023-05-26 07:23:32,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_in4_gb', purging
2023-05-26 07:23:32,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6vvlhrcx', purging
2023-05-26 07:23:32,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:32,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:33,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:33,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:33,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:33,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:33,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:33,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:34,209 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:34,243 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:34,271 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:34,504 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:35,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b8ney7z8', purging
2023-05-26 07:23:35,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2igyegd', purging
2023-05-26 07:23:35,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5m30sjez', purging
2023-05-26 07:23:35,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yt_qxis_', purging
2023-05-26 07:23:35,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:35,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:35,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:35,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:35,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:35,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:35,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:35,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:36,869 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:36,891 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:36,920 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:37,173 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:38,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q84cmpqq', purging
2023-05-26 07:23:38,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0uep1hb', purging
2023-05-26 07:23:38,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ob0bg4z', purging
2023-05-26 07:23:38,315 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7vko07mw', purging
2023-05-26 07:23:38,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:38,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:38,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:38,320 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:38,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:38,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:38,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:38,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:39,575 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:39,617 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:39,642 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:39,814 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:41,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-krmiq18m', purging
2023-05-26 07:23:41,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sb_hksdf', purging
2023-05-26 07:23:41,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vnrm_rde', purging
2023-05-26 07:23:41,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-94eaihp4', purging
2023-05-26 07:23:41,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:41,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:41,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:41,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:41,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:41,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:41,188 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:41,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:42,309 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:42,367 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:42,532 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:43,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9lbax01', purging
2023-05-26 07:23:43,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1_69n4ry', purging
2023-05-26 07:23:43,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a7g03oth', purging
2023-05-26 07:23:43,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_jjeh8oq', purging
2023-05-26 07:23:43,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:43,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:43,777 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:43,777 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:43,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:43,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:44,770 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:44,793 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:44,962 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:46,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g__975il', purging
2023-05-26 07:23:46,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3sscoy74', purging
2023-05-26 07:23:46,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h_cb9cjj', purging
2023-05-26 07:23:46,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:46,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:46,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:46,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:46,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:46,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:47,219 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:47,242 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:47,427 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:48,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vjrp7t51', purging
2023-05-26 07:23:48,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wilbk30c', purging
2023-05-26 07:23:48,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w48_9he0', purging
2023-05-26 07:23:48,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:48,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:48,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:48,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:48,802 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:48,802 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:49,706 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:49,728 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:49,894 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:51,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2bj6engu', purging
2023-05-26 07:23:51,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-io6zfejf', purging
2023-05-26 07:23:51,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dm4uqvj9', purging
2023-05-26 07:23:51,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:51,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:51,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:51,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:51,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:51,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:52,134 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:52,164 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:52,335 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:53,532 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rn_iaqlf', purging
2023-05-26 07:23:53,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0zhfk2o5', purging
2023-05-26 07:23:53,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a3_q7dy1', purging
2023-05-26 07:23:53,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:53,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:53,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:53,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:53,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:53,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:54,575 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:54,596 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:54,758 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:56,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-929b55tq', purging
2023-05-26 07:23:56,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4a3addg4', purging
2023-05-26 07:23:56,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nxqsqh2s', purging
2023-05-26 07:23:56,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:56,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:56,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:56,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:56,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:56,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:57,067 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:57,104 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:57,271 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:58,474 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ujt92ww', purging
2023-05-26 07:23:58,475 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9eobz6je', purging
2023-05-26 07:23:58,475 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xtfwydhe', purging
2023-05-26 07:23:58,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:58,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:58,541 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:58,541 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:23:58,680 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:23:58,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:23:59,495 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:59,534 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:23:59,695 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:00,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-20cnujqe', purging
2023-05-26 07:24:00,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-paeatp8l', purging
2023-05-26 07:24:00,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9anv7xzn', purging
2023-05-26 07:24:00,869 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:00,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:00,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:00,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:01,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:01,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:01,920 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:01,949 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:02,131 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:03,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-taltpa7s', purging
2023-05-26 07:24:03,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m7ws79gk', purging
2023-05-26 07:24:03,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ln061qat', purging
2023-05-26 07:24:03,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:03,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:03,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:03,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:03,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:03,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:04,310 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:04,340 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:04,509 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:05,686 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f70x4qwx', purging
2023-05-26 07:24:05,687 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yfv8t3qi', purging
2023-05-26 07:24:05,687 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uj4bbd_2', purging
2023-05-26 07:24:05,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:05,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:05,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:05,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:05,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:05,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:06,761 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:06,784 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:06,957 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:08,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c28vb_w5', purging
2023-05-26 07:24:08,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6l7y0ofb', purging
2023-05-26 07:24:08,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z0xczd5a', purging
2023-05-26 07:24:08,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:08,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:08,169 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:08,169 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:08,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:08,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:09,155 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:09,177 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:09,360 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:10,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qdo_v48j', purging
2023-05-26 07:24:10,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-61lfeh9d', purging
2023-05-26 07:24:10,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wc2508pm', purging
2023-05-26 07:24:10,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:10,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:10,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:10,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:10,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:10,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:11,642 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:11,675 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:11,847 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:13,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y29o_5wl', purging
2023-05-26 07:24:13,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xeiuube_', purging
2023-05-26 07:24:13,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qxx5k2tj', purging
2023-05-26 07:24:13,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:13,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:13,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:13,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:13,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:13,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:14,066 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:14,089 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:14,262 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:15,443 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z4y4mu9z', purging
2023-05-26 07:24:15,443 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k62tffsz', purging
2023-05-26 07:24:15,443 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qswe6oan', purging
2023-05-26 07:24:15,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:15,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:15,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:15,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:15,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:15,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:16,480 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:16,510 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:16,681 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:17,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7n75g7k1', purging
2023-05-26 07:24:17,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_9katwd8', purging
2023-05-26 07:24:17,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e672fw7y', purging
2023-05-26 07:24:17,865 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:17,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:17,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:17,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:18,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:18,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:18,886 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:18,923 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:19,090 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:20,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ozew30zu', purging
2023-05-26 07:24:20,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fbara_30', purging
2023-05-26 07:24:20,260 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kb3f8gqs', purging
2023-05-26 07:24:20,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:20,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:20,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:20,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:20,473 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:20,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:21,320 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:21,345 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:21,522 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:22,704 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7rkul0s8', purging
2023-05-26 07:24:22,704 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_jl64xvn', purging
2023-05-26 07:24:22,704 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wbit4y8z', purging
2023-05-26 07:24:22,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:22,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:22,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:22,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:22,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:22,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:23,738 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:23,777 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:23,940 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:25,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-moiy7zrv', purging
2023-05-26 07:24:25,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m62ulx0i', purging
2023-05-26 07:24:25,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s9p5oubx', purging
2023-05-26 07:24:25,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:25,161 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:25,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:25,161 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:25,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:25,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:26,238 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:26,274 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:26,428 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:27,641 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qjtra0q5', purging
2023-05-26 07:24:27,641 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-etskjj7f', purging
2023-05-26 07:24:27,642 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pr8r5bzj', purging
2023-05-26 07:24:27,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:27,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:27,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:27,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:27,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:27,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:28,698 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:28,736 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:28,908 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:30,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-siu61e_5', purging
2023-05-26 07:24:30,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ksto21bq', purging
2023-05-26 07:24:30,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8hs_nb22', purging
2023-05-26 07:24:30,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:30,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:30,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:30,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:30,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:30,309 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:31,153 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:31,198 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:31,368 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:32,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vlpdmzf0', purging
2023-05-26 07:24:32,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h4h7p4i9', purging
2023-05-26 07:24:32,554 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c_vrhv64', purging
2023-05-26 07:24:32,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:32,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:32,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:32,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:32,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:32,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:33,588 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:33,619 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:33,789 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:34,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ujg54qum', purging
2023-05-26 07:24:34,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-syeozdwm', purging
2023-05-26 07:24:34,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g7tdy3hj', purging
2023-05-26 07:24:34,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:34,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:34,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:34,996 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:35,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:35,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:36,054 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:36,092 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:36,255 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:37,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-devxi_lv', purging
2023-05-26 07:24:37,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i7ckqa3x', purging
2023-05-26 07:24:37,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p0eaxno4', purging
2023-05-26 07:24:37,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:37,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:37,473 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:37,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:37,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:37,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:38,512 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:38,542 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:38,699 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:39,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_ihg961', purging
2023-05-26 07:24:39,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jsii53us', purging
2023-05-26 07:24:39,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m9mblblo', purging
2023-05-26 07:24:39,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:39,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:39,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:39,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:40,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:40,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:40,977 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:41,020 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:41,176 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:42,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s25bfkcd', purging
2023-05-26 07:24:42,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lw67zsu4', purging
2023-05-26 07:24:42,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_ncoyou', purging
2023-05-26 07:24:42,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:42,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:42,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:42,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:42,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:42,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:43,472 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:43,488 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:43,655 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:44,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wjmdnseb', purging
2023-05-26 07:24:44,856 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xto_oi8_', purging
2023-05-26 07:24:44,856 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gw5p0m2t', purging
2023-05-26 07:24:44,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:44,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:44,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:44,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:45,024 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:45,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:45,901 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:45,938 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:46,103 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:47,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2yci2nq', purging
2023-05-26 07:24:47,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tx74b5n1', purging
2023-05-26 07:24:47,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c0lo585r', purging
2023-05-26 07:24:47,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:47,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:47,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:47,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:47,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:47,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:48,338 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:48,377 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:48,529 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:49,735 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tfbfl9ye', purging
2023-05-26 07:24:49,736 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xyc3e_wc', purging
2023-05-26 07:24:49,736 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-258fsipg', purging
2023-05-26 07:24:49,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:49,737 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:49,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:49,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:49,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:49,908 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:50,797 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:50,818 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:50,988 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:52,177 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ngej1a0w', purging
2023-05-26 07:24:52,177 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2qgdnpcs', purging
2023-05-26 07:24:52,177 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-97zzao05', purging
2023-05-26 07:24:52,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:52,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:52,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:52,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:52,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:52,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:53,207 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:53,241 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:53,411 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:54,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ksfvv_0', purging
2023-05-26 07:24:54,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ssa9fl61', purging
2023-05-26 07:24:54,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u2tz9hjb', purging
2023-05-26 07:24:54,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:54,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:54,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:54,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:54,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:54,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:55,618 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:55,665 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:55,842 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:56,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i7i1wxq5', purging
2023-05-26 07:24:56,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6pz3uhpw', purging
2023-05-26 07:24:56,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6ab8swp', purging
2023-05-26 07:24:56,960 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:56,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:57,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:57,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:57,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:57,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:24:58,002 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:58,030 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:58,197 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:24:59,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-becieqle', purging
2023-05-26 07:24:59,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psn2kog1', purging
2023-05-26 07:24:59,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5xeqp11n', purging
2023-05-26 07:24:59,437 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:59,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:59,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:59,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:24:59,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:24:59,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:00,515 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:00,533 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:00,708 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:01,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7l41oiv_', purging
2023-05-26 07:25:01,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8sysgm94', purging
2023-05-26 07:25:01,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yeezebve', purging
2023-05-26 07:25:01,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:01,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:01,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:01,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:02,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:02,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:02,951 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:02,977 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:03,160 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:04,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8j4uz9sc', purging
2023-05-26 07:25:04,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wi3ydbmb', purging
2023-05-26 07:25:04,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qylgckxr', purging
2023-05-26 07:25:04,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:04,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:04,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:04,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:04,529 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:04,529 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:05,373 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:05,404 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:05,576 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:06,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-27wgv06q', purging
2023-05-26 07:25:06,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a6pc5qta', purging
2023-05-26 07:25:06,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vlzldh5g', purging
2023-05-26 07:25:06,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:06,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:06,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:06,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:06,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:06,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:07,718 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:07,750 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:07,922 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:09,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x52ba8q0', purging
2023-05-26 07:25:09,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-44ev76pw', purging
2023-05-26 07:25:09,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n0bkrgwk', purging
2023-05-26 07:25:09,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:09,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:09,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:09,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:09,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:09,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:10,159 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:10,211 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:10,373 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:11,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v4_es724', purging
2023-05-26 07:25:11,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q11q4aar', purging
2023-05-26 07:25:11,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4dygkwky', purging
2023-05-26 07:25:11,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:11,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:11,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:11,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:11,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:11,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:12,652 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:12,678 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:12,857 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:14,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3s3v3jx_', purging
2023-05-26 07:25:14,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rv6waok5', purging
2023-05-26 07:25:14,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cxe31fiq', purging
2023-05-26 07:25:14,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:14,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:14,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:14,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:14,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:14,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:15,100 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:15,124 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:15,289 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:16,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:16,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f42h00jk', purging
2023-05-26 07:25:16,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:16,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3lsesstm', purging
2023-05-26 07:25:16,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__8bs1wk', purging
2023-05-26 07:25:16,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:16,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:16,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:16,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:17,589 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:17,611 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:17,784 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:18,999 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8o3tw9vt', purging
2023-05-26 07:25:19,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xaajcq6_', purging
2023-05-26 07:25:19,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-empfwlid', purging
2023-05-26 07:25:19,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:19,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:19,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:19,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:19,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:19,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:20,082 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:20,095 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:20,283 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:21,450 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ogsfngto', purging
2023-05-26 07:25:21,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tb22obei', purging
2023-05-26 07:25:21,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u3e9a5v_', purging
2023-05-26 07:25:21,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:21,451 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:21,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:21,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:21,696 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:21,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:22,471 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:22,508 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:22,680 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:23,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tjsfe9rd', purging
2023-05-26 07:25:23,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qk0ooy67', purging
2023-05-26 07:25:23,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-17kfa05s', purging
2023-05-26 07:25:23,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:23,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:23,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:23,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:24,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:24,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:24,858 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:24,896 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:25,068 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:26,266 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ookte4s6', purging
2023-05-26 07:25:26,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-klri2_se', purging
2023-05-26 07:25:26,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b1w3lsj7', purging
2023-05-26 07:25:26,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:26,268 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:26,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:26,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:26,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:26,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:27,314 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:27,335 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:27,501 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:28,680 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tae48209', purging
2023-05-26 07:25:28,680 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8vrhsf_e', purging
2023-05-26 07:25:28,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-96vlqrts', purging
2023-05-26 07:25:28,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:28,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:28,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:28,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:28,911 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:28,911 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:29,727 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:29,754 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:29,920 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:31,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:31,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z3b1j7nf', purging
2023-05-26 07:25:31,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:31,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fs62p6tz', purging
2023-05-26 07:25:31,134 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7i9cigq', purging
2023-05-26 07:25:31,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:31,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:31,304 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:31,304 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:32,189 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:32,221 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:32,382 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:33,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wpv1pl75', purging
2023-05-26 07:25:33,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i1jf7y4g', purging
2023-05-26 07:25:33,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6rmx_of3', purging
2023-05-26 07:25:33,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:33,588 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:33,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:33,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:33,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:33,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:34,633 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:34,684 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:34,848 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:35,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mc1ryy_9', purging
2023-05-26 07:25:35,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-onyi7tkp', purging
2023-05-26 07:25:35,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-apt9vpl8', purging
2023-05-26 07:25:35,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:35,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:36,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:36,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:36,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:36,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:37,023 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:37,044 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:37,227 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:38,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iapho11y', purging
2023-05-26 07:25:38,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_1y8ruhm', purging
2023-05-26 07:25:38,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9w0m3plv', purging
2023-05-26 07:25:38,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:38,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:38,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:38,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:38,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:38,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:39,436 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:39,458 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:39,642 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:40,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lkn2md7y', purging
2023-05-26 07:25:40,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-erk4cdb1', purging
2023-05-26 07:25:40,848 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2kuw9hsu', purging
2023-05-26 07:25:40,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:40,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:40,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:40,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:40,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:40,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:41,928 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:41,955 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:42,115 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:43,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8tsveq72', purging
2023-05-26 07:25:43,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0fcz71jb', purging
2023-05-26 07:25:43,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6leuivn9', purging
2023-05-26 07:25:43,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:43,338 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:43,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:43,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:43,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:43,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:44,367 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:44,402 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:44,568 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:45,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9l15cs_k', purging
2023-05-26 07:25:45,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-phnmybcs', purging
2023-05-26 07:25:45,740 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hedfqkzj', purging
2023-05-26 07:25:45,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:45,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:45,774 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:45,774 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:45,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:45,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:46,786 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:46,816 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:46,999 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:48,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:48,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-arvtlexh', purging
2023-05-26 07:25:48,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:48,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-trh5kx_x', purging
2023-05-26 07:25:48,188 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cnra7h7z', purging
2023-05-26 07:25:48,188 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:48,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:48,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:48,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:49,246 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:49,269 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:49,444 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:50,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jktq4auu', purging
2023-05-26 07:25:50,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0uziryq', purging
2023-05-26 07:25:50,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e3m49f66', purging
2023-05-26 07:25:50,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:50,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:50,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:50,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:50,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:50,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:51,677 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:51,706 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:51,868 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:53,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v6958gtp', purging
2023-05-26 07:25:53,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qw5kakkn', purging
2023-05-26 07:25:53,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s94wrtrv', purging
2023-05-26 07:25:53,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:53,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:53,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:53,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:53,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:53,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:54,134 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:54,169 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:54,321 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:55,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bncoo6mc', purging
2023-05-26 07:25:55,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-71cnu3wc', purging
2023-05-26 07:25:55,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vjgclp8f', purging
2023-05-26 07:25:55,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:55,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:55,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:55,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:55,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:55,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:56,565 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:56,580 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:56,756 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:57,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0jn20c58', purging
2023-05-26 07:25:57,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ouhjsnkc', purging
2023-05-26 07:25:57,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hdvu2uj2', purging
2023-05-26 07:25:57,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:57,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:57,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:57,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:25:58,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:25:58,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:25:59,062 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:59,083 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:25:59,262 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:00,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ezt35mm', purging
2023-05-26 07:26:00,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8xor21i6', purging
2023-05-26 07:26:00,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9z76qu17', purging
2023-05-26 07:26:00,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:00,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:00,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:00,451 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:00,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:00,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:01,452 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:01,485 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:01,658 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:02,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8azso3rq', purging
2023-05-26 07:26:02,783 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_gt8tf7x', purging
2023-05-26 07:26:02,783 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03a_hg3t', purging
2023-05-26 07:26:02,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:02,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:02,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:02,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:03,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:03,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:03,851 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:03,889 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:04,057 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:05,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pogiihjg', purging
2023-05-26 07:26:05,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_83k9lwv', purging
2023-05-26 07:26:05,264 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v20a6ef2', purging
2023-05-26 07:26:05,265 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:05,265 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:05,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:05,317 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:05,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:05,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:06,302 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:06,339 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:06,520 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:07,687 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-589uxbv5', purging
2023-05-26 07:26:07,687 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2jgt040r', purging
2023-05-26 07:26:07,687 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s5w_fsxp', purging
2023-05-26 07:26:07,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:07,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:07,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:07,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:07,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:07,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:08,741 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:08,763 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:08,932 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:10,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fuo_6tqk', purging
2023-05-26 07:26:10,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_2kyubob', purging
2023-05-26 07:26:10,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-47_mlapo', purging
2023-05-26 07:26:10,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:10,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:10,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:10,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:10,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:10,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:11,147 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:11,168 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:11,363 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:12,521 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ohegybh', purging
2023-05-26 07:26:12,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tshq5y10', purging
2023-05-26 07:26:12,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z3emmkql', purging
2023-05-26 07:26:12,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:12,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:12,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:12,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:12,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:12,751 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:13,556 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:13,585 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:13,751 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:14,936 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vjrdpmxu', purging
2023-05-26 07:26:14,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9n7snlxa', purging
2023-05-26 07:26:14,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3c9agbch', purging
2023-05-26 07:26:14,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:14,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:14,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:14,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:15,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:15,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:15,966 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:16,007 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:16,175 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:17,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uj9ja7s2', purging
2023-05-26 07:26:17,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lgitw8lm', purging
2023-05-26 07:26:17,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2g70utdp', purging
2023-05-26 07:26:17,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:17,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:17,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:17,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:17,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:17,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:18,388 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:18,424 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:18,584 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:19,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fm6ikaoo', purging
2023-05-26 07:26:19,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b0kvyul4', purging
2023-05-26 07:26:19,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dcpq2j51', purging
2023-05-26 07:26:19,763 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:19,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:19,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:19,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:19,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:19,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:20,806 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:20,846 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:21,022 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:22,203 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n5qju5p_', purging
2023-05-26 07:26:22,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:22,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:22,203 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mmgvye9z', purging
2023-05-26 07:26:22,204 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c13jv8to', purging
2023-05-26 07:26:22,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:22,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:22,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:22,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:23,239 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:23,272 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:23,426 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:24,641 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58o810nl', purging
2023-05-26 07:26:24,641 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-thmx954a', purging
2023-05-26 07:26:24,642 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dkknhmql', purging
2023-05-26 07:26:24,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:24,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:24,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:24,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:24,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:24,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:25,695 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:25,734 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:25,881 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:27,085 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o4o5sthu', purging
2023-05-26 07:26:27,085 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-64ccok_5', purging
2023-05-26 07:26:27,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-izkl63o5', purging
2023-05-26 07:26:27,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:27,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:27,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:27,151 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:27,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:27,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:28,140 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:28,182 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:28,356 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:29,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-auc8qvf6', purging
2023-05-26 07:26:29,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fin2x2on', purging
2023-05-26 07:26:29,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zqmbnwxs', purging
2023-05-26 07:26:29,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:29,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:29,615 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:29,615 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:29,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:29,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:30,596 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 07:26:30,805 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:31,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f6x0yk7b', purging
2023-05-26 07:26:31,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pnrir0bf', purging
2023-05-26 07:26:31,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-onxune8_', purging
2023-05-26 07:26:31,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:31,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:32,151 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:32,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:32,820 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:32,993 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:34,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hmpctxfd', purging
2023-05-26 07:26:34,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f3pbfego', purging
2023-05-26 07:26:34,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:34,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:34,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:34,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:35,034 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:35,200 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:36,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ykzoyaht', purging
2023-05-26 07:26:36,505 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-halj5z9w', purging
2023-05-26 07:26:36,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:36,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:36,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:36,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:37,358 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:37,526 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:38,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-53ls2hn9', purging
2023-05-26 07:26:38,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qa8i1uoo', purging
2023-05-26 07:26:38,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:38,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:38,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:38,881 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:39,553 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:39,710 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:40,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-972w6n41', purging
2023-05-26 07:26:40,909 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nb1op2c2', purging
2023-05-26 07:26:40,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:40,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:41,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:41,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:41,743 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:41,914 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:43,109 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_l7_l8p2', purging
2023-05-26 07:26:43,109 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pxcq1s1l', purging
2023-05-26 07:26:43,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:43,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:43,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:43,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:43,950 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:44,107 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:45,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gtne1oyz', purging
2023-05-26 07:26:45,307 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aylvvr3p', purging
2023-05-26 07:26:45,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:45,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:45,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:45,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:46,139 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:46,322 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:47,490 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-99w_lbyl', purging
2023-05-26 07:26:47,491 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dzit174q', purging
2023-05-26 07:26:47,491 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:47,491 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:47,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:47,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:48,333 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:48,497 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:49,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1h3620wp', purging
2023-05-26 07:26:49,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g3igy5tj', purging
2023-05-26 07:26:49,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:49,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:49,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:49,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:50,541 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:50,723 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:51,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xl1sc6sf', purging
2023-05-26 07:26:51,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wwoby0do', purging
2023-05-26 07:26:51,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:51,933 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:52,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:52,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:52,775 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:52,937 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:54,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u8ruqvio', purging
2023-05-26 07:26:54,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r5ota0o7', purging
2023-05-26 07:26:54,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:54,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:54,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:54,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:54,948 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:55,121 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:56,327 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jbdnvuvn', purging
2023-05-26 07:26:56,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ektw8tj', purging
2023-05-26 07:26:56,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:56,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:56,498 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:56,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:57,175 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:57,348 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:58,528 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s5retwiz', purging
2023-05-26 07:26:58,528 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9j5lqvby', purging
2023-05-26 07:26:58,529 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:58,529 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:26:58,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:26:58,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:26:59,361 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:26:59,542 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:00,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8z59oz78', purging
2023-05-26 07:27:00,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_3yke8n', purging
2023-05-26 07:27:00,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:00,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:00,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:00,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:01,552 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:01,723 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:02,938 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r7vg4e_o', purging
2023-05-26 07:27:02,938 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-915qj801', purging
2023-05-26 07:27:02,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:02,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:03,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:03,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:03,775 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:03,937 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:05,108 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5yhd7f5p', purging
2023-05-26 07:27:05,109 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0sm707oc', purging
2023-05-26 07:27:05,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:05,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:05,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:05,243 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:05,945 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:06,106 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:07,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whct7l1g', purging
2023-05-26 07:27:07,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-144vv_d_', purging
2023-05-26 07:27:07,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:07,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:07,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:07,509 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:08,186 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:08,372 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:09,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xwvgat23', purging
2023-05-26 07:27:09,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-422o3b7j', purging
2023-05-26 07:27:09,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:09,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:09,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:09,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:10,411 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:10,584 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:11,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oveh8s16', purging
2023-05-26 07:27:11,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_3hg9o_s', purging
2023-05-26 07:27:11,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:11,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:11,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:11,933 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:12,600 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:12,780 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:13,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4y9gfl31', purging
2023-05-26 07:27:13,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mx9d6tcc', purging
2023-05-26 07:27:13,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:13,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:14,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:14,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:14,797 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:14,974 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:16,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r0w8plkc', purging
2023-05-26 07:27:16,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2nn0paty', purging
2023-05-26 07:27:16,169 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:16,169 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:16,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:16,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:17,004 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:17,178 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:18,371 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h9tzwy2r', purging
2023-05-26 07:27:18,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qu83wwdv', purging
2023-05-26 07:27:18,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:18,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:18,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:18,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:19,213 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:19,378 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:20,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t7lu3do9', purging
2023-05-26 07:27:20,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-puwhhw3y', purging
2023-05-26 07:27:20,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:20,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:20,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:20,745 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:21,420 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:21,592 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:22,795 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jkmjtww7', purging
2023-05-26 07:27:22,795 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kxa8ewl4', purging
2023-05-26 07:27:22,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:22,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:22,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:22,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:23,641 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:23,814 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:24,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pz4phnm0', purging
2023-05-26 07:27:24,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rkyipe66', purging
2023-05-26 07:27:24,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:24,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:25,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:25,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:25,825 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:25,997 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:27,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v6wgzt8d', purging
2023-05-26 07:27:27,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-018b8x5r', purging
2023-05-26 07:27:27,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:27,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:27,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:27,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:28,010 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:28,170 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:29,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ulfxjwzy', purging
2023-05-26 07:27:29,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eqs653i8', purging
2023-05-26 07:27:29,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:29,391 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:29,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:29,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:30,236 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:30,399 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:31,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vadkvs5k', purging
2023-05-26 07:27:31,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6r8htx57', purging
2023-05-26 07:27:31,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:31,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:31,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:31,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:32,428 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:32,601 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:33,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uzqn9mw0', purging
2023-05-26 07:27:33,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pjqm1_wg', purging
2023-05-26 07:27:33,794 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:33,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:33,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:33,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:34,637 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:34,797 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:36,015 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7pyr660l', purging
2023-05-26 07:27:36,015 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x93_almr', purging
2023-05-26 07:27:36,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:36,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:36,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:36,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:36,868 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:37,026 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:38,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s01465bx', purging
2023-05-26 07:27:38,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yt9lwct0', purging
2023-05-26 07:27:38,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:38,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:38,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:38,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:39,072 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:39,242 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:40,513 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2lt9zr4', purging
2023-05-26 07:27:40,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-veb59zk9', purging
2023-05-26 07:27:40,514 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:40,514 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:40,662 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:40,662 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:41,384 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:41,555 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:42,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5q8wvepz', purging
2023-05-26 07:27:42,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3nqild25', purging
2023-05-26 07:27:42,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:42,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:42,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:42,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:43,583 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:43,740 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:44,967 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l91to2nc', purging
2023-05-26 07:27:44,967 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rmh92exz', purging
2023-05-26 07:27:44,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:44,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:45,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:45,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:45,803 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:45,971 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:47,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-404j389b', purging
2023-05-26 07:27:47,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zj62jj1b', purging
2023-05-26 07:27:47,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:47,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:47,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:47,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:48,018 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:48,193 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:49,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rbposiuh', purging
2023-05-26 07:27:49,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mcg0d1gn', purging
2023-05-26 07:27:49,390 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:49,390 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:49,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:49,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:50,216 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:50,384 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:51,591 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xp2x0ew3', purging
2023-05-26 07:27:51,592 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vun6p9t6', purging
2023-05-26 07:27:51,592 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:51,592 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:51,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:51,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:52,411 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:52,581 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:53,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fqom5prj', purging
2023-05-26 07:27:53,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-20pf7k02', purging
2023-05-26 07:27:53,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:53,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:53,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:53,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:54,600 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:54,758 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:55,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ett20884', purging
2023-05-26 07:27:55,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-73hhzp48', purging
2023-05-26 07:27:55,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:55,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:56,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:56,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:56,795 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:56,965 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:58,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eanhzsy3', purging
2023-05-26 07:27:58,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qklrk9vf', purging
2023-05-26 07:27:58,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:58,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:27:58,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:27:58,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:27:58,998 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:27:59,171 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:00,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2pxkh1da', purging
2023-05-26 07:28:00,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2xg1obco', purging
2023-05-26 07:28:00,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:00,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:00,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:00,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:01,171 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:01,346 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:02,507 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g5o_db4h', purging
2023-05-26 07:28:02,507 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6t284slx', purging
2023-05-26 07:28:02,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:02,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:02,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:02,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:03,328 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:03,499 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:04,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rbeo1eoq', purging
2023-05-26 07:28:04,682 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ldpvm_8y', purging
2023-05-26 07:28:04,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:04,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:04,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:04,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:05,528 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:05,706 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:06,909 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r8ne4b81', purging
2023-05-26 07:28:06,909 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psp7ixdk', purging
2023-05-26 07:28:06,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:06,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:07,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:07,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:07,752 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:07,916 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:09,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x3bq9fjt', purging
2023-05-26 07:28:09,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-huhrpixk', purging
2023-05-26 07:28:09,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:09,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:09,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:09,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:09,933 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:10,092 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:11,276 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ulr_sj3_', purging
2023-05-26 07:28:11,277 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p81scn1r', purging
2023-05-26 07:28:11,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:11,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:11,460 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:11,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:12,116 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:12,304 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:13,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0038ioqs', purging
2023-05-26 07:28:13,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tep_xog9', purging
2023-05-26 07:28:13,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:13,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:13,695 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:13,695 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:14,342 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:14,508 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:15,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tdpyd3rc', purging
2023-05-26 07:28:15,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ymi_ldu7', purging
2023-05-26 07:28:15,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:15,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:15,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:15,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:16,547 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:16,714 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:17,910 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1_etlge8', purging
2023-05-26 07:28:17,910 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hx77z2nq', purging
2023-05-26 07:28:17,911 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:17,911 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:18,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:18,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:18,758 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:18,925 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:20,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mikzpbvc', purging
2023-05-26 07:28:20,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5exp1t9q', purging
2023-05-26 07:28:20,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:20,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:20,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:20,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:21,013 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:21,188 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:22,387 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iecer2kw', purging
2023-05-26 07:28:22,387 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-in8j585h', purging
2023-05-26 07:28:22,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:22,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-26 07:28:22,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:22,528 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-26 07:28:23,399 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:24,720 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ftvezjh4', purging
2023-05-26 07:28:24,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kqsum37o', purging
2023-05-26 07:28:24,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:24,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:25,491 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:26,822 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9vnggqr', purging
2023-05-26 07:28:26,823 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:26,823 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:27,594 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:28,923 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u0fhu3h0', purging
2023-05-26 07:28:28,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:28,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:29,693 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:31,018 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4uwdhhv6', purging
2023-05-26 07:28:31,018 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:31,018 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:31,786 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:33,107 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7q55ozjr', purging
2023-05-26 07:28:33,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:33,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:33,883 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:35,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ev7kxkj_', purging
2023-05-26 07:28:35,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:35,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:35,980 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:37,300 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mkl6nzxs', purging
2023-05-26 07:28:37,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:37,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:38,083 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:39,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b2jqmh4p', purging
2023-05-26 07:28:39,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:39,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:40,177 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:41,473 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-txuwvcg8', purging
2023-05-26 07:28:41,473 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:41,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:42,235 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:43,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ciewkm4d', purging
2023-05-26 07:28:43,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:43,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:44,356 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:45,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n35omncz', purging
2023-05-26 07:28:45,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:45,712 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:46,486 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:47,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u1f0scf0', purging
2023-05-26 07:28:47,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:47,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:48,598 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:49,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-byvz5ob4', purging
2023-05-26 07:28:49,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:49,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:50,714 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:52,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bew92cof', purging
2023-05-26 07:28:52,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:52,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:52,858 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:54,157 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_3j29siv', purging
2023-05-26 07:28:54,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:54,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:54,927 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:56,242 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wif_mhcs', purging
2023-05-26 07:28:56,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:56,243 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:57,010 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:28:58,311 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mu4cpl98', purging
2023-05-26 07:28:58,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:28:58,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:28:59,074 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:00,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rmgpmt07', purging
2023-05-26 07:29:00,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:00,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:01,177 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:02,493 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7nrftat0', purging
2023-05-26 07:29:02,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:02,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:03,267 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:04,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ntxwv6w', purging
2023-05-26 07:29:04,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:04,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:05,357 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:06,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rkvpsqkd', purging
2023-05-26 07:29:06,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:06,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:07,458 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:08,783 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e1gi_tdi', purging
2023-05-26 07:29:08,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:08,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:09,563 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:10,858 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7eh88dvp', purging
2023-05-26 07:29:10,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:10,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:11,622 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:12,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bodcvidl', purging
2023-05-26 07:29:12,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:12,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:13,688 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:14,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-43jlvrjg', purging
2023-05-26 07:29:14,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:14,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:15,796 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:17,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7ze6g4v', purging
2023-05-26 07:29:17,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:17,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:17,958 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:19,291 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ru887021', purging
2023-05-26 07:29:19,292 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:19,292 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:20,087 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:21,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5jdbxhc9', purging
2023-05-26 07:29:21,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:21,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:22,179 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:23,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1myup45n', purging
2023-05-26 07:29:23,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:23,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:24,269 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:25,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qwgnetfa', purging
2023-05-26 07:29:25,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:25,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:26,349 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:27,679 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7cqof9ye', purging
2023-05-26 07:29:27,680 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:27,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:28,479 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:29,774 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dv2_qwoi', purging
2023-05-26 07:29:29,774 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:29,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:30,535 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:31,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gjn8lo8e', purging
2023-05-26 07:29:31,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:31,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:32,602 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:33,916 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cwkzcgmi', purging
2023-05-26 07:29:33,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:33,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:34,678 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:35,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qew7jp9s', purging
2023-05-26 07:29:35,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:35,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:36,748 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:38,055 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jov77x5t', purging
2023-05-26 07:29:38,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:38,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:38,818 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:40,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1p2hch5d', purging
2023-05-26 07:29:40,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:40,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:40,882 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:42,182 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-18a9wwiz', purging
2023-05-26 07:29:42,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:42,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:42,946 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:44,245 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lz5963he', purging
2023-05-26 07:29:44,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:44,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:45,021 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:46,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3zb5cxd_', purging
2023-05-26 07:29:46,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:46,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:47,096 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:48,442 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vz4mz32p', purging
2023-05-26 07:29:48,443 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:48,443 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:49,227 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:50,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bt67u3xf', purging
2023-05-26 07:29:50,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:50,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:51,362 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:52,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g4d44e42', purging
2023-05-26 07:29:52,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:52,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:53,433 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:54,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gmul13r1', purging
2023-05-26 07:29:54,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:54,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:55,493 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:56,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vo7i8y7_', purging
2023-05-26 07:29:56,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:56,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:57,559 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:29:58,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c_dbwd23', purging
2023-05-26 07:29:58,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:29:58,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:29:59,637 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:00,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2by9og_n', purging
2023-05-26 07:30:00,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:00,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:01,719 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:03,049 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-paognbvf', purging
2023-05-26 07:30:03,050 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:03,050 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:03,819 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:05,156 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6gokhp6w', purging
2023-05-26 07:30:05,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:05,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:05,935 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:07,246 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mwmk4ue5', purging
2023-05-26 07:30:07,247 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:07,247 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:08,014 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:09,310 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-51ieklc8', purging
2023-05-26 07:30:09,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:09,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:10,078 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:11,375 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_rp78oed', purging
2023-05-26 07:30:11,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:11,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:12,137 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:13,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2yr09fqm', purging
2023-05-26 07:30:13,437 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:13,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:14,196 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:15,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0nec8ov6', purging
2023-05-26 07:30:15,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:15,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:16,265 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:17,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-665c5y6x', purging
2023-05-26 07:30:17,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:17,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:18,360 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:19,710 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2hjfrtal', purging
2023-05-26 07:30:19,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:19,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:20,506 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:21,872 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n9vpoz54', purging
2023-05-26 07:30:21,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:21,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:22,645 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:23,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vgrjkho5', purging
2023-05-26 07:30:23,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:23,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:24,701 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:26,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pq7uz7b1', purging
2023-05-26 07:30:26,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:26,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:26,787 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:28,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qmh8mndd', purging
2023-05-26 07:30:28,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:28,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:28,870 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:30,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yrs37d7d', purging
2023-05-26 07:30:30,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:30,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:30,942 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:32,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-afh_i28p', purging
2023-05-26 07:30:32,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:32,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:33,015 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:34,315 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pr2ecnx7', purging
2023-05-26 07:30:34,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:34,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:35,100 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:36,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zzyg3h6h', purging
2023-05-26 07:30:36,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:36,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:37,178 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:38,513 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kjdjj8ed', purging
2023-05-26 07:30:38,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:38,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:39,276 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:40,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-extriupv', purging
2023-05-26 07:30:40,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:40,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:41,340 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:42,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hgj7qvqs', purging
2023-05-26 07:30:42,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:42,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:43,415 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:44,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rlhvv0z7', purging
2023-05-26 07:30:44,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:44,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:45,483 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:46,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zade8iij', purging
2023-05-26 07:30:46,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:46,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:47,538 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:48,845 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yr4_fqpe', purging
2023-05-26 07:30:48,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:48,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:49,610 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:50,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gaip4glt', purging
2023-05-26 07:30:50,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:50,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:51,761 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:53,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sy1pnt1d', purging
2023-05-26 07:30:53,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:53,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:53,879 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:55,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-97hxz0a7', purging
2023-05-26 07:30:55,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:55,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:55,938 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:57,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-daitgm1y', purging
2023-05-26 07:30:57,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:57,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:30:58,006 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:30:59,309 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8i0hsrfc', purging
2023-05-26 07:30:59,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:30:59,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:00,071 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:01,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ye_9mlk1', purging
2023-05-26 07:31:01,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:01,374 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:02,145 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:03,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2uukxbp', purging
2023-05-26 07:31:03,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:03,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:04,209 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:05,509 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t0t_8pfd', purging
2023-05-26 07:31:05,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:05,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:06,280 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:07,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mgu6611q', purging
2023-05-26 07:31:07,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:07,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:08,365 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:09,679 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nbse0kfo', purging
2023-05-26 07:31:09,680 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:09,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:10,494 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:11,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jxp2214h', purging
2023-05-26 07:31:11,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:11,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:12,568 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:13,883 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8a2y1kdg', purging
2023-05-26 07:31:13,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:13,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:14,645 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:15,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2t9uno1b', purging
2023-05-26 07:31:15,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:15,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:16,728 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:18,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3qa6t6yu', purging
2023-05-26 07:31:18,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:18,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:18,819 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:20,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9nox222', purging
2023-05-26 07:31:20,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:20,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:20,900 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:22,247 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ru3l9_f', purging
2023-05-26 07:31:22,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:22,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:23,026 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:24,388 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k8a0pwf3', purging
2023-05-26 07:31:24,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:24,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:25,199 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:26,505 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yhlq46jo', purging
2023-05-26 07:31:26,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:26,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:27,272 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:28,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3bq9w2js', purging
2023-05-26 07:31:28,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:28,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:29,363 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:30,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lky5rg_5', purging
2023-05-26 07:31:30,670 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:30,670 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:31,432 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:32,734 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dwj1o8s6', purging
2023-05-26 07:31:32,735 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:32,735 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:33,533 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:34,837 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1zf1xbet', purging
2023-05-26 07:31:34,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:34,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:35,602 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:36,909 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ng3i8q3', purging
2023-05-26 07:31:36,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:36,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:37,680 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:38,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o04vflqh', purging
2023-05-26 07:31:38,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:38,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:39,749 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:41,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-he1p4uxa', purging
2023-05-26 07:31:41,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:41,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:41,806 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:43,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ei07r91x', purging
2023-05-26 07:31:43,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:43,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:43,930 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:45,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ukt2uv39', purging
2023-05-26 07:31:45,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:45,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:45,997 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:47,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_kr1dkh', purging
2023-05-26 07:31:47,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:47,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:48,083 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:49,393 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h1xo47qe', purging
2023-05-26 07:31:49,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:49,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:50,157 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:51,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y46rd3eu', purging
2023-05-26 07:31:51,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:51,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:52,286 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:53,599 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-imfo2niq', purging
2023-05-26 07:31:53,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:53,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:54,371 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:55,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bqsqeapu', purging
2023-05-26 07:31:55,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:55,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:56,516 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:57,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c4v5ksl8', purging
2023-05-26 07:31:57,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:57,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:31:58,618 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:31:59,923 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ax9khjyf', purging
2023-05-26 07:31:59,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:31:59,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:00,705 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:02,020 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sx54251a', purging
2023-05-26 07:32:02,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:02,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:02,785 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:04,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vy7vkn88', purging
2023-05-26 07:32:04,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:04,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:04,866 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:06,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g6jq15j8', purging
2023-05-26 07:32:06,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:06,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:06,933 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:08,242 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hdlem7g8', purging
2023-05-26 07:32:08,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:08,243 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:09,019 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:10,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ujfhihg', purging
2023-05-26 07:32:10,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:10,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:11,106 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:12,412 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1pd_hxi7', purging
2023-05-26 07:32:12,412 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:12,412 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:13,180 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:14,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9y46ty6', purging
2023-05-26 07:32:14,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:14,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:15,259 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:16,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vp21c_4o', purging
2023-05-26 07:32:16,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:16,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:17,336 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:18,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zhih3kb9', purging
2023-05-26 07:32:18,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:18,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:19,429 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:20,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p67sqzrl', purging
2023-05-26 07:32:20,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:20,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:21,516 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:22,858 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e1y7je7d', purging
2023-05-26 07:32:22,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:22,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:23,661 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:24,986 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y8ijpy5g', purging
2023-05-26 07:32:24,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:24,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:25,761 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:27,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vslc1qyz', purging
2023-05-26 07:32:27,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:27,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:27,877 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:29,248 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7eqskzwc', purging
2023-05-26 07:32:29,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:29,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:30,030 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:31,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rxz1r3et', purging
2023-05-26 07:32:31,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:31,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:32,114 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:33,444 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9nqdn_fy', purging
2023-05-26 07:32:33,445 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:33,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:34,220 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:35,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-enq7c4zy', purging
2023-05-26 07:32:35,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:35,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:36,283 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:37,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sm89eudn', purging
2023-05-26 07:32:37,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:37,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:38,359 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:39,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-43prl1dw', purging
2023-05-26 07:32:39,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:39,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:40,423 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:41,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lp8q9f2c', purging
2023-05-26 07:32:41,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:41,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:42,503 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:43,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g_rj2mxy', purging
2023-05-26 07:32:43,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:43,808 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:44,577 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:45,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-saswlkvt', purging
2023-05-26 07:32:45,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:45,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:46,657 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:47,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kaao0oi7', purging
2023-05-26 07:32:47,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:47,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:48,735 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:50,043 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nvmtuf05', purging
2023-05-26 07:32:50,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:50,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:50,807 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:52,119 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-anbl0onr', purging
2023-05-26 07:32:52,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:52,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:52,894 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:54,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8xmbyf95', purging
2023-05-26 07:32:54,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:54,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:54,979 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:56,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rwg_2a69', purging
2023-05-26 07:32:56,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:56,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:57,062 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:32:58,370 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gkcapfs4', purging
2023-05-26 07:32:58,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:32:58,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:32:59,170 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:00,538 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9svw7372', purging
2023-05-26 07:33:00,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:00,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:01,326 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:02,636 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xv321v_4', purging
2023-05-26 07:33:02,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:02,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:03,420 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:04,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m9k0aqqu', purging
2023-05-26 07:33:04,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:04,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:05,509 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:06,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xhv_wq02', purging
2023-05-26 07:33:06,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:06,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:07,601 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:08,908 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y74y6cn5', purging
2023-05-26 07:33:08,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:08,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:09,692 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:11,005 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mo5fj1qq', purging
2023-05-26 07:33:11,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:11,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:11,772 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:13,080 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-29heknp8', purging
2023-05-26 07:33:13,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:13,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:13,854 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:15,157 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fz1uewle', purging
2023-05-26 07:33:15,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:15,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:15,921 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:17,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-88f3xt0e', purging
2023-05-26 07:33:17,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:17,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:17,994 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:19,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gq4jw77x', purging
2023-05-26 07:33:19,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:19,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:20,069 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:21,387 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-keu6jk3w', purging
2023-05-26 07:33:21,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:21,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:22,160 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:23,485 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-djl4zlvw', purging
2023-05-26 07:33:23,486 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:23,486 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:24,257 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:25,567 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6myi0i5f', purging
2023-05-26 07:33:25,568 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:25,568 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:26,341 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:27,655 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xi9gafjx', purging
2023-05-26 07:33:27,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:27,656 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:28,422 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:29,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vzr4cov2', purging
2023-05-26 07:33:29,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:29,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:30,506 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:31,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uk60cdme', purging
2023-05-26 07:33:31,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:31,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:32,666 - distributed.nanny - WARNING - Restarting worker
2023-05-26 07:33:34,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ox5tzoxl', purging
2023-05-26 07:33:34,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-26 07:33:34,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-26 07:33:34,788 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 864 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
