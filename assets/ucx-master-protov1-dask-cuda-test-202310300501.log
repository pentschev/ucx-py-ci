============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.3, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-10-30 05:24:42,997 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:24:43,001 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:24:43,004 - distributed.scheduler - INFO - State start
2023-10-30 05:24:43,027 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:24:43,028 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-30 05:24:43,028 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:24:43,029 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:24:43,128 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41783'
2023-10-30 05:24:43,142 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44691'
2023-10-30 05:24:43,145 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32795'
2023-10-30 05:24:43,152 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36571'
2023-10-30 05:24:43,720 - distributed.scheduler - INFO - Receive client connection: Client-a0a1a27b-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:24:43,731 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32964
2023-10-30 05:24:44,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:44,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:44,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:44,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:44,697 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:44,697 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:44,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:44,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:44,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:44,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:44,715 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:44,718 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-10-30 05:24:44,733 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34313
2023-10-30 05:24:44,733 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34313
2023-10-30 05:24:44,733 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45863
2023-10-30 05:24:44,733 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-30 05:24:44,733 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:44,733 - distributed.worker - INFO -               Threads:                          4
2023-10-30 05:24:44,733 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-30 05:24:44,733 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-_9jbgyxt
2023-10-30 05:24:44,733 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f8b6b5d8-d36a-4988-a5eb-eb5bccdf9692
2023-10-30 05:24:44,734 - distributed.worker - INFO - Starting Worker plugin PreImport-21f3b800-a5b7-493f-8c57-a44e40144659
2023-10-30 05:24:44,734 - distributed.worker - INFO - Starting Worker plugin RMMSetup-092eaadd-0758-45e7-b16f-5c791764944e
2023-10-30 05:24:44,734 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,151 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34313', status: init, memory: 0, processing: 0>
2023-10-30 05:24:45,152 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34313
2023-10-30 05:24:45,152 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32970
2023-10-30 05:24:45,153 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:45,154 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-30 05:24:45,154 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,155 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-30 05:24:45,857 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45865
2023-10-30 05:24:45,857 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45865
2023-10-30 05:24:45,857 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40671
2023-10-30 05:24:45,857 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44417
2023-10-30 05:24:45,858 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40671
2023-10-30 05:24:45,858 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-30 05:24:45,858 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43727
2023-10-30 05:24:45,858 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,858 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-30 05:24:45,858 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,858 - distributed.worker - INFO -               Threads:                          4
2023-10-30 05:24:45,858 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-30 05:24:45,858 - distributed.worker - INFO -               Threads:                          4
2023-10-30 05:24:45,858 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-7qalga6s
2023-10-30 05:24:45,858 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-30 05:24:45,858 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-ted0yw2_
2023-10-30 05:24:45,858 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f003b345-33eb-4659-a971-0ee1ff2181cb
2023-10-30 05:24:45,859 - distributed.worker - INFO - Starting Worker plugin PreImport-bf5ac885-c295-47cc-8e62-4e100be37bbf
2023-10-30 05:24:45,859 - distributed.worker - INFO - Starting Worker plugin PreImport-b1376a6a-d8e9-4999-9ed6-7c0087af7335
2023-10-30 05:24:45,859 - distributed.worker - INFO - Starting Worker plugin RMMSetup-67c242b7-2de8-45f5-a76f-f99e0376dba4
2023-10-30 05:24:45,859 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4a6f06d8-de5f-48de-8933-6ccaa6b09d2c
2023-10-30 05:24:45,859 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-51133e52-7f0e-4107-af36-4d5f834eba37
2023-10-30 05:24:45,859 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,860 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,881 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45865', status: init, memory: 0, processing: 0>
2023-10-30 05:24:45,882 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45865
2023-10-30 05:24:45,882 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32984
2023-10-30 05:24:45,882 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:45,883 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-30 05:24:45,883 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,884 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40671', status: init, memory: 0, processing: 0>
2023-10-30 05:24:45,884 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40671
2023-10-30 05:24:45,885 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32994
2023-10-30 05:24:45,885 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-30 05:24:45,886 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:45,887 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-30 05:24:45,887 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,889 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-30 05:24:45,909 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41891
2023-10-30 05:24:45,910 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41891
2023-10-30 05:24:45,910 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43363
2023-10-30 05:24:45,910 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-30 05:24:45,910 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,910 - distributed.worker - INFO -               Threads:                          4
2023-10-30 05:24:45,911 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-30 05:24:45,911 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-90ycji8x
2023-10-30 05:24:45,911 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b313d4df-46cd-4936-b981-95715c8a9ed4
2023-10-30 05:24:45,911 - distributed.worker - INFO - Starting Worker plugin PreImport-5cc849eb-0864-4968-a297-dcd1093776d3
2023-10-30 05:24:45,911 - distributed.worker - INFO - Starting Worker plugin RMMSetup-57550b0e-f7d1-4bf3-abe4-318e8cb7d14b
2023-10-30 05:24:45,912 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,928 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41891', status: init, memory: 0, processing: 0>
2023-10-30 05:24:45,928 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41891
2023-10-30 05:24:45,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33010
2023-10-30 05:24:45,929 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:45,930 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-30 05:24:45,930 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:45,932 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-30 05:24:46,002 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-30 05:24:46,001 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-30 05:24:46,002 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-30 05:24:46,002 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-30 05:24:46,006 - distributed.scheduler - INFO - Remove client Client-a0a1a27b-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:24:46,006 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32964; closing.
2023-10-30 05:24:46,007 - distributed.scheduler - INFO - Remove client Client-a0a1a27b-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:24:46,007 - distributed.scheduler - INFO - Close client connection: Client-a0a1a27b-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:24:46,008 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41783'. Reason: nanny-close
2023-10-30 05:24:46,008 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:46,009 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44691'. Reason: nanny-close
2023-10-30 05:24:46,009 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:46,009 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45865. Reason: nanny-close
2023-10-30 05:24:46,010 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32795'. Reason: nanny-close
2023-10-30 05:24:46,010 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:46,010 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40671. Reason: nanny-close
2023-10-30 05:24:46,010 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36571'. Reason: nanny-close
2023-10-30 05:24:46,011 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:46,011 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41891. Reason: nanny-close
2023-10-30 05:24:46,011 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-30 05:24:46,011 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32984; closing.
2023-10-30 05:24:46,011 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34313. Reason: nanny-close
2023-10-30 05:24:46,012 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45865', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643486.0122058')
2023-10-30 05:24:46,012 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-30 05:24:46,013 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-30 05:24:46,013 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:46,013 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33010; closing.
2023-10-30 05:24:46,013 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32994; closing.
2023-10-30 05:24:46,014 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-30 05:24:46,014 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:46,014 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41891', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643486.0141718')
2023-10-30 05:24:46,014 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:46,014 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40671', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643486.0145607')
2023-10-30 05:24:46,015 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32970; closing.
2023-10-30 05:24:46,015 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:46,015 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34313', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643486.0155597')
2023-10-30 05:24:46,015 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:24:46,974 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:24:46,974 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:24:46,975 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:24:46,976 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-30 05:24:46,976 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-10-30 05:24:48,771 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:24:48,775 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:24:48,778 - distributed.scheduler - INFO - State start
2023-10-30 05:24:48,797 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:24:48,798 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:24:48,798 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:24:48,798 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:24:48,942 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37843'
2023-10-30 05:24:48,957 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42307'
2023-10-30 05:24:48,965 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33717'
2023-10-30 05:24:48,980 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46809'
2023-10-30 05:24:48,982 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41121'
2023-10-30 05:24:48,990 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39789'
2023-10-30 05:24:49,001 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33289'
2023-10-30 05:24:49,009 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35515'
2023-10-30 05:24:50,185 - distributed.scheduler - INFO - Receive client connection: Client-a417f1da-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:24:50,196 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52226
2023-10-30 05:24:50,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:50,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:50,564 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:50,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:50,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:50,808 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:50,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:50,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:50,834 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:50,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:50,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:50,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:50,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:50,839 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:50,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:50,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:50,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:50,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:50,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:50,841 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:50,843 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:50,844 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:50,844 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:50,845 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:51,991 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39067
2023-10-30 05:24:51,991 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39067
2023-10-30 05:24:51,991 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41357
2023-10-30 05:24:51,991 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:24:51,991 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:51,992 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:24:51,992 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:24:51,992 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wgndktxp
2023-10-30 05:24:51,992 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1459957b-16bf-44be-8cf2-7f908bc2a08c
2023-10-30 05:24:51,993 - distributed.worker - INFO - Starting Worker plugin PreImport-9fdd8903-36e0-4c30-8f10-b6427143564a
2023-10-30 05:24:51,993 - distributed.worker - INFO - Starting Worker plugin RMMSetup-acbdb241-bd8c-4ecf-ab24-e98a6c408d11
2023-10-30 05:24:52,447 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:52,473 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39067', status: init, memory: 0, processing: 0>
2023-10-30 05:24:52,474 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39067
2023-10-30 05:24:52,474 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52246
2023-10-30 05:24:52,475 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:52,476 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:24:52,476 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:52,478 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:24:53,101 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41481
2023-10-30 05:24:53,103 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41481
2023-10-30 05:24:53,103 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33167
2023-10-30 05:24:53,104 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,104 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,104 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:24:53,104 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:24:53,104 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wiskai5l
2023-10-30 05:24:53,105 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2531b55d-c36d-47cf-8e30-99d66c50d9bf
2023-10-30 05:24:53,105 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d72f45e1-89f4-4168-9340-3d86b6f366ad
2023-10-30 05:24:53,200 - distributed.worker - INFO - Starting Worker plugin PreImport-8b7af589-34bf-4d8f-a131-cc3de191897e
2023-10-30 05:24:53,200 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,225 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41481', status: init, memory: 0, processing: 0>
2023-10-30 05:24:53,226 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41481
2023-10-30 05:24:53,226 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52252
2023-10-30 05:24:53,228 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:53,228 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,228 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:24:53,259 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41391
2023-10-30 05:24:53,259 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43085
2023-10-30 05:24:53,260 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41391
2023-10-30 05:24:53,260 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43085
2023-10-30 05:24:53,260 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33003
2023-10-30 05:24:53,260 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37211
2023-10-30 05:24:53,260 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,260 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,260 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,260 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,260 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:24:53,260 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:24:53,261 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:24:53,261 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:24:53,261 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-spbmjg81
2023-10-30 05:24:53,261 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-la056uvi
2023-10-30 05:24:53,261 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1f831985-236e-4659-8b8c-d00b63e9fe38
2023-10-30 05:24:53,261 - distributed.worker - INFO - Starting Worker plugin PreImport-43f816a3-47ed-4257-ae07-1f05af1c1e23
2023-10-30 05:24:53,261 - distributed.worker - INFO - Starting Worker plugin PreImport-a3475b8a-784a-4414-8d57-f110f4bc5f0c
2023-10-30 05:24:53,261 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-920c4d7b-97b5-4faf-ac06-01c96f22d985
2023-10-30 05:24:53,261 - distributed.worker - INFO - Starting Worker plugin RMMSetup-af835aa8-4977-4bb5-a336-7d5725901c18
2023-10-30 05:24:53,261 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f6e841cd-5185-4d56-a380-146d85c96745
2023-10-30 05:24:53,265 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42057
2023-10-30 05:24:53,266 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42057
2023-10-30 05:24:53,266 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37015
2023-10-30 05:24:53,266 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,266 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,266 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:24:53,267 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:24:53,267 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rs687y6a
2023-10-30 05:24:53,267 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-99a23a3d-5455-4125-bdd3-99c1f4e62fd1
2023-10-30 05:24:53,267 - distributed.worker - INFO - Starting Worker plugin PreImport-6db7f715-a5a0-45d5-96df-7cbbc4071317
2023-10-30 05:24:53,267 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9448e5d7-799f-4d67-b389-1309622df05d
2023-10-30 05:24:53,269 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33785
2023-10-30 05:24:53,271 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33785
2023-10-30 05:24:53,271 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44613
2023-10-30 05:24:53,271 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,271 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,271 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:24:53,271 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:24:53,271 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yz9hb5xw
2023-10-30 05:24:53,272 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-af12a05f-7967-4af3-b6d4-71ce00696092
2023-10-30 05:24:53,273 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0b8b2197-b320-4b42-a534-58701c9cd02b
2023-10-30 05:24:53,283 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44085
2023-10-30 05:24:53,284 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44085
2023-10-30 05:24:53,284 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43597
2023-10-30 05:24:53,283 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40131
2023-10-30 05:24:53,284 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,284 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40131
2023-10-30 05:24:53,284 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,284 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33371
2023-10-30 05:24:53,284 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,284 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:24:53,284 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,284 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:24:53,284 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q9rvugda
2023-10-30 05:24:53,284 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:24:53,284 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:24:53,284 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-41jdlspe
2023-10-30 05:24:53,285 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b8162f5-e06a-4cbd-9339-55322c4a9b0e
2023-10-30 05:24:53,285 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-35cdcdb9-e7c1-4155-a1ad-1387f26692fe
2023-10-30 05:24:53,285 - distributed.worker - INFO - Starting Worker plugin PreImport-84131c74-b857-45f6-a1e8-f731379a2f2b
2023-10-30 05:24:53,285 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eb96adbd-3966-427c-bfdc-df5988cb35ea
2023-10-30 05:24:53,288 - distributed.worker - INFO - Starting Worker plugin PreImport-97419a33-921e-40d0-81ea-8d617801de39
2023-10-30 05:24:53,288 - distributed.worker - INFO - Starting Worker plugin RMMSetup-95ef88ee-4d6c-443b-88e9-54975281e1d2
2023-10-30 05:24:53,401 - distributed.worker - INFO - Starting Worker plugin PreImport-7367c3cd-929d-404a-8e6e-3b8c6614eb80
2023-10-30 05:24:53,401 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,401 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,401 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,401 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,427 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42057', status: init, memory: 0, processing: 0>
2023-10-30 05:24:53,427 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42057
2023-10-30 05:24:53,427 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52256
2023-10-30 05:24:53,428 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41391', status: init, memory: 0, processing: 0>
2023-10-30 05:24:53,428 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:53,429 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41391
2023-10-30 05:24:53,429 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52258
2023-10-30 05:24:53,429 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,429 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,430 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33785', status: init, memory: 0, processing: 0>
2023-10-30 05:24:53,430 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:53,430 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33785
2023-10-30 05:24:53,430 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52274
2023-10-30 05:24:53,431 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,431 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,431 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:24:53,431 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43085', status: init, memory: 0, processing: 0>
2023-10-30 05:24:53,432 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43085
2023-10-30 05:24:53,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52272
2023-10-30 05:24:53,432 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:53,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:24:53,432 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:53,433 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,433 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,433 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,433 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,435 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:24:53,435 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:24:53,436 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,439 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,464 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44085', status: init, memory: 0, processing: 0>
2023-10-30 05:24:53,465 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44085
2023-10-30 05:24:53,465 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52284
2023-10-30 05:24:53,465 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40131', status: init, memory: 0, processing: 0>
2023-10-30 05:24:53,466 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40131
2023-10-30 05:24:53,466 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52294
2023-10-30 05:24:53,466 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:53,467 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,467 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,468 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:24:53,469 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:24:53,469 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:24:53,470 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:24:53,471 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:24:53,531 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:24:53,531 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:24:53,531 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:24:53,531 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:24:53,531 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:24:53,531 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:24:53,532 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:24:53,532 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:24:53,536 - distributed.scheduler - INFO - Remove client Client-a417f1da-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:24:53,536 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52226; closing.
2023-10-30 05:24:53,536 - distributed.scheduler - INFO - Remove client Client-a417f1da-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:24:53,537 - distributed.scheduler - INFO - Close client connection: Client-a417f1da-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:24:53,538 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37843'. Reason: nanny-close
2023-10-30 05:24:53,538 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:53,539 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42307'. Reason: nanny-close
2023-10-30 05:24:53,539 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:53,540 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40131. Reason: nanny-close
2023-10-30 05:24:53,540 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33717'. Reason: nanny-close
2023-10-30 05:24:53,540 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:53,540 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44085. Reason: nanny-close
2023-10-30 05:24:53,540 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46809'. Reason: nanny-close
2023-10-30 05:24:53,541 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:53,541 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41391. Reason: nanny-close
2023-10-30 05:24:53,541 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41121'. Reason: nanny-close
2023-10-30 05:24:53,541 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:53,541 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42057. Reason: nanny-close
2023-10-30 05:24:53,542 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39789'. Reason: nanny-close
2023-10-30 05:24:53,542 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:53,542 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:24:53,542 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52294; closing.
2023-10-30 05:24:53,542 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41481. Reason: nanny-close
2023-10-30 05:24:53,542 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33289'. Reason: nanny-close
2023-10-30 05:24:53,542 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40131', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643493.5427701')
2023-10-30 05:24:53,542 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:53,542 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:24:53,543 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:24:53,543 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35515'. Reason: nanny-close
2023-10-30 05:24:53,543 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33785. Reason: nanny-close
2023-10-30 05:24:53,543 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:24:53,543 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39067. Reason: nanny-close
2023-10-30 05:24:53,543 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:24:53,544 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43085. Reason: nanny-close
2023-10-30 05:24:53,544 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:53,544 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52284; closing.
2023-10-30 05:24:53,544 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:53,544 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52258; closing.
2023-10-30 05:24:53,545 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:53,545 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:53,545 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52256; closing.
2023-10-30 05:24:53,545 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:24:53,545 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44085', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643493.5458431')
2023-10-30 05:24:53,546 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:24:53,546 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41391', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643493.5463054')
2023-10-30 05:24:53,546 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:24:53,546 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:24:53,547 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42057', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643493.547183')
2023-10-30 05:24:53,547 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52252; closing.
2023-10-30 05:24:53,547 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:53,548 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:53,548 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:53,548 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41481', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643493.5484908')
2023-10-30 05:24:53,548 - distributed.nanny - INFO - Worker closed
2023-10-30 05:24:53,548 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52246; closing.
2023-10-30 05:24:53,549 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52274; closing.
2023-10-30 05:24:53,549 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39067', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643493.549692')
2023-10-30 05:24:53,550 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33785', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643493.5501645')
2023-10-30 05:24:53,550 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52272; closing.
2023-10-30 05:24:53,551 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43085', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643493.5510807')
2023-10-30 05:24:53,551 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:24:55,055 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:24:55,055 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:24:55,056 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:24:55,057 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:24:55,057 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-10-30 05:24:56,905 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:24:56,909 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:24:56,912 - distributed.scheduler - INFO - State start
2023-10-30 05:24:56,931 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:24:56,931 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:24:56,932 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:24:56,932 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:24:57,110 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42733'
2023-10-30 05:24:57,125 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46443'
2023-10-30 05:24:57,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40783'
2023-10-30 05:24:57,147 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33165'
2023-10-30 05:24:57,149 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39853'
2023-10-30 05:24:57,158 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41451'
2023-10-30 05:24:57,168 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35065'
2023-10-30 05:24:57,177 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42115'
2023-10-30 05:24:57,915 - distributed.scheduler - INFO - Receive client connection: Client-a8f0ba27-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:24:57,925 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52438
2023-10-30 05:24:58,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:58,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:58,732 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:58,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:58,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:58,841 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:58,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:58,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:58,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:58,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:58,885 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:58,888 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:58,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:58,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:58,908 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:59,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:59,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:59,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:59,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:59,095 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:59,095 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:24:59,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:24:59,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:24:59,133 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:00,322 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38415
2023-10-30 05:25:00,323 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38415
2023-10-30 05:25:00,324 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38981
2023-10-30 05:25:00,324 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:00,324 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:00,324 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:00,324 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:00,324 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q0na5158
2023-10-30 05:25:00,324 - distributed.worker - INFO - Starting Worker plugin PreImport-ae7952bf-4dfc-451b-91aa-7fcbca7c617a
2023-10-30 05:25:00,325 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a4297c33-e2d2-4940-8f5a-b7432d2817e5
2023-10-30 05:25:00,325 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2a4cd257-0928-4ee8-9f52-0e33ff189e88
2023-10-30 05:25:00,650 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:00,681 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38415', status: init, memory: 0, processing: 0>
2023-10-30 05:25:00,682 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38415
2023-10-30 05:25:00,682 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38710
2023-10-30 05:25:00,683 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:00,684 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:00,684 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:00,686 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:01,864 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45473
2023-10-30 05:25:01,865 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45473
2023-10-30 05:25:01,865 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39731
2023-10-30 05:25:01,865 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,865 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,865 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:01,865 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:01,866 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ys5hkqjl
2023-10-30 05:25:01,866 - distributed.worker - INFO - Starting Worker plugin PreImport-5c6c9b9f-eda0-4fc7-a3f4-99897835e9fd
2023-10-30 05:25:01,866 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-18fa460e-2b41-4abf-b03e-498e6478f282
2023-10-30 05:25:01,866 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1fc840db-acea-4eeb-bbf3-7c043395fedb
2023-10-30 05:25:01,876 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40071
2023-10-30 05:25:01,876 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40071
2023-10-30 05:25:01,876 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41557
2023-10-30 05:25:01,877 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,877 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,877 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:01,877 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:01,877 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s5u9jbyh
2023-10-30 05:25:01,877 - distributed.worker - INFO - Starting Worker plugin PreImport-fd4441cb-a038-4c64-96c4-a74326206653
2023-10-30 05:25:01,878 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5d4e2191-308c-48ad-ad7f-42b85e136e06
2023-10-30 05:25:01,878 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6e7b166e-9704-4198-8305-633cc9e346aa
2023-10-30 05:25:01,885 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33751
2023-10-30 05:25:01,886 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33751
2023-10-30 05:25:01,886 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45197
2023-10-30 05:25:01,886 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,886 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,886 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:01,886 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:01,886 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-chkjyevg
2023-10-30 05:25:01,887 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4e35bc98-e1f1-49fc-a1f8-ee5b26c5e274
2023-10-30 05:25:01,886 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33125
2023-10-30 05:25:01,887 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33125
2023-10-30 05:25:01,887 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41423
2023-10-30 05:25:01,887 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,887 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,887 - distributed.worker - INFO - Starting Worker plugin PreImport-f40f0498-5844-4bea-aaaf-176f6f38e0a2
2023-10-30 05:25:01,887 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:01,888 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:01,888 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a1e9c810-ffa5-47f3-8440-dede38219bbf
2023-10-30 05:25:01,888 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xbrjpcj2
2023-10-30 05:25:01,888 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1b7dcd95-28ad-4a46-8f9c-55bfade12ba9
2023-10-30 05:25:01,888 - distributed.worker - INFO - Starting Worker plugin RMMSetup-73a5ef80-b2c3-4d68-bc2a-975cda81376f
2023-10-30 05:25:01,890 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41601
2023-10-30 05:25:01,891 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41601
2023-10-30 05:25:01,891 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41721
2023-10-30 05:25:01,891 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,891 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,892 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:01,892 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:01,892 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rzh2bnvs
2023-10-30 05:25:01,891 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37677
2023-10-30 05:25:01,893 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7cd9f6a6-3419-4cab-be08-22261cdbf7a2
2023-10-30 05:25:01,893 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37677
2023-10-30 05:25:01,893 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36655
2023-10-30 05:25:01,893 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,893 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,893 - distributed.worker - INFO - Starting Worker plugin PreImport-319f2a65-11e9-4a60-8912-fa3daa409131
2023-10-30 05:25:01,893 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:01,893 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e124f35f-f234-419b-bab4-d804a9c6debe
2023-10-30 05:25:01,893 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:01,894 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pqin75v6
2023-10-30 05:25:01,895 - distributed.worker - INFO - Starting Worker plugin PreImport-7ee976ca-9930-4ce4-a860-2032f83d717e
2023-10-30 05:25:01,895 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b5ef70c8-aa6c-4f44-a12e-6fd0496e8441
2023-10-30 05:25:01,917 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,921 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45825
2023-10-30 05:25:01,922 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45825
2023-10-30 05:25:01,922 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43363
2023-10-30 05:25:01,922 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,922 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,922 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,922 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:01,923 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:01,923 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tghd70rs
2023-10-30 05:25:01,923 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d585f496-b186-42ca-8f33-3559330b9f9e
2023-10-30 05:25:01,926 - distributed.worker - INFO - Starting Worker plugin PreImport-1ba9d71d-e49c-4193-9571-e3635c63915f
2023-10-30 05:25:01,926 - distributed.worker - INFO - Starting Worker plugin PreImport-72222b3e-d94d-47e7-affc-1a7c570d5d17
2023-10-30 05:25:01,926 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab8c1635-75e2-4eec-bd05-3ac5fdae9102
2023-10-30 05:25:01,926 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,926 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,929 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f1d3fd72-a760-4d42-86eb-f451d63bc39a
2023-10-30 05:25:01,930 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,931 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,934 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,941 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45473', status: init, memory: 0, processing: 0>
2023-10-30 05:25:01,942 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45473
2023-10-30 05:25:01,942 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38716
2023-10-30 05:25:01,943 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:01,943 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,943 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,945 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:01,947 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40071', status: init, memory: 0, processing: 0>
2023-10-30 05:25:01,948 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40071
2023-10-30 05:25:01,948 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38726
2023-10-30 05:25:01,949 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:01,950 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,950 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,951 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:01,952 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33125', status: init, memory: 0, processing: 0>
2023-10-30 05:25:01,953 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33125
2023-10-30 05:25:01,953 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38738
2023-10-30 05:25:01,954 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:01,955 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,955 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,956 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:01,959 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41601', status: init, memory: 0, processing: 0>
2023-10-30 05:25:01,960 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41601
2023-10-30 05:25:01,960 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38750
2023-10-30 05:25:01,961 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37677', status: init, memory: 0, processing: 0>
2023-10-30 05:25:01,961 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:01,962 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37677
2023-10-30 05:25:01,962 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38744
2023-10-30 05:25:01,962 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,962 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,963 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33751', status: init, memory: 0, processing: 0>
2023-10-30 05:25:01,963 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:01,964 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33751
2023-10-30 05:25:01,964 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38742
2023-10-30 05:25:01,964 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,964 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,965 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:01,965 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:01,966 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45825', status: init, memory: 0, processing: 0>
2023-10-30 05:25:01,966 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,966 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,966 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45825
2023-10-30 05:25:01,966 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:01,966 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38766
2023-10-30 05:25:01,968 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:01,969 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:01,969 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:01,969 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:01,971 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:02,063 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:02,064 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:02,064 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:02,064 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:02,064 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:02,064 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:02,064 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:02,065 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:02,070 - distributed.scheduler - INFO - Remove client Client-a8f0ba27-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:02,070 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52438; closing.
2023-10-30 05:25:02,070 - distributed.scheduler - INFO - Remove client Client-a8f0ba27-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:02,071 - distributed.scheduler - INFO - Close client connection: Client-a8f0ba27-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:02,071 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42733'. Reason: nanny-close
2023-10-30 05:25:02,072 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:02,073 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46443'. Reason: nanny-close
2023-10-30 05:25:02,073 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:02,073 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45825. Reason: nanny-close
2023-10-30 05:25:02,073 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40783'. Reason: nanny-close
2023-10-30 05:25:02,074 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:02,074 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33165'. Reason: nanny-close
2023-10-30 05:25:02,074 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38415. Reason: nanny-close
2023-10-30 05:25:02,074 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:02,075 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41601. Reason: nanny-close
2023-10-30 05:25:02,075 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39853'. Reason: nanny-close
2023-10-30 05:25:02,075 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40071. Reason: nanny-close
2023-10-30 05:25:02,075 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:02,075 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41451'. Reason: nanny-close
2023-10-30 05:25:02,076 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:02,076 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:02,076 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38766; closing.
2023-10-30 05:25:02,076 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37677. Reason: nanny-close
2023-10-30 05:25:02,076 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35065'. Reason: nanny-close
2023-10-30 05:25:02,076 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:02,077 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45825', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643502.0770175')
2023-10-30 05:25:02,077 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33751. Reason: nanny-close
2023-10-30 05:25:02,077 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:02,077 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42115'. Reason: nanny-close
2023-10-30 05:25:02,077 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:02,077 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:02,077 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:02,077 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33125. Reason: nanny-close
2023-10-30 05:25:02,077 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38750; closing.
2023-10-30 05:25:02,078 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:02,078 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45473. Reason: nanny-close
2023-10-30 05:25:02,078 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41601', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643502.078904')
2023-10-30 05:25:02,079 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:02,079 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:02,079 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:02,079 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:02,079 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:02,080 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:02,080 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:02,080 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38726; closing.
2023-10-30 05:25:02,081 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38710; closing.
2023-10-30 05:25:02,081 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:02,081 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:02,082 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:02,082 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:02,082 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:38750>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-30 05:25:02,084 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40071', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643502.0842836')
2023-10-30 05:25:02,084 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38415', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643502.084823')
2023-10-30 05:25:02,085 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38744; closing.
2023-10-30 05:25:02,086 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37677', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643502.0862794')
2023-10-30 05:25:02,086 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38742; closing.
2023-10-30 05:25:02,087 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38738; closing.
2023-10-30 05:25:02,087 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38716; closing.
2023-10-30 05:25:02,088 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33751', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643502.08792')
2023-10-30 05:25:02,088 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33125', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643502.0885162')
2023-10-30 05:25:02,089 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45473', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643502.0890932')
2023-10-30 05:25:02,089 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:25:03,638 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:25:03,639 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:25:03,639 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:25:03,641 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:25:03,641 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-10-30 05:25:05,809 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:05,813 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:25:05,816 - distributed.scheduler - INFO - State start
2023-10-30 05:25:05,836 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:05,837 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:25:05,837 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:25:05,838 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:25:05,962 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36031'
2023-10-30 05:25:05,977 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45913'
2023-10-30 05:25:05,993 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43277'
2023-10-30 05:25:05,994 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35269'
2023-10-30 05:25:06,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38313'
2023-10-30 05:25:06,024 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45861'
2023-10-30 05:25:06,040 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34459'
2023-10-30 05:25:06,060 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37319'
2023-10-30 05:25:06,760 - distributed.scheduler - INFO - Receive client connection: Client-ae11e894-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:06,774 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38884
2023-10-30 05:25:07,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:07,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:07,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:07,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:07,830 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:07,832 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:07,911 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:07,911 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:07,915 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:07,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:07,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:07,923 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:07,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:07,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:07,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:07,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:07,930 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:07,930 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:07,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:07,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:07,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:07,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:07,969 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:07,971 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:10,284 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37563
2023-10-30 05:25:10,286 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37563
2023-10-30 05:25:10,286 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40815
2023-10-30 05:25:10,286 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,287 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,287 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:10,287 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:10,287 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hfw05p_p
2023-10-30 05:25:10,288 - distributed.worker - INFO - Starting Worker plugin PreImport-85d14773-52da-4da1-9e4a-af9c22327c2e
2023-10-30 05:25:10,288 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5277330b-0f2f-49d3-bd53-10d2f853a3bb
2023-10-30 05:25:10,319 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44243
2023-10-30 05:25:10,321 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44243
2023-10-30 05:25:10,321 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34743
2023-10-30 05:25:10,321 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,322 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,322 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:10,322 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:10,322 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7p0tjuxi
2023-10-30 05:25:10,323 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2e7d100e-0f50-454b-ac75-e82de6ae6c83
2023-10-30 05:25:10,323 - distributed.worker - INFO - Starting Worker plugin PreImport-32c9fdb2-34f3-48a3-9e1e-741efccf4d58
2023-10-30 05:25:10,324 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b4dfbbd9-5d14-43d0-89d8-80ac5bf6ed4c
2023-10-30 05:25:10,419 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38197
2023-10-30 05:25:10,419 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38197
2023-10-30 05:25:10,420 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33235
2023-10-30 05:25:10,420 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,420 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,420 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:10,420 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:10,420 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-43qkylnf
2023-10-30 05:25:10,420 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dd3d1ddb-1d0d-46d3-ba35-24203e867d48
2023-10-30 05:25:10,426 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41143
2023-10-30 05:25:10,426 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41143
2023-10-30 05:25:10,426 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46881
2023-10-30 05:25:10,427 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,427 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,427 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:10,427 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:10,427 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cu94iopa
2023-10-30 05:25:10,427 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6a624e07-98d3-4f9e-86a7-a88025a1cee0
2023-10-30 05:25:10,427 - distributed.worker - INFO - Starting Worker plugin PreImport-ef90423f-2ce6-45d7-a4ad-fb9af680d2d9
2023-10-30 05:25:10,428 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eeb2fc8d-0948-40cc-bdde-9f1ef6bb123f
2023-10-30 05:25:10,439 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4738961f-1b22-457e-986a-8a6a06cee837
2023-10-30 05:25:10,440 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,484 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37563', status: init, memory: 0, processing: 0>
2023-10-30 05:25:10,487 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37563
2023-10-30 05:25:10,487 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42230
2023-10-30 05:25:10,489 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:10,490 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,490 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,492 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:10,494 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45325
2023-10-30 05:25:10,495 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45325
2023-10-30 05:25:10,495 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38539
2023-10-30 05:25:10,495 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,495 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,495 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:10,495 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:10,496 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5aajoeuk
2023-10-30 05:25:10,496 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4ee176a5-a0b0-4668-b1f7-afbb7c620db4
2023-10-30 05:25:10,496 - distributed.worker - INFO - Starting Worker plugin PreImport-372a4ed2-0701-49f3-ad55-7dbf8b515f6b
2023-10-30 05:25:10,497 - distributed.worker - INFO - Starting Worker plugin RMMSetup-139f9cc2-a730-4c67-acfd-e68d19593c9c
2023-10-30 05:25:10,507 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37435
2023-10-30 05:25:10,508 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37435
2023-10-30 05:25:10,508 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39707
2023-10-30 05:25:10,508 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,508 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,509 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:10,509 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:10,509 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xfqfuf3w
2023-10-30 05:25:10,510 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5423e9e3-ab44-440d-a501-7f1daf85b705
2023-10-30 05:25:10,512 - distributed.worker - INFO - Starting Worker plugin PreImport-33a044be-489d-43f7-96a1-46a125b93e5e
2023-10-30 05:25:10,512 - distributed.worker - INFO - Starting Worker plugin RMMSetup-559ce404-636f-46e6-affc-cb459b592dc0
2023-10-30 05:25:10,530 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45155
2023-10-30 05:25:10,531 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45155
2023-10-30 05:25:10,531 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35931
2023-10-30 05:25:10,531 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,532 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,532 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:10,532 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:10,532 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2hhsccdu
2023-10-30 05:25:10,531 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42605
2023-10-30 05:25:10,532 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42605
2023-10-30 05:25:10,532 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45263
2023-10-30 05:25:10,532 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,532 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-64e7bf24-6e00-49d8-afb9-a9de5a8b867a
2023-10-30 05:25:10,532 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,532 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:10,533 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:10,533 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ducy9wpy
2023-10-30 05:25:10,533 - distributed.worker - INFO - Starting Worker plugin PreImport-c72a3d15-5216-4cc4-a4b5-011102e5cda0
2023-10-30 05:25:10,533 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-780483d1-9b2c-422c-bf8b-4eb92d0b009d
2023-10-30 05:25:10,533 - distributed.worker - INFO - Starting Worker plugin PreImport-112bb938-1f68-4a74-8223-43d1fb9b669f
2023-10-30 05:25:10,534 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0b389da9-389e-4af9-a356-467ac160a6c5
2023-10-30 05:25:10,535 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4b14c540-d7d9-4073-bb40-8bee2bd4e354
2023-10-30 05:25:10,545 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,576 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44243', status: init, memory: 0, processing: 0>
2023-10-30 05:25:10,577 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44243
2023-10-30 05:25:10,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42236
2023-10-30 05:25:10,578 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:10,579 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-387399ef-94a7-48da-8190-53eb59a6a807
2023-10-30 05:25:10,579 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,579 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,579 - distributed.worker - INFO - Starting Worker plugin PreImport-962b24e8-fbf2-436b-9bdd-a7f14bcbb605
2023-10-30 05:25:10,579 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,582 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:10,584 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,602 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38197', status: init, memory: 0, processing: 0>
2023-10-30 05:25:10,603 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38197
2023-10-30 05:25:10,603 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42238
2023-10-30 05:25:10,604 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:10,605 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,605 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,606 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:10,607 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41143', status: init, memory: 0, processing: 0>
2023-10-30 05:25:10,607 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41143
2023-10-30 05:25:10,607 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42250
2023-10-30 05:25:10,608 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:10,609 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,609 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,610 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:10,650 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,681 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45325', status: init, memory: 0, processing: 0>
2023-10-30 05:25:10,681 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45325
2023-10-30 05:25:10,681 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42262
2023-10-30 05:25:10,683 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:10,684 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,684 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,686 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:10,690 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,699 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,715 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,719 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45155', status: init, memory: 0, processing: 0>
2023-10-30 05:25:10,719 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45155
2023-10-30 05:25:10,720 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42268
2023-10-30 05:25:10,721 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:10,722 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,722 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,724 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:10,728 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37435', status: init, memory: 0, processing: 0>
2023-10-30 05:25:10,729 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37435
2023-10-30 05:25:10,729 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42274
2023-10-30 05:25:10,730 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:10,731 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,731 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,733 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:10,744 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42605', status: init, memory: 0, processing: 0>
2023-10-30 05:25:10,744 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42605
2023-10-30 05:25:10,744 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42286
2023-10-30 05:25:10,746 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:10,747 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:10,747 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:10,749 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:10,822 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:10,822 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:10,822 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:10,823 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:10,823 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:10,823 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:10,823 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:10,823 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:10,834 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:10,835 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:10,835 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:10,835 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:10,835 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:10,835 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:10,835 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:10,838 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:10,845 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:10,847 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:10,851 - distributed.scheduler - INFO - Remove client Client-ae11e894-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:10,851 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38884; closing.
2023-10-30 05:25:10,851 - distributed.scheduler - INFO - Remove client Client-ae11e894-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:10,851 - distributed.scheduler - INFO - Close client connection: Client-ae11e894-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:10,853 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36031'. Reason: nanny-close
2023-10-30 05:25:10,853 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:10,854 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45913'. Reason: nanny-close
2023-10-30 05:25:10,854 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:10,855 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43277'. Reason: nanny-close
2023-10-30 05:25:10,855 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37563. Reason: nanny-close
2023-10-30 05:25:10,855 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:10,855 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35269'. Reason: nanny-close
2023-10-30 05:25:10,855 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44243. Reason: nanny-close
2023-10-30 05:25:10,855 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:10,856 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45325. Reason: nanny-close
2023-10-30 05:25:10,856 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38313'. Reason: nanny-close
2023-10-30 05:25:10,856 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:10,856 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37435. Reason: nanny-close
2023-10-30 05:25:10,856 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45861'. Reason: nanny-close
2023-10-30 05:25:10,856 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:10,857 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34459'. Reason: nanny-close
2023-10-30 05:25:10,857 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:10,857 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37319'. Reason: nanny-close
2023-10-30 05:25:10,858 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:10,858 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:10,858 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42605. Reason: nanny-close
2023-10-30 05:25:10,858 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41143. Reason: nanny-close
2023-10-30 05:25:10,858 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42274; closing.
2023-10-30 05:25:10,858 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:10,858 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45155. Reason: nanny-close
2023-10-30 05:25:10,858 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42230; closing.
2023-10-30 05:25:10,858 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38197. Reason: nanny-close
2023-10-30 05:25:10,859 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42262; closing.
2023-10-30 05:25:10,859 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37435', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643510.859622')
2023-10-30 05:25:10,860 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:10,860 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:10,860 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:10,860 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:10,860 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37563', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643510.8605251')
2023-10-30 05:25:10,860 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:10,861 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:10,861 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45325', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643510.8611205')
2023-10-30 05:25:10,861 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:10,862 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:10,862 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:10,863 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:10,863 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:10,863 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42286; closing.
2023-10-30 05:25:10,864 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42250; closing.
2023-10-30 05:25:10,865 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42605', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643510.8653982')
2023-10-30 05:25:10,865 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:10,866 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41143', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643510.8659658')
2023-10-30 05:25:10,866 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:10,866 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42268; closing.
2023-10-30 05:25:10,866 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42238; closing.
2023-10-30 05:25:10,867 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45155', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643510.8674731')
2023-10-30 05:25:10,868 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38197', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643510.8680356')
2023-10-30 05:25:10,868 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:10,868 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42236; closing.
2023-10-30 05:25:10,869 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44243', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643510.8691294')
2023-10-30 05:25:10,869 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:25:12,420 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:25:12,420 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:25:12,421 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:25:12,422 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:25:12,423 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-10-30 05:25:14,479 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:14,483 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:25:14,486 - distributed.scheduler - INFO - State start
2023-10-30 05:25:14,510 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:14,511 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:25:14,512 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:25:14,512 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:25:14,882 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38437'
2023-10-30 05:25:14,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43803'
2023-10-30 05:25:14,906 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43767'
2023-10-30 05:25:14,907 - distributed.scheduler - INFO - Receive client connection: Client-b3540db2-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:14,915 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44655'
2023-10-30 05:25:14,921 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42426
2023-10-30 05:25:14,924 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35163'
2023-10-30 05:25:14,933 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32991'
2023-10-30 05:25:14,944 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43693'
2023-10-30 05:25:14,953 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41133'
2023-10-30 05:25:16,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:16,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:16,802 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:16,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:16,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:16,807 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:16,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:16,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:16,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:16,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:16,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:16,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:16,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:16,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:16,815 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:16,815 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:16,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:16,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:16,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:16,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:16,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:16,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:16,821 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:16,821 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:19,549 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41781
2023-10-30 05:25:19,549 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41781
2023-10-30 05:25:19,550 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38615
2023-10-30 05:25:19,550 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,550 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,550 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:19,550 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:19,550 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uxv5swcz
2023-10-30 05:25:19,549 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44807
2023-10-30 05:25:19,550 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44807
2023-10-30 05:25:19,550 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40807
2023-10-30 05:25:19,550 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,550 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,550 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2ceb9856-eaed-4c0d-a6ea-c2b32fa01fc5
2023-10-30 05:25:19,550 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:19,551 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:19,551 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jzq9ga56
2023-10-30 05:25:19,551 - distributed.worker - INFO - Starting Worker plugin PreImport-90fc16a9-8de2-453a-a8d5-b6b9c66a98b8
2023-10-30 05:25:19,551 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5ab18dc4-0e84-455f-9742-cc7144f5c03a
2023-10-30 05:25:19,551 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5d4c31ef-8dfd-4f16-8f28-e56f0e689073
2023-10-30 05:25:19,552 - distributed.worker - INFO - Starting Worker plugin PreImport-97e766b9-0271-45b6-9773-0a3202172309
2023-10-30 05:25:19,553 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c582489b-1361-44f6-b45d-d8cfab792b2b
2023-10-30 05:25:19,586 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43915
2023-10-30 05:25:19,587 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43915
2023-10-30 05:25:19,587 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43443
2023-10-30 05:25:19,587 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,587 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,587 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:19,587 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:19,587 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-shbhpak4
2023-10-30 05:25:19,587 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33235
2023-10-30 05:25:19,588 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33235
2023-10-30 05:25:19,588 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42797
2023-10-30 05:25:19,588 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,588 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,588 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-776b7cde-971d-4549-a02a-39007412a657
2023-10-30 05:25:19,588 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:19,588 - distributed.worker - INFO - Starting Worker plugin PreImport-8b3c5edf-69cb-40eb-a899-3076fbb1d5a7
2023-10-30 05:25:19,588 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:19,588 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1wiu8y8q
2023-10-30 05:25:19,588 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d8a7b6d8-8d24-4540-af27-a93edf0ddd76
2023-10-30 05:25:19,589 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-83501bb1-faf6-411d-9ffd-09fb5314a96e
2023-10-30 05:25:19,589 - distributed.worker - INFO - Starting Worker plugin PreImport-4c9fbd60-5fe1-4747-8806-878dc0dcfa6f
2023-10-30 05:25:19,589 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bc777e70-73a5-4b24-88c7-4790f667f2e3
2023-10-30 05:25:19,621 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43577
2023-10-30 05:25:19,621 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43577
2023-10-30 05:25:19,622 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40057
2023-10-30 05:25:19,622 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,622 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,622 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:19,622 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:19,622 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8u0w89ct
2023-10-30 05:25:19,622 - distributed.worker - INFO - Starting Worker plugin PreImport-f1d88afa-44b9-4712-a883-25e8d11051dc
2023-10-30 05:25:19,623 - distributed.worker - INFO - Starting Worker plugin RMMSetup-29cf8b95-04e5-49ea-854c-81fccb6ff1ef
2023-10-30 05:25:19,706 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35353
2023-10-30 05:25:19,707 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35353
2023-10-30 05:25:19,707 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44117
2023-10-30 05:25:19,707 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,707 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,707 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:19,707 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:19,707 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ag8psda4
2023-10-30 05:25:19,708 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b1b39195-ae42-4da5-b4d2-2b427b915bff
2023-10-30 05:25:19,708 - distributed.worker - INFO - Starting Worker plugin PreImport-2c2506c3-e47c-4db5-b3d0-4be6b31426b9
2023-10-30 05:25:19,708 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aea7cfc0-b683-47b0-a7ed-8101b7d953d2
2023-10-30 05:25:19,771 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46233
2023-10-30 05:25:19,772 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46233
2023-10-30 05:25:19,772 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36249
2023-10-30 05:25:19,772 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,772 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,772 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:19,772 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:19,773 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tcyj_hdd
2023-10-30 05:25:19,773 - distributed.worker - INFO - Starting Worker plugin PreImport-7c4e6ee2-1c15-495a-873a-cf59d4dfab99
2023-10-30 05:25:19,773 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4ec3dc5a-36cd-4ca8-b568-97260959b7a2
2023-10-30 05:25:19,773 - distributed.worker - INFO - Starting Worker plugin RMMSetup-311a9e54-d073-4668-90fb-a2652cc4f534
2023-10-30 05:25:19,803 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45563
2023-10-30 05:25:19,824 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45563
2023-10-30 05:25:19,825 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45847
2023-10-30 05:25:19,825 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,825 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,826 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:19,827 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:19,827 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-idsf2o8q
2023-10-30 05:25:19,830 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-da1a4fed-14df-43d5-a291-570232486b94
2023-10-30 05:25:19,831 - distributed.worker - INFO - Starting Worker plugin PreImport-5408c9f1-054b-4565-8ed8-9ba998380d98
2023-10-30 05:25:19,831 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e9f782dd-e850-4a9b-904c-db66b3128c8b
2023-10-30 05:25:19,870 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,889 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,891 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,893 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,906 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44807', status: init, memory: 0, processing: 0>
2023-10-30 05:25:19,907 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44807
2023-10-30 05:25:19,907 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42446
2023-10-30 05:25:19,909 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:19,910 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,910 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,912 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-98a8f36d-7479-4585-bb9a-ea92072694e1
2023-10-30 05:25:19,912 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:19,912 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,916 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33235', status: init, memory: 0, processing: 0>
2023-10-30 05:25:19,917 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33235
2023-10-30 05:25:19,917 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42450
2023-10-30 05:25:19,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:19,919 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,919 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:19,929 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43915', status: init, memory: 0, processing: 0>
2023-10-30 05:25:19,930 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43915
2023-10-30 05:25:19,930 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42480
2023-10-30 05:25:19,931 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41781', status: init, memory: 0, processing: 0>
2023-10-30 05:25:19,931 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:19,931 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41781
2023-10-30 05:25:19,931 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42464
2023-10-30 05:25:19,932 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,932 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,933 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:19,934 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:19,934 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,934 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,936 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:19,946 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43577', status: init, memory: 0, processing: 0>
2023-10-30 05:25:19,946 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43577
2023-10-30 05:25:19,947 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50474
2023-10-30 05:25:19,948 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:19,949 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,949 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,951 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:19,964 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,986 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35353', status: init, memory: 0, processing: 0>
2023-10-30 05:25:19,987 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35353
2023-10-30 05:25:19,987 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50488
2023-10-30 05:25:19,988 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:19,988 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,989 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:19,989 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:19,990 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:20,013 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46233', status: init, memory: 0, processing: 0>
2023-10-30 05:25:20,014 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46233
2023-10-30 05:25:20,014 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50494
2023-10-30 05:25:20,015 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:20,016 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:20,016 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:20,017 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:20,020 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:20,047 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45563', status: init, memory: 0, processing: 0>
2023-10-30 05:25:20,047 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45563
2023-10-30 05:25:20,047 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50496
2023-10-30 05:25:20,049 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:20,050 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:20,050 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:20,052 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:20,089 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,089 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,090 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,090 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,090 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,090 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,090 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,090 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,101 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:20,102 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:20,102 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:20,102 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:20,102 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:20,102 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:20,102 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:20,102 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:25:20,109 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,110 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:20,112 - distributed.scheduler - INFO - Remove client Client-b3540db2-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:20,112 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42426; closing.
2023-10-30 05:25:20,113 - distributed.scheduler - INFO - Remove client Client-b3540db2-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:20,113 - distributed.scheduler - INFO - Close client connection: Client-b3540db2-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:20,114 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38437'. Reason: nanny-close
2023-10-30 05:25:20,115 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:20,116 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43803'. Reason: nanny-close
2023-10-30 05:25:20,116 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:20,116 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43577. Reason: nanny-close
2023-10-30 05:25:20,116 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43767'. Reason: nanny-close
2023-10-30 05:25:20,116 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:20,117 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45563. Reason: nanny-close
2023-10-30 05:25:20,117 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44655'. Reason: nanny-close
2023-10-30 05:25:20,117 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:20,117 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35353. Reason: nanny-close
2023-10-30 05:25:20,118 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35163'. Reason: nanny-close
2023-10-30 05:25:20,118 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:20,118 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33235. Reason: nanny-close
2023-10-30 05:25:20,118 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32991'. Reason: nanny-close
2023-10-30 05:25:20,118 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:20,118 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:20,118 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50474; closing.
2023-10-30 05:25:20,119 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41781. Reason: nanny-close
2023-10-30 05:25:20,119 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43693'. Reason: nanny-close
2023-10-30 05:25:20,119 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43577', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643520.1191232')
2023-10-30 05:25:20,119 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:20,119 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:20,119 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:20,119 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44807. Reason: nanny-close
2023-10-30 05:25:20,119 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41133'. Reason: nanny-close
2023-10-30 05:25:20,119 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:20,120 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46233. Reason: nanny-close
2023-10-30 05:25:20,120 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43915. Reason: nanny-close
2023-10-30 05:25:20,120 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:20,120 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50496; closing.
2023-10-30 05:25:20,121 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50488; closing.
2023-10-30 05:25:20,121 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:20,121 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:20,121 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:20,121 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:20,122 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45563', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643520.121934')
2023-10-30 05:25:20,122 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35353', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643520.122321')
2023-10-30 05:25:20,122 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:20,122 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:20,122 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42450; closing.
2023-10-30 05:25:20,123 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:20,123 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33235', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643520.1234872')
2023-10-30 05:25:20,123 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42464; closing.
2023-10-30 05:25:20,124 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:20,124 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:20,124 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:20,124 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41781', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643520.1244547')
2023-10-30 05:25:20,124 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:20,124 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:20,124 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42446; closing.
2023-10-30 05:25:20,125 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50494; closing.
2023-10-30 05:25:20,125 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44807', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643520.1254616')
2023-10-30 05:25:20,125 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46233', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643520.125841')
2023-10-30 05:25:20,126 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42480; closing.
2023-10-30 05:25:20,126 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43915', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643520.1265366')
2023-10-30 05:25:20,126 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:25:21,631 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:25:21,632 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:25:21,632 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:25:21,633 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:25:21,634 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-10-30 05:25:23,764 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:23,768 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:25:23,771 - distributed.scheduler - INFO - State start
2023-10-30 05:25:23,793 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:23,793 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:25:23,794 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:25:23,794 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:25:23,923 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40059'
2023-10-30 05:25:23,940 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45779'
2023-10-30 05:25:23,955 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38459'
2023-10-30 05:25:23,957 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36325'
2023-10-30 05:25:23,965 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45055'
2023-10-30 05:25:23,973 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33563'
2023-10-30 05:25:23,985 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34373'
2023-10-30 05:25:23,995 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32863'
2023-10-30 05:25:25,066 - distributed.scheduler - INFO - Receive client connection: Client-b8cb73ff-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:25,078 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50666
2023-10-30 05:25:25,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:25,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:25,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:25,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:25,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:25,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:25,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:25,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:25,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:25,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:25,838 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:25,841 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:25,862 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:25,862 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:25,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:25,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:25,866 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:25,868 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:25,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:25,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:25,888 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:25,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:25,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:25,965 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:28,430 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44091
2023-10-30 05:25:28,431 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44091
2023-10-30 05:25:28,431 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34011
2023-10-30 05:25:28,431 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,431 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,431 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:28,432 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:28,432 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hftxirmg
2023-10-30 05:25:28,431 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46163
2023-10-30 05:25:28,432 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46163
2023-10-30 05:25:28,432 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44525
2023-10-30 05:25:28,432 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,432 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,432 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3dbb8d98-9880-423a-9fb9-eb9c9f2fc2d1
2023-10-30 05:25:28,432 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:28,432 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:28,432 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nw_wsu9c
2023-10-30 05:25:28,433 - distributed.worker - INFO - Starting Worker plugin PreImport-2436e80c-97dc-4568-83b7-6327bba7471f
2023-10-30 05:25:28,432 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33299
2023-10-30 05:25:28,433 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33299
2023-10-30 05:25:28,433 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9ae83687-d998-4597-b101-a327a3928ea3
2023-10-30 05:25:28,433 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40735
2023-10-30 05:25:28,433 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bda92f75-c20d-4721-b000-986277090490
2023-10-30 05:25:28,433 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,433 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,433 - distributed.worker - INFO - Starting Worker plugin PreImport-83f638aa-c05a-4e60-b096-d261f240b963
2023-10-30 05:25:28,433 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:28,433 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7303510c-9a18-47ac-8ccf-96b489df3f7f
2023-10-30 05:25:28,433 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:28,433 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qrhrq99t
2023-10-30 05:25:28,434 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c970aadb-842a-4210-a379-fecf475894f2
2023-10-30 05:25:28,434 - distributed.worker - INFO - Starting Worker plugin PreImport-1d6c8ff4-74f7-4aa1-a751-8b5620bb13b2
2023-10-30 05:25:28,434 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d011f49e-5533-4f27-8c30-7530d44ba41d
2023-10-30 05:25:28,487 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42021
2023-10-30 05:25:28,489 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42021
2023-10-30 05:25:28,488 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42681
2023-10-30 05:25:28,489 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38917
2023-10-30 05:25:28,489 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42681
2023-10-30 05:25:28,489 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,490 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,490 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40759
2023-10-30 05:25:28,489 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34321
2023-10-30 05:25:28,490 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,490 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:28,490 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34321
2023-10-30 05:25:28,490 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,490 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40155
2023-10-30 05:25:28,490 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:28,490 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sc02h5b2
2023-10-30 05:25:28,490 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:28,490 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,490 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:28,490 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:28,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7xncjb5s
2023-10-30 05:25:28,490 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:28,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-byz_rywb
2023-10-30 05:25:28,491 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-81af3093-d30f-4a94-a821-8e6730dfd66a
2023-10-30 05:25:28,491 - distributed.worker - INFO - Starting Worker plugin PreImport-b2f3d81b-0b9d-4aa1-b583-0b0ff9428ad7
2023-10-30 05:25:28,491 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c4c815f1-5156-4321-be57-3a3aab841fdd
2023-10-30 05:25:28,491 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b2a64be5-32ad-429a-9039-d3101ab74ea8
2023-10-30 05:25:28,491 - distributed.worker - INFO - Starting Worker plugin PreImport-c7f72b1a-0135-46e4-b1cb-88e87d6f0f5d
2023-10-30 05:25:28,491 - distributed.worker - INFO - Starting Worker plugin PreImport-7a66f36a-6ed0-47c5-be0a-4c591097a49a
2023-10-30 05:25:28,491 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a51a2ea2-e0cd-4d13-aa1f-06e953595946
2023-10-30 05:25:28,491 - distributed.worker - INFO - Starting Worker plugin RMMSetup-20e49ee9-7918-4d26-ae83-102ecf4baadc
2023-10-30 05:25:28,502 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39877
2023-10-30 05:25:28,503 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39877
2023-10-30 05:25:28,503 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40147
2023-10-30 05:25:28,503 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,503 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,503 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:28,503 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:28,503 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dcnemivd
2023-10-30 05:25:28,504 - distributed.worker - INFO - Starting Worker plugin PreImport-4b08a527-5746-424b-8f40-6bd7d026953f
2023-10-30 05:25:28,504 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1c84171c-18aa-4414-a71f-0f1e169d19ec
2023-10-30 05:25:28,504 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6a18a175-46e0-40da-9510-e68d3cbd572c
2023-10-30 05:25:28,531 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42461
2023-10-30 05:25:28,533 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42461
2023-10-30 05:25:28,533 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42239
2023-10-30 05:25:28,533 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,533 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,533 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:28,533 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:25:28,533 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ru7ugh2p
2023-10-30 05:25:28,534 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0e787114-cb85-4438-ab18-0d49fde0cd37
2023-10-30 05:25:28,534 - distributed.worker - INFO - Starting Worker plugin PreImport-0ee360b3-4365-4299-a250-41989ca70d42
2023-10-30 05:25:28,534 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3bb53cd9-3661-4328-8a8b-a88e2e0e2c00
2023-10-30 05:25:28,631 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,632 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,632 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,632 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5b11c6a6-d565-4f65-a8de-f939261148ba
2023-10-30 05:25:28,632 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,669 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,675 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,683 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,686 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46163', status: init, memory: 0, processing: 0>
2023-10-30 05:25:28,687 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46163
2023-10-30 05:25:28,688 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50702
2023-10-30 05:25:28,689 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33299', status: init, memory: 0, processing: 0>
2023-10-30 05:25:28,689 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:28,689 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33299
2023-10-30 05:25:28,689 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50688
2023-10-30 05:25:28,690 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,690 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,691 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:28,693 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,693 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,695 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44091', status: init, memory: 0, processing: 0>
2023-10-30 05:25:28,696 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44091
2023-10-30 05:25:28,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50718
2023-10-30 05:25:28,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:28,698 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:28,699 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,700 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,700 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,701 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:28,702 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42681', status: init, memory: 0, processing: 0>
2023-10-30 05:25:28,703 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42681
2023-10-30 05:25:28,703 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50728
2023-10-30 05:25:28,703 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:28,705 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:28,706 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,706 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,710 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:28,717 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42461', status: init, memory: 0, processing: 0>
2023-10-30 05:25:28,718 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42461
2023-10-30 05:25:28,718 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50746
2023-10-30 05:25:28,720 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:28,722 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42021', status: init, memory: 0, processing: 0>
2023-10-30 05:25:28,722 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,722 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,722 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42021
2023-10-30 05:25:28,722 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50736
2023-10-30 05:25:28,724 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34321', status: init, memory: 0, processing: 0>
2023-10-30 05:25:28,724 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:28,725 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34321
2023-10-30 05:25:28,725 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50762
2023-10-30 05:25:28,725 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,725 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,725 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:28,726 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39877', status: init, memory: 0, processing: 0>
2023-10-30 05:25:28,726 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:28,727 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39877
2023-10-30 05:25:28,727 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50764
2023-10-30 05:25:28,728 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,728 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,728 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:28,728 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:28,728 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:28,728 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:28,730 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:28,730 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:28,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:28,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:28,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:28,743 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:28,743 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:28,743 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:28,743 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:28,743 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:25:28,748 - distributed.scheduler - INFO - Remove client Client-b8cb73ff-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:28,748 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50666; closing.
2023-10-30 05:25:28,748 - distributed.scheduler - INFO - Remove client Client-b8cb73ff-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:28,749 - distributed.scheduler - INFO - Close client connection: Client-b8cb73ff-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:28,750 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40059'. Reason: nanny-close
2023-10-30 05:25:28,751 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:28,752 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45779'. Reason: nanny-close
2023-10-30 05:25:28,752 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42681. Reason: nanny-close
2023-10-30 05:25:28,752 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:28,752 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38459'. Reason: nanny-close
2023-10-30 05:25:28,753 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:28,753 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42021. Reason: nanny-close
2023-10-30 05:25:28,753 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36325'. Reason: nanny-close
2023-10-30 05:25:28,753 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:28,753 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46163. Reason: nanny-close
2023-10-30 05:25:28,754 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45055'. Reason: nanny-close
2023-10-30 05:25:28,754 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:28,754 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:28,754 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33299. Reason: nanny-close
2023-10-30 05:25:28,754 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50728; closing.
2023-10-30 05:25:28,754 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33563'. Reason: nanny-close
2023-10-30 05:25:28,754 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42681', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643528.754836')
2023-10-30 05:25:28,754 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:28,755 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44091. Reason: nanny-close
2023-10-30 05:25:28,755 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:28,755 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34373'. Reason: nanny-close
2023-10-30 05:25:28,755 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:28,755 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:28,755 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42461. Reason: nanny-close
2023-10-30 05:25:28,755 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32863'. Reason: nanny-close
2023-10-30 05:25:28,756 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:28,756 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39877. Reason: nanny-close
2023-10-30 05:25:28,756 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:28,756 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:28,756 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50702; closing.
2023-10-30 05:25:28,757 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50736; closing.
2023-10-30 05:25:28,757 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:28,757 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34321. Reason: nanny-close
2023-10-30 05:25:28,757 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:28,757 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46163', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643528.7578084')
2023-10-30 05:25:28,757 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:28,758 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:28,758 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42021', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643528.758175')
2023-10-30 05:25:28,758 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:28,758 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:28,758 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50688; closing.
2023-10-30 05:25:28,758 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:28,759 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33299', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643528.7589557')
2023-10-30 05:25:28,759 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:28,759 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50718; closing.
2023-10-30 05:25:28,759 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:28,760 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50746; closing.
2023-10-30 05:25:28,760 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:28,760 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50764; closing.
2023-10-30 05:25:28,760 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:28,760 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44091', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643528.7606874')
2023-10-30 05:25:28,761 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42461', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643528.761152')
2023-10-30 05:25:28,761 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39877', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643528.7615633')
2023-10-30 05:25:28,761 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50762; closing.
2023-10-30 05:25:28,762 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34321', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643528.7623782')
2023-10-30 05:25:28,762 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:25:30,267 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:25:30,267 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:25:30,268 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:25:30,269 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:25:30,269 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-10-30 05:25:32,352 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:32,359 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:25:32,364 - distributed.scheduler - INFO - State start
2023-10-30 05:25:32,391 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:32,392 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:25:32,393 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:25:32,394 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:25:32,486 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39641'
2023-10-30 05:25:33,216 - distributed.scheduler - INFO - Receive client connection: Client-bde6d89f-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:33,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38124
2023-10-30 05:25:34,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:34,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:34,719 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:35,750 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44139
2023-10-30 05:25:35,751 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44139
2023-10-30 05:25:35,751 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-10-30 05:25:35,751 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:35,751 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:35,751 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:35,751 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-30 05:25:35,751 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nt3rrtnw
2023-10-30 05:25:35,752 - distributed.worker - INFO - Starting Worker plugin PreImport-1b5d9c78-b47b-494e-8ab2-e3c7b9ea8436
2023-10-30 05:25:35,752 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-97079c2c-4d09-4cff-b0f6-8586f730f5f3
2023-10-30 05:25:35,752 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6e5c2371-6d43-48bc-9f11-0da911389bed
2023-10-30 05:25:35,753 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:35,782 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44139', status: init, memory: 0, processing: 0>
2023-10-30 05:25:35,784 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44139
2023-10-30 05:25:35,784 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38144
2023-10-30 05:25:35,785 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:35,786 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:35,786 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:35,788 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:35,806 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:35,809 - distributed.scheduler - INFO - Remove client Client-bde6d89f-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:35,809 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38124; closing.
2023-10-30 05:25:35,809 - distributed.scheduler - INFO - Remove client Client-bde6d89f-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:35,809 - distributed.scheduler - INFO - Close client connection: Client-bde6d89f-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:35,810 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39641'. Reason: nanny-close
2023-10-30 05:25:35,828 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:35,829 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44139. Reason: nanny-close
2023-10-30 05:25:35,831 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:35,831 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38144; closing.
2023-10-30 05:25:35,831 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44139', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643535.8316185')
2023-10-30 05:25:35,831 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:25:35,832 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:36,977 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:25:36,977 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:25:36,978 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:25:36,979 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:25:36,980 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-10-30 05:25:41,022 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:41,027 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:25:41,030 - distributed.scheduler - INFO - State start
2023-10-30 05:25:41,051 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:41,051 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:25:41,052 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:25:41,052 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:25:41,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40231'
2023-10-30 05:25:41,218 - distributed.scheduler - INFO - Receive client connection: Client-c3200352-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:41,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47572
2023-10-30 05:25:42,727 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:42,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:43,269 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:44,075 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35577
2023-10-30 05:25:44,076 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35577
2023-10-30 05:25:44,076 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45829
2023-10-30 05:25:44,076 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:25:44,076 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:44,076 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:44,076 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-30 05:25:44,076 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mdjcib8w
2023-10-30 05:25:44,077 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-205bca46-e3f0-43a3-b7bb-81af2f6d7d4c
2023-10-30 05:25:44,077 - distributed.worker - INFO - Starting Worker plugin PreImport-937e51df-f72d-4dfc-b61a-4c5808ebc934
2023-10-30 05:25:44,078 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e9a69885-f8d2-4594-9656-f1d05e038d8b
2023-10-30 05:25:44,079 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:44,107 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35577', status: init, memory: 0, processing: 0>
2023-10-30 05:25:44,108 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35577
2023-10-30 05:25:44,108 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47590
2023-10-30 05:25:44,109 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:44,109 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:25:44,109 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:44,112 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:25:44,183 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:44,186 - distributed.scheduler - INFO - Remove client Client-c3200352-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:44,186 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47572; closing.
2023-10-30 05:25:44,186 - distributed.scheduler - INFO - Remove client Client-c3200352-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:44,187 - distributed.scheduler - INFO - Close client connection: Client-c3200352-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:44,188 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40231'. Reason: nanny-close
2023-10-30 05:25:44,188 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:44,190 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35577. Reason: nanny-close
2023-10-30 05:25:44,192 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47590; closing.
2023-10-30 05:25:44,192 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:25:44,192 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35577', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643544.1925757')
2023-10-30 05:25:44,192 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:25:44,194 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:45,354 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:25:45,355 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:25:45,355 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:25:45,356 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:25:45,357 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-10-30 05:25:47,341 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:47,345 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:25:47,349 - distributed.scheduler - INFO - State start
2023-10-30 05:25:47,370 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:47,371 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:25:47,372 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:25:47,372 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:25:51,125 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:47602'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:47602>: Stream is closed
2023-10-30 05:25:51,420 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:25:51,420 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:25:51,420 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:25:51,421 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:25:51,421 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-10-30 05:25:53,257 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:53,261 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:25:53,264 - distributed.scheduler - INFO - State start
2023-10-30 05:25:53,285 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:53,286 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-30 05:25:53,287 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:25:53,287 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:25:53,441 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40449'
2023-10-30 05:25:53,823 - distributed.scheduler - INFO - Receive client connection: Client-ca87525a-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:53,835 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41992
2023-10-30 05:25:54,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:25:54,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:25:54,902 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:25:55,811 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46071
2023-10-30 05:25:55,811 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46071
2023-10-30 05:25:55,811 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41843
2023-10-30 05:25:55,811 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-30 05:25:55,811 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:55,812 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:25:55,812 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-30 05:25:55,812 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-n0madaud
2023-10-30 05:25:55,812 - distributed.worker - INFO - Starting Worker plugin PreImport-b3f2ba01-cdba-44fd-8e79-777c4e56e815
2023-10-30 05:25:55,812 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-21ba442f-c738-4f04-8c07-833b107acf55
2023-10-30 05:25:55,813 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8033c3de-9d32-4cc8-b587-826f1eca4c44
2023-10-30 05:25:55,813 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:55,841 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46071', status: init, memory: 0, processing: 0>
2023-10-30 05:25:55,842 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46071
2023-10-30 05:25:55,842 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42018
2023-10-30 05:25:55,843 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:25:55,844 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-30 05:25:55,844 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:25:55,846 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-30 05:25:55,870 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:25:55,873 - distributed.scheduler - INFO - Remove client Client-ca87525a-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:55,873 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41992; closing.
2023-10-30 05:25:55,873 - distributed.scheduler - INFO - Remove client Client-ca87525a-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:55,874 - distributed.scheduler - INFO - Close client connection: Client-ca87525a-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:55,874 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40449'. Reason: nanny-close
2023-10-30 05:25:55,875 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:25:55,876 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46071. Reason: nanny-close
2023-10-30 05:25:55,878 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-30 05:25:55,878 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42018; closing.
2023-10-30 05:25:55,878 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46071', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643555.8783119')
2023-10-30 05:25:55,878 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:25:55,879 - distributed.nanny - INFO - Worker closed
2023-10-30 05:25:56,790 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:25:56,791 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:25:56,791 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:25:56,792 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-30 05:25:56,792 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-10-30 05:25:58,870 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:58,874 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:25:58,877 - distributed.scheduler - INFO - State start
2023-10-30 05:25:58,898 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:25:58,899 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:25:58,899 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:25:58,900 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:25:59,004 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38373'
2023-10-30 05:25:59,016 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44939'
2023-10-30 05:25:59,024 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36715'
2023-10-30 05:25:59,038 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34801'
2023-10-30 05:25:59,041 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36981'
2023-10-30 05:25:59,049 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42873'
2023-10-30 05:25:59,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33137'
2023-10-30 05:25:59,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40393'
2023-10-30 05:25:59,156 - distributed.scheduler - INFO - Receive client connection: Client-cdc58287-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:25:59,172 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40282
2023-10-30 05:26:00,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:00,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:00,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:00,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:00,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:00,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:00,849 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:00,850 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:00,850 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:00,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:00,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:00,879 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:00,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:00,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:00,891 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:00,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:00,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:00,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:00,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:00,903 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:00,906 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:00,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:00,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:00,929 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:03,193 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36279
2023-10-30 05:26:03,194 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36279
2023-10-30 05:26:03,194 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38417
2023-10-30 05:26:03,194 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,194 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,194 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:03,194 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:26:03,194 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jgysf8vg
2023-10-30 05:26:03,195 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f1916995-70c2-49ab-86f0-0f0fa7880615
2023-10-30 05:26:03,195 - distributed.worker - INFO - Starting Worker plugin PreImport-23afd4d6-9597-4942-8ec8-214f1b357118
2023-10-30 05:26:03,195 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e5a81004-981f-455d-befd-01810a3dceda
2023-10-30 05:26:03,309 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43075
2023-10-30 05:26:03,309 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43075
2023-10-30 05:26:03,309 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32783
2023-10-30 05:26:03,309 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,309 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,310 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:03,310 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:26:03,310 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t2ty7x1t
2023-10-30 05:26:03,310 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-384c8ef3-3684-4a6f-809b-bc3bee906f6e
2023-10-30 05:26:03,311 - distributed.worker - INFO - Starting Worker plugin PreImport-471b9526-9cf2-4241-b197-bb56fb9244e4
2023-10-30 05:26:03,311 - distributed.worker - INFO - Starting Worker plugin RMMSetup-44effec4-d52e-4f37-bfc2-09d1efa1c31c
2023-10-30 05:26:03,312 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33295
2023-10-30 05:26:03,312 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33295
2023-10-30 05:26:03,312 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33109
2023-10-30 05:26:03,312 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,313 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,313 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:03,313 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:26:03,313 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4m4x9cpk
2023-10-30 05:26:03,312 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39043
2023-10-30 05:26:03,313 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39043
2023-10-30 05:26:03,313 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40661
2023-10-30 05:26:03,313 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,313 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,313 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d3bd0340-1df0-43d8-ba23-aac77ea36268
2023-10-30 05:26:03,313 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:03,313 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:26:03,314 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w73xrb5j
2023-10-30 05:26:03,314 - distributed.worker - INFO - Starting Worker plugin PreImport-7f9ecf62-6382-4a5e-a54c-749ba5128553
2023-10-30 05:26:03,314 - distributed.worker - INFO - Starting Worker plugin RMMSetup-29165c97-183a-4c77-b677-52afff1b7660
2023-10-30 05:26:03,314 - distributed.worker - INFO - Starting Worker plugin PreImport-3f5222aa-5cda-4672-b54f-d325fbdd3157
2023-10-30 05:26:03,314 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3806a35d-420e-4782-89cc-0f909ac678e3
2023-10-30 05:26:03,314 - distributed.worker - INFO - Starting Worker plugin RMMSetup-196f1a3a-6b04-49fe-a354-c14cab78c0b7
2023-10-30 05:26:03,317 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,322 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40579
2023-10-30 05:26:03,323 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40579
2023-10-30 05:26:03,323 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40381
2023-10-30 05:26:03,323 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,323 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,323 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:03,323 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:26:03,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cey3ofl7
2023-10-30 05:26:03,324 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5d88d603-4fa8-4b4d-a9db-9e3dfccceb23
2023-10-30 05:26:03,325 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46269
2023-10-30 05:26:03,326 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46269
2023-10-30 05:26:03,326 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43105
2023-10-30 05:26:03,326 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,326 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,326 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:03,326 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:26:03,326 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s87wnwi8
2023-10-30 05:26:03,327 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f7ea0f9e-ba96-4b09-bb60-3cb115da2de1
2023-10-30 05:26:03,327 - distributed.worker - INFO - Starting Worker plugin PreImport-8b23dad8-6583-43f7-b48c-a884df10dc7e
2023-10-30 05:26:03,327 - distributed.worker - INFO - Starting Worker plugin PreImport-4d8d5018-f32b-4c09-bfb7-5d8f53aedaa3
2023-10-30 05:26:03,328 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0e05ce36-6a54-4897-b705-5c9218a557a2
2023-10-30 05:26:03,328 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8a47dc0c-c9cd-41f6-8674-fe393e935acc
2023-10-30 05:26:03,341 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36279', status: init, memory: 0, processing: 0>
2023-10-30 05:26:03,343 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36279
2023-10-30 05:26:03,343 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54124
2023-10-30 05:26:03,344 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:03,345 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,345 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,346 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:03,346 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41339
2023-10-30 05:26:03,347 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41339
2023-10-30 05:26:03,347 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35009
2023-10-30 05:26:03,347 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,347 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,346 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33075
2023-10-30 05:26:03,347 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:03,347 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33075
2023-10-30 05:26:03,348 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:26:03,348 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34873
2023-10-30 05:26:03,348 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ln9xflxk
2023-10-30 05:26:03,348 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,348 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,348 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:03,348 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-30 05:26:03,348 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-muflj9bu
2023-10-30 05:26:03,348 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-23e50037-60d1-42a9-aa3d-437be2599f2a
2023-10-30 05:26:03,348 - distributed.worker - INFO - Starting Worker plugin PreImport-159d3604-044b-4c48-815c-4a3af29d8d99
2023-10-30 05:26:03,348 - distributed.worker - INFO - Starting Worker plugin RMMSetup-10553e4e-2064-423d-969e-d666598db765
2023-10-30 05:26:03,348 - distributed.worker - INFO - Starting Worker plugin PreImport-baea7635-9514-465b-bbe9-aa9fb3248195
2023-10-30 05:26:03,349 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dfc67090-0550-4bf9-b800-dd69d03a1905
2023-10-30 05:26:03,462 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,471 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,471 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,471 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,471 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,475 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,485 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8c28c2eb-cc15-4dc0-83a8-57f5b4968b55
2023-10-30 05:26:03,486 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,495 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33295', status: init, memory: 0, processing: 0>
2023-10-30 05:26:03,496 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33295
2023-10-30 05:26:03,496 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54150
2023-10-30 05:26:03,496 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39043', status: init, memory: 0, processing: 0>
2023-10-30 05:26:03,497 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:03,497 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39043
2023-10-30 05:26:03,497 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54148
2023-10-30 05:26:03,497 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,498 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,498 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43075', status: init, memory: 0, processing: 0>
2023-10-30 05:26:03,498 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:03,498 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43075
2023-10-30 05:26:03,498 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54140
2023-10-30 05:26:03,499 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,499 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,499 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:03,499 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46269', status: init, memory: 0, processing: 0>
2023-10-30 05:26:03,500 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:03,500 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46269
2023-10-30 05:26:03,500 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54166
2023-10-30 05:26:03,501 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,501 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:03,501 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,501 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40579', status: init, memory: 0, processing: 0>
2023-10-30 05:26:03,501 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:03,502 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40579
2023-10-30 05:26:03,502 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54172
2023-10-30 05:26:03,502 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,502 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,503 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41339', status: init, memory: 0, processing: 0>
2023-10-30 05:26:03,503 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:03,503 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41339
2023-10-30 05:26:03,503 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54184
2023-10-30 05:26:03,503 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:03,504 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:03,504 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,504 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,504 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:03,505 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,505 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,507 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:03,507 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:03,517 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33075', status: init, memory: 0, processing: 0>
2023-10-30 05:26:03,517 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33075
2023-10-30 05:26:03,517 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54196
2023-10-30 05:26:03,519 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:03,519 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:03,520 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:03,522 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:03,578 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:26:03,579 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:26:03,579 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:26:03,579 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:26:03,579 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:26:03,579 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:26:03,580 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:26:03,580 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-30 05:26:03,592 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:03,592 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:03,592 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:03,592 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:03,592 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:03,592 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:03,592 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:03,593 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:03,596 - distributed.scheduler - INFO - Remove client Client-cdc58287-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:03,596 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40282; closing.
2023-10-30 05:26:03,597 - distributed.scheduler - INFO - Remove client Client-cdc58287-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:03,597 - distributed.scheduler - INFO - Close client connection: Client-cdc58287-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:03,598 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38373'. Reason: nanny-close
2023-10-30 05:26:03,598 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:03,599 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44939'. Reason: nanny-close
2023-10-30 05:26:03,600 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:03,600 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33075. Reason: nanny-close
2023-10-30 05:26:03,600 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36715'. Reason: nanny-close
2023-10-30 05:26:03,600 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:03,600 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43075. Reason: nanny-close
2023-10-30 05:26:03,601 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34801'. Reason: nanny-close
2023-10-30 05:26:03,601 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:03,601 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36279. Reason: nanny-close
2023-10-30 05:26:03,601 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36981'. Reason: nanny-close
2023-10-30 05:26:03,601 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:03,602 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33295. Reason: nanny-close
2023-10-30 05:26:03,602 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:03,602 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42873'. Reason: nanny-close
2023-10-30 05:26:03,602 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54196; closing.
2023-10-30 05:26:03,602 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:03,602 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40579. Reason: nanny-close
2023-10-30 05:26:03,602 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33075', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643563.602702')
2023-10-30 05:26:03,602 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33137'. Reason: nanny-close
2023-10-30 05:26:03,602 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:03,602 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:03,603 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:03,603 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54124; closing.
2023-10-30 05:26:03,603 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46269. Reason: nanny-close
2023-10-30 05:26:03,603 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40393'. Reason: nanny-close
2023-10-30 05:26:03,603 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:03,603 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39043. Reason: nanny-close
2023-10-30 05:26:03,603 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36279', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643563.6036673')
2023-10-30 05:26:03,603 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:03,604 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:03,604 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41339. Reason: nanny-close
2023-10-30 05:26:03,604 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:03,604 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54140; closing.
2023-10-30 05:26:03,604 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:03,605 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:03,605 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:03,605 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:03,605 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:54124>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-30 05:26:03,606 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:03,606 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:03,606 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54150; closing.
2023-10-30 05:26:03,606 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43075', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643563.606857')
2023-10-30 05:26:03,607 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:03,607 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:03,607 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33295', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643563.6076248')
2023-10-30 05:26:03,607 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:03,608 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54172; closing.
2023-10-30 05:26:03,608 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:03,608 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40579', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643563.6087148')
2023-10-30 05:26:03,609 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54148; closing.
2023-10-30 05:26:03,609 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54166; closing.
2023-10-30 05:26:03,609 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54184; closing.
2023-10-30 05:26:03,609 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39043', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643563.6097448')
2023-10-30 05:26:03,610 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46269', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643563.6102047')
2023-10-30 05:26:03,610 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41339', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643563.6105545')
2023-10-30 05:26:03,610 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:26:05,015 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:26:05,015 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:26:05,016 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:26:05,017 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:26:05,017 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-10-30 05:26:07,048 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:26:07,052 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:26:07,055 - distributed.scheduler - INFO - State start
2023-10-30 05:26:07,077 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:26:07,078 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:26:07,079 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:26:07,079 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:26:07,118 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44383'
2023-10-30 05:26:07,472 - distributed.scheduler - INFO - Receive client connection: Client-d2a77723-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:07,485 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54288
2023-10-30 05:26:08,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:08,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:08,621 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:09,440 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38063
2023-10-30 05:26:09,441 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38063
2023-10-30 05:26:09,441 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44693
2023-10-30 05:26:09,441 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:09,441 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:09,441 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:09,441 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-30 05:26:09,441 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kmjo4m5h
2023-10-30 05:26:09,441 - distributed.worker - INFO - Starting Worker plugin PreImport-1f613931-214f-431a-a1df-7bea031ad689
2023-10-30 05:26:09,442 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d5aaa443-3aa4-489e-9069-d38cd713b8e3
2023-10-30 05:26:09,531 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3613c8f9-5544-4976-8c8b-9d21dc0aa080
2023-10-30 05:26:09,531 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:09,561 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38063', status: init, memory: 0, processing: 0>
2023-10-30 05:26:09,562 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38063
2023-10-30 05:26:09,562 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54310
2023-10-30 05:26:09,563 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:09,564 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:09,564 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:09,565 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:09,625 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:26:09,629 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:09,630 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:09,633 - distributed.scheduler - INFO - Remove client Client-d2a77723-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:09,633 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54288; closing.
2023-10-30 05:26:09,633 - distributed.scheduler - INFO - Remove client Client-d2a77723-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:09,633 - distributed.scheduler - INFO - Close client connection: Client-d2a77723-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:09,634 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44383'. Reason: nanny-close
2023-10-30 05:26:09,635 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:09,636 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38063. Reason: nanny-close
2023-10-30 05:26:09,637 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:09,637 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54310; closing.
2023-10-30 05:26:09,638 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38063', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643569.6382089')
2023-10-30 05:26:09,638 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:26:09,639 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:10,601 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:26:10,601 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:26:10,601 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:26:10,602 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:26:10,603 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-10-30 05:26:12,549 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:26:12,553 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-30 05:26:12,556 - distributed.scheduler - INFO - State start
2023-10-30 05:26:12,577 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-30 05:26:12,578 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-30 05:26:12,578 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-30 05:26:12,579 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-30 05:26:12,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40157'
2023-10-30 05:26:14,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-30 05:26:14,099 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-30 05:26:14,102 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-30 05:26:14,424 - distributed.scheduler - INFO - Receive client connection: Client-d5f718de-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:14,436 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39170
2023-10-30 05:26:14,914 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40507
2023-10-30 05:26:14,914 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40507
2023-10-30 05:26:14,915 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46401
2023-10-30 05:26:14,915 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-30 05:26:14,915 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:14,915 - distributed.worker - INFO -               Threads:                          1
2023-10-30 05:26:14,915 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-30 05:26:14,915 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-upes4rtf
2023-10-30 05:26:14,915 - distributed.worker - INFO - Starting Worker plugin PreImport-40f5c976-39da-471d-8668-5b8f96541d8e
2023-10-30 05:26:14,916 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-be84a8b0-acbf-47d2-a833-935a41f610fd
2023-10-30 05:26:14,916 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2cedd647-52f9-4c2c-9260-215fac6b754d
2023-10-30 05:26:15,023 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:15,052 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40507', status: init, memory: 0, processing: 0>
2023-10-30 05:26:15,053 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40507
2023-10-30 05:26:15,054 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39188
2023-10-30 05:26:15,054 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-30 05:26:15,055 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-30 05:26:15,055 - distributed.worker - INFO - -------------------------------------------------
2023-10-30 05:26:15,057 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-30 05:26:15,152 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-10-30 05:26:15,155 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-30 05:26:15,159 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:15,160 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-30 05:26:15,162 - distributed.scheduler - INFO - Remove client Client-d5f718de-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:15,162 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39170; closing.
2023-10-30 05:26:15,163 - distributed.scheduler - INFO - Remove client Client-d5f718de-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:15,163 - distributed.scheduler - INFO - Close client connection: Client-d5f718de-76e4-11ee-bd97-d8c49764f6bb
2023-10-30 05:26:15,164 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40157'. Reason: nanny-close
2023-10-30 05:26:15,165 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-30 05:26:15,166 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40507. Reason: nanny-close
2023-10-30 05:26:15,167 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39188; closing.
2023-10-30 05:26:15,167 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-30 05:26:15,168 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40507', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698643575.168279')
2023-10-30 05:26:15,168 - distributed.scheduler - INFO - Lost all workers
2023-10-30 05:26:15,169 - distributed.nanny - INFO - Worker closed
2023-10-30 05:26:16,081 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-30 05:26:16,082 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-30 05:26:16,082 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-30 05:26:16,083 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-30 05:26:16,084 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] 2023-10-30 05:27:19,616 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-10-30 05:27:19,618 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-30 05:27:19,618 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-10-30 05:27:19,621 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:57568', name: 2, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-30 05:27:19,623 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1510, in _connect
    async def _connect(self, addr: str, timeout: float | None = None) -> Comm:
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
Task exception was never retrieved
future: <Task finished name='Task-1344' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] [1698643676.378222] [dgx13:70386:0]            sock.c:470  UCX  ERROR bind(fd=138 addr=0.0.0.0:53338) failed: Address already in use
[1698643677.843192] [dgx13:70479:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:37948) failed: Address already in use
[1698643677.843251] [dgx13:70479:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:33756) failed: Address already in use
[1698643680.044915] [dgx13:70472:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:58538) failed: Address already in use
[1698643680.045009] [dgx13:70472:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:58128) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] [1698643818.380741] [dgx13:73269:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:38938) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38807 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42793 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38285 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] [1698644023.775326] [dgx13:77358:0]            sock.c:470  UCX  ERROR bind(fd=134 addr=0.0.0.0:34933) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] [1698644052.007638] [dgx13:77889:0]            sock.c:470  UCX  ERROR bind(fd=135 addr=0.0.0.0:49586) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] 2023-10-30 05:37:18,244 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-30 05:37:18,254 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-30 05:37:18,422 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-30 05:37:18,431 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-30 05:37:18,447 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'ucx://127.0.0.1:49345'.
2023-10-30 05:37:18,447 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'ucx://127.0.0.1:44787'.
2023-10-30 05:37:18,448 - distributed.worker - ERROR - Scheduler was unaware of this worker 'ucx://127.0.0.1:49345'. Shutting down.
2023-10-30 05:37:18,462 - distributed.worker - ERROR - Scheduler was unaware of this worker 'ucx://127.0.0.1:44787'. Shutting down.
2023-10-30 05:37:18,476 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7ff657f364f0>>, <Task finished name='Task-17' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-17' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-30 05:37:18,478 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7ff7095d74f0>>, <Task finished name='Task-17' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-17' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 407, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 158, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/core.py", line 150, in _decode_default
    return pickle.loads(sub_header["pickled-obj"], buffers=sub_frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-30 05:37:20,479 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-10-30 05:37:20,481 - distributed.nanny - ERROR - Worker process died unexpectedly
