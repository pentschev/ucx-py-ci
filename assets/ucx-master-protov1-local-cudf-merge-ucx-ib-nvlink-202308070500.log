2023-08-07 06:10:10,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:10,440 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:10,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:10,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:10,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:10,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:10,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:10,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:10,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:10,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:10,597 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:10,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:10,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:10,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:10,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:10,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[1691388620.563192] [dgx13:69651:0]    ib_mlx5dv_md.c:407  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:69651:0:69651]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  69651) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f81cdcb2ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f81cdcb08a1]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a3c) [0x7f81cdcb0a3c]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x72c14) [0x7f81cdd5ac14]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f81cdd32e3f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f81cdd6eddd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x707) [0x7f81cdd743a7]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f81cdd7502f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6cec2) [0x7f81cde25ec2]
 9  /opt/conda/envs/gdf/bin/python(+0x149dc7) [0x55cd5c50edc7]
10  /opt/conda/envs/gdf/bin/python(PyObject_Call+0x158) [0x55cd5c50d1a8]
11  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55cd5c4f3d36]
12  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55cd5c4ed27a]
13  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55cd5c4fec05]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55cd5c4ef3cb]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55cd5c4ed27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55cd5c4fec05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55cd5c4ef3cb]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55cd5c51370e]
19  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55cd5c4f4923]
20  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55cd5c51370e]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55cd5c4f4923]
22  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55cd5c51370e]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55cd5c4f4923]
24  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55cd5c51370e]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55cd5c4f4923]
26  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55cd5c51370e]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55cd5c4f4923]
28  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55cd5c51370e]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f82644272fe]
30  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8b4e) [0x7f8264427b4e]
31  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55cd5c4f72bc]
32  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55cd5c4aa817]
33  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55cd5c4f5f83]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55cd5c4f3d36]
35  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55cd5c4feef3]
36  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55cd5c4ee81b]
37  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55cd5c4feef3]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55cd5c4ee81b]
39  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55cd5c4feef3]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55cd5c4ee81b]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55cd5c4feef3]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55cd5c4ee81b]
43  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55cd5c4ed27a]
44  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55cd5c4fec05]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55cd5c4f2fa7]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55cd5c4ed27a]
47  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55cd5c50c935]
48  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55cd5c50d104]
49  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55cd5c5d3fc8]
50  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55cd5c4f72bc]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55cd5c4f21bb]
52  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55cd5c4feef3]
53  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55cd5c50cc72]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55cd5c4f21bb]
55  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55cd5c4feef3]
56  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55cd5c4ee81b]
57  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55cd5c4ed27a]
58  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55cd5c4fec05]
59  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55cd5c4ee81b]
60  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55cd5c4feef3]
61  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55cd5c4ee568]
=================================
[1691388620.683659] [dgx13:69660:0]    ib_mlx5dv_md.c:407  UCX  ERROR mlx5_0: LRU push returned Unsupported operation
[dgx13:69660:0:69660]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  69660) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f1841ac4ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f1841ac28a1]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a3c) [0x7f1841ac2a3c]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x72c14) [0x7f1841b6cc14]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f1841b44e3f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f1841b80ddd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x707) [0x7f1841b863a7]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f1841b8702f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6cec2) [0x7f1841c37ec2]
 9  /opt/conda/envs/gdf/bin/python(+0x149dc7) [0x55fc01a61dc7]
10  /opt/conda/envs/gdf/bin/python(PyObject_Call+0x158) [0x55fc01a601a8]
11  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55fc01a46d36]
12  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fc01a4027a]
13  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fc01a51c05]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55fc01a423cb]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fc01a4027a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fc01a51c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55fc01a423cb]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55fc01a6670e]
19  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55fc01a47923]
20  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55fc01a6670e]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55fc01a47923]
22  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55fc01a6670e]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55fc01a47923]
24  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55fc01a6670e]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55fc01a47923]
26  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55fc01a6670e]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x55fc01a47923]
28  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55fc01a6670e]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f1867ed32fe]
30  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8b4e) [0x7f1867ed3b4e]
31  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55fc01a4a2bc]
32  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55fc019fd817]
33  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55fc01a48f83]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55fc01a46d36]
35  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fc01a51ef3]
36  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fc01a4181b]
37  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fc01a51ef3]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fc01a4181b]
39  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fc01a51ef3]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fc01a4181b]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fc01a51ef3]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fc01a4181b]
43  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fc01a4027a]
44  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fc01a51c05]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55fc01a45fa7]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fc01a4027a]
47  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55fc01a5f935]
48  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55fc01a60104]
49  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55fc01b26fc8]
50  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55fc01a4a2bc]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55fc01a451bb]
52  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fc01a51ef3]
53  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55fc01a5fc72]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55fc01a451bb]
55  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fc01a51ef3]
56  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fc01a4181b]
57  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55fc01a4027a]
58  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55fc01a51c05]
59  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55fc01a4181b]
60  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55fc01a51ef3]
61  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55fc01a41568]
=================================
[1691388620.753728] [dgx13:69644:0]    ib_mlx5dv_md.c:407  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:69644:0:69644]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  69644) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fdc6069aced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7fdc606988a1]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x28a3c) [0x7fdc60698a3c]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x72c14) [0x7fdc60742c14]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7fdc6071ae3f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7fdc60756ddd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x707) [0x7fdc6075c3a7]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7fdc6075d02f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6cec2) [0x7fdc6080dec2]
 9  /opt/conda/envs/gdf/bin/python(+0x149dc7) [0x558ca83b5dc7]
10  /opt/conda/envs/gdf/bin/python(PyObject_Call+0x158) [0x558ca83b41a8]
11  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x558ca839ad36]
12  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558ca839427a]
13  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x558ca83a5c05]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x558ca83963cb]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558ca839427a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x558ca83a5c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x558ca83963cb]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558ca83ba70e]
19  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558ca839b923]
20  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558ca83ba70e]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558ca839b923]
22  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558ca83ba70e]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558ca839b923]
24  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558ca83ba70e]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558ca839b923]
26  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558ca83ba70e]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x558ca839b923]
28  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x558ca83ba70e]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fdc72a932fe]
30  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8b4e) [0x7fdc72a93b4e]
31  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x558ca839e2bc]
32  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x558ca8351817]
33  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x558ca839cf83]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x558ca839ad36]
35  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558ca83a5ef3]
36  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558ca839581b]
37  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558ca83a5ef3]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558ca839581b]
39  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558ca83a5ef3]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558ca839581b]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558ca83a5ef3]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558ca839581b]
43  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558ca839427a]
44  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x558ca83a5c05]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x558ca8399fa7]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558ca839427a]
47  /opt/conda/envs/gdf/bin/python(+0x147935) [0x558ca83b3935]
48  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x558ca83b4104]
49  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x558ca847afc8]
50  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x558ca839e2bc]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x558ca83991bb]
52  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558ca83a5ef3]
53  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x558ca83b3c72]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x558ca83991bb]
55  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558ca83a5ef3]
56  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558ca839581b]
57  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x558ca839427a]
58  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x558ca83a5c05]
59  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x558ca839581b]
60  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x558ca83a5ef3]
61  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x558ca8395568]
=================================
Task exception was never retrieved
future: <Task finished name='Task-903' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-08-07 06:10:20,818 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd4b132c1c0, tag: 0x212bd400670901ea, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd4b132c1c0, tag: 0x212bd400670901ea, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:20,819 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fcba15da280, tag: 0x6127fa8cf09f8848, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fcba15da280, tag: 0x6127fa8cf09f8848, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:20,819 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f65dded6140, tag: 0x4f932a3b8e9a794e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f65dded6140, tag: 0x4f932a3b8e9a794e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:20,830 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 330, in connect
    await wait_for(comm.write(local_info), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 289, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:52044 after 30 s
2023-08-07 06:10:20,832 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:36650 -> ucx://127.0.0.1:52044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 289, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-08-07 06:10:20,972 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43830
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f65dded6280, tag: 0x7fa7d9e0a8d700fa, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f65dded6280, tag: 0x7fa7d9e0a8d700fa, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:43830 after 30 s
2023-08-07 06:10:21,007 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f1e8162a240, tag: 0x1a0f5eddb2626d3a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f1e8162a240, tag: 0x1a0f5eddb2626d3a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-07 06:10:21,008 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43830
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f1e8162a200, tag: 0xcd3b23c31110a5c6, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f1e8162a200, tag: 0xcd3b23c31110a5c6, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:21,060 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52948 -> ucx://127.0.0.1:52044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd4b132c2c0, tag: 0x457b567270472e9e, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,061 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52948 -> ucx://127.0.0.1:43830
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd4b132c380, tag: 0x599b835c1f074d3a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,061 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52948 -> ucx://127.0.0.1:59031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd4b132c340, tag: 0x1ccfa681599151f7, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,063 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd4b132c200, tag: 0x784013343d248f21, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd4b132c200, tag: 0x784013343d248f21, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:21,063 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43830
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd4b132c140, tag: 0x2e8b4e5b9b13e34a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd4b132c140, tag: 0x2e8b4e5b9b13e34a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:21,102 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39720 -> ucx://127.0.0.1:52044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcba15da340, tag: 0x2462760db1835f89, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,103 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:39720 -> ucx://127.0.0.1:43830
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcba15da380, tag: 0x2e332c66d3eb7edb, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,104 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43830
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fcba15da240, tag: 0x1cebfa7960e4673e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fcba15da240, tag: 0x1cebfa7960e4673e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:21,106 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fcba15da140, tag: 0xbff29c6cb1597356, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fcba15da140, tag: 0xbff29c6cb1597356, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:21,148 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:43983 -> ucx://127.0.0.1:52044
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1e8162a300, tag: 0xd3be489fe1291455, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,148 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:43983 -> ucx://127.0.0.1:43830
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1e8162a380, tag: 0xab56f5965f605efd, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,149 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:43983 -> ucx://127.0.0.1:59031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1e8162a3c0, tag: 0x8d4620b9b76e7c87, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,150 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f1e8162a180, tag: 0x2451b343304e77b8, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f1e8162a180, tag: 0x2451b343304e77b8, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:21,277 - distributed.nanny - WARNING - Restarting worker
2023-08-07 06:10:21,287 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:36650 -> ucx://127.0.0.1:43830
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fbd402ff440, tag: 0xf09b4d54cdf46dc5, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,288 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:36650 -> ucx://127.0.0.1:59031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fbd402ff380, tag: 0x724b8209c4e599e8, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,289 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43830
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fbd402ff200, tag: 0x4209375426fc285f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fbd402ff200, tag: 0x4209375426fc285f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:21,289 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fbd402ff140, tag: 0xf0a4caef94786ef7, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fbd402ff140, tag: 0xf0a4caef94786ef7, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-07 06:10:21,341 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33488 -> ucx://127.0.0.1:59031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f65dded6380, tag: 0xe3bafcf5711d0408, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-07 06:10:21,343 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59031
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7f65dded61c0, tag: 0xb27c7df8ca1068bb, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7f65dded61c0, tag: 0xb27c7df8ca1068bb, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-07 06:10:21,452 - distributed.nanny - WARNING - Restarting worker
2023-08-07 06:10:21,535 - distributed.nanny - WARNING - Restarting worker
2023-08-07 06:10:22,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:22,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:23,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:23,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:23,140 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-07 06:10:23,141 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-07 06:10:23,145 - distributed.worker - ERROR - tuple indices must be integers or slices, not str
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2902, in get_data_from_worker
    status = response["status"]
TypeError: tuple indices must be integers or slices, not str
2023-08-07 06:10:23,167 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-054f65580a5efedc40c26858beb83d02', 5)
Function:  <dask.layers.CallableLazyImport object at 0x7fc70c
args:      ([               key   payload
shuffle                     
0           285464  82222088
0          1020281  48228346
0           295186  83870446
0          1034029  73269790
0          1029616  87925392
...            ...       ...
0        799890154  91792853
0        799990460  23455259
0        799990373  30546306
0        799981023  87571534
0        799880294  60248773

[12502296 rows x 2 columns],                key   payload
shuffle                     
1           229178   7908610
1           245752  69729938
1           262046  67802403
1           158544  43746109
1           281069  43503946
...            ...       ...
1        799778304  29851171
1        799846763  48270820
1        799834586  38412957
1        799727256  17051987
1        799637519  26413160

[12499115 rows x 2 columns],                key   payload
shuffle                     
2          1123515   1680686
2           170298   8758936
2          1134691  33462579
2           298421  51429126
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-07 06:10:23,182 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-07 06:10:23,182 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-07 06:10:23,413 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 7)
Function:  <dask.layers.CallableLazyImport object at 0x7fb89b
args:      ([                key   payload
11406     826442993  14911233
11417     826337630  20681154
11904     855350019  65860337
11924     816838986   9308929
11934     706929849  30788709
...             ...       ...
99985800  805986182  11967089
99985806  807996538  72066579
99985807  852743565  91685570
99985811  835070072  74478213
99985821  100993883  45765506

[12500893 rows x 2 columns],                 key   payload
73440     920984084  65335124
84610     412543494  60741404
73452     906042290  84265040
84611     721247557    348648
73453     925137531  74232833
...             ...       ...
99983297  923806681  14711126
99980190  944167520  66523913
99983305  929436487  19386149
99983316  958390817  14365874
99983320  928541600   9324991

[12495890 rows x 2 columns],                  key   payload
59465     1024166093  31304597
59468      529867227   5987556
59472     1012196898  45885582
59483      425383025  46086294
80096     1013952113  84844805
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
