============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.2, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-10-25 05:38:12,220 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:12,224 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45415 instead
  warnings.warn(
2023-10-25 05:38:12,228 - distributed.scheduler - INFO - State start
2023-10-25 05:38:12,250 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:12,251 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-25 05:38:12,251 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45415/status
2023-10-25 05:38:12,252 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:38:12,350 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39651'
2023-10-25 05:38:12,369 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43815'
2023-10-25 05:38:12,372 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45155'
2023-10-25 05:38:12,376 - distributed.scheduler - INFO - Receive client connection: Client-aecdbb02-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:12,381 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43069'
2023-10-25 05:38:12,390 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42380
2023-10-25 05:38:14,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:14,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:14,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:14,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:14,062 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:14,062 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:14,070 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:14,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:14,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:14,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:14,074 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-10-25 05:38:14,076 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44949
2023-10-25 05:38:14,077 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44949
2023-10-25 05:38:14,077 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40883
2023-10-25 05:38:14,077 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-25 05:38:14,077 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:14,077 - distributed.worker - INFO -               Threads:                          4
2023-10-25 05:38:14,077 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-25 05:38:14,077 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-om7x4gj_
2023-10-25 05:38:14,077 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-09a9e1d2-f2fe-458c-8549-24a80920970f
2023-10-25 05:38:14,078 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:14,078 - distributed.worker - INFO - Starting Worker plugin PreImport-4711ef43-5901-466e-a086-9b4b034465f3
2023-10-25 05:38:14,078 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0bf14038-f4ad-4dd8-95dc-f68baa1a438c
2023-10-25 05:38:14,078 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:14,542 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44949', status: init, memory: 0, processing: 0>
2023-10-25 05:38:14,543 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44949
2023-10-25 05:38:14,543 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42418
2023-10-25 05:38:14,544 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:14,545 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-25 05:38:14,545 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:14,546 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-25 05:38:15,462 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35817
2023-10-25 05:38:15,463 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35817
2023-10-25 05:38:15,463 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43999
2023-10-25 05:38:15,463 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-25 05:38:15,463 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:15,463 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34071
2023-10-25 05:38:15,463 - distributed.worker - INFO -               Threads:                          4
2023-10-25 05:38:15,463 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34071
2023-10-25 05:38:15,463 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-25 05:38:15,463 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38987
2023-10-25 05:38:15,463 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-rrsebiyq
2023-10-25 05:38:15,463 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-25 05:38:15,463 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46159
2023-10-25 05:38:15,463 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46159
2023-10-25 05:38:15,464 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:15,464 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43225
2023-10-25 05:38:15,464 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-25 05:38:15,464 - distributed.worker - INFO -               Threads:                          4
2023-10-25 05:38:15,464 - distributed.worker - INFO - Starting Worker plugin RMMSetup-48aaffe3-a2b2-4518-8f10-d6fb7ed9b7b9
2023-10-25 05:38:15,464 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:15,464 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-25 05:38:15,464 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-t52hg7br
2023-10-25 05:38:15,464 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6cac6050-bb64-41f6-b387-bb457154307b
2023-10-25 05:38:15,464 - distributed.worker - INFO -               Threads:                          4
2023-10-25 05:38:15,464 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-25 05:38:15,464 - distributed.worker - INFO - Starting Worker plugin PreImport-c88e2865-584f-47d5-9f50-54d0533e1d48
2023-10-25 05:38:15,464 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-qzot21pq
2023-10-25 05:38:15,464 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6e0416b3-418b-4d37-aac7-7c40597bb42c
2023-10-25 05:38:15,464 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:15,464 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-122037f8-38fc-42d7-9a2e-131a05a19c57
2023-10-25 05:38:15,465 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1936b709-80e9-49b3-9fe5-90b92774cb83
2023-10-25 05:38:15,465 - distributed.worker - INFO - Starting Worker plugin PreImport-2ac534de-bfc3-4d48-9f76-df2f32c63662
2023-10-25 05:38:15,465 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2e268293-20d9-47d5-a9ed-e9b83d373d7a
2023-10-25 05:38:15,465 - distributed.worker - INFO - Starting Worker plugin PreImport-ec6f6b3f-c42b-41c6-b6eb-48b7c4f428f4
2023-10-25 05:38:15,465 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:15,465 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:15,485 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35817', status: init, memory: 0, processing: 0>
2023-10-25 05:38:15,486 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35817
2023-10-25 05:38:15,486 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42432
2023-10-25 05:38:15,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:15,488 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-25 05:38:15,488 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:15,489 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46159', status: init, memory: 0, processing: 0>
2023-10-25 05:38:15,489 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-25 05:38:15,490 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46159
2023-10-25 05:38:15,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42440
2023-10-25 05:38:15,491 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:15,491 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-25 05:38:15,491 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:15,493 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-25 05:38:15,499 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34071', status: init, memory: 0, processing: 0>
2023-10-25 05:38:15,500 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34071
2023-10-25 05:38:15,500 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42444
2023-10-25 05:38:15,501 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:15,502 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-25 05:38:15,502 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:15,504 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-25 05:38:15,557 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-25 05:38:15,557 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-25 05:38:15,557 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-25 05:38:15,598 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-25 05:38:15,603 - distributed.scheduler - INFO - Remove client Client-aecdbb02-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:15,603 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42380; closing.
2023-10-25 05:38:15,603 - distributed.scheduler - INFO - Remove client Client-aecdbb02-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:15,604 - distributed.scheduler - INFO - Close client connection: Client-aecdbb02-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:15,605 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45155'. Reason: nanny-close
2023-10-25 05:38:15,605 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:15,606 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43069'. Reason: nanny-close
2023-10-25 05:38:15,606 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:15,606 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46159. Reason: nanny-close
2023-10-25 05:38:15,607 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39651'. Reason: nanny-close
2023-10-25 05:38:15,607 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:15,607 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34071. Reason: nanny-close
2023-10-25 05:38:15,607 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43815'. Reason: nanny-close
2023-10-25 05:38:15,607 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:15,608 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35817. Reason: nanny-close
2023-10-25 05:38:15,608 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44949. Reason: nanny-close
2023-10-25 05:38:15,608 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-25 05:38:15,609 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42440; closing.
2023-10-25 05:38:15,609 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-25 05:38:15,609 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-25 05:38:15,609 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46159', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212295.6098535')
2023-10-25 05:38:15,610 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42432; closing.
2023-10-25 05:38:15,610 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:15,611 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:15,611 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:15,611 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35817', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212295.61123')
2023-10-25 05:38:15,611 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-25 05:38:15,611 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42444; closing.
2023-10-25 05:38:15,612 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34071', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212295.612785')
2023-10-25 05:38:15,613 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:15,613 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:42432>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-25 05:38:15,615 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42418; closing.
2023-10-25 05:38:15,615 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44949', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212295.615558')
2023-10-25 05:38:15,615 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:38:16,621 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:38:16,621 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:38:16,622 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:38:16,623 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-25 05:38:16,623 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-10-25 05:38:18,634 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:18,638 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34423 instead
  warnings.warn(
2023-10-25 05:38:18,642 - distributed.scheduler - INFO - State start
2023-10-25 05:38:18,663 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:18,664 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:38:18,664 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34423/status
2023-10-25 05:38:18,665 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:38:18,827 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37885'
2023-10-25 05:38:18,840 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37315'
2023-10-25 05:38:18,848 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44911'
2023-10-25 05:38:18,864 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37177'
2023-10-25 05:38:18,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45585'
2023-10-25 05:38:18,874 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40349'
2023-10-25 05:38:18,886 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46575'
2023-10-25 05:38:18,896 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45727'
2023-10-25 05:38:20,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:20,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:20,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:20,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:20,753 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:20,753 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:20,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:20,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:20,785 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:20,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:20,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:20,792 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:20,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:20,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:20,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:20,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:20,816 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:20,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:20,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:20,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:20,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:20,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:20,822 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:20,824 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:22,720 - distributed.scheduler - INFO - Receive client connection: Client-b2a39b8d-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:22,735 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57570
2023-10-25 05:38:23,363 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45689
2023-10-25 05:38:23,363 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45689
2023-10-25 05:38:23,364 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40037
2023-10-25 05:38:23,364 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,364 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,364 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:23,364 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:23,364 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-70i1l3uc
2023-10-25 05:38:23,364 - distributed.worker - INFO - Starting Worker plugin RMMSetup-967b2527-52ed-4144-ae59-a4e12dcaa92e
2023-10-25 05:38:23,488 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43551
2023-10-25 05:38:23,489 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43551
2023-10-25 05:38:23,489 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38117
2023-10-25 05:38:23,489 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,489 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,489 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:23,490 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:23,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6x2vfezc
2023-10-25 05:38:23,490 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5a90e9a2-0cfe-4028-9a2f-6531b5dcd905
2023-10-25 05:38:23,490 - distributed.worker - INFO - Starting Worker plugin PreImport-00f487a7-de3b-45dc-b91b-3afdcba91d24
2023-10-25 05:38:23,490 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e79dea09-7d00-4729-b672-a2bcaea48928
2023-10-25 05:38:23,502 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45611
2023-10-25 05:38:23,503 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45611
2023-10-25 05:38:23,503 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41239
2023-10-25 05:38:23,503 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,503 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,503 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:23,504 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:23,504 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bhtvjgej
2023-10-25 05:38:23,504 - distributed.worker - INFO - Starting Worker plugin RMMSetup-232d7c53-afd9-4871-9e09-da0874cbef6b
2023-10-25 05:38:23,505 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7a3d0a12-db53-45bb-b6a6-2fbd7ce0b38b
2023-10-25 05:38:23,506 - distributed.worker - INFO - Starting Worker plugin PreImport-ef419e1f-cce1-4bab-bb61-0ca5d8652c05
2023-10-25 05:38:23,506 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,509 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34079
2023-10-25 05:38:23,510 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34079
2023-10-25 05:38:23,510 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36863
2023-10-25 05:38:23,510 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,510 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,510 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:23,510 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:23,510 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-69garipk
2023-10-25 05:38:23,511 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-41b3498b-b5ab-4505-9c05-fb0dee91f2c9
2023-10-25 05:38:23,511 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7d2de1b1-e294-44df-93fb-ed74cb2c07cd
2023-10-25 05:38:23,514 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34355
2023-10-25 05:38:23,514 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34355
2023-10-25 05:38:23,515 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37295
2023-10-25 05:38:23,515 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,515 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,515 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:23,515 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:23,515 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1_fqmz0l
2023-10-25 05:38:23,515 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d3173ac6-41dc-4dcc-9cbd-2d59d690718b
2023-10-25 05:38:23,515 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39401
2023-10-25 05:38:23,517 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39401
2023-10-25 05:38:23,517 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36767
2023-10-25 05:38:23,517 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,517 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cbf6240d-3fbd-41c5-a69e-036d02c2c669
2023-10-25 05:38:23,517 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,517 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:23,518 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:23,518 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mj32k_2q
2023-10-25 05:38:23,519 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d50bcee0-8209-4a5d-8efe-1383018dea9a
2023-10-25 05:38:23,664 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43557
2023-10-25 05:38:23,665 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43557
2023-10-25 05:38:23,665 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45651
2023-10-25 05:38:23,666 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,666 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,666 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:23,666 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:23,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k5ngnvn9
2023-10-25 05:38:23,667 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2df357fe-a54c-4f02-8271-9158ddf290ad
2023-10-25 05:38:23,673 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45689', status: init, memory: 0, processing: 0>
2023-10-25 05:38:23,675 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45689
2023-10-25 05:38:23,675 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57576
2023-10-25 05:38:23,676 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:23,677 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,677 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,678 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:23,687 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40469
2023-10-25 05:38:23,689 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40469
2023-10-25 05:38:23,689 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44731
2023-10-25 05:38:23,689 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,689 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,689 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:23,689 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:23,689 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-smcor605
2023-10-25 05:38:23,690 - distributed.worker - INFO - Starting Worker plugin RMMSetup-685c3fb9-754d-485e-8aae-7f5ab93ffc22
2023-10-25 05:38:23,800 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,808 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-99cb6278-aeab-4c20-a790-e3ebec923151
2023-10-25 05:38:23,809 - distributed.worker - INFO - Starting Worker plugin PreImport-91998579-cace-4592-88f4-f92fe013c3b9
2023-10-25 05:38:23,809 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,816 - distributed.worker - INFO - Starting Worker plugin PreImport-bcd090f4-ca13-4079-85ae-c70418e9a64a
2023-10-25 05:38:23,816 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0d7c33f5-aa3b-4eb5-91ac-01488013a050
2023-10-25 05:38:23,817 - distributed.worker - INFO - Starting Worker plugin PreImport-9425a110-1753-4b40-8b54-af53b61dd325
2023-10-25 05:38:23,817 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,817 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,825 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43551', status: init, memory: 0, processing: 0>
2023-10-25 05:38:23,825 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43551
2023-10-25 05:38:23,826 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57580
2023-10-25 05:38:23,826 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e8e5c8c-bf65-4f25-afc2-8482d4450400
2023-10-25 05:38:23,826 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:23,827 - distributed.worker - INFO - Starting Worker plugin PreImport-d89d5a4d-0a60-4291-8d08-ea10f8c3180d
2023-10-25 05:38:23,827 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,828 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,828 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,829 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:23,846 - distributed.worker - INFO - Starting Worker plugin PreImport-6f8d788f-eac4-4a83-8f5c-ca7a0118a508
2023-10-25 05:38:23,847 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,854 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8712768d-9e97-47a7-8cbc-0897296f47f5
2023-10-25 05:38:23,855 - distributed.worker - INFO - Starting Worker plugin PreImport-df303230-6c10-49d6-ad6b-95af6d83ea16
2023-10-25 05:38:23,856 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,856 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40469', status: init, memory: 0, processing: 0>
2023-10-25 05:38:23,856 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40469
2023-10-25 05:38:23,857 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57624
2023-10-25 05:38:23,857 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43557', status: init, memory: 0, processing: 0>
2023-10-25 05:38:23,858 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43557
2023-10-25 05:38:23,858 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:23,858 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57602
2023-10-25 05:38:23,859 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,859 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34355', status: init, memory: 0, processing: 0>
2023-10-25 05:38:23,859 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,860 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34355
2023-10-25 05:38:23,860 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57614
2023-10-25 05:38:23,860 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:23,860 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:23,860 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45611', status: init, memory: 0, processing: 0>
2023-10-25 05:38:23,861 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,861 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,861 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45611
2023-10-25 05:38:23,861 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57590
2023-10-25 05:38:23,862 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:23,863 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,863 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,863 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:23,863 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:23,864 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,864 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,865 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:23,866 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:23,885 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34079', status: init, memory: 0, processing: 0>
2023-10-25 05:38:23,886 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34079
2023-10-25 05:38:23,886 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57628
2023-10-25 05:38:23,887 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:23,888 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,888 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,890 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:23,894 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39401', status: init, memory: 0, processing: 0>
2023-10-25 05:38:23,894 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39401
2023-10-25 05:38:23,895 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57632
2023-10-25 05:38:23,896 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:23,897 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:23,897 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:23,898 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:23,973 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:23,973 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:23,974 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:23,974 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:23,974 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:23,974 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:23,974 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:23,974 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:23,978 - distributed.scheduler - INFO - Remove client Client-b2a39b8d-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:23,979 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57570; closing.
2023-10-25 05:38:23,979 - distributed.scheduler - INFO - Remove client Client-b2a39b8d-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:23,979 - distributed.scheduler - INFO - Close client connection: Client-b2a39b8d-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:23,980 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37885'. Reason: nanny-close
2023-10-25 05:38:23,980 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:23,981 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37315'. Reason: nanny-close
2023-10-25 05:38:23,982 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:23,982 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43551. Reason: nanny-close
2023-10-25 05:38:23,982 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44911'. Reason: nanny-close
2023-10-25 05:38:23,982 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:23,982 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45689. Reason: nanny-close
2023-10-25 05:38:23,983 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37177'. Reason: nanny-close
2023-10-25 05:38:23,983 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:23,983 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45611. Reason: nanny-close
2023-10-25 05:38:23,984 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:23,984 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45585'. Reason: nanny-close
2023-10-25 05:38:23,984 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:23,984 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57580; closing.
2023-10-25 05:38:23,984 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34079. Reason: nanny-close
2023-10-25 05:38:23,985 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43551', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212303.9849331')
2023-10-25 05:38:23,985 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40349'. Reason: nanny-close
2023-10-25 05:38:23,985 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39401. Reason: nanny-close
2023-10-25 05:38:23,985 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:23,985 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:23,985 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:23,986 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:23,985 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46575'. Reason: nanny-close
2023-10-25 05:38:23,986 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:23,986 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40469. Reason: nanny-close
2023-10-25 05:38:23,986 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45727'. Reason: nanny-close
2023-10-25 05:38:23,986 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57590; closing.
2023-10-25 05:38:23,987 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:23,987 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57576; closing.
2023-10-25 05:38:23,987 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:23,987 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:23,987 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:23,987 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:23,987 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34355. Reason: nanny-close
2023-10-25 05:38:23,987 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45611', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212303.9878857')
2023-10-25 05:38:23,987 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43557. Reason: nanny-close
2023-10-25 05:38:23,988 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45689', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212303.9883046')
2023-10-25 05:38:23,988 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:23,988 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57628; closing.
2023-10-25 05:38:23,988 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:23,989 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:23,989 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34079', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212303.9890916')
2023-10-25 05:38:23,990 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:23,990 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:23,990 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57632; closing.
2023-10-25 05:38:23,990 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:23,990 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57624; closing.
2023-10-25 05:38:23,990 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39401', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212303.9908676')
2023-10-25 05:38:23,991 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40469', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212303.99132')
2023-10-25 05:38:23,991 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57614; closing.
2023-10-25 05:38:23,991 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57602; closing.
2023-10-25 05:38:23,991 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:23,992 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:23,992 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34355', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212303.9922707')
2023-10-25 05:38:23,992 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43557', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212303.9926827')
2023-10-25 05:38:23,992 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:38:25,447 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:38:25,448 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:38:25,448 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:38:25,450 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:38:25,450 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-10-25 05:38:27,575 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:27,579 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42277 instead
  warnings.warn(
2023-10-25 05:38:27,582 - distributed.scheduler - INFO - State start
2023-10-25 05:38:27,604 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:27,605 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:38:27,606 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42277/status
2023-10-25 05:38:27,606 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:38:27,761 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38097'
2023-10-25 05:38:27,778 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34087'
2023-10-25 05:38:27,794 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41427'
2023-10-25 05:38:27,806 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44751'
2023-10-25 05:38:27,809 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42039'
2023-10-25 05:38:27,818 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42783'
2023-10-25 05:38:27,829 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34457'
2023-10-25 05:38:27,840 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35643'
2023-10-25 05:38:29,108 - distributed.scheduler - INFO - Receive client connection: Client-b7faa339-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:29,120 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57820
2023-10-25 05:38:29,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:29,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:29,468 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:29,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:29,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:29,767 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:29,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:29,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:29,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:29,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:29,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:29,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:29,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:29,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:29,773 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:29,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:29,774 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:29,774 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:29,775 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:29,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:29,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:29,776 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:29,778 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:29,779 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:31,159 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36511
2023-10-25 05:38:31,160 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36511
2023-10-25 05:38:31,160 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36225
2023-10-25 05:38:31,160 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:31,160 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:31,160 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:31,160 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:31,160 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fhqom4mb
2023-10-25 05:38:31,161 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1bb5d074-f0f9-4e9e-97f8-cb4460458654
2023-10-25 05:38:31,229 - distributed.worker - INFO - Starting Worker plugin PreImport-b14808e4-502e-4b00-a3c2-aa7829827876
2023-10-25 05:38:31,229 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d38cd559-171e-4c14-9ae5-b804aad64819
2023-10-25 05:38:31,229 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:31,251 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36511', status: init, memory: 0, processing: 0>
2023-10-25 05:38:31,252 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36511
2023-10-25 05:38:31,252 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44044
2023-10-25 05:38:31,253 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:31,254 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:31,254 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:31,256 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:32,222 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36131
2023-10-25 05:38:32,223 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36131
2023-10-25 05:38:32,223 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41933
2023-10-25 05:38:32,223 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,223 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,223 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:32,223 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:32,223 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j8_hue41
2023-10-25 05:38:32,224 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7360bb8b-ea20-4243-904f-cd47a8c73ba7
2023-10-25 05:38:32,229 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37326773-cd8c-4947-bd85-c2a1feaef031
2023-10-25 05:38:32,229 - distributed.worker - INFO - Starting Worker plugin PreImport-e2162d84-9546-41de-b672-82058f50ba61
2023-10-25 05:38:32,229 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,411 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36131', status: init, memory: 0, processing: 0>
2023-10-25 05:38:32,412 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36131
2023-10-25 05:38:32,412 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44060
2023-10-25 05:38:32,413 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:32,414 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,414 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,416 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:32,518 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39435
2023-10-25 05:38:32,519 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39435
2023-10-25 05:38:32,519 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40273
2023-10-25 05:38:32,519 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,519 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,519 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:32,519 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:32,519 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oczn0dnv
2023-10-25 05:38:32,520 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3d6e4636-a1b5-4276-95ee-4a5237580508
2023-10-25 05:38:32,539 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40695
2023-10-25 05:38:32,539 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40695
2023-10-25 05:38:32,540 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40459
2023-10-25 05:38:32,540 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,540 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,540 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:32,540 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:32,540 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2_8g4gtw
2023-10-25 05:38:32,540 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6598c046-4c22-4dbf-b347-1b8eae0c2b80
2023-10-25 05:38:32,541 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e4c3b1b0-4396-4c4e-a93c-039923a5fe01
2023-10-25 05:38:32,542 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38531
2023-10-25 05:38:32,543 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38531
2023-10-25 05:38:32,543 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33065
2023-10-25 05:38:32,542 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41479
2023-10-25 05:38:32,543 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,543 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,543 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41479
2023-10-25 05:38:32,543 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42479
2023-10-25 05:38:32,543 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,543 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:32,543 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,543 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:32,543 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uzjzjgwv
2023-10-25 05:38:32,543 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:32,543 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:32,543 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jatxqq74
2023-10-25 05:38:32,543 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff0098f2-7c3c-4cfa-8f87-baefaad52cb8
2023-10-25 05:38:32,544 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e9634204-cf14-4052-868a-420dbf5f7a2a
2023-10-25 05:38:32,544 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c8f0a0c2-dc49-4cfd-ae9b-a0f8d2846ad2
2023-10-25 05:38:32,544 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45627
2023-10-25 05:38:32,545 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45627
2023-10-25 05:38:32,545 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41315
2023-10-25 05:38:32,545 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,545 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,545 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:32,546 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:32,546 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0zcha4_p
2023-10-25 05:38:32,546 - distributed.worker - INFO - Starting Worker plugin RMMSetup-831bf70e-36c6-4816-aa88-f9941d2cb697
2023-10-25 05:38:32,546 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41125
2023-10-25 05:38:32,547 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41125
2023-10-25 05:38:32,547 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34247
2023-10-25 05:38:32,547 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,547 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,547 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:32,547 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:32,547 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ijwyg1ud
2023-10-25 05:38:32,548 - distributed.worker - INFO - Starting Worker plugin PreImport-1128f6f3-ab36-418a-a16b-4ddcef678e8a
2023-10-25 05:38:32,548 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-00307204-7788-4739-b232-6a4e7e164a75
2023-10-25 05:38:32,548 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2410f7ab-a3c5-4ed8-a5ec-f51596b5704d
2023-10-25 05:38:32,570 - distributed.worker - INFO - Starting Worker plugin PreImport-ad5be8e5-a985-4eed-a7ce-0a45f9c095b8
2023-10-25 05:38:32,570 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-26f7754b-ce09-4ef4-880d-8de57e6d4499
2023-10-25 05:38:32,570 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,571 - distributed.worker - INFO - Starting Worker plugin PreImport-f9027742-ca73-42f4-a5ef-d20f5d3886ff
2023-10-25 05:38:32,572 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,587 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-40e2be5c-f7f6-491a-8f8c-04c21a150ebe
2023-10-25 05:38:32,588 - distributed.worker - INFO - Starting Worker plugin PreImport-37919dbd-505c-4fd8-abec-41d6391d33df
2023-10-25 05:38:32,588 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,592 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-097bb85f-d4a2-4bcb-b2fc-5969b2f39a60
2023-10-25 05:38:32,592 - distributed.worker - INFO - Starting Worker plugin PreImport-df3d7d01-b4d9-4795-a36e-13c4c840ef2e
2023-10-25 05:38:32,592 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,592 - distributed.worker - INFO - Starting Worker plugin PreImport-a4963429-9e88-435b-b916-08c76ea3559c
2023-10-25 05:38:32,593 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,593 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,593 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40695', status: init, memory: 0, processing: 0>
2023-10-25 05:38:32,594 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40695
2023-10-25 05:38:32,594 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44068
2023-10-25 05:38:32,595 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:32,596 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,596 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,597 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:32,600 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45627', status: init, memory: 0, processing: 0>
2023-10-25 05:38:32,600 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45627
2023-10-25 05:38:32,600 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44074
2023-10-25 05:38:32,602 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:32,603 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,603 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,605 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:32,618 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41125', status: init, memory: 0, processing: 0>
2023-10-25 05:38:32,619 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41125
2023-10-25 05:38:32,619 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44100
2023-10-25 05:38:32,620 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:32,621 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39435', status: init, memory: 0, processing: 0>
2023-10-25 05:38:32,621 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,621 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,621 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39435
2023-10-25 05:38:32,621 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44084
2023-10-25 05:38:32,622 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38531', status: init, memory: 0, processing: 0>
2023-10-25 05:38:32,623 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:32,623 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38531
2023-10-25 05:38:32,623 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44086
2023-10-25 05:38:32,623 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:32,624 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,624 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,624 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41479', status: init, memory: 0, processing: 0>
2023-10-25 05:38:32,624 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:32,624 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41479
2023-10-25 05:38:32,625 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44106
2023-10-25 05:38:32,625 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,625 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,626 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:32,626 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:32,626 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:32,627 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:32,627 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:32,629 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:32,663 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:32,663 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:32,663 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:32,663 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:32,664 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:32,664 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:32,664 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:32,664 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:32,668 - distributed.scheduler - INFO - Remove client Client-b7faa339-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:32,669 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57820; closing.
2023-10-25 05:38:32,669 - distributed.scheduler - INFO - Remove client Client-b7faa339-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:32,669 - distributed.scheduler - INFO - Close client connection: Client-b7faa339-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:32,670 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38097'. Reason: nanny-close
2023-10-25 05:38:32,671 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:32,672 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34087'. Reason: nanny-close
2023-10-25 05:38:32,672 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:32,672 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36511. Reason: nanny-close
2023-10-25 05:38:32,673 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41427'. Reason: nanny-close
2023-10-25 05:38:32,673 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44751'. Reason: nanny-close
2023-10-25 05:38:32,673 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:32,673 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45627. Reason: nanny-close
2023-10-25 05:38:32,673 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42039'. Reason: nanny-close
2023-10-25 05:38:32,674 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42783'. Reason: nanny-close
2023-10-25 05:38:32,674 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34457'. Reason: nanny-close
2023-10-25 05:38:32,674 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41125. Reason: nanny-close
2023-10-25 05:38:32,674 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:32,674 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35643'. Reason: nanny-close
2023-10-25 05:38:32,674 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44044; closing.
2023-10-25 05:38:32,674 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:32,674 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:32,675 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40695. Reason: nanny-close
2023-10-25 05:38:32,675 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36511', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212312.6750534')
2023-10-25 05:38:32,675 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36131. Reason: nanny-close
2023-10-25 05:38:32,676 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:32,676 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:32,676 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:32,676 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:32,676 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44074; closing.
2023-10-25 05:38:32,677 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:32,677 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45627', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212312.6777678')
2023-10-25 05:38:32,677 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:32,678 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:32,678 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44100; closing.
2023-10-25 05:38:32,678 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:32,678 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:32,678 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:32,678 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38531. Reason: nanny-close
2023-10-25 05:38:32,678 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:32,678 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41125', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212312.6787505')
2023-10-25 05:38:32,679 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41479. Reason: nanny-close
2023-10-25 05:38:32,679 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44068; closing.
2023-10-25 05:38:32,679 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39435. Reason: nanny-close
2023-10-25 05:38:32,679 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:32,680 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40695', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212312.6802783')
2023-10-25 05:38:32,680 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:32,680 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44060; closing.
2023-10-25 05:38:32,681 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:32,681 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36131', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212312.681437')
2023-10-25 05:38:32,681 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:32,681 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:32,682 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44086; closing.
2023-10-25 05:38:32,682 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44106; closing.
2023-10-25 05:38:32,683 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38531', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212312.6829498')
2023-10-25 05:38:32,683 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41479', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212312.6833456')
2023-10-25 05:38:32,683 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:32,683 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:32,683 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44084; closing.
2023-10-25 05:38:32,684 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39435', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212312.684121')
2023-10-25 05:38:32,684 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:38:32,684 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44086>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-25 05:38:32,686 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44106>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-25 05:38:34,238 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:38:34,238 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:38:34,239 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:38:34,240 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:38:34,240 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-10-25 05:38:36,611 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:36,615 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44837 instead
  warnings.warn(
2023-10-25 05:38:36,619 - distributed.scheduler - INFO - State start
2023-10-25 05:38:36,649 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:36,650 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:38:36,651 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44837/status
2023-10-25 05:38:36,652 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:38:36,774 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34843'
2023-10-25 05:38:36,792 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46223'
2023-10-25 05:38:36,802 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34973'
2023-10-25 05:38:36,810 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36743'
2023-10-25 05:38:36,818 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36347'
2023-10-25 05:38:36,827 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36119'
2023-10-25 05:38:36,838 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41473'
2023-10-25 05:38:36,847 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34141'
2023-10-25 05:38:37,436 - distributed.scheduler - INFO - Receive client connection: Client-bd40bb8f-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:37,451 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44296
2023-10-25 05:38:38,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:38,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:38,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:38,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:38,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:38,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:38,658 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:38,661 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:38,661 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:38,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:38,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:38,721 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:38,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:38,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:38,726 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:38,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:38,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:38,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:38,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:38,750 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:38,751 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:38,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:38,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:38,825 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:41,667 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46553
2023-10-25 05:38:41,668 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46553
2023-10-25 05:38:41,668 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40557
2023-10-25 05:38:41,668 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,668 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,668 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:41,668 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:41,669 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qiw7wmzt
2023-10-25 05:38:41,669 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cd068bb5-8fa1-468d-b6f2-bbcd736b25ee
2023-10-25 05:38:41,671 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3b775ef7-808d-40c9-a770-139a4980ddcb
2023-10-25 05:38:41,669 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45887
2023-10-25 05:38:41,671 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45887
2023-10-25 05:38:41,671 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36671
2023-10-25 05:38:41,672 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,672 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,672 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:41,672 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:41,672 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-847rgoei
2023-10-25 05:38:41,674 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5ee25039-74ad-4eee-9e0b-fe810b117d06
2023-10-25 05:38:41,848 - distributed.worker - INFO - Starting Worker plugin PreImport-0e2de589-0ea9-4a53-9e2f-33af037c32e5
2023-10-25 05:38:41,849 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,886 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46553', status: init, memory: 0, processing: 0>
2023-10-25 05:38:41,887 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0457c0c8-9c1a-4c1a-bf26-4e9ffa1491e4
2023-10-25 05:38:41,888 - distributed.worker - INFO - Starting Worker plugin PreImport-b9226b88-ebd0-4842-b36e-caf67a02ad27
2023-10-25 05:38:41,888 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,888 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46553
2023-10-25 05:38:41,888 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52232
2023-10-25 05:38:41,889 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:41,890 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,890 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,892 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:41,928 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45887', status: init, memory: 0, processing: 0>
2023-10-25 05:38:41,929 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45887
2023-10-25 05:38:41,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52240
2023-10-25 05:38:41,930 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:41,931 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,931 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,932 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:41,935 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39407
2023-10-25 05:38:41,936 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39407
2023-10-25 05:38:41,936 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36401
2023-10-25 05:38:41,936 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,936 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,936 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:41,936 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:41,936 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-x9dzhaxx
2023-10-25 05:38:41,937 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2073227f-baa2-4803-aa8a-1bfc1e547a11
2023-10-25 05:38:41,939 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37057
2023-10-25 05:38:41,940 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37057
2023-10-25 05:38:41,940 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39159
2023-10-25 05:38:41,940 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,941 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,941 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:41,941 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:41,941 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oa5329bq
2023-10-25 05:38:41,941 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3e2f567e-2eee-4d6a-bb57-b09a3a900925
2023-10-25 05:38:41,945 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44383
2023-10-25 05:38:41,946 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44383
2023-10-25 05:38:41,946 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45413
2023-10-25 05:38:41,946 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,946 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,946 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:41,946 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:41,946 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gusps9c7
2023-10-25 05:38:41,947 - distributed.worker - INFO - Starting Worker plugin RMMSetup-972c8406-ae96-4140-9531-a1eeb2aa443e
2023-10-25 05:38:41,946 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43045
2023-10-25 05:38:41,947 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43045
2023-10-25 05:38:41,947 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37891
2023-10-25 05:38:41,947 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,947 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,947 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:41,948 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:41,948 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sqxorsfy
2023-10-25 05:38:41,947 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45103
2023-10-25 05:38:41,948 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45103
2023-10-25 05:38:41,948 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37131
2023-10-25 05:38:41,946 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40755
2023-10-25 05:38:41,948 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,948 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,948 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40755
2023-10-25 05:38:41,948 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34173
2023-10-25 05:38:41,948 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:41,948 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:41,948 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d613bb97-e5a5-4216-aa1a-598a3c87f9ad
2023-10-25 05:38:41,948 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:41,948 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:41,948 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5_n3hwj0
2023-10-25 05:38:41,948 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:41,948 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:41,948 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wg3stwre
2023-10-25 05:38:41,948 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7ebad789-d8aa-4b6a-a5d6-c2b2a729baba
2023-10-25 05:38:41,949 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dafd46b2-cfa1-480f-86b1-046f9e0a505f
2023-10-25 05:38:41,949 - distributed.worker - INFO - Starting Worker plugin PreImport-2e3a8ed3-f10f-4798-9669-4767f878a056
2023-10-25 05:38:41,949 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c846bc9c-0b02-4f50-b9df-0d551901dfdb
2023-10-25 05:38:41,949 - distributed.worker - INFO - Starting Worker plugin RMMSetup-62aa6fc6-09bc-401f-bd5b-83fc286a9579
2023-10-25 05:38:42,157 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5dc48aa4-5211-4396-bb7e-7cf122950f21
2023-10-25 05:38:42,158 - distributed.worker - INFO - Starting Worker plugin PreImport-5bed06eb-3dcb-44e6-8033-b8dd4f0af61b
2023-10-25 05:38:42,158 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,164 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9deb4b95-407e-445b-964c-fde7df7aac91
2023-10-25 05:38:42,164 - distributed.worker - INFO - Starting Worker plugin PreImport-ab2607b7-77b7-4bee-9e42-b022e9830a5f
2023-10-25 05:38:42,164 - distributed.worker - INFO - Starting Worker plugin PreImport-c4afb4d7-510d-447d-a140-4682c8c7f453
2023-10-25 05:38:42,164 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,164 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8299e172-f9eb-4561-8ca5-94fae14ee531
2023-10-25 05:38:42,165 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,165 - distributed.worker - INFO - Starting Worker plugin PreImport-2483be92-ea86-4d6c-933c-5fc6e6038cc7
2023-10-25 05:38:42,165 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,165 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,165 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1285e5bd-efde-4804-800d-c92c5e6e4de0
2023-10-25 05:38:42,166 - distributed.worker - INFO - Starting Worker plugin PreImport-c8441699-a2da-4f7b-b05b-eb8539edaabc
2023-10-25 05:38:42,167 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,183 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39407', status: init, memory: 0, processing: 0>
2023-10-25 05:38:42,183 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39407
2023-10-25 05:38:42,183 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52248
2023-10-25 05:38:42,184 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:42,185 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:42,185 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,187 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:42,190 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37057', status: init, memory: 0, processing: 0>
2023-10-25 05:38:42,190 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37057
2023-10-25 05:38:42,190 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52252
2023-10-25 05:38:42,191 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45103', status: init, memory: 0, processing: 0>
2023-10-25 05:38:42,191 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:42,191 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45103
2023-10-25 05:38:42,191 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52266
2023-10-25 05:38:42,192 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:42,192 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,192 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:42,193 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:42,193 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,193 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:42,195 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:42,197 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40755', status: init, memory: 0, processing: 0>
2023-10-25 05:38:42,198 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40755
2023-10-25 05:38:42,198 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52280
2023-10-25 05:38:42,199 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44383', status: init, memory: 0, processing: 0>
2023-10-25 05:38:42,199 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:42,199 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44383
2023-10-25 05:38:42,199 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52284
2023-10-25 05:38:42,200 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:42,200 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,200 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43045', status: init, memory: 0, processing: 0>
2023-10-25 05:38:42,201 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:42,201 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43045
2023-10-25 05:38:42,201 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52272
2023-10-25 05:38:42,202 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:42,202 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,202 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:42,202 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:42,203 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:42,204 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:42,204 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:42,206 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:42,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:42,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:42,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:42,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:42,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:42,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:42,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:42,215 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:38:42,225 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:42,225 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:42,225 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:42,225 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:42,225 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:42,225 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:42,225 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:42,225 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:42,232 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:42,233 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:42,236 - distributed.scheduler - INFO - Remove client Client-bd40bb8f-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:42,236 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44296; closing.
2023-10-25 05:38:42,236 - distributed.scheduler - INFO - Remove client Client-bd40bb8f-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:42,237 - distributed.scheduler - INFO - Close client connection: Client-bd40bb8f-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:42,238 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34843'. Reason: nanny-close
2023-10-25 05:38:42,238 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:42,239 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46223'. Reason: nanny-close
2023-10-25 05:38:42,239 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:42,239 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45103. Reason: nanny-close
2023-10-25 05:38:42,240 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34973'. Reason: nanny-close
2023-10-25 05:38:42,240 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36743'. Reason: nanny-close
2023-10-25 05:38:42,240 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:42,240 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37057. Reason: nanny-close
2023-10-25 05:38:42,240 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36347'. Reason: nanny-close
2023-10-25 05:38:42,241 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:42,241 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46553. Reason: nanny-close
2023-10-25 05:38:42,241 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36119'. Reason: nanny-close
2023-10-25 05:38:42,241 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:42,241 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:42,241 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52266; closing.
2023-10-25 05:38:42,241 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45887. Reason: nanny-close
2023-10-25 05:38:42,242 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41473'. Reason: nanny-close
2023-10-25 05:38:42,242 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45103', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212322.242044')
2023-10-25 05:38:42,242 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34141'. Reason: nanny-close
2023-10-25 05:38:42,242 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:42,242 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39407. Reason: nanny-close
2023-10-25 05:38:42,243 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:42,243 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:42,243 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52252; closing.
2023-10-25 05:38:42,244 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:42,244 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:42,244 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37057', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212322.2444067')
2023-10-25 05:38:42,244 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:42,244 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52232; closing.
2023-10-25 05:38:42,245 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46553', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212322.2452168')
2023-10-25 05:38:42,245 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:42,245 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52240; closing.
2023-10-25 05:38:42,245 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:42,246 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45887', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212322.2459874')
2023-10-25 05:38:42,246 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:42,246 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52248; closing.
2023-10-25 05:38:42,246 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39407', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212322.2466457')
2023-10-25 05:38:42,247 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:42,248 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44383. Reason: nanny-close
2023-10-25 05:38:42,249 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:42,250 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40755. Reason: nanny-close
2023-10-25 05:38:42,250 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52284; closing.
2023-10-25 05:38:42,250 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:42,251 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44383', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212322.2511294')
2023-10-25 05:38:42,252 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:42,252 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:42,252 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52280; closing.
2023-10-25 05:38:42,253 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40755', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212322.2531796')
2023-10-25 05:38:42,254 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:42,256 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:42,257 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43045. Reason: nanny-close
2023-10-25 05:38:42,259 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52272; closing.
2023-10-25 05:38:42,259 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:42,259 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43045', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212322.2592986')
2023-10-25 05:38:42,259 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:38:42,260 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:43,805 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:38:43,805 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:38:43,806 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:38:43,807 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:38:43,807 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-10-25 05:38:45,931 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:45,936 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34679 instead
  warnings.warn(
2023-10-25 05:38:45,940 - distributed.scheduler - INFO - State start
2023-10-25 05:38:45,961 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:45,962 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:38:45,963 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34679/status
2023-10-25 05:38:45,963 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:38:46,085 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34813'
2023-10-25 05:38:46,099 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33441'
2023-10-25 05:38:46,114 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39949'
2023-10-25 05:38:46,116 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41865'
2023-10-25 05:38:46,125 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42811'
2023-10-25 05:38:46,133 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40395'
2023-10-25 05:38:46,145 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46667'
2023-10-25 05:38:46,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45901'
2023-10-25 05:38:46,447 - distributed.scheduler - INFO - Receive client connection: Client-c2e2d7c3-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:46,460 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52446
2023-10-25 05:38:48,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:48,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:48,143 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:48,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:48,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:48,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:48,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:48,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:48,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:48,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:48,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:48,149 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:48,150 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:48,150 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:48,151 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:48,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:48,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:48,157 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:48,159 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:48,159 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:48,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:48,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:48,164 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:48,166 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:51,132 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45771
2023-10-25 05:38:51,133 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45771
2023-10-25 05:38:51,133 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45141
2023-10-25 05:38:51,133 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,133 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,133 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:51,133 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:51,133 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-if0_ujjr
2023-10-25 05:38:51,134 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1b1c1fb3-7757-4b4d-bbd7-a54ec84b163a
2023-10-25 05:38:51,151 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43705
2023-10-25 05:38:51,152 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43705
2023-10-25 05:38:51,152 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42251
2023-10-25 05:38:51,152 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,152 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,152 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:51,153 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:51,152 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34719
2023-10-25 05:38:51,153 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gsa7_fa6
2023-10-25 05:38:51,153 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34719
2023-10-25 05:38:51,153 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34703
2023-10-25 05:38:51,153 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,153 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,153 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:51,153 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37e1d8eb-b439-4f5b-b36c-d1c33df133b5
2023-10-25 05:38:51,153 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:51,153 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8gu9fk2o
2023-10-25 05:38:51,154 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c5ab9f00-164c-4e19-8f0a-5e6490456870
2023-10-25 05:38:51,154 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ebbb3510-9299-4657-a799-1327d8462655
2023-10-25 05:38:51,155 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1ee3f475-be13-4afd-9852-e4afe3d75d63
2023-10-25 05:38:51,159 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33311
2023-10-25 05:38:51,159 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33675
2023-10-25 05:38:51,160 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33675
2023-10-25 05:38:51,160 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33311
2023-10-25 05:38:51,160 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39497
2023-10-25 05:38:51,160 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40279
2023-10-25 05:38:51,160 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,160 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,160 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,160 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,160 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:51,160 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:51,160 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:51,160 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:51,160 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g70mirz1
2023-10-25 05:38:51,160 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-40ttfbui
2023-10-25 05:38:51,161 - distributed.worker - INFO - Starting Worker plugin RMMSetup-67d2b126-4404-4e4a-b843-2d0fa11eb013
2023-10-25 05:38:51,161 - distributed.worker - INFO - Starting Worker plugin RMMSetup-61d7082a-f805-4b4d-ae72-db191331a140
2023-10-25 05:38:51,167 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39965
2023-10-25 05:38:51,168 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39965
2023-10-25 05:38:51,168 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43231
2023-10-25 05:38:51,168 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,168 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,168 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:51,168 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:51,168 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d6mk5hzo
2023-10-25 05:38:51,169 - distributed.worker - INFO - Starting Worker plugin RMMSetup-45b43afb-5ba6-4d37-85d2-1c6b94641112
2023-10-25 05:38:51,172 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35013
2023-10-25 05:38:51,172 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35013
2023-10-25 05:38:51,172 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45783
2023-10-25 05:38:51,173 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46809
2023-10-25 05:38:51,173 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45783
2023-10-25 05:38:51,173 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,173 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,173 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35289
2023-10-25 05:38:51,173 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,173 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:51,173 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,173 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:51,173 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vzk2744s
2023-10-25 05:38:51,173 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:38:51,173 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:38:51,173 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2gz41cx6
2023-10-25 05:38:51,173 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b4a4b722-c439-4ae3-b05b-bdbdd174427a
2023-10-25 05:38:51,174 - distributed.worker - INFO - Starting Worker plugin PreImport-f10ade10-3329-4b87-817d-b31c72affa8f
2023-10-25 05:38:51,174 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6ca26bf3-5cc8-4d3f-b661-cd286e261fcb
2023-10-25 05:38:51,174 - distributed.worker - INFO - Starting Worker plugin RMMSetup-db043c06-3a61-4191-8932-8a3c879504c8
2023-10-25 05:38:51,393 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e9f2bff8-b327-405f-8c19-9436309f157c
2023-10-25 05:38:51,394 - distributed.worker - INFO - Starting Worker plugin PreImport-8d7922da-44d7-4411-909d-088a3b077da2
2023-10-25 05:38:51,395 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,402 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,405 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fe91e13c-6f77-4217-8c93-b9dc335a84fc
2023-10-25 05:38:51,406 - distributed.worker - INFO - Starting Worker plugin PreImport-dcc41077-6371-4045-a5fc-d59d611b3b29
2023-10-25 05:38:51,406 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,417 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-27c494bd-d1ca-4f96-a8da-41d4159634f9
2023-10-25 05:38:51,418 - distributed.worker - INFO - Starting Worker plugin PreImport-7a4ec282-c080-4377-9455-195b6047b183
2023-10-25 05:38:51,418 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,420 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a70c6587-9f44-4794-9848-1b43b06120b5
2023-10-25 05:38:51,420 - distributed.worker - INFO - Starting Worker plugin PreImport-09efaeeb-b1fc-4a8e-89a2-707bc1b20424
2023-10-25 05:38:51,420 - distributed.worker - INFO - Starting Worker plugin PreImport-d7191fd2-275e-42f5-a778-0e9863dcdaf1
2023-10-25 05:38:51,420 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,420 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,421 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dc0379ed-bc07-4267-a0fd-9609330203a8
2023-10-25 05:38:51,421 - distributed.worker - INFO - Starting Worker plugin PreImport-5bcbfe93-50c9-4850-8a74-c89d28d3c790
2023-10-25 05:38:51,421 - distributed.worker - INFO - Starting Worker plugin PreImport-cbedb7d5-b3b5-4e5d-8813-371e5790adab
2023-10-25 05:38:51,421 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,421 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,426 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45771', status: init, memory: 0, processing: 0>
2023-10-25 05:38:51,428 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45771
2023-10-25 05:38:51,428 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33114
2023-10-25 05:38:51,429 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:51,430 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,430 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,432 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35013', status: init, memory: 0, processing: 0>
2023-10-25 05:38:51,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:51,432 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35013
2023-10-25 05:38:51,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33120
2023-10-25 05:38:51,433 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:51,434 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,434 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,435 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39965', status: init, memory: 0, processing: 0>
2023-10-25 05:38:51,436 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:51,436 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39965
2023-10-25 05:38:51,436 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33132
2023-10-25 05:38:51,437 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:51,438 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,438 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,440 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:51,446 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33675', status: init, memory: 0, processing: 0>
2023-10-25 05:38:51,447 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33675
2023-10-25 05:38:51,447 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33144
2023-10-25 05:38:51,448 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45783', status: init, memory: 0, processing: 0>
2023-10-25 05:38:51,448 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:51,448 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45783
2023-10-25 05:38:51,448 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33152
2023-10-25 05:38:51,449 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,449 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,449 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:51,450 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,450 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,450 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:51,452 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:51,457 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43705', status: init, memory: 0, processing: 0>
2023-10-25 05:38:51,457 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43705
2023-10-25 05:38:51,457 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33176
2023-10-25 05:38:51,459 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:51,460 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,460 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,462 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:51,464 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33311', status: init, memory: 0, processing: 0>
2023-10-25 05:38:51,465 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33311
2023-10-25 05:38:51,465 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33192
2023-10-25 05:38:51,466 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:51,467 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,467 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,467 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34719', status: init, memory: 0, processing: 0>
2023-10-25 05:38:51,468 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34719
2023-10-25 05:38:51,468 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33168
2023-10-25 05:38:51,469 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:51,469 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:38:51,471 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:38:51,471 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:38:51,473 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:38:51,510 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,510 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,510 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,511 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,511 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,511 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,511 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,511 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,521 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:51,521 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:51,521 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:51,521 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:51,522 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:51,522 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:51,522 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:51,522 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:38:51,528 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,529 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:38:51,532 - distributed.scheduler - INFO - Remove client Client-c2e2d7c3-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:51,532 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52446; closing.
2023-10-25 05:38:51,532 - distributed.scheduler - INFO - Remove client Client-c2e2d7c3-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:51,533 - distributed.scheduler - INFO - Close client connection: Client-c2e2d7c3-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:51,534 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34813'. Reason: nanny-close
2023-10-25 05:38:51,534 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:51,535 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33441'. Reason: nanny-close
2023-10-25 05:38:51,536 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:51,536 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35013. Reason: nanny-close
2023-10-25 05:38:51,536 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39949'. Reason: nanny-close
2023-10-25 05:38:51,536 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:51,536 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45783. Reason: nanny-close
2023-10-25 05:38:51,536 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41865'. Reason: nanny-close
2023-10-25 05:38:51,537 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:51,537 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42811'. Reason: nanny-close
2023-10-25 05:38:51,537 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45771. Reason: nanny-close
2023-10-25 05:38:51,537 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:51,538 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40395'. Reason: nanny-close
2023-10-25 05:38:51,538 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:51,538 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33120; closing.
2023-10-25 05:38:51,538 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43705. Reason: nanny-close
2023-10-25 05:38:51,538 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:51,538 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39965. Reason: nanny-close
2023-10-25 05:38:51,538 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35013', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212331.5387297')
2023-10-25 05:38:51,538 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46667'. Reason: nanny-close
2023-10-25 05:38:51,538 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:51,539 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:51,539 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33675. Reason: nanny-close
2023-10-25 05:38:51,539 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45901'. Reason: nanny-close
2023-10-25 05:38:51,539 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:38:51,540 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:51,540 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:51,540 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33311. Reason: nanny-close
2023-10-25 05:38:51,540 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33152; closing.
2023-10-25 05:38:51,540 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:51,540 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34719. Reason: nanny-close
2023-10-25 05:38:51,541 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:51,541 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:51,541 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45783', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212331.5415452')
2023-10-25 05:38:51,542 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33114; closing.
2023-10-25 05:38:51,542 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:51,542 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:51,542 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45771', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212331.5428545')
2023-10-25 05:38:51,543 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:51,543 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:51,543 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33132; closing.
2023-10-25 05:38:51,543 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33176; closing.
2023-10-25 05:38:51,543 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:51,544 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39965', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212331.5440464')
2023-10-25 05:38:51,544 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:38:51,544 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43705', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212331.5444088')
2023-10-25 05:38:51,544 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:51,544 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33144; closing.
2023-10-25 05:38:51,545 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33675', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212331.5454338')
2023-10-25 05:38:51,545 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33192; closing.
2023-10-25 05:38:51,546 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33168; closing.
2023-10-25 05:38:51,546 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:51,546 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33311', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212331.5464666')
2023-10-25 05:38:51,546 - distributed.nanny - INFO - Worker closed
2023-10-25 05:38:51,546 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34719', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212331.5468717')
2023-10-25 05:38:51,547 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:38:53,201 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:38:53,202 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:38:53,202 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:38:53,204 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:38:53,204 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-10-25 05:38:55,246 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:55,250 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45317 instead
  warnings.warn(
2023-10-25 05:38:55,254 - distributed.scheduler - INFO - State start
2023-10-25 05:38:55,275 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:38:55,276 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:38:55,277 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45317/status
2023-10-25 05:38:55,277 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:38:55,627 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36559'
2023-10-25 05:38:55,645 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33507'
2023-10-25 05:38:55,661 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44981'
2023-10-25 05:38:55,663 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42113'
2023-10-25 05:38:55,671 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42845'
2023-10-25 05:38:55,680 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45475'
2023-10-25 05:38:55,692 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34497'
2023-10-25 05:38:55,703 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39313'
2023-10-25 05:38:56,689 - distributed.scheduler - INFO - Receive client connection: Client-c87de60c-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:38:56,702 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33376
2023-10-25 05:38:57,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:57,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:57,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:57,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:57,498 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:57,498 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:57,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:57,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:57,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:57,501 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:57,502 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:57,504 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:57,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:57,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:57,534 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:57,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:57,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:57,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:57,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:57,558 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:57,559 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:38:57,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:38:57,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:38:57,638 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:00,008 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40055
2023-10-25 05:39:00,009 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40055
2023-10-25 05:39:00,009 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37565
2023-10-25 05:39:00,009 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,010 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,010 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:00,010 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:00,010 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_lx7_jp0
2023-10-25 05:39:00,010 - distributed.worker - INFO - Starting Worker plugin RMMSetup-96d04be9-3d58-4468-a5a7-1e59526023d0
2023-10-25 05:39:00,011 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33971
2023-10-25 05:39:00,012 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33971
2023-10-25 05:39:00,012 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45319
2023-10-25 05:39:00,012 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,012 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,012 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:00,012 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:00,012 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z_q80yi4
2023-10-25 05:39:00,013 - distributed.worker - INFO - Starting Worker plugin PreImport-9af0f9ce-813a-4774-88b4-629dc39ffd41
2023-10-25 05:39:00,013 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9de0d856-b3bc-4f29-bdee-1fc4e16ccd51
2023-10-25 05:39:00,013 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fa1cd799-afac-4e3f-8d7b-de3730b7e0a7
2023-10-25 05:39:00,031 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34657
2023-10-25 05:39:00,031 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34657
2023-10-25 05:39:00,032 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41137
2023-10-25 05:39:00,032 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,032 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,032 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:00,032 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:00,032 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1zb7ob_7
2023-10-25 05:39:00,032 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ed1a9654-2b9b-49fe-a3be-c7e3a8411a25
2023-10-25 05:39:00,090 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37129
2023-10-25 05:39:00,091 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37129
2023-10-25 05:39:00,091 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37545
2023-10-25 05:39:00,091 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,091 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,091 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:00,091 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:00,091 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fl4yu_fh
2023-10-25 05:39:00,092 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e71d0d73-07ad-400a-981d-e5ee5e5ee504
2023-10-25 05:39:00,152 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,154 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c99be737-472f-4193-b061-987a89c9cbba
2023-10-25 05:39:00,154 - distributed.worker - INFO - Starting Worker plugin PreImport-e70e5269-f623-4065-b7ce-237d94ba6627
2023-10-25 05:39:00,154 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,162 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0ef6427e-86fc-4440-bd3f-232451190c1a
2023-10-25 05:39:00,162 - distributed.worker - INFO - Starting Worker plugin PreImport-4e29665e-b8ab-4080-96ed-7599828ef6c2
2023-10-25 05:39:00,162 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,183 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33971', status: init, memory: 0, processing: 0>
2023-10-25 05:39:00,185 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33971
2023-10-25 05:39:00,185 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45314
2023-10-25 05:39:00,186 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:00,186 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40055', status: init, memory: 0, processing: 0>
2023-10-25 05:39:00,186 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,187 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,187 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40055
2023-10-25 05:39:00,187 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45316
2023-10-25 05:39:00,188 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:00,188 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:00,188 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,188 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,190 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:00,330 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34657', status: init, memory: 0, processing: 0>
2023-10-25 05:39:00,331 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34657
2023-10-25 05:39:00,331 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45328
2023-10-25 05:39:00,332 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:00,333 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,333 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,334 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:00,370 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41307
2023-10-25 05:39:00,371 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41307
2023-10-25 05:39:00,371 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37031
2023-10-25 05:39:00,371 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,371 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,372 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:00,372 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:00,372 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_dca1xe_
2023-10-25 05:39:00,372 - distributed.worker - INFO - Starting Worker plugin PreImport-b016d3b2-e8a4-4587-adae-aaa1e98a8afc
2023-10-25 05:39:00,372 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ae459000-2c9f-41eb-aff1-b1130f0bf687
2023-10-25 05:39:00,373 - distributed.worker - INFO - Starting Worker plugin RMMSetup-70c8c919-ec9b-4707-a545-92117c69c31a
2023-10-25 05:39:00,371 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37883
2023-10-25 05:39:00,372 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38711
2023-10-25 05:39:00,373 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38711
2023-10-25 05:39:00,373 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37883
2023-10-25 05:39:00,373 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34773
2023-10-25 05:39:00,373 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39757
2023-10-25 05:39:00,373 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,374 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,374 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,374 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,374 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:00,374 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:00,374 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:00,374 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nufvvgv_
2023-10-25 05:39:00,374 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:00,374 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lqwknsbp
2023-10-25 05:39:00,374 - distributed.worker - INFO - Starting Worker plugin PreImport-62ea7cf5-5233-4c3e-b04f-5162d02262e5
2023-10-25 05:39:00,374 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cc651527-db3f-4036-abd3-1a6fe3e0e2ee
2023-10-25 05:39:00,375 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-970e9e86-4af5-4454-8222-43b3321e6766
2023-10-25 05:39:00,375 - distributed.worker - INFO - Starting Worker plugin PreImport-30ae1b0d-32e7-43f8-a1ec-b5d6c92a22e5
2023-10-25 05:39:00,375 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f58245d3-d0c7-4c59-a2a6-a100cd94c257
2023-10-25 05:39:00,376 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ed932eaa-8cf5-42f7-82a7-5d7500dfdfad
2023-10-25 05:39:00,379 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38891
2023-10-25 05:39:00,379 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38891
2023-10-25 05:39:00,380 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45557
2023-10-25 05:39:00,380 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,380 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,380 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:00,380 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:00,380 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fmcz775b
2023-10-25 05:39:00,380 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f683bbda-6f16-4eca-aef4-255dc616a314
2023-10-25 05:39:00,390 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ef767a73-6938-44de-b181-cdb19a0a6e62
2023-10-25 05:39:00,391 - distributed.worker - INFO - Starting Worker plugin PreImport-60808a7e-505d-4611-8055-a50367cd29a1
2023-10-25 05:39:00,392 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,425 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37129', status: init, memory: 0, processing: 0>
2023-10-25 05:39:00,426 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37129
2023-10-25 05:39:00,426 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45330
2023-10-25 05:39:00,427 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:00,429 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,429 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:00,517 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e0579251-476d-4df8-bf09-93fd3c8d9bdf
2023-10-25 05:39:00,517 - distributed.worker - INFO - Starting Worker plugin PreImport-ecfed824-b114-4e5a-8391-056083024aba
2023-10-25 05:39:00,517 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,528 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,532 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,535 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,539 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38891', status: init, memory: 0, processing: 0>
2023-10-25 05:39:00,540 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38891
2023-10-25 05:39:00,540 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45334
2023-10-25 05:39:00,541 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:00,541 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,541 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,543 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:00,562 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38711', status: init, memory: 0, processing: 0>
2023-10-25 05:39:00,563 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38711
2023-10-25 05:39:00,563 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45342
2023-10-25 05:39:00,565 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:00,566 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,566 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,566 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41307', status: init, memory: 0, processing: 0>
2023-10-25 05:39:00,567 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41307
2023-10-25 05:39:00,567 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45344
2023-10-25 05:39:00,568 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:00,568 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:00,570 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,570 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,572 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:00,572 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37883', status: init, memory: 0, processing: 0>
2023-10-25 05:39:00,573 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37883
2023-10-25 05:39:00,573 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45356
2023-10-25 05:39:00,574 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:00,575 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:00,575 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:00,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:00,643 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:00,643 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:00,644 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:00,644 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:00,644 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:00,644 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:00,644 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:00,645 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:00,648 - distributed.scheduler - INFO - Remove client Client-c87de60c-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:00,649 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33376; closing.
2023-10-25 05:39:00,649 - distributed.scheduler - INFO - Remove client Client-c87de60c-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:00,649 - distributed.scheduler - INFO - Close client connection: Client-c87de60c-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:00,650 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36559'. Reason: nanny-close
2023-10-25 05:39:00,651 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:00,651 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33507'. Reason: nanny-close
2023-10-25 05:39:00,652 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:00,652 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37883. Reason: nanny-close
2023-10-25 05:39:00,652 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44981'. Reason: nanny-close
2023-10-25 05:39:00,652 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:00,652 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41307. Reason: nanny-close
2023-10-25 05:39:00,653 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42113'. Reason: nanny-close
2023-10-25 05:39:00,653 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:00,653 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33971. Reason: nanny-close
2023-10-25 05:39:00,653 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42845'. Reason: nanny-close
2023-10-25 05:39:00,653 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:00,654 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40055. Reason: nanny-close
2023-10-25 05:39:00,654 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45475'. Reason: nanny-close
2023-10-25 05:39:00,654 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:00,654 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:00,654 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37129. Reason: nanny-close
2023-10-25 05:39:00,654 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45356; closing.
2023-10-25 05:39:00,654 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34497'. Reason: nanny-close
2023-10-25 05:39:00,655 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37883', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212340.6550527')
2023-10-25 05:39:00,655 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:00,655 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:00,655 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:00,655 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39313'. Reason: nanny-close
2023-10-25 05:39:00,655 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38711. Reason: nanny-close
2023-10-25 05:39:00,655 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:00,655 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38891. Reason: nanny-close
2023-10-25 05:39:00,656 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:00,656 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34657. Reason: nanny-close
2023-10-25 05:39:00,656 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:00,657 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:00,657 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45316; closing.
2023-10-25 05:39:00,657 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:00,657 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45344; closing.
2023-10-25 05:39:00,657 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:00,657 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45314; closing.
2023-10-25 05:39:00,658 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:00,658 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40055', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212340.6585412')
2023-10-25 05:39:00,658 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:00,658 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:00,659 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41307', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212340.6589706')
2023-10-25 05:39:00,659 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:00,659 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33971', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212340.6593626')
2023-10-25 05:39:00,659 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:00,660 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45330; closing.
2023-10-25 05:39:00,660 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:00,661 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:00,661 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37129', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212340.6612108')
2023-10-25 05:39:00,661 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45334; closing.
2023-10-25 05:39:00,661 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45342; closing.
2023-10-25 05:39:00,662 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:00,662 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45328; closing.
2023-10-25 05:39:00,662 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38891', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212340.6625242')
2023-10-25 05:39:00,663 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38711', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212340.6630886')
2023-10-25 05:39:00,663 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34657', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212340.6635485')
2023-10-25 05:39:00,663 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:39:02,268 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:39:02,268 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:39:02,269 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:39:02,270 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:39:02,271 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-10-25 05:39:04,471 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:04,476 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34651 instead
  warnings.warn(
2023-10-25 05:39:04,479 - distributed.scheduler - INFO - State start
2023-10-25 05:39:04,502 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:04,503 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:39:04,504 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34651/status
2023-10-25 05:39:04,505 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:39:04,582 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45395'
2023-10-25 05:39:05,082 - distributed.scheduler - INFO - Receive client connection: Client-cdf3b83c-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:05,094 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45456
2023-10-25 05:39:06,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:06,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:06,647 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:07,567 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43773
2023-10-25 05:39:07,568 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43773
2023-10-25 05:39:07,568 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-10-25 05:39:07,568 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:07,568 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:07,568 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:07,568 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-25 05:39:07,568 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o3wqeoap
2023-10-25 05:39:07,569 - distributed.worker - INFO - Starting Worker plugin RMMSetup-290bd899-e535-4bad-8fee-f559eafea066
2023-10-25 05:39:07,569 - distributed.worker - INFO - Starting Worker plugin PreImport-3c729404-cce9-4269-bbc5-7dfbed785dd2
2023-10-25 05:39:07,569 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-83a287b7-254f-4a36-8ecd-3c563c35148e
2023-10-25 05:39:07,570 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:07,598 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43773', status: init, memory: 0, processing: 0>
2023-10-25 05:39:07,599 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43773
2023-10-25 05:39:07,599 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45468
2023-10-25 05:39:07,600 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:07,601 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:07,601 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:07,603 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:07,641 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:07,644 - distributed.scheduler - INFO - Remove client Client-cdf3b83c-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:07,644 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45456; closing.
2023-10-25 05:39:07,645 - distributed.scheduler - INFO - Remove client Client-cdf3b83c-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:07,645 - distributed.scheduler - INFO - Close client connection: Client-cdf3b83c-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:07,646 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45395'. Reason: nanny-close
2023-10-25 05:39:07,646 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:07,647 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43773. Reason: nanny-close
2023-10-25 05:39:07,649 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:07,649 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45468; closing.
2023-10-25 05:39:07,650 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43773', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212347.6500034')
2023-10-25 05:39:07,650 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:39:07,651 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:08,963 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:39:08,963 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:39:08,964 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:39:08,965 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:39:08,965 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-10-25 05:39:13,097 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:13,102 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-25 05:39:13,106 - distributed.scheduler - INFO - State start
2023-10-25 05:39:13,268 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:13,269 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:39:13,269 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-25 05:39:13,270 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:39:13,272 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44481'
2023-10-25 05:39:13,294 - distributed.scheduler - INFO - Receive client connection: Client-d30dc59b-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:13,306 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34502
2023-10-25 05:39:14,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:14,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:15,558 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:17,173 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41763
2023-10-25 05:39:17,173 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41763
2023-10-25 05:39:17,174 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36859
2023-10-25 05:39:17,174 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:17,174 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:17,174 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:17,174 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-25 05:39:17,174 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j3x00e6w
2023-10-25 05:39:17,174 - distributed.worker - INFO - Starting Worker plugin RMMSetup-44cfad4f-0326-43d1-b3c8-0531f836d47c
2023-10-25 05:39:17,175 - distributed.worker - INFO - Starting Worker plugin PreImport-3f579c0e-07d2-496b-b6e2-19623776cddd
2023-10-25 05:39:17,176 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-15d8caa0-23b4-442e-a2f0-7cf81dd88ee2
2023-10-25 05:39:17,177 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:17,210 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41763', status: init, memory: 0, processing: 0>
2023-10-25 05:39:17,212 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41763
2023-10-25 05:39:17,212 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34526
2023-10-25 05:39:17,213 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:17,214 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:17,214 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:17,217 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:17,276 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:17,279 - distributed.scheduler - INFO - Remove client Client-d30dc59b-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:17,279 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34502; closing.
2023-10-25 05:39:17,280 - distributed.scheduler - INFO - Remove client Client-d30dc59b-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:17,280 - distributed.scheduler - INFO - Close client connection: Client-d30dc59b-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:17,281 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44481'. Reason: nanny-close
2023-10-25 05:39:17,281 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:17,283 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41763. Reason: nanny-close
2023-10-25 05:39:17,285 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34526; closing.
2023-10-25 05:39:17,285 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:17,286 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41763', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212357.2859554')
2023-10-25 05:39:17,286 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:39:17,287 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:18,598 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:39:18,599 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:39:18,599 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:39:18,600 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:39:18,600 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-10-25 05:39:20,881 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:20,886 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-25 05:39:20,889 - distributed.scheduler - INFO - State start
2023-10-25 05:39:20,915 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:20,916 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:39:20,917 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-25 05:39:20,917 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:39:25,298 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:55820'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:55820>: Stream is closed
2023-10-25 05:39:25,598 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:39:25,599 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:39:25,599 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:39:25,600 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:39:25,600 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-10-25 05:39:27,612 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:27,616 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35655 instead
  warnings.warn(
2023-10-25 05:39:27,620 - distributed.scheduler - INFO - State start
2023-10-25 05:39:27,643 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:27,644 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-25 05:39:27,644 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35655/status
2023-10-25 05:39:27,645 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:39:27,751 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37781'
2023-10-25 05:39:28,805 - distributed.scheduler - INFO - Receive client connection: Client-dbc687f4-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:28,818 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55736
2023-10-25 05:39:29,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:29,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:29,361 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:30,170 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34875
2023-10-25 05:39:30,171 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34875
2023-10-25 05:39:30,171 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33925
2023-10-25 05:39:30,171 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-25 05:39:30,171 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:30,171 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:30,171 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-25 05:39:30,171 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-j4hbifxj
2023-10-25 05:39:30,172 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2312c89a-6656-4a19-92a7-8586c995f770
2023-10-25 05:39:30,172 - distributed.worker - INFO - Starting Worker plugin PreImport-a154477d-d80a-47b6-a8c8-2f8915a94033
2023-10-25 05:39:30,172 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f583feb5-e42b-4104-8900-84ae4adea624
2023-10-25 05:39:30,173 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:30,199 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34875', status: init, memory: 0, processing: 0>
2023-10-25 05:39:30,200 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34875
2023-10-25 05:39:30,200 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36490
2023-10-25 05:39:30,201 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:30,202 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-25 05:39:30,202 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:30,204 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-25 05:39:30,243 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:30,245 - distributed.scheduler - INFO - Remove client Client-dbc687f4-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:30,246 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55736; closing.
2023-10-25 05:39:30,246 - distributed.scheduler - INFO - Remove client Client-dbc687f4-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:30,246 - distributed.scheduler - INFO - Close client connection: Client-dbc687f4-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:30,247 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37781'. Reason: nanny-close
2023-10-25 05:39:30,248 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:30,249 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34875. Reason: nanny-close
2023-10-25 05:39:30,250 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36490; closing.
2023-10-25 05:39:30,250 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-25 05:39:30,251 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34875', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212370.251232')
2023-10-25 05:39:30,251 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:39:30,252 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:31,263 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:39:31,264 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:39:31,264 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:39:31,265 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-25 05:39:31,265 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-10-25 05:39:33,221 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:33,225 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-25 05:39:33,228 - distributed.scheduler - INFO - State start
2023-10-25 05:39:33,399 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:33,400 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:39:33,401 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-25 05:39:33,401 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:39:33,524 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40397'
2023-10-25 05:39:33,540 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37797'
2023-10-25 05:39:33,548 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45891'
2023-10-25 05:39:33,562 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32919'
2023-10-25 05:39:33,565 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41201'
2023-10-25 05:39:33,573 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37023'
2023-10-25 05:39:33,584 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41017'
2023-10-25 05:39:33,594 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34265'
2023-10-25 05:39:35,095 - distributed.scheduler - INFO - Receive client connection: Client-df1d922b-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:35,110 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35574
2023-10-25 05:39:35,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:35,295 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:35,298 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:35,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:35,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:35,320 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:35,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:35,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:35,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:35,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:35,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:35,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:35,336 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:35,337 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:35,337 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:35,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:35,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:35,375 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:35,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:35,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:35,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:35,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:35,380 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:35,381 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:37,929 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43747
2023-10-25 05:39:37,930 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43747
2023-10-25 05:39:37,930 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33751
2023-10-25 05:39:37,930 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:37,930 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:37,931 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:37,931 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:37,931 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6fbeau29
2023-10-25 05:39:37,932 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d9d75dd6-8eab-43da-a0a5-ad17a0246f3f
2023-10-25 05:39:37,934 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36657
2023-10-25 05:39:37,936 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36657
2023-10-25 05:39:37,936 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44901
2023-10-25 05:39:37,936 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:37,937 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:37,937 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:37,937 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:37,937 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2ugjj4ug
2023-10-25 05:39:37,938 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ad3573d7-aff2-4f34-b894-0d9f555ef942
2023-10-25 05:39:37,978 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41935
2023-10-25 05:39:37,979 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41935
2023-10-25 05:39:37,979 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44993
2023-10-25 05:39:37,979 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:37,979 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:37,979 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:37,980 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:37,980 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e1ehtdpc
2023-10-25 05:39:37,980 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9bbe0e34-a0d0-48c0-8752-3ba37ab47973
2023-10-25 05:39:37,999 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40743
2023-10-25 05:39:38,000 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40743
2023-10-25 05:39:38,000 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42209
2023-10-25 05:39:38,000 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,000 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,000 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:38,000 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:38,000 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kkb1sdbl
2023-10-25 05:39:38,001 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0e6480a8-d465-4125-b073-325d0416441d
2023-10-25 05:39:38,001 - distributed.worker - INFO - Starting Worker plugin RMMSetup-53f47bf8-0309-4858-8a39-d8a76ff8b5f5
2023-10-25 05:39:38,036 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41475
2023-10-25 05:39:38,036 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41475
2023-10-25 05:39:38,037 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36997
2023-10-25 05:39:38,037 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,037 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,037 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:38,037 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:38,037 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1cygtucg
2023-10-25 05:39:38,037 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1cfbece0-2bdd-49bd-ac1c-67d042df059a
2023-10-25 05:39:38,039 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7c62b61e-e59d-4b78-8e0b-6420f46b5962
2023-10-25 05:39:38,044 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42965
2023-10-25 05:39:38,044 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42965
2023-10-25 05:39:38,045 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39791
2023-10-25 05:39:38,045 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,045 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,045 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:38,045 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:38,045 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lqzgetxa
2023-10-25 05:39:38,045 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aaff3806-6451-4edd-aa63-f6c958135cb7
2023-10-25 05:39:38,072 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39731
2023-10-25 05:39:38,073 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39731
2023-10-25 05:39:38,073 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39863
2023-10-25 05:39:38,073 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,073 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,073 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:38,074 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:38,074 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-89b4kxmh
2023-10-25 05:39:38,074 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b1f84cac-e87f-44ce-98be-4fa2d1e875b4
2023-10-25 05:39:38,078 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35353
2023-10-25 05:39:38,079 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35353
2023-10-25 05:39:38,079 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42827
2023-10-25 05:39:38,079 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,079 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,079 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:38,080 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-25 05:39:38,080 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hvth502y
2023-10-25 05:39:38,080 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f3f08fd1-4b64-4129-958d-3b0e0eefe8c7
2023-10-25 05:39:38,117 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ae28fead-2e10-4652-a314-753c5ce72d6e
2023-10-25 05:39:38,118 - distributed.worker - INFO - Starting Worker plugin PreImport-9436d0d2-21d2-43c7-9677-f3c68a147463
2023-10-25 05:39:38,119 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,145 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d2071a2e-3d0c-409c-92b9-f62ea2835b15
2023-10-25 05:39:38,145 - distributed.worker - INFO - Starting Worker plugin PreImport-fe1d357e-298b-4349-898b-a66a26aab5a7
2023-10-25 05:39:38,146 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,164 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43747', status: init, memory: 0, processing: 0>
2023-10-25 05:39:38,166 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43747
2023-10-25 05:39:38,166 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35594
2023-10-25 05:39:38,168 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:38,170 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,170 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,172 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:38,177 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-14480b02-9646-40f2-957f-96aeb8edd63f
2023-10-25 05:39:38,177 - distributed.worker - INFO - Starting Worker plugin PreImport-e039321d-27f9-4dfd-a98a-cea86e5554c1
2023-10-25 05:39:38,177 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,188 - distributed.worker - INFO - Starting Worker plugin PreImport-e615ae98-b9eb-46ce-99e6-2a7255b03b50
2023-10-25 05:39:38,188 - distributed.worker - INFO - Starting Worker plugin PreImport-a9111540-e846-4c8c-a562-f34683b2ef23
2023-10-25 05:39:38,188 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,189 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,190 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36657', status: init, memory: 0, processing: 0>
2023-10-25 05:39:38,190 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36657
2023-10-25 05:39:38,190 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35604
2023-10-25 05:39:38,192 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:38,193 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,193 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,195 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:38,205 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e6b85bb3-6d42-4de9-a91d-80b4684cf8d3
2023-10-25 05:39:38,205 - distributed.worker - INFO - Starting Worker plugin PreImport-26d85ca0-ad23-4352-9a4f-a8befa9952de
2023-10-25 05:39:38,205 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,210 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d4f7b8e6-2d6f-4ea3-b1f4-ff0b361f692c
2023-10-25 05:39:38,210 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d970b595-0f79-434c-8b4b-8b9b318d6a30
2023-10-25 05:39:38,210 - distributed.worker - INFO - Starting Worker plugin PreImport-caf64162-347f-47ff-92b5-979812de267d
2023-10-25 05:39:38,211 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,211 - distributed.worker - INFO - Starting Worker plugin PreImport-55e0dca7-5109-49a7-9df2-5e9c7ae44cf8
2023-10-25 05:39:38,211 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,212 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41935', status: init, memory: 0, processing: 0>
2023-10-25 05:39:38,212 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41935
2023-10-25 05:39:38,213 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35608
2023-10-25 05:39:38,213 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:38,214 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,214 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,216 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:38,223 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40743', status: init, memory: 0, processing: 0>
2023-10-25 05:39:38,223 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40743
2023-10-25 05:39:38,223 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35618
2023-10-25 05:39:38,224 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41475', status: init, memory: 0, processing: 0>
2023-10-25 05:39:38,225 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41475
2023-10-25 05:39:38,225 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35634
2023-10-25 05:39:38,225 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:38,226 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,226 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,226 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:38,227 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,227 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,228 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:38,229 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:38,233 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42965', status: init, memory: 0, processing: 0>
2023-10-25 05:39:38,234 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42965
2023-10-25 05:39:38,234 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35644
2023-10-25 05:39:38,235 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:38,235 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,235 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,237 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39731', status: init, memory: 0, processing: 0>
2023-10-25 05:39:38,237 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:38,237 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39731
2023-10-25 05:39:38,237 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35650
2023-10-25 05:39:38,238 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:38,239 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,239 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,240 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:38,247 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35353', status: init, memory: 0, processing: 0>
2023-10-25 05:39:38,248 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35353
2023-10-25 05:39:38,248 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35664
2023-10-25 05:39:38,249 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:38,250 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:38,250 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:38,252 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:38,282 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:38,282 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:38,282 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:38,283 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:38,283 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:38,283 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:38,283 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:38,283 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-25 05:39:38,295 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:38,295 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:38,295 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:38,296 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:38,296 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:38,296 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:38,296 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:38,296 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:38,301 - distributed.scheduler - INFO - Remove client Client-df1d922b-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:38,301 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35574; closing.
2023-10-25 05:39:38,301 - distributed.scheduler - INFO - Remove client Client-df1d922b-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:38,302 - distributed.scheduler - INFO - Close client connection: Client-df1d922b-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:38,302 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40397'. Reason: nanny-close
2023-10-25 05:39:38,303 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:38,304 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37797'. Reason: nanny-close
2023-10-25 05:39:38,304 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:38,304 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39731. Reason: nanny-close
2023-10-25 05:39:38,305 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45891'. Reason: nanny-close
2023-10-25 05:39:38,305 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:38,305 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41935. Reason: nanny-close
2023-10-25 05:39:38,305 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32919'. Reason: nanny-close
2023-10-25 05:39:38,305 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:38,306 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36657. Reason: nanny-close
2023-10-25 05:39:38,306 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41201'. Reason: nanny-close
2023-10-25 05:39:38,306 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:38,306 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:38,306 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35650; closing.
2023-10-25 05:39:38,306 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40743. Reason: nanny-close
2023-10-25 05:39:38,306 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37023'. Reason: nanny-close
2023-10-25 05:39:38,307 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39731', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212378.3070595')
2023-10-25 05:39:38,307 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:38,307 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:38,307 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43747. Reason: nanny-close
2023-10-25 05:39:38,307 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41017'. Reason: nanny-close
2023-10-25 05:39:38,307 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:38,307 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42965. Reason: nanny-close
2023-10-25 05:39:38,308 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34265'. Reason: nanny-close
2023-10-25 05:39:38,308 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:38,308 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:38,308 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:38,308 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35353. Reason: nanny-close
2023-10-25 05:39:38,308 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35608; closing.
2023-10-25 05:39:38,308 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:38,309 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:38,309 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41935', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212378.3097694')
2023-10-25 05:39:38,310 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:38,310 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41475. Reason: nanny-close
2023-10-25 05:39:38,310 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35604; closing.
2023-10-25 05:39:38,310 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:38,310 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:38,310 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36657', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212378.31085')
2023-10-25 05:39:38,311 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35618; closing.
2023-10-25 05:39:38,311 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:38,311 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:38,311 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:38,312 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:38,312 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40743', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212378.3119936')
2023-10-25 05:39:38,312 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:38,312 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35594; closing.
2023-10-25 05:39:38,312 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35644; closing.
2023-10-25 05:39:38,313 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:38,313 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43747', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212378.3134413')
2023-10-25 05:39:38,313 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:38,313 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42965', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212378.3139045')
2023-10-25 05:39:38,314 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35664; closing.
2023-10-25 05:39:38,314 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35634; closing.
2023-10-25 05:39:38,315 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35353', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212378.3150344')
2023-10-25 05:39:38,315 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41475', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212378.3155258')
2023-10-25 05:39:38,315 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:39:39,920 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:39:39,921 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:39:39,921 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:39:39,922 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:39:39,923 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-10-25 05:39:42,033 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:42,037 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33481 instead
  warnings.warn(
2023-10-25 05:39:42,041 - distributed.scheduler - INFO - State start
2023-10-25 05:39:42,064 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:42,065 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:39:42,066 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33481/status
2023-10-25 05:39:42,066 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:39:42,198 - distributed.scheduler - INFO - Receive client connection: Client-e453c336-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:42,214 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41388
2023-10-25 05:39:42,215 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42067'
2023-10-25 05:39:43,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:43,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:43,841 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:44,744 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40927
2023-10-25 05:39:44,745 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40927
2023-10-25 05:39:44,745 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46829
2023-10-25 05:39:44,745 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:44,745 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:44,745 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:44,745 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-25 05:39:44,745 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0nml27hz
2023-10-25 05:39:44,745 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c84febdb-0808-49ec-9607-a6bc2d142211
2023-10-25 05:39:44,746 - distributed.worker - INFO - Starting Worker plugin PreImport-ae2723a5-7cfe-489e-b540-aaf012416494
2023-10-25 05:39:44,746 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d1a0bcfb-c1d4-4abf-8533-21d01fc7aabc
2023-10-25 05:39:44,847 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:44,873 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40927', status: init, memory: 0, processing: 0>
2023-10-25 05:39:44,875 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40927
2023-10-25 05:39:44,875 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41418
2023-10-25 05:39:44,876 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:44,876 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:44,877 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:44,878 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:44,971 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:39:44,975 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:44,977 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:44,979 - distributed.scheduler - INFO - Remove client Client-e453c336-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:44,979 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41388; closing.
2023-10-25 05:39:44,980 - distributed.scheduler - INFO - Remove client Client-e453c336-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:44,980 - distributed.scheduler - INFO - Close client connection: Client-e453c336-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:44,981 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42067'. Reason: nanny-close
2023-10-25 05:39:44,981 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:44,983 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40927. Reason: nanny-close
2023-10-25 05:39:44,984 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:44,984 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41418; closing.
2023-10-25 05:39:44,985 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40927', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212384.9850156')
2023-10-25 05:39:44,985 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:39:44,986 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:46,242 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:39:46,243 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:39:46,244 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:39:46,246 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:39:46,247 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-10-25 05:39:48,565 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:48,570 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-25 05:39:48,573 - distributed.scheduler - INFO - State start
2023-10-25 05:39:48,596 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-25 05:39:48,597 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-25 05:39:48,598 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-25 05:39:48,598 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-25 05:39:48,736 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43805'
2023-10-25 05:39:49,138 - distributed.scheduler - INFO - Receive client connection: Client-e82f9fd0-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:49,154 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41514
2023-10-25 05:39:50,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-25 05:39:50,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-25 05:39:50,499 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-25 05:39:51,356 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35955
2023-10-25 05:39:51,357 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35955
2023-10-25 05:39:51,357 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37159
2023-10-25 05:39:51,357 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-25 05:39:51,357 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:51,357 - distributed.worker - INFO -               Threads:                          1
2023-10-25 05:39:51,357 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-25 05:39:51,357 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pqdamykr
2023-10-25 05:39:51,358 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f7567df5-8745-4f39-ac64-d5e691ea750b
2023-10-25 05:39:51,358 - distributed.worker - INFO - Starting Worker plugin PreImport-25d30fed-133b-4079-b3e1-c6f9971fd050
2023-10-25 05:39:51,358 - distributed.worker - INFO - Starting Worker plugin RMMSetup-928275a9-2eb2-464f-89d9-55cb858f3f9b
2023-10-25 05:39:51,456 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:51,482 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35955', status: init, memory: 0, processing: 0>
2023-10-25 05:39:51,483 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35955
2023-10-25 05:39:51,483 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33944
2023-10-25 05:39:51,484 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-25 05:39:51,485 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-25 05:39:51,485 - distributed.worker - INFO - -------------------------------------------------
2023-10-25 05:39:51,487 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-25 05:39:51,499 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-10-25 05:39:51,503 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-25 05:39:51,506 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:51,508 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-25 05:39:51,511 - distributed.scheduler - INFO - Remove client Client-e82f9fd0-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:51,511 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41514; closing.
2023-10-25 05:39:51,511 - distributed.scheduler - INFO - Remove client Client-e82f9fd0-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:51,511 - distributed.scheduler - INFO - Close client connection: Client-e82f9fd0-72f8-11ee-b194-d8c49764f6bb
2023-10-25 05:39:51,512 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43805'. Reason: nanny-close
2023-10-25 05:39:51,521 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-25 05:39:51,522 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35955. Reason: nanny-close
2023-10-25 05:39:51,525 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-25 05:39:51,525 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33944; closing.
2023-10-25 05:39:51,525 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35955', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698212391.5254183')
2023-10-25 05:39:51,525 - distributed.scheduler - INFO - Lost all workers
2023-10-25 05:39:51,526 - distributed.nanny - INFO - Worker closed
2023-10-25 05:39:52,528 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-25 05:39:52,529 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-25 05:39:52,529 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-25 05:39:52,530 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-25 05:39:52,530 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37213 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37247 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38425 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44025 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34839 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44367 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34169 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34565 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40013 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41607 instead
  warnings.warn(
2023-10-25 05:41:56,714 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-25 05:41:56,718 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:43005', name: 1, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37627 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43687 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44475 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43187 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42553 instead
  warnings.warn(
2023-10-25 05:44:18,783 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-10-25 05:44:18,791 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://127.0.0.1:58782', name: 0, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37139 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38771 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42603 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38877 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34255 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39283 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42071 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39865 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42609 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43633 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46297 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44131 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45499 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43275 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33757 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45923 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45301 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37733 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34471 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46427 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45557 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36711 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43795 instead
  warnings.warn(
2023-10-25 05:51:32,365 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-25 05:51:32,368 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-25 05:51:32,374 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-25 05:51:32,377 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44144 remote=tcp://127.0.0.1:40537>: Stream is closed
2023-10-25 05:51:32,377 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:45587'.
2023-10-25 05:51:32,377 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44132 remote=tcp://127.0.0.1:40537>: Stream is closed
2023-10-25 05:51:32,378 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:46821'.
2023-10-25 05:51:32,379 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7ff35a33b4c0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-25 05:51:32,380 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fdb723c14c0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-25 05:51:32,383 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:46551'.
2023-10-25 05:51:32,384 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:46551'. Shutting down.
2023-10-25 05:51:32,386 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fb1c3f094c0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-25 05:51:32,393 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-25 05:51:32,400 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:40727'.
2023-10-25 05:51:32,401 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:40727'. Shutting down.
2023-10-25 05:51:32,404 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f5ee27494c0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-10-25 05:51:34,382 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-10-25 05:51:34,383 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-10-25 05:51:34,388 - distributed.nanny - ERROR - Worker process died unexpectedly
