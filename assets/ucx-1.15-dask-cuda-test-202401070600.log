============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-07 06:38:01,427 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:01,431 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33615 instead
  warnings.warn(
2024-01-07 06:38:01,435 - distributed.scheduler - INFO - State start
2024-01-07 06:38:01,460 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:01,460 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-07 06:38:01,461 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33615/status
2024-01-07 06:38:01,461 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:38:01,623 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36043'
2024-01-07 06:38:01,647 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33515'
2024-01-07 06:38:01,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42765'
2024-01-07 06:38:01,659 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37981'
2024-01-07 06:38:02,504 - distributed.scheduler - INFO - Receive client connection: Client-4c963138-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:02,521 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55888
2024-01-07 06:38:03,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:03,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:03,482 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:03,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:03,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:03,483 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40051
2024-01-07 06:38:03,483 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40051
2024-01-07 06:38:03,483 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43721
2024-01-07 06:38:03,483 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:38:03,483 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,483 - distributed.worker - INFO -               Threads:                          4
2024-01-07 06:38:03,483 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-07 06:38:03,483 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-_fst6dtx
2024-01-07 06:38:03,484 - distributed.worker - INFO - Starting Worker plugin PreImport-c93f1d26-8d6f-4737-9dac-f321458063ce
2024-01-07 06:38:03,484 - distributed.worker - INFO - Starting Worker plugin RMMSetup-17e388ca-c133-415e-865a-48739ee5167d
2024-01-07 06:38:03,484 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c22f8cfe-66f3-49d5-bd4a-c7b46dba257b
2024-01-07 06:38:03,484 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,486 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:03,487 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45779
2024-01-07 06:38:03,487 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45779
2024-01-07 06:38:03,487 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39075
2024-01-07 06:38:03,487 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:38:03,487 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,487 - distributed.worker - INFO -               Threads:                          4
2024-01-07 06:38:03,487 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-07 06:38:03,487 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-zosh6usq
2024-01-07 06:38:03,488 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5d8890ca-17e6-4447-9800-011b459e6d20
2024-01-07 06:38:03,488 - distributed.worker - INFO - Starting Worker plugin PreImport-09bbce47-a35c-4182-8eb2-8a4a788bc6f2
2024-01-07 06:38:03,488 - distributed.worker - INFO - Starting Worker plugin RMMSetup-176fb6f1-6a7b-434a-9742-a6cb24862ff1
2024-01-07 06:38:03,488 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:03,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:03,496 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:03,497 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38003
2024-01-07 06:38:03,497 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38003
2024-01-07 06:38:03,497 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37433
2024-01-07 06:38:03,497 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:38:03,497 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,497 - distributed.worker - INFO -               Threads:                          4
2024-01-07 06:38:03,497 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-07 06:38:03,497 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-m9vjk9y2
2024-01-07 06:38:03,497 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0dab7095-1b81-4680-9faa-ba2e9a8eb28a
2024-01-07 06:38:03,497 - distributed.worker - INFO - Starting Worker plugin PreImport-dbbd7013-0c21-4e02-835e-c6a200fbfef7
2024-01-07 06:38:03,498 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2b79b34f-4387-452f-982f-f493112a607b
2024-01-07 06:38:03,498 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:03,528 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:03,532 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:03,532 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32819
2024-01-07 06:38:03,532 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32819
2024-01-07 06:38:03,532 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37853
2024-01-07 06:38:03,533 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:38:03,533 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,533 - distributed.worker - INFO -               Threads:                          4
2024-01-07 06:38:03,533 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-07 06:38:03,533 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-uw80ofa4
2024-01-07 06:38:03,533 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-84b51bbe-f19a-4613-9d43-27bd9277bfb9
2024-01-07 06:38:03,534 - distributed.worker - INFO - Starting Worker plugin PreImport-8f9f4e04-370a-4c3f-a018-a984c543a4f6
2024-01-07 06:38:03,534 - distributed.worker - INFO - Starting Worker plugin RMMSetup-25a2c139-857a-4a59-978c-6d0816a146cf
2024-01-07 06:38:03,534 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,664 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40051', status: init, memory: 0, processing: 0>
2024-01-07 06:38:03,665 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40051
2024-01-07 06:38:03,665 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55912
2024-01-07 06:38:03,666 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:03,667 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:38:03,667 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,668 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:38:03,677 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45779', status: init, memory: 0, processing: 0>
2024-01-07 06:38:03,677 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45779
2024-01-07 06:38:03,678 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55922
2024-01-07 06:38:03,678 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38003', status: init, memory: 0, processing: 0>
2024-01-07 06:38:03,678 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:03,679 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38003
2024-01-07 06:38:03,679 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55926
2024-01-07 06:38:03,679 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:38:03,679 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,680 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:03,680 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32819', status: init, memory: 0, processing: 0>
2024-01-07 06:38:03,680 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:38:03,680 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:38:03,680 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,681 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32819
2024-01-07 06:38:03,681 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55932
2024-01-07 06:38:03,682 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:38:03,682 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:03,682 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:38:03,682 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:03,684 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:38:03,749 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-07 06:38:03,749 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-07 06:38:03,750 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-07 06:38:03,750 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-07 06:38:03,755 - distributed.scheduler - INFO - Remove client Client-4c963138-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:03,755 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55888; closing.
2024-01-07 06:38:03,755 - distributed.scheduler - INFO - Remove client Client-4c963138-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:03,756 - distributed.scheduler - INFO - Close client connection: Client-4c963138-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:03,757 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36043'. Reason: nanny-close
2024-01-07 06:38:03,757 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:03,757 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33515'. Reason: nanny-close
2024-01-07 06:38:03,758 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:03,758 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42765'. Reason: nanny-close
2024-01-07 06:38:03,758 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45779. Reason: nanny-close
2024-01-07 06:38:03,758 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:03,758 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37981'. Reason: nanny-close
2024-01-07 06:38:03,758 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38003. Reason: nanny-close
2024-01-07 06:38:03,759 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:03,759 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40051. Reason: nanny-close
2024-01-07 06:38:03,759 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32819. Reason: nanny-close
2024-01-07 06:38:03,760 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55922; closing.
2024-01-07 06:38:03,760 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:38:03,760 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:38:03,760 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45779', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609483.7605543')
2024-01-07 06:38:03,760 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:38:03,761 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:38:03,761 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55926; closing.
2024-01-07 06:38:03,761 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:03,761 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:03,761 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55932; closing.
2024-01-07 06:38:03,762 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:03,762 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38003', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609483.7621245')
2024-01-07 06:38:03,762 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55912; closing.
2024-01-07 06:38:03,762 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:03,762 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32819', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609483.7628188')
2024-01-07 06:38:03,763 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40051', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609483.7632146')
2024-01-07 06:38:03,763 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:38:04,472 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:38:04,472 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:38:04,472 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:38:04,473 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-07 06:38:04,474 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-07 06:38:06,768 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:06,773 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33869 instead
  warnings.warn(
2024-01-07 06:38:06,777 - distributed.scheduler - INFO - State start
2024-01-07 06:38:06,800 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:06,801 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:38:06,801 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33869/status
2024-01-07 06:38:06,801 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:38:06,925 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43719'
2024-01-07 06:38:06,940 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45065'
2024-01-07 06:38:06,947 - distributed.scheduler - INFO - Receive client connection: Client-4fc11fbd-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:06,950 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43237'
2024-01-07 06:38:06,960 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37134
2024-01-07 06:38:06,965 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43781'
2024-01-07 06:38:06,968 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44195'
2024-01-07 06:38:06,976 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45897'
2024-01-07 06:38:06,987 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43525'
2024-01-07 06:38:06,996 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36633'
2024-01-07 06:38:08,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:08,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:08,776 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:08,777 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39503
2024-01-07 06:38:08,777 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39503
2024-01-07 06:38:08,777 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46211
2024-01-07 06:38:08,777 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:08,777 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:08,777 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:08,777 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:08,777 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0e86cb3y
2024-01-07 06:38:08,777 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ea294506-0514-4b65-937f-a19926595303
2024-01-07 06:38:08,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:08,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:08,789 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:08,790 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38311
2024-01-07 06:38:08,790 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38311
2024-01-07 06:38:08,790 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37961
2024-01-07 06:38:08,790 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:08,790 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:08,790 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:08,791 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:08,791 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-70p2y4qh
2024-01-07 06:38:08,791 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f6598797-4227-4cf8-9e8c-6308518bec15
2024-01-07 06:38:08,791 - distributed.worker - INFO - Starting Worker plugin PreImport-87640fc7-f80f-4ed2-ae0b-3fb42e2921c2
2024-01-07 06:38:08,792 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b74bd8ec-e092-4eef-a2de-57091447321f
2024-01-07 06:38:08,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:08,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:08,814 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:08,814 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39903
2024-01-07 06:38:08,814 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39903
2024-01-07 06:38:08,814 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44305
2024-01-07 06:38:08,814 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:08,815 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:08,815 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:08,815 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:08,815 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-34icbi3g
2024-01-07 06:38:08,815 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0a5eaea-c881-4d9d-b1ca-15c5e3fcf310
2024-01-07 06:38:09,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:09,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:09,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:09,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:09,015 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:09,016 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36499
2024-01-07 06:38:09,016 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36499
2024-01-07 06:38:09,016 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45715
2024-01-07 06:38:09,016 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:09,016 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:09,016 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:09,016 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:09,016 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vl79cceo
2024-01-07 06:38:09,017 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0cd6fec8-ec64-4a90-a7ba-0cb3acab820c
2024-01-07 06:38:09,017 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:09,018 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45673
2024-01-07 06:38:09,018 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45673
2024-01-07 06:38:09,018 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38709
2024-01-07 06:38:09,018 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:09,018 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:09,018 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:09,018 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:09,018 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9jvisgoz
2024-01-07 06:38:09,018 - distributed.worker - INFO - Starting Worker plugin PreImport-e3e6be55-4bb3-4b9d-8de9-d5d4564abdaa
2024-01-07 06:38:09,019 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d47bb30a-c734-4a6f-9836-3af256e309ca
2024-01-07 06:38:09,019 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bc0a82f9-2aff-4616-8a05-6d1cb650a255
2024-01-07 06:38:09,043 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:09,043 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:09,047 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:09,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:09,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:09,048 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42419
2024-01-07 06:38:09,048 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42419
2024-01-07 06:38:09,048 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44241
2024-01-07 06:38:09,048 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:09,048 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:09,049 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:09,049 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:09,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:09,049 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7hbpxb31
2024-01-07 06:38:09,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:09,049 - distributed.worker - INFO - Starting Worker plugin PreImport-b1a91eed-be71-4c5f-9834-68da49602e83
2024-01-07 06:38:09,049 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0f4e2e7b-c973-4dae-9dfa-fc8cb354c139
2024-01-07 06:38:09,049 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2f6b8523-a6e9-4f2a-bb31-4dc14c534ce4
2024-01-07 06:38:09,052 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:09,053 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39341
2024-01-07 06:38:09,053 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39341
2024-01-07 06:38:09,053 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39911
2024-01-07 06:38:09,053 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:09,053 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:09,054 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:09,054 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:09,054 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d3a5mqd5
2024-01-07 06:38:09,054 - distributed.worker - INFO - Starting Worker plugin RMMSetup-96ce23cb-af6a-42d1-b8c4-f99ac2edc4c1
2024-01-07 06:38:09,055 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:09,056 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40677
2024-01-07 06:38:09,056 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40677
2024-01-07 06:38:09,056 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42215
2024-01-07 06:38:09,056 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:09,056 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:09,056 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:09,056 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:09,056 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-guvjhbyn
2024-01-07 06:38:09,057 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cb1da832-1b02-468b-ba92-9101aa843ff4
2024-01-07 06:38:09,635 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0afc9c54-9c3e-4f61-b3e0-aa59d0ab4d42
2024-01-07 06:38:09,635 - distributed.worker - INFO - Starting Worker plugin PreImport-a2e50020-b61a-42ba-a1d6-f4089febf78b
2024-01-07 06:38:09,636 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:09,666 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39503', status: init, memory: 0, processing: 0>
2024-01-07 06:38:09,668 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39503
2024-01-07 06:38:09,668 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37152
2024-01-07 06:38:09,669 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:09,670 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:09,670 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:09,672 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:10,853 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:10,889 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38311', status: init, memory: 0, processing: 0>
2024-01-07 06:38:10,889 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38311
2024-01-07 06:38:10,889 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58612
2024-01-07 06:38:10,891 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:10,892 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:10,892 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:10,894 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:10,941 - distributed.worker - INFO - Starting Worker plugin PreImport-eb4695c0-8abb-4a17-acda-a735107b07f6
2024-01-07 06:38:10,942 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eb2bf494-3959-4602-b028-0e66f6b1cecd
2024-01-07 06:38:10,943 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:10,973 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39903', status: init, memory: 0, processing: 0>
2024-01-07 06:38:10,974 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39903
2024-01-07 06:38:10,974 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58622
2024-01-07 06:38:10,976 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:10,976 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:10,977 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:10,979 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:11,040 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-50155f24-09ee-4a39-bdfb-0662c12f704e
2024-01-07 06:38:11,041 - distributed.worker - INFO - Starting Worker plugin PreImport-af477f3a-575a-4165-8f01-bce4db19eeef
2024-01-07 06:38:11,042 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,045 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,064 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36499', status: init, memory: 0, processing: 0>
2024-01-07 06:38:11,065 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36499
2024-01-07 06:38:11,065 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58638
2024-01-07 06:38:11,066 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:11,067 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:11,067 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,067 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45673', status: init, memory: 0, processing: 0>
2024-01-07 06:38:11,068 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45673
2024-01-07 06:38:11,068 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58640
2024-01-07 06:38:11,068 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:11,069 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:11,069 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:11,069 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,071 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:11,081 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f72bf778-af85-47b1-a294-f4ad534e74bd
2024-01-07 06:38:11,082 - distributed.worker - INFO - Starting Worker plugin PreImport-bbfaa934-87a3-4dfe-83da-0f1d3c69d116
2024-01-07 06:38:11,083 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,088 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,089 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-25915007-9743-4330-bfd7-6ad37493adae
2024-01-07 06:38:11,091 - distributed.worker - INFO - Starting Worker plugin PreImport-32a91b5a-22a9-4ebf-916c-c6ed2f30ad76
2024-01-07 06:38:11,091 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,113 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42419', status: init, memory: 0, processing: 0>
2024-01-07 06:38:11,113 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42419
2024-01-07 06:38:11,113 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58654
2024-01-07 06:38:11,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:11,115 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39341', status: init, memory: 0, processing: 0>
2024-01-07 06:38:11,116 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:11,116 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39341
2024-01-07 06:38:11,116 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58652
2024-01-07 06:38:11,116 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,117 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:11,117 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:11,118 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40677', status: init, memory: 0, processing: 0>
2024-01-07 06:38:11,118 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:11,118 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,119 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40677
2024-01-07 06:38:11,119 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58658
2024-01-07 06:38:11,120 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:11,120 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:11,121 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:11,121 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:11,123 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:11,133 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:11,134 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:11,134 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:11,134 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:11,134 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:11,134 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:11,134 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:11,134 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:11,139 - distributed.scheduler - INFO - Remove client Client-4fc11fbd-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:11,139 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37134; closing.
2024-01-07 06:38:11,139 - distributed.scheduler - INFO - Remove client Client-4fc11fbd-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:11,140 - distributed.scheduler - INFO - Close client connection: Client-4fc11fbd-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:11,140 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43719'. Reason: nanny-close
2024-01-07 06:38:11,141 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:11,141 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45065'. Reason: nanny-close
2024-01-07 06:38:11,141 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:11,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43237'. Reason: nanny-close
2024-01-07 06:38:11,142 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38311. Reason: nanny-close
2024-01-07 06:38:11,142 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:11,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43781'. Reason: nanny-close
2024-01-07 06:38:11,142 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39503. Reason: nanny-close
2024-01-07 06:38:11,142 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:11,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44195'. Reason: nanny-close
2024-01-07 06:38:11,143 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42419. Reason: nanny-close
2024-01-07 06:38:11,143 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:11,143 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45897'. Reason: nanny-close
2024-01-07 06:38:11,143 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40677. Reason: nanny-close
2024-01-07 06:38:11,143 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:11,143 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43525'. Reason: nanny-close
2024-01-07 06:38:11,143 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:11,144 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39903. Reason: nanny-close
2024-01-07 06:38:11,144 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36633'. Reason: nanny-close
2024-01-07 06:38:11,144 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39341. Reason: nanny-close
2024-01-07 06:38:11,144 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:11,144 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45673. Reason: nanny-close
2024-01-07 06:38:11,144 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58654; closing.
2024-01-07 06:38:11,145 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:11,145 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36499. Reason: nanny-close
2024-01-07 06:38:11,145 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42419', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609491.145209')
2024-01-07 06:38:11,145 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:11,145 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:11,145 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:11,146 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:11,146 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37152; closing.
2024-01-07 06:38:11,146 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:11,146 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:11,146 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58612; closing.
2024-01-07 06:38:11,146 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:11,146 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:11,147 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:11,147 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58622; closing.
2024-01-07 06:38:11,147 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:11,147 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39503', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609491.1476343')
2024-01-07 06:38:11,148 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:11,148 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:11,148 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38311', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609491.1480098')
2024-01-07 06:38:11,148 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:11,148 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58658; closing.
2024-01-07 06:38:11,148 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:11,149 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39903', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609491.1491637')
2024-01-07 06:38:11,149 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:11,149 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40677', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609491.1495612')
2024-01-07 06:38:11,149 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58652; closing.
2024-01-07 06:38:11,150 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58640; closing.
2024-01-07 06:38:11,150 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39341', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609491.1505866')
2024-01-07 06:38:11,150 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45673', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609491.1509383')
2024-01-07 06:38:11,151 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58638; closing.
2024-01-07 06:38:11,151 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36499', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609491.1516724')
2024-01-07 06:38:11,151 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:38:12,156 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:38:12,157 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:38:12,157 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:38:12,158 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:38:12,158 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-07 06:38:14,524 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:14,529 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38913 instead
  warnings.warn(
2024-01-07 06:38:14,533 - distributed.scheduler - INFO - State start
2024-01-07 06:38:14,562 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:14,563 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:38:14,565 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38913/status
2024-01-07 06:38:14,565 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:38:14,576 - distributed.scheduler - INFO - Receive client connection: Client-545a0c99-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:14,592 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58728
2024-01-07 06:38:14,699 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32999'
2024-01-07 06:38:14,722 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33127'
2024-01-07 06:38:14,733 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42939'
2024-01-07 06:38:14,736 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33175'
2024-01-07 06:38:14,747 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37347'
2024-01-07 06:38:14,757 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44317'
2024-01-07 06:38:14,766 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34511'
2024-01-07 06:38:14,777 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44527'
2024-01-07 06:38:16,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:16,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:16,559 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:16,560 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44835
2024-01-07 06:38:16,560 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44835
2024-01-07 06:38:16,560 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38267
2024-01-07 06:38:16,560 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:16,560 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:16,560 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:16,560 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:16,560 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-x1tgeoyq
2024-01-07 06:38:16,560 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-92d5259a-508b-424d-af72-d86cab25abfb
2024-01-07 06:38:16,560 - distributed.worker - INFO - Starting Worker plugin PreImport-708d7a50-7af0-4480-b999-7fb720345f88
2024-01-07 06:38:16,561 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9024f22b-3d8f-48b9-87fc-3f803fcf1c28
2024-01-07 06:38:16,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:16,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:16,613 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:16,614 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39789
2024-01-07 06:38:16,614 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39789
2024-01-07 06:38:16,614 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42987
2024-01-07 06:38:16,614 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:16,614 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:16,614 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:16,614 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:16,614 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d_8qqitv
2024-01-07 06:38:16,614 - distributed.worker - INFO - Starting Worker plugin PreImport-e86cb4c4-52dc-4814-9139-8b65a0de4544
2024-01-07 06:38:16,615 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dae51768-2d1d-47d3-aebb-8a67d731d321
2024-01-07 06:38:16,615 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f6cd2c78-f961-435c-a1e6-59ff47ae01ea
2024-01-07 06:38:16,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:16,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:16,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:16,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:16,790 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:16,792 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37411
2024-01-07 06:38:16,792 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37411
2024-01-07 06:38:16,792 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45031
2024-01-07 06:38:16,792 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:16,792 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:16,792 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:16,792 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:16,793 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nkfi50bc
2024-01-07 06:38:16,793 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff1f6012-92e6-4089-bfd7-62c3d672c57d
2024-01-07 06:38:16,794 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:16,796 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43923
2024-01-07 06:38:16,796 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43923
2024-01-07 06:38:16,796 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38901
2024-01-07 06:38:16,796 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:16,796 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:16,797 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:16,797 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:16,797 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8oxmkjye
2024-01-07 06:38:16,797 - distributed.worker - INFO - Starting Worker plugin PreImport-1a73adcf-4450-4e59-8c8c-82c8b1ff17c3
2024-01-07 06:38:16,797 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bec04ca3-933e-4e74-85a3-12d0162c1a31
2024-01-07 06:38:16,798 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a6a84732-23ce-4ea8-a346-87e842858f5a
2024-01-07 06:38:16,822 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:16,823 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:16,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:16,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:16,830 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:16,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:16,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:16,832 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46129
2024-01-07 06:38:16,832 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46129
2024-01-07 06:38:16,832 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33055
2024-01-07 06:38:16,832 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:16,832 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:16,832 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:16,832 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:16,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:16,832 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-35vjtlss
2024-01-07 06:38:16,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:16,833 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c0d65737-d191-4385-a98a-83deee882b23
2024-01-07 06:38:16,837 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:16,839 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36481
2024-01-07 06:38:16,839 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36481
2024-01-07 06:38:16,839 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42211
2024-01-07 06:38:16,839 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:16,839 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:16,839 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:16,839 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:16,839 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w_wlv_y1
2024-01-07 06:38:16,840 - distributed.worker - INFO - Starting Worker plugin RMMSetup-741eb5f6-f61c-476e-94d6-c323af929f96
2024-01-07 06:38:16,843 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:16,844 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:16,845 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34283
2024-01-07 06:38:16,846 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34283
2024-01-07 06:38:16,846 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34689
2024-01-07 06:38:16,846 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:16,846 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:16,846 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:16,846 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:16,846 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j9h9j0x8
2024-01-07 06:38:16,846 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32833
2024-01-07 06:38:16,847 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32833
2024-01-07 06:38:16,847 - distributed.worker - INFO - Starting Worker plugin RMMSetup-64b61bde-bc92-42b4-aa6d-0bc94cae2d32
2024-01-07 06:38:16,847 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42263
2024-01-07 06:38:16,847 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:16,847 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:16,847 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:16,847 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:16,847 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6a9fe_z5
2024-01-07 06:38:16,848 - distributed.worker - INFO - Starting Worker plugin PreImport-46171502-955d-426b-b847-8b64a4666d1a
2024-01-07 06:38:16,848 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9d12838f-f9e6-4815-bad6-fc8c798954ce
2024-01-07 06:38:16,848 - distributed.worker - INFO - Starting Worker plugin RMMSetup-79236348-a571-4af8-b36c-471adbb7ddd3
2024-01-07 06:38:17,030 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:17,061 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44835', status: init, memory: 0, processing: 0>
2024-01-07 06:38:17,062 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44835
2024-01-07 06:38:17,062 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58824
2024-01-07 06:38:17,063 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:17,064 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:17,064 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:17,066 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:18,523 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,551 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39789', status: init, memory: 0, processing: 0>
2024-01-07 06:38:18,551 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39789
2024-01-07 06:38:18,551 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58834
2024-01-07 06:38:18,552 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:18,553 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:18,553 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,554 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:18,602 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,631 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b24449b9-1363-490b-b286-68c2576b6108
2024-01-07 06:38:18,634 - distributed.worker - INFO - Starting Worker plugin PreImport-afaf64c1-88c5-4787-84ec-598381b197a7
2024-01-07 06:38:18,634 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,637 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43923', status: init, memory: 0, processing: 0>
2024-01-07 06:38:18,637 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43923
2024-01-07 06:38:18,637 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58848
2024-01-07 06:38:18,639 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:18,640 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:18,640 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,642 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:18,665 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37411', status: init, memory: 0, processing: 0>
2024-01-07 06:38:18,666 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37411
2024-01-07 06:38:18,666 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58858
2024-01-07 06:38:18,667 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:18,668 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:18,669 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,669 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-385d9eca-fe3d-4755-98dc-1920d544b47f
2024-01-07 06:38:18,670 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:18,671 - distributed.worker - INFO - Starting Worker plugin PreImport-c4146a64-8443-414d-bcfc-edf421c0ece0
2024-01-07 06:38:18,672 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,683 - distributed.worker - INFO - Starting Worker plugin PreImport-047254ea-4767-4520-b746-926e2ca773fe
2024-01-07 06:38:18,684 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-78ce0f82-9ccb-41a0-b13d-c7a604942503
2024-01-07 06:38:18,685 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,690 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8f2420cd-c9f4-4977-bb0d-6f169ba6b887
2024-01-07 06:38:18,691 - distributed.worker - INFO - Starting Worker plugin PreImport-cc2273fe-bfca-4964-bfab-2c91bbab60f9
2024-01-07 06:38:18,692 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,702 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46129', status: init, memory: 0, processing: 0>
2024-01-07 06:38:18,703 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46129
2024-01-07 06:38:18,703 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58868
2024-01-07 06:38:18,704 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,704 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:18,706 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:18,706 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,707 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:18,718 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36481', status: init, memory: 0, processing: 0>
2024-01-07 06:38:18,719 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36481
2024-01-07 06:38:18,719 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58878
2024-01-07 06:38:18,720 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:18,721 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:18,722 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,723 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:18,729 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34283', status: init, memory: 0, processing: 0>
2024-01-07 06:38:18,729 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34283
2024-01-07 06:38:18,729 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58888
2024-01-07 06:38:18,730 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32833', status: init, memory: 0, processing: 0>
2024-01-07 06:38:18,731 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32833
2024-01-07 06:38:18,731 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58900
2024-01-07 06:38:18,731 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:18,731 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:18,732 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:18,732 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,732 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:18,732 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:18,734 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:18,734 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:18,809 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:18,810 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:18,810 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:18,810 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:18,810 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:18,810 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:18,810 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:18,810 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:18,815 - distributed.scheduler - INFO - Remove client Client-545a0c99-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:18,815 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58728; closing.
2024-01-07 06:38:18,815 - distributed.scheduler - INFO - Remove client Client-545a0c99-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:18,816 - distributed.scheduler - INFO - Close client connection: Client-545a0c99-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:18,816 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32999'. Reason: nanny-close
2024-01-07 06:38:18,817 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:18,817 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33127'. Reason: nanny-close
2024-01-07 06:38:18,817 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:18,818 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42939'. Reason: nanny-close
2024-01-07 06:38:18,818 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44835. Reason: nanny-close
2024-01-07 06:38:18,818 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:18,818 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33175'. Reason: nanny-close
2024-01-07 06:38:18,818 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:18,818 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43923. Reason: nanny-close
2024-01-07 06:38:18,818 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37347'. Reason: nanny-close
2024-01-07 06:38:18,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37411. Reason: nanny-close
2024-01-07 06:38:18,819 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:18,819 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44317'. Reason: nanny-close
2024-01-07 06:38:18,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39789. Reason: nanny-close
2024-01-07 06:38:18,819 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:18,819 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34511'. Reason: nanny-close
2024-01-07 06:38:18,820 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:18,820 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34283. Reason: nanny-close
2024-01-07 06:38:18,820 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44527'. Reason: nanny-close
2024-01-07 06:38:18,820 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:18,820 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:18,820 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58824; closing.
2024-01-07 06:38:18,820 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36481. Reason: nanny-close
2024-01-07 06:38:18,820 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:18,820 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:18,820 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46129. Reason: nanny-close
2024-01-07 06:38:18,820 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44835', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609498.8208778')
2024-01-07 06:38:18,821 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:18,821 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58834; closing.
2024-01-07 06:38:18,821 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32833. Reason: nanny-close
2024-01-07 06:38:18,821 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:18,822 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39789', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609498.8219838')
2024-01-07 06:38:18,822 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:18,822 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:18,822 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58858; closing.
2024-01-07 06:38:18,822 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:18,822 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58848; closing.
2024-01-07 06:38:18,822 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:18,822 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:18,823 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:18,823 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37411', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609498.8234324')
2024-01-07 06:38:18,823 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43923', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609498.823812')
2024-01-07 06:38:18,823 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:18,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:18,824 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:18,824 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:18,825 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:18,824 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:58834>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-07 06:38:18,826 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58888; closing.
2024-01-07 06:38:18,826 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58878; closing.
2024-01-07 06:38:18,827 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34283', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609498.8270836')
2024-01-07 06:38:18,827 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36481', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609498.82745')
2024-01-07 06:38:18,827 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58868; closing.
2024-01-07 06:38:18,828 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58900; closing.
2024-01-07 06:38:18,828 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46129', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609498.8283637')
2024-01-07 06:38:18,828 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32833', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609498.8287513')
2024-01-07 06:38:18,828 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:38:19,733 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:38:19,733 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:38:19,733 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:38:19,735 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:38:19,735 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-07 06:38:22,108 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:22,113 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41171 instead
  warnings.warn(
2024-01-07 06:38:22,117 - distributed.scheduler - INFO - State start
2024-01-07 06:38:22,140 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:22,141 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:38:22,142 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41171/status
2024-01-07 06:38:22,142 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:38:22,285 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38017'
2024-01-07 06:38:22,309 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38151'
2024-01-07 06:38:22,324 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40131'
2024-01-07 06:38:22,334 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40021'
2024-01-07 06:38:22,337 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39085'
2024-01-07 06:38:22,346 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33169'
2024-01-07 06:38:22,357 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38485'
2024-01-07 06:38:22,366 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45399'
2024-01-07 06:38:22,692 - distributed.scheduler - INFO - Receive client connection: Client-58e3ce94-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:22,707 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56326
2024-01-07 06:38:24,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:24,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:24,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:24,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:24,191 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:24,191 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:24,192 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45115
2024-01-07 06:38:24,192 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39019
2024-01-07 06:38:24,192 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45115
2024-01-07 06:38:24,192 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39019
2024-01-07 06:38:24,192 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37345
2024-01-07 06:38:24,192 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:24,192 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45681
2024-01-07 06:38:24,192 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:24,192 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:24,192 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:24,192 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:24,192 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:24,192 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:24,192 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nu2ogz37
2024-01-07 06:38:24,192 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:24,192 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4y4esce1
2024-01-07 06:38:24,192 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ba6457c4-191b-4b8d-9e0d-84a95bd6263e
2024-01-07 06:38:24,193 - distributed.worker - INFO - Starting Worker plugin PreImport-e8ffaefe-06ce-4212-b970-81b572e71f5f
2024-01-07 06:38:24,193 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b6b8daf1-fe77-4a5f-84d5-de7f258a7739
2024-01-07 06:38:24,193 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0331e3dd-6841-4e42-b5fc-034484c07c5b
2024-01-07 06:38:24,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:24,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:24,205 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:24,205 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:24,207 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:24,208 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36223
2024-01-07 06:38:24,208 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36223
2024-01-07 06:38:24,208 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41415
2024-01-07 06:38:24,208 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:24,209 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:24,209 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:24,209 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:24,209 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gmcr44f9
2024-01-07 06:38:24,209 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a7c4f596-8c84-4f24-9440-c7a604f76660
2024-01-07 06:38:24,210 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:24,210 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34449
2024-01-07 06:38:24,210 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34449
2024-01-07 06:38:24,211 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38727
2024-01-07 06:38:24,211 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:24,211 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:24,211 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:24,211 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:24,211 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jjv7epe8
2024-01-07 06:38:24,211 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7cfa708c-166a-43c0-acbc-11dbc8d7fbf0
2024-01-07 06:38:24,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:24,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:24,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:24,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:24,235 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:24,236 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33001
2024-01-07 06:38:24,236 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33001
2024-01-07 06:38:24,236 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45583
2024-01-07 06:38:24,236 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:24,236 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:24,236 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:24,236 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:24,236 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-an6977zv
2024-01-07 06:38:24,237 - distributed.worker - INFO - Starting Worker plugin RMMSetup-172e4180-e2ba-43bf-9d6d-ab96ad3979ad
2024-01-07 06:38:24,238 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:24,239 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39989
2024-01-07 06:38:24,239 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39989
2024-01-07 06:38:24,239 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40639
2024-01-07 06:38:24,239 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:24,239 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:24,239 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:24,239 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:24,239 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ny2e91ep
2024-01-07 06:38:24,239 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b6522f39-632f-43c8-805f-80de7c5b149a
2024-01-07 06:38:24,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:24,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:24,290 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:24,291 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44341
2024-01-07 06:38:24,291 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44341
2024-01-07 06:38:24,291 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42971
2024-01-07 06:38:24,291 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:24,291 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:24,291 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:24,291 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:24,291 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8k_a3uiw
2024-01-07 06:38:24,291 - distributed.worker - INFO - Starting Worker plugin RMMSetup-88ca6a7f-ddf8-4a93-9657-0df1f0e946a1
2024-01-07 06:38:24,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:24,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:24,297 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:24,298 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35695
2024-01-07 06:38:24,298 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35695
2024-01-07 06:38:24,298 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41225
2024-01-07 06:38:24,298 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:24,298 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:24,298 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:24,298 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:24,298 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lag8td1j
2024-01-07 06:38:24,299 - distributed.worker - INFO - Starting Worker plugin PreImport-fd2e5226-9e88-4cc1-9e6f-02f58338760a
2024-01-07 06:38:24,299 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fbc00a70-ec8d-4d87-96b3-d85682c9d559
2024-01-07 06:38:24,299 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c19b473d-793a-4e1e-9a7a-ff7b7c825f54
2024-01-07 06:38:26,439 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,455 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2ce528f0-4efd-4def-937e-66409241b526
2024-01-07 06:38:26,459 - distributed.worker - INFO - Starting Worker plugin PreImport-81cb5dc0-7550-49d8-94e8-003d8d3932b1
2024-01-07 06:38:26,461 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,472 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39019', status: init, memory: 0, processing: 0>
2024-01-07 06:38:26,473 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39019
2024-01-07 06:38:26,474 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56340
2024-01-07 06:38:26,475 - distributed.worker - INFO - Starting Worker plugin PreImport-94e05d6d-fd78-4c47-a4ca-bbdeafbe6f9e
2024-01-07 06:38:26,475 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:26,475 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6c2efd41-a1cf-46d0-b1b1-a6e55a4ab4d0
2024-01-07 06:38:26,476 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,476 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:26,476 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,478 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:26,492 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45115', status: init, memory: 0, processing: 0>
2024-01-07 06:38:26,493 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45115
2024-01-07 06:38:26,493 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56346
2024-01-07 06:38:26,494 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:26,495 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:26,495 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,497 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:26,498 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36223', status: init, memory: 0, processing: 0>
2024-01-07 06:38:26,498 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-30da5cd4-a92a-4531-affb-789a5a3c47a6
2024-01-07 06:38:26,499 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36223
2024-01-07 06:38:26,499 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56358
2024-01-07 06:38:26,499 - distributed.worker - INFO - Starting Worker plugin PreImport-3582909b-ca60-4d7e-9624-0a5700f8f26c
2024-01-07 06:38:26,500 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:26,500 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,500 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:26,501 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,502 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:26,518 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-33474b9e-4e50-4271-a51d-db702bcbf9be
2024-01-07 06:38:26,519 - distributed.worker - INFO - Starting Worker plugin PreImport-6e7f1b0f-fb3a-4c77-8f7a-4ff2cc859009
2024-01-07 06:38:26,520 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3da30a0a-179a-4c53-8291-e8486a233e82
2024-01-07 06:38:26,520 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,520 - distributed.worker - INFO - Starting Worker plugin PreImport-346edaff-8e06-421c-8da5-3b7a982d9079
2024-01-07 06:38:26,521 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,521 - distributed.worker - INFO - Starting Worker plugin PreImport-45c5120a-984e-4090-8b87-8b7aa346d909
2024-01-07 06:38:26,522 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d598a6e4-1095-4919-af3c-2d7e634aee3f
2024-01-07 06:38:26,522 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,524 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,533 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33001', status: init, memory: 0, processing: 0>
2024-01-07 06:38:26,534 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33001
2024-01-07 06:38:26,534 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56364
2024-01-07 06:38:26,536 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:26,536 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:26,537 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,539 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:26,547 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39989', status: init, memory: 0, processing: 0>
2024-01-07 06:38:26,548 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39989
2024-01-07 06:38:26,548 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56376
2024-01-07 06:38:26,549 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:26,549 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44341', status: init, memory: 0, processing: 0>
2024-01-07 06:38:26,550 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:26,550 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44341
2024-01-07 06:38:26,550 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,550 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56396
2024-01-07 06:38:26,551 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34449', status: init, memory: 0, processing: 0>
2024-01-07 06:38:26,551 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:26,551 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:26,551 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34449
2024-01-07 06:38:26,551 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56392
2024-01-07 06:38:26,552 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:26,552 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,552 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:26,553 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:26,553 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,554 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:26,555 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:26,557 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35695', status: init, memory: 0, processing: 0>
2024-01-07 06:38:26,558 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35695
2024-01-07 06:38:26,558 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56410
2024-01-07 06:38:26,560 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:26,561 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:26,561 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:26,563 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:26,591 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:26,591 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:26,591 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:26,591 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:26,591 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:26,592 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:26,592 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:26,592 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:26,603 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:26,603 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:26,603 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:26,603 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:26,603 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:26,603 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:26,603 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:26,604 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:26,612 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:26,614 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:26,616 - distributed.scheduler - INFO - Remove client Client-58e3ce94-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:26,616 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56326; closing.
2024-01-07 06:38:26,616 - distributed.scheduler - INFO - Remove client Client-58e3ce94-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:26,617 - distributed.scheduler - INFO - Close client connection: Client-58e3ce94-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:26,617 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38017'. Reason: nanny-close
2024-01-07 06:38:26,618 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:26,618 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38151'. Reason: nanny-close
2024-01-07 06:38:26,619 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:26,619 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40131'. Reason: nanny-close
2024-01-07 06:38:26,619 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36223. Reason: nanny-close
2024-01-07 06:38:26,619 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:26,619 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40021'. Reason: nanny-close
2024-01-07 06:38:26,619 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34449. Reason: nanny-close
2024-01-07 06:38:26,619 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:26,620 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39085'. Reason: nanny-close
2024-01-07 06:38:26,620 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:26,620 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39019. Reason: nanny-close
2024-01-07 06:38:26,620 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33169'. Reason: nanny-close
2024-01-07 06:38:26,620 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:26,620 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45115. Reason: nanny-close
2024-01-07 06:38:26,620 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38485'. Reason: nanny-close
2024-01-07 06:38:26,620 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44341. Reason: nanny-close
2024-01-07 06:38:26,621 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:26,621 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:26,621 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45399'. Reason: nanny-close
2024-01-07 06:38:26,621 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56358; closing.
2024-01-07 06:38:26,621 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39989. Reason: nanny-close
2024-01-07 06:38:26,621 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:26,621 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36223', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609506.6215634')
2024-01-07 06:38:26,621 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:26,622 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35695. Reason: nanny-close
2024-01-07 06:38:26,622 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:26,622 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33001. Reason: nanny-close
2024-01-07 06:38:26,622 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:26,622 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:26,623 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:26,623 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:26,623 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:26,623 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56340; closing.
2024-01-07 06:38:26,623 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:26,623 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56392; closing.
2024-01-07 06:38:26,624 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39019', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609506.6248028')
2024-01-07 06:38:26,624 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:26,625 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:26,625 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:26,625 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:26,625 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56396; closing.
2024-01-07 06:38:26,625 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34449', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609506.6254125')
2024-01-07 06:38:26,625 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:26,625 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56346; closing.
2024-01-07 06:38:26,625 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56376; closing.
2024-01-07 06:38:26,626 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44341', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609506.6264477')
2024-01-07 06:38:26,626 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:26,626 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45115', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609506.6267934')
2024-01-07 06:38:26,627 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39989', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609506.6270885')
2024-01-07 06:38:26,627 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:26,627 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56410; closing.
2024-01-07 06:38:26,628 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56364; closing.
2024-01-07 06:38:26,628 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35695', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609506.6285222')
2024-01-07 06:38:26,628 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33001', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609506.6289086')
2024-01-07 06:38:26,629 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:38:27,734 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:38:27,734 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:38:27,735 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:38:27,736 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:38:27,736 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-07 06:38:30,089 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:30,094 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36007 instead
  warnings.warn(
2024-01-07 06:38:30,098 - distributed.scheduler - INFO - State start
2024-01-07 06:38:30,121 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:30,122 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:38:30,122 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36007/status
2024-01-07 06:38:30,123 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:38:30,385 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43299'
2024-01-07 06:38:30,410 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33927'
2024-01-07 06:38:30,414 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40209'
2024-01-07 06:38:30,423 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37707'
2024-01-07 06:38:30,432 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46527'
2024-01-07 06:38:30,441 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34827'
2024-01-07 06:38:30,451 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33997'
2024-01-07 06:38:30,461 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44139'
2024-01-07 06:38:32,129 - distributed.scheduler - INFO - Receive client connection: Client-5daa9c56-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:32,147 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38874
2024-01-07 06:38:32,343 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:32,343 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:32,348 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:32,349 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45245
2024-01-07 06:38:32,349 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45245
2024-01-07 06:38:32,349 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42903
2024-01-07 06:38:32,349 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:32,349 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:32,349 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:32,349 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:32,349 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-crii8krq
2024-01-07 06:38:32,349 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0736776e-27e7-4cfd-a38d-fbda41b9146f
2024-01-07 06:38:32,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:32,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:32,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:32,360 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:32,362 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:32,362 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35323
2024-01-07 06:38:32,362 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35323
2024-01-07 06:38:32,362 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33791
2024-01-07 06:38:32,362 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:32,363 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:32,363 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:32,363 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:32,363 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wuy9dope
2024-01-07 06:38:32,363 - distributed.worker - INFO - Starting Worker plugin RMMSetup-19bf2213-7648-4e43-b4d9-27319c92a75c
2024-01-07 06:38:32,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:32,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:32,364 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:32,364 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46583
2024-01-07 06:38:32,365 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46583
2024-01-07 06:38:32,365 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43461
2024-01-07 06:38:32,365 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:32,365 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:32,365 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:32,365 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:32,365 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uuivb9xv
2024-01-07 06:38:32,365 - distributed.worker - INFO - Starting Worker plugin RMMSetup-00afda09-323b-407a-9ce9-e7e5c258d15e
2024-01-07 06:38:32,368 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:32,368 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34455
2024-01-07 06:38:32,369 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34455
2024-01-07 06:38:32,369 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39263
2024-01-07 06:38:32,369 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:32,369 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:32,369 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:32,369 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:32,369 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8htlx0n7
2024-01-07 06:38:32,369 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9a037718-2b15-4591-bcd8-78d745df2676
2024-01-07 06:38:32,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:32,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:32,385 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:32,386 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37535
2024-01-07 06:38:32,386 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37535
2024-01-07 06:38:32,386 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41885
2024-01-07 06:38:32,386 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:32,386 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:32,386 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:32,386 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:32,386 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p1b4l6r6
2024-01-07 06:38:32,387 - distributed.worker - INFO - Starting Worker plugin PreImport-2a1e4361-9e66-46bd-b603-49a9136fdcd5
2024-01-07 06:38:32,387 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-436e434f-8c6d-478b-94f5-fe3f4806e386
2024-01-07 06:38:32,387 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8b4e5583-328e-4b0b-92ec-03eba83df1fa
2024-01-07 06:38:32,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:32,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:32,403 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:32,404 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39195
2024-01-07 06:38:32,404 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39195
2024-01-07 06:38:32,404 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46691
2024-01-07 06:38:32,404 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:32,404 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:32,404 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:32,404 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:32,404 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g6mynkhb
2024-01-07 06:38:32,404 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b0aeac8b-b519-418e-998a-d3db78ec827f
2024-01-07 06:38:32,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:32,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:32,426 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:32,427 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35907
2024-01-07 06:38:32,427 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35907
2024-01-07 06:38:32,427 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46131
2024-01-07 06:38:32,427 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:32,427 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:32,427 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:32,428 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:32,428 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q8tshw87
2024-01-07 06:38:32,428 - distributed.worker - INFO - Starting Worker plugin PreImport-904d2d3e-5737-4f36-af50-08d29990b57e
2024-01-07 06:38:32,428 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-508fc9c3-2788-4399-a9b4-67039f0a6471
2024-01-07 06:38:32,428 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ce932c34-0562-40f1-b7d3-2f16097eb7e3
2024-01-07 06:38:32,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:32,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:32,477 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:32,478 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36617
2024-01-07 06:38:32,478 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36617
2024-01-07 06:38:32,478 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44201
2024-01-07 06:38:32,478 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:32,479 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:32,479 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:32,479 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:32,479 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-htzw09a_
2024-01-07 06:38:32,479 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c7d25a57-d3a5-44c0-b8ed-10ce44bde8c5
2024-01-07 06:38:32,479 - distributed.worker - INFO - Starting Worker plugin PreImport-67b5cb9a-3666-4d96-9b29-528cf078cbe4
2024-01-07 06:38:32,479 - distributed.worker - INFO - Starting Worker plugin RMMSetup-28927062-bba1-403d-a8aa-d37ada62aa18
2024-01-07 06:38:34,608 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3379091e-e8ec-4ae9-a8ab-230579c4291b
2024-01-07 06:38:34,609 - distributed.worker - INFO - Starting Worker plugin PreImport-9b0c0bc8-e722-4a5d-97b3-32c29af9dfba
2024-01-07 06:38:34,609 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,632 - distributed.worker - INFO - Starting Worker plugin PreImport-db2c655e-947a-497c-853c-c0ea67824bf3
2024-01-07 06:38:34,632 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7a16b1e2-7b92-4ff3-bb56-85e57cffda07
2024-01-07 06:38:34,633 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,634 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45245', status: init, memory: 0, processing: 0>
2024-01-07 06:38:34,635 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45245
2024-01-07 06:38:34,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38900
2024-01-07 06:38:34,636 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:34,637 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:34,637 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,638 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:34,642 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8671c1cc-814e-453b-bb2c-d81889f684f2
2024-01-07 06:38:34,643 - distributed.worker - INFO - Starting Worker plugin PreImport-71a48544-b0d7-4b76-89f8-070844be5934
2024-01-07 06:38:34,645 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,658 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46583', status: init, memory: 0, processing: 0>
2024-01-07 06:38:34,658 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46583
2024-01-07 06:38:34,659 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38914
2024-01-07 06:38:34,659 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:34,660 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:34,660 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,662 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:34,667 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6972ef8b-a485-4210-9c9b-a5a703540a42
2024-01-07 06:38:34,667 - distributed.worker - INFO - Starting Worker plugin PreImport-2bf770ce-6014-42b7-b8e8-1a55709c71fe
2024-01-07 06:38:34,667 - distributed.worker - INFO - Starting Worker plugin PreImport-3fe65467-1813-4081-ba49-a347913e9a2e
2024-01-07 06:38:34,668 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5a390013-46e9-4858-beaa-0822db677782
2024-01-07 06:38:34,668 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,668 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,676 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,678 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35323', status: init, memory: 0, processing: 0>
2024-01-07 06:38:34,679 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35323
2024-01-07 06:38:34,679 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38930
2024-01-07 06:38:34,680 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:34,681 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:34,681 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,683 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:34,685 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,690 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,694 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39195', status: init, memory: 0, processing: 0>
2024-01-07 06:38:34,694 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39195
2024-01-07 06:38:34,694 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38946
2024-01-07 06:38:34,695 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34455', status: init, memory: 0, processing: 0>
2024-01-07 06:38:34,695 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:34,696 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34455
2024-01-07 06:38:34,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38952
2024-01-07 06:38:34,696 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:34,696 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,697 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:34,697 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:34,697 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,698 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:34,699 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:34,712 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37535', status: init, memory: 0, processing: 0>
2024-01-07 06:38:34,713 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37535
2024-01-07 06:38:34,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38954
2024-01-07 06:38:34,714 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:34,715 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:34,715 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,716 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35907', status: init, memory: 0, processing: 0>
2024-01-07 06:38:34,717 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35907
2024-01-07 06:38:34,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38970
2024-01-07 06:38:34,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:34,718 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:34,718 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:34,719 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,720 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:34,726 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36617', status: init, memory: 0, processing: 0>
2024-01-07 06:38:34,726 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36617
2024-01-07 06:38:34,727 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38978
2024-01-07 06:38:34,728 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:34,729 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:34,729 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:34,731 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:34,830 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,831 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,831 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,831 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,831 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,831 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,831 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,832 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,844 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:34,845 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:34,845 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:34,845 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:34,845 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:34,845 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:34,845 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:34,845 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:38:34,855 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:34,860 - distributed.scheduler - INFO - Remove client Client-5daa9c56-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:34,860 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38874; closing.
2024-01-07 06:38:34,861 - distributed.scheduler - INFO - Remove client Client-5daa9c56-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:34,861 - distributed.scheduler - INFO - Close client connection: Client-5daa9c56-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:34,862 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37707'. Reason: nanny-close
2024-01-07 06:38:34,863 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:34,863 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34827'. Reason: nanny-close
2024-01-07 06:38:34,864 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:34,864 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46583. Reason: nanny-close
2024-01-07 06:38:34,864 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33997'. Reason: nanny-close
2024-01-07 06:38:34,865 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:34,865 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39195. Reason: nanny-close
2024-01-07 06:38:34,865 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44139'. Reason: nanny-close
2024-01-07 06:38:34,865 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:34,866 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43299'. Reason: nanny-close
2024-01-07 06:38:34,866 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:34,866 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37535. Reason: nanny-close
2024-01-07 06:38:34,866 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38914; closing.
2024-01-07 06:38:34,866 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:34,867 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33927'. Reason: nanny-close
2024-01-07 06:38:34,867 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46583', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609514.8670237')
2024-01-07 06:38:34,867 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35323. Reason: nanny-close
2024-01-07 06:38:34,867 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:34,867 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40209'. Reason: nanny-close
2024-01-07 06:38:34,867 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34455. Reason: nanny-close
2024-01-07 06:38:34,868 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38946; closing.
2024-01-07 06:38:34,868 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:34,868 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:34,868 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:34,868 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45245. Reason: nanny-close
2024-01-07 06:38:34,868 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46527'. Reason: nanny-close
2024-01-07 06:38:34,868 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:34,869 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39195', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609514.8689544')
2024-01-07 06:38:34,869 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35907. Reason: nanny-close
2024-01-07 06:38:34,870 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38954; closing.
2024-01-07 06:38:34,870 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:34,870 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:34,870 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37535', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609514.8707356')
2024-01-07 06:38:34,870 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36617. Reason: nanny-close
2024-01-07 06:38:34,871 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38930; closing.
2024-01-07 06:38:34,871 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38952; closing.
2024-01-07 06:38:34,871 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:34,871 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:34,871 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35323', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609514.8718317')
2024-01-07 06:38:34,871 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:34,872 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34455', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609514.8723366')
2024-01-07 06:38:34,872 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:34,872 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:34,872 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38900; closing.
2024-01-07 06:38:34,873 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:34,873 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45245', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609514.87341')
2024-01-07 06:38:34,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:34,874 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:34,874 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:34,874 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38970; closing.
2024-01-07 06:38:34,874 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:34,875 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35907', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609514.87509')
2024-01-07 06:38:34,875 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38978; closing.
2024-01-07 06:38:34,876 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36617', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609514.8762069')
2024-01-07 06:38:34,876 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:38:34,877 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:34,876 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:38970>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-07 06:38:36,179 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:38:36,179 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:38:36,180 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:38:36,181 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:38:36,181 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-07 06:38:38,693 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:38,697 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35303 instead
  warnings.warn(
2024-01-07 06:38:38,701 - distributed.scheduler - INFO - State start
2024-01-07 06:38:38,729 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:38,730 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:38:38,730 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35303/status
2024-01-07 06:38:38,730 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:38:38,901 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34743'
2024-01-07 06:38:38,935 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43175'
2024-01-07 06:38:38,938 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32949'
2024-01-07 06:38:38,947 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35925'
2024-01-07 06:38:38,955 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39915'
2024-01-07 06:38:38,964 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37563'
2024-01-07 06:38:38,974 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36687'
2024-01-07 06:38:38,983 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42435'
2024-01-07 06:38:40,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:40,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:40,824 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:40,825 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41929
2024-01-07 06:38:40,825 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41929
2024-01-07 06:38:40,825 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35969
2024-01-07 06:38:40,825 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:40,825 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:40,825 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:40,825 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:40,825 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vo3y0p6k
2024-01-07 06:38:40,825 - distributed.worker - INFO - Starting Worker plugin PreImport-c496208d-c800-44bc-9026-367f61c33f4d
2024-01-07 06:38:40,825 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f9f30cb1-1faf-41c1-9310-5a0c6779ee78
2024-01-07 06:38:40,825 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ec2899d7-7587-4845-8000-7b3d167b8ae2
2024-01-07 06:38:40,829 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:40,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:40,833 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:40,834 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45649
2024-01-07 06:38:40,834 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45649
2024-01-07 06:38:40,834 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35757
2024-01-07 06:38:40,834 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:40,834 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:40,834 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:40,835 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:40,835 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ylke68yv
2024-01-07 06:38:40,835 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c5937642-f8fe-45f6-b032-1289349358bb
2024-01-07 06:38:40,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:40,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:40,843 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:40,843 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42869
2024-01-07 06:38:40,843 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42869
2024-01-07 06:38:40,844 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36471
2024-01-07 06:38:40,844 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:40,844 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:40,844 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:40,844 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:40,844 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_a2_doqx
2024-01-07 06:38:40,844 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1295e93c-8d0c-45f9-8d3a-f305d95007f7
2024-01-07 06:38:40,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:40,871 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:40,875 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:40,876 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33939
2024-01-07 06:38:40,876 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33939
2024-01-07 06:38:40,876 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38703
2024-01-07 06:38:40,876 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:40,876 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:40,877 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:40,877 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:40,877 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-amp9zv68
2024-01-07 06:38:40,877 - distributed.worker - INFO - Starting Worker plugin RMMSetup-23884b8c-48aa-4311-9bcb-a694649b1b48
2024-01-07 06:38:40,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:40,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:40,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:40,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:40,895 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:40,895 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:40,896 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33009
2024-01-07 06:38:40,896 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33009
2024-01-07 06:38:40,896 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45413
2024-01-07 06:38:40,896 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:40,896 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:40,896 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:40,896 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:40,896 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4ddoef55
2024-01-07 06:38:40,896 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44147
2024-01-07 06:38:40,896 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ac0b6848-20bf-4aaa-92e3-520ee252c0c6
2024-01-07 06:38:40,896 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44147
2024-01-07 06:38:40,896 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41165
2024-01-07 06:38:40,896 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:40,896 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:40,896 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:40,897 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:40,897 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tb7y3ibk
2024-01-07 06:38:40,897 - distributed.worker - INFO - Starting Worker plugin PreImport-d313c271-7b6f-456c-9d99-265c592d9d33
2024-01-07 06:38:40,897 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b85d190d-4752-4ba1-8b59-8f5cb8ba023a
2024-01-07 06:38:40,897 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e65153fe-1186-464e-af28-41c3ba5f0b37
2024-01-07 06:38:40,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:40,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:40,903 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:40,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:40,905 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:40,905 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37353
2024-01-07 06:38:40,906 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37353
2024-01-07 06:38:40,906 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45077
2024-01-07 06:38:40,906 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:40,906 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:40,906 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:40,906 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:40,906 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8xmuswu4
2024-01-07 06:38:40,906 - distributed.worker - INFO - Starting Worker plugin RMMSetup-61be48bf-2d82-4431-ae57-bdc278dde232
2024-01-07 06:38:40,907 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:40,907 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36197
2024-01-07 06:38:40,908 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36197
2024-01-07 06:38:40,908 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34175
2024-01-07 06:38:40,908 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:40,908 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:40,908 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:40,908 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:38:40,908 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dqirbymm
2024-01-07 06:38:40,908 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5781d240-fb3d-4ebb-bba0-6fdc2042b8b5
2024-01-07 06:38:42,411 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,439 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41929', status: init, memory: 0, processing: 0>
2024-01-07 06:38:42,453 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41929
2024-01-07 06:38:42,453 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52554
2024-01-07 06:38:42,454 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:42,455 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:42,455 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,456 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:42,515 - distributed.scheduler - INFO - Receive client connection: Client-62c67a1c-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:42,516 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52558
2024-01-07 06:38:42,816 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-76ad76eb-716d-4d82-b83f-3fb6162245f8
2024-01-07 06:38:42,816 - distributed.worker - INFO - Starting Worker plugin PreImport-1b430f69-e7ff-4da5-a053-96bc1d58d4bd
2024-01-07 06:38:42,817 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,850 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45649', status: init, memory: 0, processing: 0>
2024-01-07 06:38:42,851 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45649
2024-01-07 06:38:42,851 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52574
2024-01-07 06:38:42,852 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:42,854 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:42,854 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,855 - distributed.worker - INFO - Starting Worker plugin PreImport-07b6202d-f384-4192-abfb-1ad64712b653
2024-01-07 06:38:42,855 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d13ca57b-2de9-48c9-a7b0-502c455d43c0
2024-01-07 06:38:42,856 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:42,856 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,887 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42869', status: init, memory: 0, processing: 0>
2024-01-07 06:38:42,888 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42869
2024-01-07 06:38:42,888 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52580
2024-01-07 06:38:42,889 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:42,891 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:42,891 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,893 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:42,933 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,939 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ae57f48f-1085-44e8-a7ed-85fc9dd77c1c
2024-01-07 06:38:42,940 - distributed.worker - INFO - Starting Worker plugin PreImport-49f688b9-3d7c-464e-bf5b-155339ea0cc7
2024-01-07 06:38:42,940 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,943 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5dd55da7-a2a5-4d68-8c2b-4a94d31ee89e
2024-01-07 06:38:42,944 - distributed.worker - INFO - Starting Worker plugin PreImport-56786c1e-c1bb-4f38-96f9-fb0f73227fc3
2024-01-07 06:38:42,945 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,951 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1745b14e-fc77-4f62-95fa-a14c6988144a
2024-01-07 06:38:42,952 - distributed.worker - INFO - Starting Worker plugin PreImport-3d91e0d6-336b-4261-acae-92f0fd23e794
2024-01-07 06:38:42,952 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,959 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44147', status: init, memory: 0, processing: 0>
2024-01-07 06:38:42,959 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44147
2024-01-07 06:38:42,959 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52596
2024-01-07 06:38:42,960 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:42,961 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:42,961 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,961 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33939', status: init, memory: 0, processing: 0>
2024-01-07 06:38:42,962 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33939
2024-01-07 06:38:42,962 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52604
2024-01-07 06:38:42,962 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:42,963 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:42,964 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:42,964 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,965 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:42,976 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36197', status: init, memory: 0, processing: 0>
2024-01-07 06:38:42,977 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36197
2024-01-07 06:38:42,977 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52622
2024-01-07 06:38:42,978 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:42,979 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37353', status: init, memory: 0, processing: 0>
2024-01-07 06:38:42,979 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:42,979 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,979 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37353
2024-01-07 06:38:42,979 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52620
2024-01-07 06:38:42,980 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:42,981 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:42,982 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:42,982 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:42,984 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:42,997 - distributed.worker - INFO - Starting Worker plugin PreImport-5b682033-2036-44b5-94c2-523b8a4b3054
2024-01-07 06:38:42,998 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4dca9707-fc11-4a02-8584-3b0ac23c0057
2024-01-07 06:38:42,998 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:43,029 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33009', status: init, memory: 0, processing: 0>
2024-01-07 06:38:43,030 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33009
2024-01-07 06:38:43,030 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52638
2024-01-07 06:38:43,031 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:43,032 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:43,032 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:43,034 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:43,139 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:43,139 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:43,139 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:43,139 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:43,139 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:43,140 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:43,140 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:43,140 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:38:43,145 - distributed.scheduler - INFO - Remove client Client-62c67a1c-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:43,145 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52558; closing.
2024-01-07 06:38:43,145 - distributed.scheduler - INFO - Remove client Client-62c67a1c-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:43,145 - distributed.scheduler - INFO - Close client connection: Client-62c67a1c-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:43,146 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34743'. Reason: nanny-close
2024-01-07 06:38:43,147 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:43,147 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43175'. Reason: nanny-close
2024-01-07 06:38:43,147 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:43,147 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32949'. Reason: nanny-close
2024-01-07 06:38:43,148 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33009. Reason: nanny-close
2024-01-07 06:38:43,148 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:43,148 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35925'. Reason: nanny-close
2024-01-07 06:38:43,148 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45649. Reason: nanny-close
2024-01-07 06:38:43,148 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:43,148 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39915'. Reason: nanny-close
2024-01-07 06:38:43,148 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41929. Reason: nanny-close
2024-01-07 06:38:43,149 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:43,149 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37563'. Reason: nanny-close
2024-01-07 06:38:43,149 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33939. Reason: nanny-close
2024-01-07 06:38:43,149 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:43,149 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36687'. Reason: nanny-close
2024-01-07 06:38:43,149 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42869. Reason: nanny-close
2024-01-07 06:38:43,149 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:43,150 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42435'. Reason: nanny-close
2024-01-07 06:38:43,150 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:43,150 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:43,150 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37353. Reason: nanny-close
2024-01-07 06:38:43,150 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52638; closing.
2024-01-07 06:38:43,150 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44147. Reason: nanny-close
2024-01-07 06:38:43,150 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:43,150 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:43,150 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33009', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609523.1506894')
2024-01-07 06:38:43,150 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36197. Reason: nanny-close
2024-01-07 06:38:43,151 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:43,151 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52554; closing.
2024-01-07 06:38:43,151 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52574; closing.
2024-01-07 06:38:43,152 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:43,152 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:43,152 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:43,152 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:43,152 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:43,152 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:43,152 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:43,152 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41929', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609523.152742')
2024-01-07 06:38:43,153 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45649', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609523.1530983')
2024-01-07 06:38:43,153 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:43,153 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52604; closing.
2024-01-07 06:38:43,153 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:43,153 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:43,154 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:43,154 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:43,154 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52580; closing.
2024-01-07 06:38:43,154 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33939', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609523.1544926')
2024-01-07 06:38:43,155 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42869', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609523.1552858')
2024-01-07 06:38:43,155 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52596; closing.
2024-01-07 06:38:43,155 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52620; closing.
2024-01-07 06:38:43,156 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52622; closing.
2024-01-07 06:38:43,156 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44147', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609523.1563616')
2024-01-07 06:38:43,156 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37353', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609523.1567082')
2024-01-07 06:38:43,157 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36197', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609523.157068')
2024-01-07 06:38:43,157 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:38:44,162 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:38:44,162 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:38:44,163 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:38:44,164 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:38:44,164 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-07 06:38:46,589 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:46,594 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35401 instead
  warnings.warn(
2024-01-07 06:38:46,599 - distributed.scheduler - INFO - State start
2024-01-07 06:38:46,623 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:46,624 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:38:46,625 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35401/status
2024-01-07 06:38:46,625 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:38:46,781 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38503'
2024-01-07 06:38:47,311 - distributed.scheduler - INFO - Receive client connection: Client-6783d3ae-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:47,325 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52712
2024-01-07 06:38:48,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:48,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:49,356 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:49,357 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42311
2024-01-07 06:38:49,357 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42311
2024-01-07 06:38:49,358 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-07 06:38:49,358 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:49,358 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:49,358 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:49,358 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:38:49,358 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-31rssf27
2024-01-07 06:38:49,358 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b39711f3-a5c4-4f2e-bd5a-d9bb4af92a74
2024-01-07 06:38:49,358 - distributed.worker - INFO - Starting Worker plugin PreImport-a5aaef3b-a84d-44f6-852d-a01373370494
2024-01-07 06:38:49,358 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ab80c170-0b65-4c94-bd74-ee2a6ba8fefa
2024-01-07 06:38:49,359 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:49,418 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42311', status: init, memory: 0, processing: 0>
2024-01-07 06:38:49,419 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42311
2024-01-07 06:38:49,419 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52738
2024-01-07 06:38:49,420 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:49,422 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:49,422 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:49,423 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:49,469 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:49,472 - distributed.scheduler - INFO - Remove client Client-6783d3ae-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:49,472 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52712; closing.
2024-01-07 06:38:49,472 - distributed.scheduler - INFO - Remove client Client-6783d3ae-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:49,472 - distributed.scheduler - INFO - Close client connection: Client-6783d3ae-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:49,473 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38503'. Reason: nanny-close
2024-01-07 06:38:49,474 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:49,475 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42311. Reason: nanny-close
2024-01-07 06:38:49,477 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52738; closing.
2024-01-07 06:38:49,477 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:49,477 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42311', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609529.4778607')
2024-01-07 06:38:49,478 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:38:49,479 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:50,138 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:38:50,139 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:38:50,139 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:38:50,140 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:38:50,140 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-07 06:38:54,777 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:54,782 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39455 instead
  warnings.warn(
2024-01-07 06:38:54,787 - distributed.scheduler - INFO - State start
2024-01-07 06:38:54,811 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:38:54,812 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:38:54,813 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39455/status
2024-01-07 06:38:54,813 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:38:54,921 - distributed.scheduler - INFO - Receive client connection: Client-6c5eb7a8-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:54,936 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57040
2024-01-07 06:38:54,986 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40849'
2024-01-07 06:38:56,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:38:56,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:38:57,618 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:38:57,618 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42261
2024-01-07 06:38:57,619 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42261
2024-01-07 06:38:57,619 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33929
2024-01-07 06:38:57,619 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:38:57,619 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:57,619 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:38:57,619 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:38:57,619 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-akr0zg10
2024-01-07 06:38:57,619 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9fafcbb5-9285-40a8-8887-7849ad47ca5e
2024-01-07 06:38:57,619 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-61ff08d8-b7eb-4229-ba98-6c7b4c75b29a
2024-01-07 06:38:57,619 - distributed.worker - INFO - Starting Worker plugin PreImport-21c88b68-a979-4c5d-804a-30f3225d0b16
2024-01-07 06:38:57,620 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:57,707 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42261', status: init, memory: 0, processing: 0>
2024-01-07 06:38:57,708 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42261
2024-01-07 06:38:57,709 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57062
2024-01-07 06:38:57,709 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:38:57,710 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:38:57,710 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:38:57,711 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:38:57,788 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:38:57,791 - distributed.scheduler - INFO - Remove client Client-6c5eb7a8-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:57,791 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57040; closing.
2024-01-07 06:38:57,791 - distributed.scheduler - INFO - Remove client Client-6c5eb7a8-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:57,791 - distributed.scheduler - INFO - Close client connection: Client-6c5eb7a8-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:38:57,792 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40849'. Reason: nanny-close
2024-01-07 06:38:57,792 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:38:57,793 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42261. Reason: nanny-close
2024-01-07 06:38:57,795 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:38:57,795 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57062; closing.
2024-01-07 06:38:57,795 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42261', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609537.795609')
2024-01-07 06:38:57,795 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:38:57,796 - distributed.nanny - INFO - Worker closed
2024-01-07 06:38:58,457 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:38:58,457 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:38:58,458 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:38:58,459 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:38:58,459 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-07 06:39:00,875 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:00,880 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36379 instead
  warnings.warn(
2024-01-07 06:39:00,885 - distributed.scheduler - INFO - State start
2024-01-07 06:39:00,907 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:00,908 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:39:00,909 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36379/status
2024-01-07 06:39:00,909 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:39:03,654 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:42346'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 969, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4428, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:42346>: Stream is closed
2024-01-07 06:39:03,999 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:39:04,000 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:39:04,000 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:39:04,001 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:39:04,002 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-07 06:39:06,450 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:06,455 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45633 instead
  warnings.warn(
2024-01-07 06:39:06,459 - distributed.scheduler - INFO - State start
2024-01-07 06:39:06,489 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:06,491 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-07 06:39:06,492 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45633/status
2024-01-07 06:39:06,492 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:39:06,530 - distributed.scheduler - INFO - Receive client connection: Client-735206cb-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:06,546 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45170
2024-01-07 06:39:06,576 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33285'
2024-01-07 06:39:08,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:08,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:08,479 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:08,480 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44353
2024-01-07 06:39:08,480 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44353
2024-01-07 06:39:08,480 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35105
2024-01-07 06:39:08,480 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-07 06:39:08,480 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:08,480 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:08,480 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:39:08,480 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-2kvge8x7
2024-01-07 06:39:08,481 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c42bf755-f7cc-4ee4-b502-e3bab1a70649
2024-01-07 06:39:08,481 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8ea5f373-cd88-45f9-9a6a-cee87427a05f
2024-01-07 06:39:08,481 - distributed.worker - INFO - Starting Worker plugin PreImport-4c26ce0c-2a0d-46b6-a19c-9e15597d5030
2024-01-07 06:39:08,481 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:08,533 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44353', status: init, memory: 0, processing: 0>
2024-01-07 06:39:08,534 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44353
2024-01-07 06:39:08,534 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45202
2024-01-07 06:39:08,535 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:08,536 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-07 06:39:08,536 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:08,537 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-07 06:39:08,586 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:08,589 - distributed.scheduler - INFO - Remove client Client-735206cb-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:08,589 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45170; closing.
2024-01-07 06:39:08,590 - distributed.scheduler - INFO - Remove client Client-735206cb-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:08,590 - distributed.scheduler - INFO - Close client connection: Client-735206cb-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:08,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33285'. Reason: nanny-close
2024-01-07 06:39:08,591 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:08,592 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44353. Reason: nanny-close
2024-01-07 06:39:08,594 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-07 06:39:08,594 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45202; closing.
2024-01-07 06:39:08,594 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44353', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609548.5945835')
2024-01-07 06:39:08,594 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:39:08,595 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:09,206 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:39:09,206 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:39:09,207 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:39:09,208 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-07 06:39:09,208 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-07 06:39:11,652 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:11,657 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45631 instead
  warnings.warn(
2024-01-07 06:39:11,661 - distributed.scheduler - INFO - State start
2024-01-07 06:39:11,683 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:11,684 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:39:11,685 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45631/status
2024-01-07 06:39:11,685 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:39:11,873 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45273'
2024-01-07 06:39:11,894 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35017'
2024-01-07 06:39:11,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33999'
2024-01-07 06:39:11,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43465'
2024-01-07 06:39:11,920 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33331'
2024-01-07 06:39:11,928 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38597'
2024-01-07 06:39:11,936 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37803'
2024-01-07 06:39:11,946 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42665'
2024-01-07 06:39:12,301 - distributed.scheduler - INFO - Receive client connection: Client-766c6457-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:12,315 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59828
2024-01-07 06:39:13,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:13,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:13,757 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:13,757 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44425
2024-01-07 06:39:13,757 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44425
2024-01-07 06:39:13,757 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36041
2024-01-07 06:39:13,757 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:13,758 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:13,758 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:13,758 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:39:13,758 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-58htxdn2
2024-01-07 06:39:13,758 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bb2c5c0f-263d-4dc5-bba0-13d9077aa383
2024-01-07 06:39:13,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:13,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:13,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:13,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:13,788 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:13,788 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:13,789 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41249
2024-01-07 06:39:13,789 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41249
2024-01-07 06:39:13,789 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42065
2024-01-07 06:39:13,789 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:13,789 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:13,789 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:13,789 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:39:13,789 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45181
2024-01-07 06:39:13,789 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2e0ogzi5
2024-01-07 06:39:13,789 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45181
2024-01-07 06:39:13,789 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41981
2024-01-07 06:39:13,790 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:13,790 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:13,790 - distributed.worker - INFO - Starting Worker plugin RMMSetup-23e3d146-b144-44e8-abfb-5ca140cb3648
2024-01-07 06:39:13,790 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:13,790 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:39:13,790 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9towvaqb
2024-01-07 06:39:13,790 - distributed.worker - INFO - Starting Worker plugin PreImport-187845af-8d87-4a01-b561-377d4940c974
2024-01-07 06:39:13,790 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-713098d6-3aa3-422c-a919-a4b51027005e
2024-01-07 06:39:13,790 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bb8a97ee-aefd-4628-ab8a-a67bf926add8
2024-01-07 06:39:13,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:13,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:13,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:13,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:13,811 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:13,812 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36571
2024-01-07 06:39:13,812 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36571
2024-01-07 06:39:13,812 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36083
2024-01-07 06:39:13,812 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:13,812 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:13,812 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:13,812 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:39:13,812 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qqv7v9_b
2024-01-07 06:39:13,812 - distributed.worker - INFO - Starting Worker plugin RMMSetup-98032295-e6f2-4a59-bffb-ea60adb95b17
2024-01-07 06:39:13,813 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:13,814 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35257
2024-01-07 06:39:13,814 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35257
2024-01-07 06:39:13,814 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45255
2024-01-07 06:39:13,814 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:13,814 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:13,815 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:13,815 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:39:13,815 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2ne5itya
2024-01-07 06:39:13,815 - distributed.worker - INFO - Starting Worker plugin RMMSetup-12b8be9b-a044-468c-b1f4-babf2914f420
2024-01-07 06:39:14,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:14,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:14,052 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:14,053 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44783
2024-01-07 06:39:14,053 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44783
2024-01-07 06:39:14,053 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36093
2024-01-07 06:39:14,053 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:14,053 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:14,054 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:14,054 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:39:14,054 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-53qg69pf
2024-01-07 06:39:14,054 - distributed.worker - INFO - Starting Worker plugin PreImport-f41c1693-95de-4a4d-a931-9e041193f1dc
2024-01-07 06:39:14,054 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-776b4e27-5836-4d55-b44a-4c301fecbd22
2024-01-07 06:39:14,054 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8572a256-ddbe-4934-aae3-788673e0c731
2024-01-07 06:39:14,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:14,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:14,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:14,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:14,067 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:14,067 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:14,068 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40673
2024-01-07 06:39:14,068 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40673
2024-01-07 06:39:14,068 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34557
2024-01-07 06:39:14,068 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:14,068 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:14,068 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:14,068 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:39:14,068 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sg40uclm
2024-01-07 06:39:14,068 - distributed.worker - INFO - Starting Worker plugin RMMSetup-138d45a1-bdfa-40de-be9e-99c7c597d204
2024-01-07 06:39:14,068 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42217
2024-01-07 06:39:14,069 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42217
2024-01-07 06:39:14,069 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44017
2024-01-07 06:39:14,069 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:14,069 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:14,069 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:14,069 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-07 06:39:14,069 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vjl4ieho
2024-01-07 06:39:14,069 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1e96bb86-a51e-473a-83e8-5e4baa37d49e
2024-01-07 06:39:15,005 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-32df71d2-f674-4cf1-b5b0-c7f31eaf498d
2024-01-07 06:39:15,006 - distributed.worker - INFO - Starting Worker plugin PreImport-fdd6958e-c32d-4ed6-971b-1752b95f0e39
2024-01-07 06:39:15,007 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,045 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44425', status: init, memory: 0, processing: 0>
2024-01-07 06:39:15,046 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44425
2024-01-07 06:39:15,046 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59848
2024-01-07 06:39:15,048 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:15,049 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:15,049 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,051 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:15,863 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bf7ca731-b7b2-48b8-9b14-2ca14f5084da
2024-01-07 06:39:15,865 - distributed.worker - INFO - Starting Worker plugin PreImport-4964cfae-6ad7-4ea0-bf00-c02034795d65
2024-01-07 06:39:15,866 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,876 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,891 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d99ca3fe-fcad-4e4b-a25a-2a2ebbe0870c
2024-01-07 06:39:15,892 - distributed.worker - INFO - Starting Worker plugin PreImport-fead108e-f0e4-4f7e-bbc1-0f645af78e23
2024-01-07 06:39:15,893 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,898 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45181', status: init, memory: 0, processing: 0>
2024-01-07 06:39:15,899 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45181
2024-01-07 06:39:15,899 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59866
2024-01-07 06:39:15,900 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:15,901 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:15,901 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,901 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36571', status: init, memory: 0, processing: 0>
2024-01-07 06:39:15,901 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36571
2024-01-07 06:39:15,902 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59858
2024-01-07 06:39:15,902 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:15,903 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:15,904 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:15,904 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,906 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:15,910 - distributed.worker - INFO - Starting Worker plugin PreImport-7b8b98ce-f572-45c9-bf72-568102a8e5bc
2024-01-07 06:39:15,911 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e2ae390b-1eb6-4269-99ce-0a8641b3f795
2024-01-07 06:39:15,912 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,917 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35257', status: init, memory: 0, processing: 0>
2024-01-07 06:39:15,917 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35257
2024-01-07 06:39:15,917 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59878
2024-01-07 06:39:15,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:15,919 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:15,919 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:15,945 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,946 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41249', status: init, memory: 0, processing: 0>
2024-01-07 06:39:15,946 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41249
2024-01-07 06:39:15,946 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59886
2024-01-07 06:39:15,948 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:15,949 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:15,949 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,951 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:15,953 - distributed.worker - INFO - Starting Worker plugin PreImport-4bb3dace-24ab-4ea9-9426-8c14480e91fd
2024-01-07 06:39:15,955 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1ff0bc74-9061-4701-8b4a-63027c46e685
2024-01-07 06:39:15,956 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,967 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44783', status: init, memory: 0, processing: 0>
2024-01-07 06:39:15,967 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44783
2024-01-07 06:39:15,967 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59896
2024-01-07 06:39:15,968 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:15,969 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:15,969 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,970 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:15,970 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37016d84-87ad-49df-8a6f-6c9d191789a0
2024-01-07 06:39:15,972 - distributed.worker - INFO - Starting Worker plugin PreImport-7d8db3e1-a1a7-476d-bb95-a3c4b3b5e461
2024-01-07 06:39:15,973 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,986 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42217', status: init, memory: 0, processing: 0>
2024-01-07 06:39:15,987 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42217
2024-01-07 06:39:15,987 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59902
2024-01-07 06:39:15,988 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:15,989 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:15,989 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:15,991 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:15,998 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40673', status: init, memory: 0, processing: 0>
2024-01-07 06:39:15,998 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40673
2024-01-07 06:39:15,998 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59912
2024-01-07 06:39:15,999 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:16,000 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:16,000 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:16,001 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:16,009 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:39:16,009 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:39:16,009 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:39:16,009 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:39:16,009 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:39:16,009 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:39:16,009 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:39:16,010 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-07 06:39:16,023 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:16,023 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:16,023 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:16,023 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:16,023 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:16,023 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:16,024 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:16,024 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:16,028 - distributed.scheduler - INFO - Remove client Client-766c6457-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:16,028 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59828; closing.
2024-01-07 06:39:16,028 - distributed.scheduler - INFO - Remove client Client-766c6457-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:16,029 - distributed.scheduler - INFO - Close client connection: Client-766c6457-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:16,030 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45273'. Reason: nanny-close
2024-01-07 06:39:16,030 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:16,030 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35017'. Reason: nanny-close
2024-01-07 06:39:16,031 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:16,031 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33999'. Reason: nanny-close
2024-01-07 06:39:16,031 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:16,031 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41249. Reason: nanny-close
2024-01-07 06:39:16,031 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43465'. Reason: nanny-close
2024-01-07 06:39:16,031 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:16,031 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44425. Reason: nanny-close
2024-01-07 06:39:16,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33331'. Reason: nanny-close
2024-01-07 06:39:16,032 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45181. Reason: nanny-close
2024-01-07 06:39:16,032 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:16,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38597'. Reason: nanny-close
2024-01-07 06:39:16,032 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35257. Reason: nanny-close
2024-01-07 06:39:16,032 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:16,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37803'. Reason: nanny-close
2024-01-07 06:39:16,033 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:16,033 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42217. Reason: nanny-close
2024-01-07 06:39:16,033 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42665'. Reason: nanny-close
2024-01-07 06:39:16,033 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36571. Reason: nanny-close
2024-01-07 06:39:16,033 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:16,033 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:16,033 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59886; closing.
2024-01-07 06:39:16,033 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44783. Reason: nanny-close
2024-01-07 06:39:16,033 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59866; closing.
2024-01-07 06:39:16,034 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:16,034 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:16,034 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41249', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609556.0342126')
2024-01-07 06:39:16,034 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45181', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609556.0347295')
2024-01-07 06:39:16,035 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:16,035 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:16,035 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59848; closing.
2024-01-07 06:39:16,035 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:16,035 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:16,035 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:16,035 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59878; closing.
2024-01-07 06:39:16,035 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:16,035 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:16,036 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44425', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609556.036594')
2024-01-07 06:39:16,036 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:16,037 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35257', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609556.0369487')
2024-01-07 06:39:16,037 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:16,037 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:16,038 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59902; closing.
2024-01-07 06:39:16,038 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59858; closing.
2024-01-07 06:39:16,038 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59896; closing.
2024-01-07 06:39:16,038 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:16,038 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42217', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609556.0385695')
2024-01-07 06:39:16,039 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36571', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609556.0389304')
2024-01-07 06:39:16,039 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44783', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609556.0392902')
2024-01-07 06:39:16,039 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40673. Reason: nanny-close
2024-01-07 06:39:16,041 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:16,041 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59912; closing.
2024-01-07 06:39:16,041 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40673', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609556.0418003')
2024-01-07 06:39:16,042 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:39:16,042 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:17,096 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:39:17,096 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:39:17,096 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:39:17,097 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:39:17,098 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-07 06:39:19,570 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:19,576 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35869 instead
  warnings.warn(
2024-01-07 06:39:19,581 - distributed.scheduler - INFO - State start
2024-01-07 06:39:19,608 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:19,609 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:39:19,610 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35869/status
2024-01-07 06:39:19,611 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:39:19,743 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40737'
2024-01-07 06:39:21,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:21,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:21,641 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:21,642 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45595
2024-01-07 06:39:21,642 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45595
2024-01-07 06:39:21,642 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37039
2024-01-07 06:39:21,642 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:21,642 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:21,642 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:21,642 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:39:21,642 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mucegcpn
2024-01-07 06:39:21,643 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9d16a470-46a0-4a13-89fc-033b9859f4f5
2024-01-07 06:39:21,643 - distributed.worker - INFO - Starting Worker plugin PreImport-b16d406f-7803-47f6-b3d8-777b0534520d
2024-01-07 06:39:21,643 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e951749a-2aa9-4c69-802c-8503b201577f
2024-01-07 06:39:21,961 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:22,024 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45595', status: init, memory: 0, processing: 0>
2024-01-07 06:39:22,040 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45595
2024-01-07 06:39:22,040 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53374
2024-01-07 06:39:22,041 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:22,041 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:22,042 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:22,043 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:22,649 - distributed.scheduler - INFO - Receive client connection: Client-7b2537c7-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:22,650 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53384
2024-01-07 06:39:22,656 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:39:22,661 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:22,663 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:22,666 - distributed.scheduler - INFO - Remove client Client-7b2537c7-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:22,667 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53384; closing.
2024-01-07 06:39:22,667 - distributed.scheduler - INFO - Remove client Client-7b2537c7-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:22,667 - distributed.scheduler - INFO - Close client connection: Client-7b2537c7-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:22,668 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40737'. Reason: nanny-close
2024-01-07 06:39:22,669 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:22,670 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45595. Reason: nanny-close
2024-01-07 06:39:22,672 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53374; closing.
2024-01-07 06:39:22,672 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:22,672 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45595', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609562.672889')
2024-01-07 06:39:22,673 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:39:22,674 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:23,434 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:39:23,435 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:39:23,435 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:39:23,436 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:39:23,436 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-07 06:39:25,879 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:25,884 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37613 instead
  warnings.warn(
2024-01-07 06:39:25,888 - distributed.scheduler - INFO - State start
2024-01-07 06:39:25,911 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-07 06:39:25,912 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-07 06:39:25,913 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37613/status
2024-01-07 06:39:25,913 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-07 06:39:25,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34857'
2024-01-07 06:39:26,240 - distributed.scheduler - INFO - Receive client connection: Client-7ed9d358-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:26,257 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53502
2024-01-07 06:39:27,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-07 06:39:27,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-07 06:39:27,857 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-07 06:39:27,858 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39495
2024-01-07 06:39:27,858 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39495
2024-01-07 06:39:27,858 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38365
2024-01-07 06:39:27,858 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-07 06:39:27,858 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:27,858 - distributed.worker - INFO -               Threads:                          1
2024-01-07 06:39:27,858 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-07 06:39:27,858 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-iplisqln
2024-01-07 06:39:27,859 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f409dd8e-1816-42bd-97e2-caffd05fe686
2024-01-07 06:39:27,859 - distributed.worker - INFO - Starting Worker plugin PreImport-378c5517-f295-4b39-b4b2-5b856bb11e18
2024-01-07 06:39:27,859 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0cd613d6-c0f1-4865-8189-ad28d5067ee8
2024-01-07 06:39:28,164 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:28,204 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39495', status: init, memory: 0, processing: 0>
2024-01-07 06:39:28,206 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39495
2024-01-07 06:39:28,206 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53528
2024-01-07 06:39:28,206 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-07 06:39:28,207 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-07 06:39:28,207 - distributed.worker - INFO - -------------------------------------------------
2024-01-07 06:39:28,208 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-07 06:39:28,253 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-07 06:39:28,258 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-07 06:39:28,262 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:28,264 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-07 06:39:28,266 - distributed.scheduler - INFO - Remove client Client-7ed9d358-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:28,266 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53502; closing.
2024-01-07 06:39:28,266 - distributed.scheduler - INFO - Remove client Client-7ed9d358-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:28,267 - distributed.scheduler - INFO - Close client connection: Client-7ed9d358-ad27-11ee-b0ee-d8c49764f6bb
2024-01-07 06:39:28,268 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34857'. Reason: nanny-close
2024-01-07 06:39:28,268 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-07 06:39:28,269 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39495. Reason: nanny-close
2024-01-07 06:39:28,271 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-07 06:39:28,271 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53528; closing.
2024-01-07 06:39:28,271 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39495', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704609568.271242')
2024-01-07 06:39:28,271 - distributed.scheduler - INFO - Lost all workers
2024-01-07 06:39:28,272 - distributed.nanny - INFO - Worker closed
2024-01-07 06:39:28,883 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-07 06:39:28,883 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-07 06:39:28,884 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-07 06:39:28,885 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-07 06:39:28,886 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33123 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39945 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39471 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33183 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44961 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41715 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41341 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41901 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45797 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34193 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42093 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44821 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38973 instead
  warnings.warn(
[1704609714.721663] [dgx13:67911:0]            sock.c:470  UCX  ERROR bind(fd=173 addr=0.0.0.0:48558) failed: Address already in use
[1704609714.924760] [dgx13:67911:0]            sock.c:470  UCX  ERROR bind(fd=179 addr=0.0.0.0:51180) failed: Address already in use
[1704609714.926900] [dgx13:67911:0]            sock.c:470  UCX  ERROR bind(fd=182 addr=0.0.0.0:37672) failed: Address already in use
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33151 instead
  warnings.warn(
[1704609732.285310] [dgx13:68228:0]            sock.c:470  UCX  ERROR bind(fd=163 addr=0.0.0.0:33369) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40819 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41347 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37169 instead
  warnings.warn(
[1704609759.125126] [dgx13:68797:0]            sock.c:470  UCX  ERROR bind(fd=123 addr=0.0.0.0:53289) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32833 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40415 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32777 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45147 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35279 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33365 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42905 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43219 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40411 instead
  warnings.warn(
sys:1: RuntimeWarning: coroutine 'BlockingMode._arm_worker' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task cancelling name='Task-3958' coro=<BlockingMode._arm_worker() running at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/continuous_ucx_progress.py:88>>
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36543 instead
  warnings.warn(
[1704609925.209778] [dgx13:71927:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:52675) failed: Address already in use
[1704609925.209876] [dgx13:71927:0]            sock.c:470  UCX  ERROR bind(fd=130 addr=0.0.0.0:50204) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36363 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45461 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33023 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42231 instead
  warnings.warn(
[1704610024.699882] [dgx13:73592:0]            sock.c:470  UCX  ERROR bind(fd=155 addr=0.0.0.0:48800) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44829 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46441 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35433 instead
  warnings.warn(
[1704610095.668502] [dgx13:74660:0]            sock.c:470  UCX  ERROR bind(fd=123 addr=0.0.0.0:55334) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32779 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34481 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39141 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42569 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34375 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46347 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40899 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43727 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34631 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44525 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35121 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33803 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33803 instead
  warnings.warn(
[1704610391.562411] [dgx13:79344:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:33002) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33735 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36557 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43945 instead
  warnings.warn(
[1704610468.070730] [dgx13:80318:0]            sock.c:470  UCX  ERROR bind(fd=159 addr=0.0.0.0:57512) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35621 instead
  warnings.warn(
[1704610490.560230] [dgx13:80647:0]            sock.c:470  UCX  ERROR bind(fd=159 addr=0.0.0.0:55290) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37535 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34385 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38625 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35035 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40305 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40421 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42835 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34075 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39571 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35971 instead
  warnings.warn(
2024-01-07 06:58:21,039 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-66e9ae79-dab7-4f17-b3c4-90d4cf625973
Function:  _run_coroutine_on_worker
args:      (121286539152955195192335649236125499516, <function shuffle_task at 0x7f563dc3b790>, ('explicit-comms-shuffle-71f91059afe4beb52d8c6be09d72a382', {0: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 0), ('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 4)}, 1: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 2)}, 2: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 3)}, 3: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 1)}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

2024-01-07 06:58:21,045 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-494e1134-acd3-4712-aed1-d98f3ab30636
Function:  _run_coroutine_on_worker
args:      (121286539152955195192335649236125499516, <function shuffle_task at 0x7f1826146ca0>, ('explicit-comms-shuffle-71f91059afe4beb52d8c6be09d72a382', {0: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 0), ('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 4)}, 1: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 2)}, 2: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 3)}, 3: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 1)}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

2024-01-07 06:58:21,065 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-e8703956-da91-40e3-8abf-ac240d265d42
Function:  _run_coroutine_on_worker
args:      (121286539152955195192335649236125499516, <function shuffle_task at 0x7efd3d256160>, ('explicit-comms-shuffle-71f91059afe4beb52d8c6be09d72a382', {0: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 0), ('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 4)}, 1: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 2)}, 2: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 3)}, 3: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 1)}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

2024-01-07 06:58:21,108 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-37785710-94b2-4bfc-80da-cdc8d2ab90a3
Function:  _run_coroutine_on_worker
args:      (121286539152955195192335649236125499516, <function shuffle_task at 0x7fd026d2e0d0>, ('explicit-comms-shuffle-71f91059afe4beb52d8c6be09d72a382', {0: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 0), ('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 4)}, 1: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 2)}, 2: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 3)}, 3: {('from_pandas-5d48eea67fb7a5813a0116c5a9918b3d', 1)}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

2024-01-07 06:58:21,381 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-96f3ebc9-7f2b-4748-9716-208acb1e23d2
Function:  _run_coroutine_on_worker
args:      (121286539152955195192335649236125499516, <function shuffle_task at 0x7f563dc3b790>, ('explicit-comms-shuffle-137841e41c51a7472bfd8ff76ea2d092', {0: set(), 1: {('from_pandas-96972ee3431941a7d2f3db7d851a0608', 2)}, 2: {('from_pandas-96972ee3431941a7d2f3db7d851a0608', 0)}, 3: {('from_pandas-96972ee3431941a7d2f3db7d851a0608', 1)}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 1, 1))
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

2024-01-07 06:58:21,387 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-4220500b-7846-495b-ab97-404bc3c03e1f
Function:  _run_coroutine_on_worker
args:      (121286539152955195192335649236125499516, <function shuffle_task at 0x7efd3d256160>, ('explicit-comms-shuffle-137841e41c51a7472bfd8ff76ea2d092', {0: set(), 1: {('from_pandas-96972ee3431941a7d2f3db7d851a0608', 2)}, 2: {('from_pandas-96972ee3431941a7d2f3db7d851a0608', 0)}, 3: {('from_pandas-96972ee3431941a7d2f3db7d851a0608', 1)}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 1, 1))
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

2024-01-07 06:58:21,389 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-cff2cb38-d090-44e8-87e1-62b33413b262
Function:  _run_coroutine_on_worker
args:      (121286539152955195192335649236125499516, <function shuffle_task at 0x7f1826146ca0>, ('explicit-comms-shuffle-137841e41c51a7472bfd8ff76ea2d092', {0: set(), 1: {('from_pandas-96972ee3431941a7d2f3db7d851a0608', 2)}, 2: {('from_pandas-96972ee3431941a7d2f3db7d851a0608', 0)}, 3: {('from_pandas-96972ee3431941a7d2f3db7d851a0608', 1)}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 1, 1))
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/src/bitmask/null_mask.cu:93: 2 cudaErrorMemoryAllocation out of memory')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 24 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
