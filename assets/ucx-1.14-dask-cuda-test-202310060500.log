============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.2, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-10-06 05:35:47,439 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:35:47,444 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44963 instead
  warnings.warn(
2023-10-06 05:35:47,448 - distributed.scheduler - INFO - State start
2023-10-06 05:35:47,966 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:35:47,968 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-06 05:35:47,969 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44963/status
2023-10-06 05:35:47,969 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:35:48,128 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33323'
2023-10-06 05:35:48,152 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35307'
2023-10-06 05:35:48,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35101'
2023-10-06 05:35:48,163 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42413'
2023-10-06 05:35:49,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:49,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:49,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:49,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:49,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:49,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:49,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:49,949 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:49,952 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:49,952 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:49,952 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:49,954 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-10-06 05:35:49,972 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44355
2023-10-06 05:35:49,972 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44355
2023-10-06 05:35:49,972 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34403
2023-10-06 05:35:49,972 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-06 05:35:49,972 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:49,972 - distributed.worker - INFO -               Threads:                          4
2023-10-06 05:35:49,972 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-06 05:35:49,972 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-l4qasl02
2023-10-06 05:35:49,973 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6b0c1129-bae9-4389-b61b-af27b3237226
2023-10-06 05:35:49,973 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-719cfee1-ad3b-45f3-98ad-5dd59fb6d2f0
2023-10-06 05:35:49,973 - distributed.worker - INFO - Starting Worker plugin PreImport-c96a4f4c-f61c-40c7-8040-5a45d321bbd1
2023-10-06 05:35:49,973 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:50,599 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44355', status: init, memory: 0, processing: 0>
2023-10-06 05:35:50,614 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44355
2023-10-06 05:35:50,614 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47906
2023-10-06 05:35:50,615 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:50,616 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-06 05:35:50,616 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:50,617 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-06 05:35:50,714 - distributed.scheduler - INFO - Receive client connection: Client-3295b13c-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:35:50,714 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47912
2023-10-06 05:35:51,329 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41915
2023-10-06 05:35:51,329 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41915
2023-10-06 05:35:51,329 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33753
2023-10-06 05:35:51,329 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-06 05:35:51,330 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:51,330 - distributed.worker - INFO -               Threads:                          4
2023-10-06 05:35:51,330 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-06 05:35:51,330 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-oz7ftka2
2023-10-06 05:35:51,330 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43727
2023-10-06 05:35:51,330 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d41c7fdc-4197-49f5-bdf1-cec486003769
2023-10-06 05:35:51,330 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43727
2023-10-06 05:35:51,331 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39337
2023-10-06 05:35:51,331 - distributed.worker - INFO - Starting Worker plugin PreImport-4628768d-e78f-4ce5-adcc-743560c40b4b
2023-10-06 05:35:51,331 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-06 05:35:51,331 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:51,331 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4f1621b7-7ad6-4c11-85a3-0a7e10c988e1
2023-10-06 05:35:51,331 - distributed.worker - INFO -               Threads:                          4
2023-10-06 05:35:51,331 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-06 05:35:51,330 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43301
2023-10-06 05:35:51,331 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-im1zs4wo
2023-10-06 05:35:51,331 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43301
2023-10-06 05:35:51,331 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34131
2023-10-06 05:35:51,331 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-06 05:35:51,331 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:51,331 - distributed.worker - INFO -               Threads:                          4
2023-10-06 05:35:51,332 - distributed.worker - INFO - Starting Worker plugin RMMSetup-055040ce-85b8-4e12-988b-0b9ed37255bc
2023-10-06 05:35:51,332 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-06 05:35:51,332 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-kipjdlod
2023-10-06 05:35:51,332 - distributed.worker - INFO - Starting Worker plugin PreImport-a676963a-525e-4a3d-b6a5-65c4b525a3c2
2023-10-06 05:35:51,332 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b2d5878b-a682-42d7-aa26-c1c1823bd97c
2023-10-06 05:35:51,332 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-af32bb0e-e145-4aff-86be-e6499a049a85
2023-10-06 05:35:51,332 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d5008153-d16f-41a7-95f0-ea0b64b25f05
2023-10-06 05:35:51,332 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:51,332 - distributed.worker - INFO - Starting Worker plugin PreImport-0fa6918c-d75e-4178-b720-fb3ed5866d0d
2023-10-06 05:35:51,333 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:51,331 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:51,356 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43727', status: init, memory: 0, processing: 0>
2023-10-06 05:35:51,356 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43727
2023-10-06 05:35:51,357 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47936
2023-10-06 05:35:51,357 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43301', status: init, memory: 0, processing: 0>
2023-10-06 05:35:51,357 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:51,358 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43301
2023-10-06 05:35:51,358 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47952
2023-10-06 05:35:51,358 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-06 05:35:51,358 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:51,359 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:51,360 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-06 05:35:51,360 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:51,360 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-06 05:35:51,362 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-06 05:35:51,368 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41915', status: init, memory: 0, processing: 0>
2023-10-06 05:35:51,368 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41915
2023-10-06 05:35:51,368 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47956
2023-10-06 05:35:51,370 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:51,371 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-06 05:35:51,371 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:51,373 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-06 05:35:51,440 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-06 05:35:51,440 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-06 05:35:51,440 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-06 05:35:51,440 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-06 05:35:51,445 - distributed.scheduler - INFO - Remove client Client-3295b13c-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:35:51,445 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47912; closing.
2023-10-06 05:35:51,445 - distributed.scheduler - INFO - Remove client Client-3295b13c-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:35:51,446 - distributed.scheduler - INFO - Close client connection: Client-3295b13c-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:35:51,447 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33323'. Reason: nanny-close
2023-10-06 05:35:51,447 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:51,448 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35307'. Reason: nanny-close
2023-10-06 05:35:51,448 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:51,448 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43727. Reason: nanny-close
2023-10-06 05:35:51,448 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35101'. Reason: nanny-close
2023-10-06 05:35:51,449 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:51,449 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43301. Reason: nanny-close
2023-10-06 05:35:51,449 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42413'. Reason: nanny-close
2023-10-06 05:35:51,449 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:51,450 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41915. Reason: nanny-close
2023-10-06 05:35:51,450 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-06 05:35:51,450 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47936; closing.
2023-10-06 05:35:51,450 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43727', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570551.450664')
2023-10-06 05:35:51,450 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44355. Reason: nanny-close
2023-10-06 05:35:51,451 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-06 05:35:51,451 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:51,451 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47952; closing.
2023-10-06 05:35:51,452 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43301', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570551.4522097')
2023-10-06 05:35:51,452 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:51,453 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-06 05:35:51,453 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-06 05:35:51,454 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:51,454 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:51,452 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:47952>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:47952>: Stream is closed
2023-10-06 05:35:51,455 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47956; closing.
2023-10-06 05:35:51,456 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41915', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570551.4561596')
2023-10-06 05:35:51,456 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47906; closing.
2023-10-06 05:35:51,456 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44355', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570551.4568424')
2023-10-06 05:35:51,457 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:35:52,714 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:35:52,714 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:35:52,715 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:35:52,716 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-06 05:35:52,716 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-10-06 05:35:54,742 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:35:54,746 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33223 instead
  warnings.warn(
2023-10-06 05:35:54,749 - distributed.scheduler - INFO - State start
2023-10-06 05:35:54,771 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:35:54,772 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:35:54,773 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33223/status
2023-10-06 05:35:54,773 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:35:54,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35621'
2023-10-06 05:35:55,008 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37345'
2023-10-06 05:35:55,023 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45439'
2023-10-06 05:35:55,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42549'
2023-10-06 05:35:55,033 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36251'
2023-10-06 05:35:55,042 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33505'
2023-10-06 05:35:55,050 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40819'
2023-10-06 05:35:55,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43715'
2023-10-06 05:35:56,200 - distributed.scheduler - INFO - Receive client connection: Client-3719090a-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:35:56,212 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37278
2023-10-06 05:35:56,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:56,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:56,779 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:56,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:56,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:56,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:56,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:56,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:56,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:56,879 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:56,881 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:56,882 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:56,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:56,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:56,923 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:56,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:56,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:56,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:56,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:56,931 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:56,932 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:57,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:35:57,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:35:57,108 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:35:58,153 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34821
2023-10-06 05:35:58,155 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34821
2023-10-06 05:35:58,155 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38627
2023-10-06 05:35:58,155 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:35:58,155 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:58,155 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:35:58,155 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:35:58,155 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nfhq9q2_
2023-10-06 05:35:58,156 - distributed.worker - INFO - Starting Worker plugin PreImport-b8399802-674c-47d7-a8e8-41b786e24442
2023-10-06 05:35:58,157 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6d1d7b6d-3110-46a9-9886-59f757917273
2023-10-06 05:35:58,158 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cd3ba4bb-e12a-4010-a2d4-82b4ff11a2da
2023-10-06 05:35:58,795 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:58,829 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34821', status: init, memory: 0, processing: 0>
2023-10-06 05:35:58,830 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34821
2023-10-06 05:35:58,830 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37300
2023-10-06 05:35:58,831 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:58,832 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:35:58,832 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:58,834 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:35:59,587 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34431
2023-10-06 05:35:59,588 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34431
2023-10-06 05:35:59,588 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36209
2023-10-06 05:35:59,588 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,588 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,588 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:35:59,588 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:35:59,588 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7tob9ebj
2023-10-06 05:35:59,589 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-13ba64a7-bc5e-4630-bfee-aef5871714ad
2023-10-06 05:35:59,589 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a7bb6777-cb13-4108-b9e8-8171c648f3e2
2023-10-06 05:35:59,597 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34311
2023-10-06 05:35:59,598 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34311
2023-10-06 05:35:59,598 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38039
2023-10-06 05:35:59,598 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,598 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,598 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:35:59,599 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:35:59,599 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vc1_uk01
2023-10-06 05:35:59,599 - distributed.worker - INFO - Starting Worker plugin RMMSetup-be81484d-97a4-4846-837d-709564d75831
2023-10-06 05:35:59,609 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35895
2023-10-06 05:35:59,610 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35895
2023-10-06 05:35:59,610 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37953
2023-10-06 05:35:59,610 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,610 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,610 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:35:59,610 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:35:59,610 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bebjhgvh
2023-10-06 05:35:59,611 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b9cad7e2-2d70-4879-88ac-d77469f53409
2023-10-06 05:35:59,622 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38061
2023-10-06 05:35:59,622 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38061
2023-10-06 05:35:59,623 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45213
2023-10-06 05:35:59,623 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,623 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,623 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:35:59,623 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:35:59,623 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3ybamkzk
2023-10-06 05:35:59,623 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6827946b-65cb-443c-ab3b-df88004a6441
2023-10-06 05:35:59,626 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41123
2023-10-06 05:35:59,627 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41123
2023-10-06 05:35:59,627 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44229
2023-10-06 05:35:59,627 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,627 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,627 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:35:59,627 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:35:59,627 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cbsw1dxs
2023-10-06 05:35:59,628 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a74a94d0-e18c-4c75-8a6e-43ea53f8db9f
2023-10-06 05:35:59,628 - distributed.worker - INFO - Starting Worker plugin PreImport-f1ccd2b0-718a-4889-9f47-7d9600b8c1d2
2023-10-06 05:35:59,629 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c8a006e3-6a13-4012-9c29-1a8354d04e0b
2023-10-06 05:35:59,628 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35187
2023-10-06 05:35:59,629 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35187
2023-10-06 05:35:59,629 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41227
2023-10-06 05:35:59,629 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,629 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,629 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:35:59,629 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:35:59,629 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3u362145
2023-10-06 05:35:59,629 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37453
2023-10-06 05:35:59,630 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37453
2023-10-06 05:35:59,630 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43521
2023-10-06 05:35:59,630 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,630 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,630 - distributed.worker - INFO - Starting Worker plugin RMMSetup-20242114-0a74-43fb-8a7b-eafa2f7be89d
2023-10-06 05:35:59,630 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:35:59,630 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:35:59,630 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zzcrp4no
2023-10-06 05:35:59,630 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d21e57d6-577b-4de4-980f-24715e6d922b
2023-10-06 05:35:59,753 - distributed.worker - INFO - Starting Worker plugin PreImport-569cbd91-0c1f-42e3-8d16-16290712e509
2023-10-06 05:35:59,753 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-491f200a-050d-4887-b493-acbba384fdca
2023-10-06 05:35:59,753 - distributed.worker - INFO - Starting Worker plugin PreImport-60aad98a-ba9f-4f9e-b3a3-74ee857bea9f
2023-10-06 05:35:59,753 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,754 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,770 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8644dddd-df7c-482e-843d-0d7adc71b800
2023-10-06 05:35:59,770 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9409fbcf-5a17-4212-b670-e82b13e55941
2023-10-06 05:35:59,770 - distributed.worker - INFO - Starting Worker plugin PreImport-49379701-dbc4-40cf-8afa-895bb5e822b6
2023-10-06 05:35:59,770 - distributed.worker - INFO - Starting Worker plugin PreImport-666cdf3e-a179-4b29-9c51-404887a03944
2023-10-06 05:35:59,770 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a0b33664-3b31-4b6d-9602-f35b19cfffc3
2023-10-06 05:35:59,770 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,770 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-96aa5e39-732c-4feb-91cb-652a34f7ebd1
2023-10-06 05:35:59,771 - distributed.worker - INFO - Starting Worker plugin PreImport-35c7bc09-c71c-4d26-8ad4-e550060b8360
2023-10-06 05:35:59,770 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,771 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,771 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,771 - distributed.worker - INFO - Starting Worker plugin PreImport-2c9ed176-702a-4509-9426-bfe46d4109ab
2023-10-06 05:35:59,772 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,780 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34311', status: init, memory: 0, processing: 0>
2023-10-06 05:35:59,781 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34311
2023-10-06 05:35:59,781 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37328
2023-10-06 05:35:59,782 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34431', status: init, memory: 0, processing: 0>
2023-10-06 05:35:59,782 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:59,783 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34431
2023-10-06 05:35:59,783 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,783 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37312
2023-10-06 05:35:59,783 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,784 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:59,785 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,785 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:35:59,785 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,787 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:35:59,794 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35895', status: init, memory: 0, processing: 0>
2023-10-06 05:35:59,794 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35895
2023-10-06 05:35:59,794 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37330
2023-10-06 05:35:59,795 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:59,795 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37453', status: init, memory: 0, processing: 0>
2023-10-06 05:35:59,796 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,796 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37453
2023-10-06 05:35:59,796 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,796 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37344
2023-10-06 05:35:59,797 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:59,797 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:35:59,798 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,798 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,799 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:35:59,807 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38061', status: init, memory: 0, processing: 0>
2023-10-06 05:35:59,808 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38061
2023-10-06 05:35:59,808 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37362
2023-10-06 05:35:59,809 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41123', status: init, memory: 0, processing: 0>
2023-10-06 05:35:59,810 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:59,810 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41123
2023-10-06 05:35:59,810 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37346
2023-10-06 05:35:59,811 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,811 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,811 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35187', status: init, memory: 0, processing: 0>
2023-10-06 05:35:59,812 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:59,812 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35187
2023-10-06 05:35:59,812 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37372
2023-10-06 05:35:59,813 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,813 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,814 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:35:59,814 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:35:59,815 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:35:59,815 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:35:59,815 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:35:59,818 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:35:59,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:35:59,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:35:59,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:35:59,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:35:59,883 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:35:59,884 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:35:59,884 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:35:59,884 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:35:59,889 - distributed.scheduler - INFO - Remove client Client-3719090a-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:35:59,889 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37278; closing.
2023-10-06 05:35:59,890 - distributed.scheduler - INFO - Remove client Client-3719090a-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:35:59,890 - distributed.scheduler - INFO - Close client connection: Client-3719090a-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:35:59,891 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35621'. Reason: nanny-close
2023-10-06 05:35:59,891 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:59,892 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37345'. Reason: nanny-close
2023-10-06 05:35:59,892 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:59,893 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41123. Reason: nanny-close
2023-10-06 05:35:59,893 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45439'. Reason: nanny-close
2023-10-06 05:35:59,893 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:59,893 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35187. Reason: nanny-close
2023-10-06 05:35:59,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42549'. Reason: nanny-close
2023-10-06 05:35:59,894 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:59,894 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34431. Reason: nanny-close
2023-10-06 05:35:59,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36251'. Reason: nanny-close
2023-10-06 05:35:59,895 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:59,895 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37453. Reason: nanny-close
2023-10-06 05:35:59,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33505'. Reason: nanny-close
2023-10-06 05:35:59,895 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:59,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40819'. Reason: nanny-close
2023-10-06 05:35:59,896 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:35:59,896 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34821. Reason: nanny-close
2023-10-06 05:35:59,896 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:59,896 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:35:59,896 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38061. Reason: nanny-close
2023-10-06 05:35:59,896 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43715'. Reason: nanny-close
2023-10-06 05:35:59,896 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37346; closing.
2023-10-06 05:35:59,896 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:35:59,896 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34311. Reason: nanny-close
2023-10-06 05:35:59,896 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:35:59,897 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41123', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570559.8972056')
2023-10-06 05:35:59,897 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:35:59,897 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35895. Reason: nanny-close
2023-10-06 05:35:59,897 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:59,897 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37344; closing.
2023-10-06 05:35:59,898 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:59,898 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37312; closing.
2023-10-06 05:35:59,898 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:35:59,898 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:59,898 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:35:59,899 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37453', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570559.8989713')
2023-10-06 05:35:59,899 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:35:59,899 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34431', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570559.8996155')
2023-10-06 05:35:59,899 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:59,900 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:59,900 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:35:59,900 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:59,901 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:59,901 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37300; closing.
2023-10-06 05:35:59,901 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37372; closing.
2023-10-06 05:35:59,902 - distributed.nanny - INFO - Worker closed
2023-10-06 05:35:59,902 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:37312>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-06 05:35:59,905 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:37344>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-06 05:35:59,905 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34821', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570559.9054656')
2023-10-06 05:35:59,906 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35187', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570559.9059007')
2023-10-06 05:35:59,906 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37362; closing.
2023-10-06 05:35:59,906 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37328; closing.
2023-10-06 05:35:59,907 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38061', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570559.9072723')
2023-10-06 05:35:59,907 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34311', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570559.9078567')
2023-10-06 05:35:59,908 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37330; closing.
2023-10-06 05:35:59,908 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35895', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570559.908572')
2023-10-06 05:35:59,908 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:36:01,459 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:36:01,460 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:36:01,461 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:36:01,462 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:36:01,463 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-10-06 05:36:03,581 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:03,585 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-06 05:36:03,588 - distributed.scheduler - INFO - State start
2023-10-06 05:36:03,731 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:03,732 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:36:03,732 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-06 05:36:03,732 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:36:03,854 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35649'
2023-10-06 05:36:03,865 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39079'
2023-10-06 05:36:03,874 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40703'
2023-10-06 05:36:03,888 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46575'
2023-10-06 05:36:03,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39319'
2023-10-06 05:36:03,897 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37795'
2023-10-06 05:36:03,905 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34991'
2023-10-06 05:36:03,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43423'
2023-10-06 05:36:04,578 - distributed.scheduler - INFO - Receive client connection: Client-3c4d58ba-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:04,589 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36192
2023-10-06 05:36:05,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:05,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:05,713 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:05,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:05,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:05,729 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:05,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:05,735 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:05,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:05,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:05,740 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:05,740 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:05,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:05,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:05,810 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:05,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:05,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:05,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:05,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:05,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:05,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:05,822 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:05,825 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:05,826 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:08,604 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33019
2023-10-06 05:36:08,606 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33019
2023-10-06 05:36:08,606 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36005
2023-10-06 05:36:08,606 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,606 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,606 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:08,606 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:08,606 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q8p8u3k2
2023-10-06 05:36:08,607 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4a6e4b36-bac0-40ea-a3ed-a8f12caa2636
2023-10-06 05:36:08,609 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41879
2023-10-06 05:36:08,611 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41879
2023-10-06 05:36:08,611 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38781
2023-10-06 05:36:08,611 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,611 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,612 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:08,612 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:08,611 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36285
2023-10-06 05:36:08,612 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36285
2023-10-06 05:36:08,612 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-207inrou
2023-10-06 05:36:08,612 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33031
2023-10-06 05:36:08,612 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,612 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,612 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:08,612 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:08,612 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lwf38vja
2023-10-06 05:36:08,613 - distributed.worker - INFO - Starting Worker plugin RMMSetup-70df51a5-53f8-4709-aaa4-c7eb4ea2f0f2
2023-10-06 05:36:08,613 - distributed.worker - INFO - Starting Worker plugin PreImport-8bc17173-1c8f-4db3-9ed9-e9efebc9b174
2023-10-06 05:36:08,613 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-047cffa7-b9ba-4250-87ef-932eacb436a0
2023-10-06 05:36:08,613 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0fd727d4-110b-47e2-a24a-d40c0f7bc2e4
2023-10-06 05:36:08,616 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42899
2023-10-06 05:36:08,616 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42899
2023-10-06 05:36:08,616 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41957
2023-10-06 05:36:08,617 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,617 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,617 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:08,617 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:08,617 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mv31pfyn
2023-10-06 05:36:08,617 - distributed.worker - INFO - Starting Worker plugin RMMSetup-807de034-8b9f-4320-bcb8-38ce4bba18b7
2023-10-06 05:36:08,621 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45079
2023-10-06 05:36:08,622 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45079
2023-10-06 05:36:08,622 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38211
2023-10-06 05:36:08,622 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,622 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,622 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:08,622 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:08,622 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3cen9cgr
2023-10-06 05:36:08,623 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fa14ed74-91c3-414c-872f-6288dae3959f
2023-10-06 05:36:08,623 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a4a95659-66d0-4d64-b8ab-29a61791dd2e
2023-10-06 05:36:08,624 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40347
2023-10-06 05:36:08,625 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40347
2023-10-06 05:36:08,626 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32907
2023-10-06 05:36:08,626 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,626 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,626 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:08,626 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:08,626 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y7aqnrz8
2023-10-06 05:36:08,625 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36299
2023-10-06 05:36:08,626 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36299
2023-10-06 05:36:08,626 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38419
2023-10-06 05:36:08,626 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,626 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,626 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:08,627 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:08,627 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k69onxyd
2023-10-06 05:36:08,627 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f9328fac-fd8d-4aee-b1e5-77b0bb3ee6b8
2023-10-06 05:36:08,627 - distributed.worker - INFO - Starting Worker plugin PreImport-69123e25-8ff4-495b-a735-779ce1097a29
2023-10-06 05:36:08,627 - distributed.worker - INFO - Starting Worker plugin PreImport-c61be822-a26e-455e-b2a7-11484da03966
2023-10-06 05:36:08,627 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-21176c16-621a-4996-a177-19764605e78e
2023-10-06 05:36:08,627 - distributed.worker - INFO - Starting Worker plugin RMMSetup-05d79c47-1a78-4973-be16-e9562c98bbb8
2023-10-06 05:36:08,627 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3f95f7b3-a21d-4341-a617-6812cac58ba4
2023-10-06 05:36:08,627 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35005
2023-10-06 05:36:08,628 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35005
2023-10-06 05:36:08,628 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40769
2023-10-06 05:36:08,628 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,628 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,628 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:08,628 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:08,628 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4jmdydwa
2023-10-06 05:36:08,629 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cbbc252e-ab1d-4a83-968c-2e4672dd4468
2023-10-06 05:36:08,654 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1520b14a-b385-4bc7-bcb2-17daaaa959da
2023-10-06 05:36:08,655 - distributed.worker - INFO - Starting Worker plugin PreImport-776e4063-a3d2-4004-8494-b82e13604010
2023-10-06 05:36:08,655 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,656 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6adec790-f1fe-4ad8-a910-65e1d67ed7f6
2023-10-06 05:36:08,656 - distributed.worker - INFO - Starting Worker plugin PreImport-91fcd3c0-38b0-4359-946f-b8d4826b06bb
2023-10-06 05:36:08,656 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,656 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,657 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bc10791c-ae55-49e5-85f6-b996ae98f59d
2023-10-06 05:36:08,657 - distributed.worker - INFO - Starting Worker plugin PreImport-1b3a69df-fbcf-4127-a97c-cf4675c084ab
2023-10-06 05:36:08,657 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,658 - distributed.worker - INFO - Starting Worker plugin PreImport-f0150d68-1de2-4e06-b894-4f7590037123
2023-10-06 05:36:08,658 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,659 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,660 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7939beb0-65f9-4181-93e9-fd9e827624f6
2023-10-06 05:36:08,660 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,660 - distributed.worker - INFO - Starting Worker plugin PreImport-bbdd96d8-9031-4a9b-a38f-fa0e59307dbd
2023-10-06 05:36:08,661 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,681 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36285', status: init, memory: 0, processing: 0>
2023-10-06 05:36:08,682 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36285
2023-10-06 05:36:08,683 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36222
2023-10-06 05:36:08,683 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:08,684 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,684 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,684 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36299', status: init, memory: 0, processing: 0>
2023-10-06 05:36:08,685 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36299
2023-10-06 05:36:08,685 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36270
2023-10-06 05:36:08,686 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:08,686 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:08,686 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45079', status: init, memory: 0, processing: 0>
2023-10-06 05:36:08,687 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,687 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,687 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45079
2023-10-06 05:36:08,687 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36244
2023-10-06 05:36:08,688 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:08,688 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:08,688 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41879', status: init, memory: 0, processing: 0>
2023-10-06 05:36:08,689 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,689 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,689 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41879
2023-10-06 05:36:08,689 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36232
2023-10-06 05:36:08,690 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:08,690 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33019', status: init, memory: 0, processing: 0>
2023-10-06 05:36:08,691 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:08,691 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33019
2023-10-06 05:36:08,691 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36206
2023-10-06 05:36:08,692 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,692 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,692 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40347', status: init, memory: 0, processing: 0>
2023-10-06 05:36:08,692 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:08,692 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40347
2023-10-06 05:36:08,693 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36278
2023-10-06 05:36:08,693 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,693 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,694 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:08,694 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:08,695 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:08,695 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,695 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,696 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35005', status: init, memory: 0, processing: 0>
2023-10-06 05:36:08,696 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35005
2023-10-06 05:36:08,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36294
2023-10-06 05:36:08,697 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:08,697 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42899', status: init, memory: 0, processing: 0>
2023-10-06 05:36:08,697 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:08,698 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42899
2023-10-06 05:36:08,698 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36254
2023-10-06 05:36:08,699 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,699 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,699 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:08,700 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:08,700 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:08,701 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:08,703 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:08,804 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:08,804 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:08,805 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:08,805 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:08,805 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:08,805 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:08,805 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:08,805 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:08,810 - distributed.scheduler - INFO - Remove client Client-3c4d58ba-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:08,810 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36192; closing.
2023-10-06 05:36:08,810 - distributed.scheduler - INFO - Remove client Client-3c4d58ba-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:08,810 - distributed.scheduler - INFO - Close client connection: Client-3c4d58ba-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:08,812 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35649'. Reason: nanny-close
2023-10-06 05:36:08,812 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:08,814 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39079'. Reason: nanny-close
2023-10-06 05:36:08,814 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:08,814 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40347. Reason: nanny-close
2023-10-06 05:36:08,815 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40703'. Reason: nanny-close
2023-10-06 05:36:08,815 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:08,815 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41879. Reason: nanny-close
2023-10-06 05:36:08,816 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46575'. Reason: nanny-close
2023-10-06 05:36:08,816 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36285. Reason: nanny-close
2023-10-06 05:36:08,816 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:08,816 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36278; closing.
2023-10-06 05:36:08,816 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:08,816 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39319'. Reason: nanny-close
2023-10-06 05:36:08,817 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40347', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570568.8169844')
2023-10-06 05:36:08,817 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45079. Reason: nanny-close
2023-10-06 05:36:08,817 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:08,817 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37795'. Reason: nanny-close
2023-10-06 05:36:08,818 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:08,818 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:08,818 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:08,818 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35005. Reason: nanny-close
2023-10-06 05:36:08,818 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:08,818 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34991'. Reason: nanny-close
2023-10-06 05:36:08,818 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36232; closing.
2023-10-06 05:36:08,818 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:08,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42899. Reason: nanny-close
2023-10-06 05:36:08,819 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:08,819 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43423'. Reason: nanny-close
2023-10-06 05:36:08,819 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41879', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570568.8196957')
2023-10-06 05:36:08,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33019. Reason: nanny-close
2023-10-06 05:36:08,819 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:08,819 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:08,820 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:08,820 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36222; closing.
2023-10-06 05:36:08,820 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36285', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570568.820505')
2023-10-06 05:36:08,820 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36299. Reason: nanny-close
2023-10-06 05:36:08,820 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36244; closing.
2023-10-06 05:36:08,821 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:08,821 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:08,821 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45079', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570568.821244')
2023-10-06 05:36:08,821 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:08,821 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36294; closing.
2023-10-06 05:36:08,822 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:08,822 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35005', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570568.822431')
2023-10-06 05:36:08,822 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:08,822 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36206; closing.
2023-10-06 05:36:08,823 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:08,823 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33019', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570568.8233604')
2023-10-06 05:36:08,823 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36254; closing.
2023-10-06 05:36:08,823 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:08,823 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36270; closing.
2023-10-06 05:36:08,824 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42899', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570568.8242176')
2023-10-06 05:36:08,824 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:08,824 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:08,824 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36299', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570568.824585')
2023-10-06 05:36:08,824 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:36:10,580 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:36:10,581 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:36:10,582 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:36:10,584 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:36:10,584 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-10-06 05:36:12,774 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:12,778 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44431 instead
  warnings.warn(
2023-10-06 05:36:12,782 - distributed.scheduler - INFO - State start
2023-10-06 05:36:12,803 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:12,804 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:36:12,805 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44431/status
2023-10-06 05:36:12,805 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:36:12,838 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38195'
2023-10-06 05:36:12,854 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39201'
2023-10-06 05:36:12,864 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39339'
2023-10-06 05:36:12,884 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36467'
2023-10-06 05:36:12,886 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34621'
2023-10-06 05:36:12,896 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33975'
2023-10-06 05:36:12,908 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41999'
2023-10-06 05:36:12,921 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35049'
2023-10-06 05:36:13,578 - distributed.scheduler - INFO - Receive client connection: Client-41bc38b2-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:13,590 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57264
2023-10-06 05:36:14,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:14,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:14,608 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:14,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:14,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:14,649 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:14,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:14,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:14,683 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:14,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:14,908 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:14,908 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:14,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:14,912 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:14,912 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:14,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:14,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:14,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:14,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:14,921 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:14,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:14,925 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:14,928 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:14,928 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:15,965 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40021
2023-10-06 05:36:15,965 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40021
2023-10-06 05:36:15,966 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46611
2023-10-06 05:36:15,966 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:15,966 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:15,966 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:15,966 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:15,966 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2jxhwuho
2023-10-06 05:36:15,966 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6605c2d7-f078-4119-b214-f611643e9cbd
2023-10-06 05:36:16,786 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e7e34ed8-fc2b-4977-9a02-27a73775e92e
2023-10-06 05:36:16,786 - distributed.worker - INFO - Starting Worker plugin PreImport-58c02f4d-7ca7-4db5-89e9-beab3b672466
2023-10-06 05:36:16,787 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:16,818 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40021', status: init, memory: 0, processing: 0>
2023-10-06 05:36:16,819 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40021
2023-10-06 05:36:16,819 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57282
2023-10-06 05:36:16,821 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:16,821 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:16,821 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:16,824 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:17,284 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43853
2023-10-06 05:36:17,286 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43853
2023-10-06 05:36:17,286 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43191
2023-10-06 05:36:17,286 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:17,287 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:17,287 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:17,287 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:17,287 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uy7k3e6k
2023-10-06 05:36:17,288 - distributed.worker - INFO - Starting Worker plugin PreImport-9aff17a3-45d9-4c8b-8f80-34fbd2b8ea6c
2023-10-06 05:36:17,288 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f3afd602-9d6e-4c6c-b104-1514537c170f
2023-10-06 05:36:17,288 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3d73f5a6-10cd-466a-a62d-1c1a122207a9
2023-10-06 05:36:17,807 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42343
2023-10-06 05:36:17,808 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42343
2023-10-06 05:36:17,808 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33375
2023-10-06 05:36:17,808 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:17,808 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:17,808 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:17,808 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:17,809 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o3om3hpj
2023-10-06 05:36:17,809 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d94b61fb-49d9-42e2-adf2-6fa75a38eb6f
2023-10-06 05:36:17,808 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33919
2023-10-06 05:36:17,809 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33919
2023-10-06 05:36:17,809 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36175
2023-10-06 05:36:17,809 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:17,809 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:17,809 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:17,810 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:17,810 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j15srs9x
2023-10-06 05:36:17,810 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c19bafed-fbf0-4dec-855d-c112eb22b4b8
2023-10-06 05:36:17,810 - distributed.worker - INFO - Starting Worker plugin RMMSetup-77aeb8f4-ad04-4378-8175-b16d03f96ac3
2023-10-06 05:36:17,810 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36153
2023-10-06 05:36:17,811 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36153
2023-10-06 05:36:17,810 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36543
2023-10-06 05:36:17,811 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33625
2023-10-06 05:36:17,811 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36543
2023-10-06 05:36:17,811 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:17,811 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45597
2023-10-06 05:36:17,811 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:17,811 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:17,811 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:17,811 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:17,811 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:17,811 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:17,811 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2z475mmo
2023-10-06 05:36:17,811 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:17,811 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ix3ydm01
2023-10-06 05:36:17,812 - distributed.worker - INFO - Starting Worker plugin RMMSetup-82fdd17a-1821-4808-b96d-1473513ec0a9
2023-10-06 05:36:17,812 - distributed.worker - INFO - Starting Worker plugin RMMSetup-af118fd9-0c83-4661-b0d1-d43f7a1e28aa
2023-10-06 05:36:17,810 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46747
2023-10-06 05:36:17,812 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46747
2023-10-06 05:36:17,813 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40551
2023-10-06 05:36:17,813 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:17,813 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:17,813 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:17,813 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:17,813 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0hrwze7f
2023-10-06 05:36:17,812 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37889
2023-10-06 05:36:17,813 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37889
2023-10-06 05:36:17,814 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44433
2023-10-06 05:36:17,814 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:17,814 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:17,814 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:17,814 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:17,814 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q204b16t
2023-10-06 05:36:17,814 - distributed.worker - INFO - Starting Worker plugin RMMSetup-530feabc-ea4d-473b-aa0d-43bd94387aff
2023-10-06 05:36:17,815 - distributed.worker - INFO - Starting Worker plugin RMMSetup-93cdd5f4-cd87-4fda-98ba-3a60bdc3ed6f
2023-10-06 05:36:17,886 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:17,917 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43853', status: init, memory: 0, processing: 0>
2023-10-06 05:36:17,918 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43853
2023-10-06 05:36:17,918 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57302
2023-10-06 05:36:17,920 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:17,921 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:17,921 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:17,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:18,057 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c511ec49-9327-4f83-9094-719a82b5bf08
2023-10-06 05:36:18,057 - distributed.worker - INFO - Starting Worker plugin PreImport-8a75bd8f-17eb-492c-8602-5309fac16fdd
2023-10-06 05:36:18,058 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,058 - distributed.worker - INFO - Starting Worker plugin PreImport-7f10b63e-c24a-4bf1-b0f7-6b28e91c8d9c
2023-10-06 05:36:18,058 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,060 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1b49fb61-6a32-441a-ab9e-fb2a3d299f67
2023-10-06 05:36:18,060 - distributed.worker - INFO - Starting Worker plugin PreImport-54f79f7b-3d35-42ab-a4d7-78cde8fee870
2023-10-06 05:36:18,060 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e10d29f0-e06e-4644-a4ce-d157043edfde
2023-10-06 05:36:18,060 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,060 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-30028de2-14f4-44d7-95b7-80724dd6c66c
2023-10-06 05:36:18,060 - distributed.worker - INFO - Starting Worker plugin PreImport-18367ac6-9f3f-4fde-bc22-94e0a78c550d
2023-10-06 05:36:18,061 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-716998fd-fdb9-495b-bf7f-039b9bd15b1b
2023-10-06 05:36:18,061 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,061 - distributed.worker - INFO - Starting Worker plugin PreImport-4465fc72-08cc-409d-adf7-abc8718347b5
2023-10-06 05:36:18,061 - distributed.worker - INFO - Starting Worker plugin PreImport-a531a1d8-f58c-497c-b718-96adfc4355f2
2023-10-06 05:36:18,061 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,062 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,090 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36543', status: init, memory: 0, processing: 0>
2023-10-06 05:36:18,090 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36543
2023-10-06 05:36:18,090 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57326
2023-10-06 05:36:18,091 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37889', status: init, memory: 0, processing: 0>
2023-10-06 05:36:18,091 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:18,092 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37889
2023-10-06 05:36:18,092 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57306
2023-10-06 05:36:18,092 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:18,093 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,093 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33919', status: init, memory: 0, processing: 0>
2023-10-06 05:36:18,093 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:18,093 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33919
2023-10-06 05:36:18,094 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57316
2023-10-06 05:36:18,094 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:18,094 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:18,094 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,094 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:18,095 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:18,096 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,096 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:18,097 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:18,098 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46747', status: init, memory: 0, processing: 0>
2023-10-06 05:36:18,098 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46747
2023-10-06 05:36:18,098 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57330
2023-10-06 05:36:18,099 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:18,100 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:18,100 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,102 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:18,105 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42343', status: init, memory: 0, processing: 0>
2023-10-06 05:36:18,105 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42343
2023-10-06 05:36:18,105 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57354
2023-10-06 05:36:18,106 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36153', status: init, memory: 0, processing: 0>
2023-10-06 05:36:18,107 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:18,107 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36153
2023-10-06 05:36:18,107 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57344
2023-10-06 05:36:18,108 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:18,108 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,108 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:18,110 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:18,110 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:18,110 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:18,111 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:18,135 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:18,135 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:18,135 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:18,135 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:18,136 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:18,136 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:18,136 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:18,136 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:18,147 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:18,147 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:18,147 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:18,147 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:18,147 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:18,148 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:18,148 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:18,148 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:18,155 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:18,156 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:18,159 - distributed.scheduler - INFO - Remove client Client-41bc38b2-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:18,159 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57264; closing.
2023-10-06 05:36:18,159 - distributed.scheduler - INFO - Remove client Client-41bc38b2-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:18,160 - distributed.scheduler - INFO - Close client connection: Client-41bc38b2-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:18,160 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38195'. Reason: nanny-close
2023-10-06 05:36:18,161 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:18,162 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39201'. Reason: nanny-close
2023-10-06 05:36:18,163 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:18,163 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46747. Reason: nanny-close
2023-10-06 05:36:18,163 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39339'. Reason: nanny-close
2023-10-06 05:36:18,163 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:18,163 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42343. Reason: nanny-close
2023-10-06 05:36:18,164 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36467'. Reason: nanny-close
2023-10-06 05:36:18,164 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:18,164 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33919. Reason: nanny-close
2023-10-06 05:36:18,164 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34621'. Reason: nanny-close
2023-10-06 05:36:18,164 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:18,165 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36543. Reason: nanny-close
2023-10-06 05:36:18,165 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33975'. Reason: nanny-close
2023-10-06 05:36:18,165 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57330; closing.
2023-10-06 05:36:18,165 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:18,165 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:18,165 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43853. Reason: nanny-close
2023-10-06 05:36:18,165 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41999'. Reason: nanny-close
2023-10-06 05:36:18,165 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46747', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570578.165688')
2023-10-06 05:36:18,165 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:18,166 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:18,166 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:18,166 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36153. Reason: nanny-close
2023-10-06 05:36:18,166 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35049'. Reason: nanny-close
2023-10-06 05:36:18,166 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57316; closing.
2023-10-06 05:36:18,166 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:18,166 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37889. Reason: nanny-close
2023-10-06 05:36:18,166 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:18,167 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:18,167 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33919', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570578.167093')
2023-10-06 05:36:18,167 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40021. Reason: nanny-close
2023-10-06 05:36:18,167 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:18,167 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:18,168 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:18,168 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:18,168 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57354; closing.
2023-10-06 05:36:18,169 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:18,169 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:18,169 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:18,170 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:18,170 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:18,169 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:57316>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-06 05:36:18,172 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:18,172 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:18,172 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42343', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570578.1722887')
2023-10-06 05:36:18,172 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57326; closing.
2023-10-06 05:36:18,174 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36543', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570578.1741815')
2023-10-06 05:36:18,174 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57302; closing.
2023-10-06 05:36:18,175 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57344; closing.
2023-10-06 05:36:18,175 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57306; closing.
2023-10-06 05:36:18,176 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43853', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570578.1760828')
2023-10-06 05:36:18,176 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36153', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570578.1766212')
2023-10-06 05:36:18,177 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37889', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570578.1769974')
2023-10-06 05:36:18,177 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57282; closing.
2023-10-06 05:36:18,178 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40021', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570578.1779916')
2023-10-06 05:36:18,178 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:36:18,178 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:57282>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-06 05:36:19,779 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:36:19,779 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:36:19,780 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:36:19,781 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:36:19,782 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-10-06 05:36:21,878 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:21,882 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45783 instead
  warnings.warn(
2023-10-06 05:36:21,886 - distributed.scheduler - INFO - State start
2023-10-06 05:36:21,906 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:21,907 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:36:21,908 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45783/status
2023-10-06 05:36:21,908 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:36:22,125 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41987'
2023-10-06 05:36:22,136 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41469'
2023-10-06 05:36:22,148 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40631'
2023-10-06 05:36:22,157 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40907'
2023-10-06 05:36:22,159 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46577'
2023-10-06 05:36:22,167 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35943'
2023-10-06 05:36:22,176 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33805'
2023-10-06 05:36:22,186 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36279'
2023-10-06 05:36:22,355 - distributed.scheduler - INFO - Receive client connection: Client-4731911a-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:22,366 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39760
2023-10-06 05:36:23,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:23,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:23,896 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:23,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:23,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:23,967 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:23,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:23,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:23,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:23,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:23,996 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:23,998 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:24,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:24,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:24,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:24,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:24,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:24,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:24,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:24,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:24,354 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:24,357 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:24,358 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:24,358 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:25,794 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45061
2023-10-06 05:36:25,794 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45061
2023-10-06 05:36:25,794 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38259
2023-10-06 05:36:25,795 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:25,795 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:25,795 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:25,795 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:25,795 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-55vkapq4
2023-10-06 05:36:25,795 - distributed.worker - INFO - Starting Worker plugin RMMSetup-21afc454-75af-4f51-95b2-e2f5a46a5052
2023-10-06 05:36:26,170 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-42692c90-acc0-4d07-a263-5dba1a192878
2023-10-06 05:36:26,171 - distributed.worker - INFO - Starting Worker plugin PreImport-66d6142d-8f0a-40df-a476-681c14ceceb3
2023-10-06 05:36:26,171 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:26,205 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45061', status: init, memory: 0, processing: 0>
2023-10-06 05:36:26,206 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45061
2023-10-06 05:36:26,206 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39778
2023-10-06 05:36:26,207 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:26,208 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:26,208 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:26,211 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:27,961 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40221
2023-10-06 05:36:27,962 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40221
2023-10-06 05:36:27,962 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34249
2023-10-06 05:36:27,962 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:27,963 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:27,963 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:27,963 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:27,963 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6gk31myl
2023-10-06 05:36:27,964 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c20c0294-72b9-49d5-9d13-6707e40f7801
2023-10-06 05:36:27,987 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43255
2023-10-06 05:36:27,988 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43255
2023-10-06 05:36:27,988 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33513
2023-10-06 05:36:27,988 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:27,988 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:27,988 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:27,989 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:27,989 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dxsw_nlb
2023-10-06 05:36:27,989 - distributed.worker - INFO - Starting Worker plugin RMMSetup-364fc8e2-bb0f-4e72-ae9b-6665a224dca3
2023-10-06 05:36:27,990 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37217
2023-10-06 05:36:27,991 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37217
2023-10-06 05:36:27,991 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35875
2023-10-06 05:36:27,991 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:27,991 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:27,991 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:27,992 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:27,992 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ld846j97
2023-10-06 05:36:27,992 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c11c2e5a-fead-45be-8574-8ef726ebc493
2023-10-06 05:36:28,033 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45851
2023-10-06 05:36:28,034 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45851
2023-10-06 05:36:28,034 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34427
2023-10-06 05:36:28,034 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,034 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,034 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:28,035 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:28,035 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hn42_a7a
2023-10-06 05:36:28,035 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-16a84c88-3165-4853-ab62-95e1d42a91be
2023-10-06 05:36:28,035 - distributed.worker - INFO - Starting Worker plugin RMMSetup-42741b54-042e-4309-9c58-c01e66995bbd
2023-10-06 05:36:28,041 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39465
2023-10-06 05:36:28,042 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39465
2023-10-06 05:36:28,042 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42717
2023-10-06 05:36:28,041 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46381
2023-10-06 05:36:28,042 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,042 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46381
2023-10-06 05:36:28,042 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,042 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38873
2023-10-06 05:36:28,042 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,042 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:28,042 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,042 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:28,042 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-day_tf07
2023-10-06 05:36:28,042 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:28,043 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:28,041 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44105
2023-10-06 05:36:28,043 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s0n4876a
2023-10-06 05:36:28,043 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44105
2023-10-06 05:36:28,043 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46537
2023-10-06 05:36:28,043 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,043 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,043 - distributed.worker - INFO - Starting Worker plugin PreImport-34a74cb2-3ea6-4eda-8d72-caafde8c8887
2023-10-06 05:36:28,043 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:28,043 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bd4873db-f941-4fe5-a566-f2ea15da5918
2023-10-06 05:36:28,043 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:28,043 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7f560316-fd67-4c7d-baa6-ae4b5ef2cae9
2023-10-06 05:36:28,043 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-onijup0t
2023-10-06 05:36:28,044 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0ad33a3-1237-464d-af77-009fc98f8287
2023-10-06 05:36:28,045 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bc3f621f-9f66-4ebf-b265-8e68faa05438
2023-10-06 05:36:28,463 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4fca164d-b297-4902-86f0-c7087b910ab7
2023-10-06 05:36:28,464 - distributed.worker - INFO - Starting Worker plugin PreImport-e6a5a9dd-2607-4505-b357-7d2de962ddcc
2023-10-06 05:36:28,464 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,465 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c5f6a9de-ef05-4618-a530-f89b9554ec91
2023-10-06 05:36:28,466 - distributed.worker - INFO - Starting Worker plugin PreImport-0018921a-59e9-4aac-894a-997b028b2355
2023-10-06 05:36:28,466 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,473 - distributed.worker - INFO - Starting Worker plugin PreImport-45ccb42e-f17e-449a-addd-6f33d5e94087
2023-10-06 05:36:28,474 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,484 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b3c16959-4f91-4cb2-9103-45145ae6a2c7
2023-10-06 05:36:28,484 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f213d90e-4798-442b-a70c-3001eb452d05
2023-10-06 05:36:28,484 - distributed.worker - INFO - Starting Worker plugin PreImport-d768203d-cc72-4dbf-8ee0-8f21dc9e817c
2023-10-06 05:36:28,485 - distributed.worker - INFO - Starting Worker plugin PreImport-687158f3-9a4f-43f6-a83d-93d8b0d2c64d
2023-10-06 05:36:28,485 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,485 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,490 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0ce0c8da-9dcb-439c-b0b5-84265ab3c8af
2023-10-06 05:36:28,490 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,491 - distributed.worker - INFO - Starting Worker plugin PreImport-3b1fbdaf-d3ca-4de7-9a62-2f75c2af9d9b
2023-10-06 05:36:28,491 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,494 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40221', status: init, memory: 0, processing: 0>
2023-10-06 05:36:28,495 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40221
2023-10-06 05:36:28,495 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39810
2023-10-06 05:36:28,496 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:28,497 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,497 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,499 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:28,503 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37217', status: init, memory: 0, processing: 0>
2023-10-06 05:36:28,504 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37217
2023-10-06 05:36:28,504 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39812
2023-10-06 05:36:28,505 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45851', status: init, memory: 0, processing: 0>
2023-10-06 05:36:28,505 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:28,506 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45851
2023-10-06 05:36:28,506 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39828
2023-10-06 05:36:28,506 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,506 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,507 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:28,508 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,508 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,508 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:28,509 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:28,517 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43255', status: init, memory: 0, processing: 0>
2023-10-06 05:36:28,518 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43255
2023-10-06 05:36:28,518 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39832
2023-10-06 05:36:28,519 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:28,519 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44105', status: init, memory: 0, processing: 0>
2023-10-06 05:36:28,520 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44105
2023-10-06 05:36:28,520 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,520 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39836
2023-10-06 05:36:28,520 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,521 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:28,521 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:28,522 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,523 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,525 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:28,526 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39465', status: init, memory: 0, processing: 0>
2023-10-06 05:36:28,527 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39465
2023-10-06 05:36:28,527 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39846
2023-10-06 05:36:28,528 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:28,530 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,530 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,532 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:28,533 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46381', status: init, memory: 0, processing: 0>
2023-10-06 05:36:28,534 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46381
2023-10-06 05:36:28,534 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39856
2023-10-06 05:36:28,535 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:28,537 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:28,537 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:28,539 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:28,615 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,615 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,615 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,615 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,616 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,616 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,616 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,617 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,632 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:28,633 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:28,633 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:28,633 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:28,633 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:28,633 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:28,633 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:28,634 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:36:28,640 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,642 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:28,645 - distributed.scheduler - INFO - Remove client Client-4731911a-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:28,645 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39760; closing.
2023-10-06 05:36:28,645 - distributed.scheduler - INFO - Remove client Client-4731911a-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:28,645 - distributed.scheduler - INFO - Close client connection: Client-4731911a-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:28,646 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41987'. Reason: nanny-close
2023-10-06 05:36:28,647 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:28,648 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41469'. Reason: nanny-close
2023-10-06 05:36:28,648 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:28,648 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44105. Reason: nanny-close
2023-10-06 05:36:28,649 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40631'. Reason: nanny-close
2023-10-06 05:36:28,649 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:28,649 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40907'. Reason: nanny-close
2023-10-06 05:36:28,649 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46381. Reason: nanny-close
2023-10-06 05:36:28,649 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:28,650 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46577'. Reason: nanny-close
2023-10-06 05:36:28,650 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45851. Reason: nanny-close
2023-10-06 05:36:28,650 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:28,650 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37217. Reason: nanny-close
2023-10-06 05:36:28,650 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35943'. Reason: nanny-close
2023-10-06 05:36:28,650 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:28,651 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33805'. Reason: nanny-close
2023-10-06 05:36:28,651 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39465. Reason: nanny-close
2023-10-06 05:36:28,651 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:28,651 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:28,651 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39836; closing.
2023-10-06 05:36:28,651 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45061. Reason: nanny-close
2023-10-06 05:36:28,651 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36279'. Reason: nanny-close
2023-10-06 05:36:28,652 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:28,652 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44105', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570588.6521447')
2023-10-06 05:36:28,652 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:28,652 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:28,652 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40221. Reason: nanny-close
2023-10-06 05:36:28,652 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:28,652 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43255. Reason: nanny-close
2023-10-06 05:36:28,653 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39812; closing.
2023-10-06 05:36:28,653 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:28,653 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:28,653 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:28,654 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:28,654 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:28,654 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37217', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570588.6542253')
2023-10-06 05:36:28,654 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:28,654 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39856; closing.
2023-10-06 05:36:28,654 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39828; closing.
2023-10-06 05:36:28,655 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:28,655 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:28,655 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:28,655 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:28,656 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:28,655 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39812>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39812>: Stream is closed
2023-10-06 05:36:28,657 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:28,657 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46381', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570588.657315')
2023-10-06 05:36:28,657 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45851', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570588.6577125')
2023-10-06 05:36:28,658 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39778; closing.
2023-10-06 05:36:28,658 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39846; closing.
2023-10-06 05:36:28,658 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45061', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570588.658827')
2023-10-06 05:36:28,659 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39465', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570588.6591215')
2023-10-06 05:36:28,659 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39810; closing.
2023-10-06 05:36:28,660 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40221', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570588.6600199')
2023-10-06 05:36:28,660 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39832; closing.
2023-10-06 05:36:28,660 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43255', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570588.6607985')
2023-10-06 05:36:28,660 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:36:28,661 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39832>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-06 05:36:30,264 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:36:30,265 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:36:30,265 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:36:30,266 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:36:30,267 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-10-06 05:36:32,547 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:32,551 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45905 instead
  warnings.warn(
2023-10-06 05:36:32,555 - distributed.scheduler - INFO - State start
2023-10-06 05:36:32,874 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:32,875 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:36:32,876 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45905/status
2023-10-06 05:36:32,876 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:36:32,905 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33047'
2023-10-06 05:36:32,918 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39273'
2023-10-06 05:36:32,930 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46117'
2023-10-06 05:36:32,942 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39239'
2023-10-06 05:36:32,944 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33557'
2023-10-06 05:36:32,952 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43401'
2023-10-06 05:36:32,962 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40761'
2023-10-06 05:36:32,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44439'
2023-10-06 05:36:34,563 - distributed.scheduler - INFO - Receive client connection: Client-4d7d5267-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:34,579 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55060
2023-10-06 05:36:34,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:34,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:34,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:34,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:34,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:34,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:34,768 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:34,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:34,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:34,769 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:34,771 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:34,773 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:34,829 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:34,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:34,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:34,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:34,834 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:34,834 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:34,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:34,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:34,872 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:34,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:34,918 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:34,923 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:37,488 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46481
2023-10-06 05:36:37,489 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46481
2023-10-06 05:36:37,489 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36467
2023-10-06 05:36:37,489 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,489 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,489 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:37,489 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:37,489 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yzk_9k0j
2023-10-06 05:36:37,490 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-079d2e10-51e3-46b3-b7fb-48a509cb144c
2023-10-06 05:36:37,490 - distributed.worker - INFO - Starting Worker plugin RMMSetup-41efb91e-5772-4e90-881a-76b1f523dca0
2023-10-06 05:36:37,490 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40415
2023-10-06 05:36:37,491 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40415
2023-10-06 05:36:37,491 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42749
2023-10-06 05:36:37,491 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,491 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,491 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:37,491 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:37,489 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38819
2023-10-06 05:36:37,491 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ylzisz7l
2023-10-06 05:36:37,491 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38819
2023-10-06 05:36:37,491 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46591
2023-10-06 05:36:37,492 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,492 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,492 - distributed.worker - INFO - Starting Worker plugin RMMSetup-00e11f46-ba45-4c6e-bb27-a39958c3d528
2023-10-06 05:36:37,492 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:37,492 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:37,492 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-16of56s6
2023-10-06 05:36:37,493 - distributed.worker - INFO - Starting Worker plugin RMMSetup-59f344d1-283b-4bca-991b-0d2e8afc924a
2023-10-06 05:36:37,641 - distributed.worker - INFO - Starting Worker plugin PreImport-4a21300d-70d1-4f8b-8a0f-4a92db1c3a14
2023-10-06 05:36:37,641 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,642 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e3b75ad3-4cb0-4357-98ec-3a9f0d7e645e
2023-10-06 05:36:37,642 - distributed.worker - INFO - Starting Worker plugin PreImport-cbf6c3d5-531a-444a-bc9e-63ac7d48b9e2
2023-10-06 05:36:37,643 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,648 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-87241399-0d17-4d1a-8492-f45020b00055
2023-10-06 05:36:37,648 - distributed.worker - INFO - Starting Worker plugin PreImport-34478c72-eafb-4379-840a-7d7c7a37b6b1
2023-10-06 05:36:37,648 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,667 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39477
2023-10-06 05:36:37,668 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39477
2023-10-06 05:36:37,668 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43391
2023-10-06 05:36:37,668 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,668 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,668 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:37,668 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:37,669 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0ov0ob4q
2023-10-06 05:36:37,669 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b8850586-b1a8-40e5-8b0f-d2763439ac4d
2023-10-06 05:36:37,673 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46509
2023-10-06 05:36:37,674 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46509
2023-10-06 05:36:37,674 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34973
2023-10-06 05:36:37,674 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,675 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,675 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:37,675 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:37,675 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5_2av54u
2023-10-06 05:36:37,675 - distributed.worker - INFO - Starting Worker plugin PreImport-ff312645-6873-4c1b-b667-66ef74d9cd1f
2023-10-06 05:36:37,675 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ee8448aa-50b3-47ee-b93f-4eb961016cd3
2023-10-06 05:36:37,677 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fab088c2-dd81-49b2-bc0d-82285568d298
2023-10-06 05:36:37,678 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38819', status: init, memory: 0, processing: 0>
2023-10-06 05:36:37,680 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38819
2023-10-06 05:36:37,680 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55092
2023-10-06 05:36:37,681 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46481', status: init, memory: 0, processing: 0>
2023-10-06 05:36:37,681 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:37,681 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46481
2023-10-06 05:36:37,681 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55088
2023-10-06 05:36:37,681 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35287
2023-10-06 05:36:37,682 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,682 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,682 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35287
2023-10-06 05:36:37,682 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44993
2023-10-06 05:36:37,682 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,682 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,682 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:37,680 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46281
2023-10-06 05:36:37,682 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:37,682 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46281
2023-10-06 05:36:37,683 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:37,683 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40415', status: init, memory: 0, processing: 0>
2023-10-06 05:36:37,683 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dbdz94ij
2023-10-06 05:36:37,683 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35175
2023-10-06 05:36:37,683 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,683 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,683 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:37,683 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,683 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:37,683 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ef398744-62b6-496a-a417-e41309a6fc54
2023-10-06 05:36:37,683 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40415
2023-10-06 05:36:37,683 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,683 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wq_afar3
2023-10-06 05:36:37,683 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55096
2023-10-06 05:36:37,683 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36787
2023-10-06 05:36:37,683 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36787
2023-10-06 05:36:37,684 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34999
2023-10-06 05:36:37,684 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,684 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,684 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:37,684 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:36:37,684 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r4ipodgx
2023-10-06 05:36:37,684 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:37,684 - distributed.worker - INFO - Starting Worker plugin RMMSetup-943496fa-aa36-4472-b8d4-6325554d250c
2023-10-06 05:36:37,684 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:37,684 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a729768c-b410-41b4-8bef-fd64ddc1efd9
2023-10-06 05:36:37,685 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:37,685 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,685 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,686 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:37,808 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,808 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-df51c58c-c0cf-42b3-a22c-4a894d931b8f
2023-10-06 05:36:37,808 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d0ef0df1-8720-4eb0-87df-f38e626cf963
2023-10-06 05:36:37,808 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-39741f5c-9c88-4375-887d-87260e5c7afd
2023-10-06 05:36:37,808 - distributed.worker - INFO - Starting Worker plugin PreImport-a2550891-d1f6-489e-8692-2a56c802457f
2023-10-06 05:36:37,808 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fbcdae3d-92f5-401a-a27e-553da218971d
2023-10-06 05:36:37,808 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,808 - distributed.worker - INFO - Starting Worker plugin PreImport-79a8d7ad-b286-4e94-9b5c-ed7154605405
2023-10-06 05:36:37,809 - distributed.worker - INFO - Starting Worker plugin PreImport-eb0a3f8e-e8bd-4aae-aa58-f8a134b98a28
2023-10-06 05:36:37,809 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,809 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,809 - distributed.worker - INFO - Starting Worker plugin PreImport-ba00c5dc-5476-4e1f-906d-284a6065762f
2023-10-06 05:36:37,810 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,833 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36787', status: init, memory: 0, processing: 0>
2023-10-06 05:36:37,834 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36787
2023-10-06 05:36:37,834 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55110
2023-10-06 05:36:37,835 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:37,836 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,836 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,836 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46281', status: init, memory: 0, processing: 0>
2023-10-06 05:36:37,836 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46281
2023-10-06 05:36:37,837 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55126
2023-10-06 05:36:37,837 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:37,838 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:37,838 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,838 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,840 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:37,846 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46509', status: init, memory: 0, processing: 0>
2023-10-06 05:36:37,847 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46509
2023-10-06 05:36:37,847 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55120
2023-10-06 05:36:37,848 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35287', status: init, memory: 0, processing: 0>
2023-10-06 05:36:37,848 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35287
2023-10-06 05:36:37,848 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55150
2023-10-06 05:36:37,848 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:37,849 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39477', status: init, memory: 0, processing: 0>
2023-10-06 05:36:37,849 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,849 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,849 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39477
2023-10-06 05:36:37,850 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55134
2023-10-06 05:36:37,850 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:37,851 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,851 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,852 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:37,852 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:37,852 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:37,853 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:37,853 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:37,854 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:37,951 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:37,952 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:37,952 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:37,952 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:37,952 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:37,952 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:37,952 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:37,953 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:36:37,957 - distributed.scheduler - INFO - Remove client Client-4d7d5267-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:37,957 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55060; closing.
2023-10-06 05:36:37,957 - distributed.scheduler - INFO - Remove client Client-4d7d5267-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:37,958 - distributed.scheduler - INFO - Close client connection: Client-4d7d5267-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:37,959 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33047'. Reason: nanny-close
2023-10-06 05:36:37,959 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:37,960 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39273'. Reason: nanny-close
2023-10-06 05:36:37,960 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:37,961 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35287. Reason: nanny-close
2023-10-06 05:36:37,961 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46117'. Reason: nanny-close
2023-10-06 05:36:37,961 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:37,961 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38819. Reason: nanny-close
2023-10-06 05:36:37,961 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39239'. Reason: nanny-close
2023-10-06 05:36:37,962 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:37,962 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46481. Reason: nanny-close
2023-10-06 05:36:37,962 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33557'. Reason: nanny-close
2023-10-06 05:36:37,963 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:37,963 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40415. Reason: nanny-close
2023-10-06 05:36:37,963 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43401'. Reason: nanny-close
2023-10-06 05:36:37,963 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:37,963 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55150; closing.
2023-10-06 05:36:37,963 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:37,963 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46509. Reason: nanny-close
2023-10-06 05:36:37,963 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40761'. Reason: nanny-close
2023-10-06 05:36:37,964 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35287', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570597.963936')
2023-10-06 05:36:37,964 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:37,964 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:37,964 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:37,964 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39477. Reason: nanny-close
2023-10-06 05:36:37,964 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44439'. Reason: nanny-close
2023-10-06 05:36:37,964 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:37,964 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46281. Reason: nanny-close
2023-10-06 05:36:37,964 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:37,965 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55092; closing.
2023-10-06 05:36:37,965 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:37,965 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36787. Reason: nanny-close
2023-10-06 05:36:37,965 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:37,965 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55088; closing.
2023-10-06 05:36:37,966 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:37,966 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:37,966 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55096; closing.
2023-10-06 05:36:37,966 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38819', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570597.9667525')
2023-10-06 05:36:37,966 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:37,967 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:37,967 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46481', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570597.9672048')
2023-10-06 05:36:37,967 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:37,967 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:37,967 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40415', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570597.967756')
2023-10-06 05:36:37,968 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:37,968 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55120; closing.
2023-10-06 05:36:37,968 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:37,968 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:37,969 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55126; closing.
2023-10-06 05:36:37,969 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55134; closing.
2023-10-06 05:36:37,969 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:37,969 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46509', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570597.9696157')
2023-10-06 05:36:37,970 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46281', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570597.9700725')
2023-10-06 05:36:37,970 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39477', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570597.9705844')
2023-10-06 05:36:37,971 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55110; closing.
2023-10-06 05:36:37,971 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36787', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570597.9714155')
2023-10-06 05:36:37,971 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:36:39,526 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:36:39,527 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:36:39,527 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:36:39,528 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:36:39,529 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-10-06 05:36:41,714 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:41,719 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42985 instead
  warnings.warn(
2023-10-06 05:36:41,723 - distributed.scheduler - INFO - State start
2023-10-06 05:36:41,746 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:41,747 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:36:41,747 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42985/status
2023-10-06 05:36:41,748 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:36:41,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41517'
2023-10-06 05:36:43,104 - distributed.scheduler - INFO - Receive client connection: Client-52f48b30-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:43,117 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55412
2023-10-06 05:36:43,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:43,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:44,263 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:45,751 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39009
2023-10-06 05:36:45,751 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39009
2023-10-06 05:36:45,751 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-10-06 05:36:45,751 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:45,751 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:45,752 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:45,752 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-06 05:36:45,752 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o8qq8jk2
2023-10-06 05:36:45,752 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2d54c63c-fcb0-4645-a8ac-286347d0a5f1
2023-10-06 05:36:45,752 - distributed.worker - INFO - Starting Worker plugin PreImport-4f9198ae-86f5-4eba-bd97-f395f12129ed
2023-10-06 05:36:45,753 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0c7b09b2-678f-4724-a589-6c6caf13af5a
2023-10-06 05:36:45,753 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:45,781 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39009', status: init, memory: 0, processing: 0>
2023-10-06 05:36:45,782 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39009
2023-10-06 05:36:45,782 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55424
2023-10-06 05:36:45,783 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:45,783 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:45,784 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:45,785 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:45,872 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:45,874 - distributed.scheduler - INFO - Remove client Client-52f48b30-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:45,875 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55412; closing.
2023-10-06 05:36:45,875 - distributed.scheduler - INFO - Remove client Client-52f48b30-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:45,875 - distributed.scheduler - INFO - Close client connection: Client-52f48b30-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:45,876 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41517'. Reason: nanny-close
2023-10-06 05:36:45,877 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:45,879 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39009. Reason: nanny-close
2023-10-06 05:36:45,881 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:45,881 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55424; closing.
2023-10-06 05:36:45,881 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39009', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570605.881431')
2023-10-06 05:36:45,881 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:36:45,882 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:46,942 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:36:46,942 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:36:46,943 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:36:46,944 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:36:46,944 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-10-06 05:36:51,034 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:51,039 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38755 instead
  warnings.warn(
2023-10-06 05:36:51,043 - distributed.scheduler - INFO - State start
2023-10-06 05:36:51,298 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:51,299 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:36:51,300 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38755/status
2023-10-06 05:36:51,300 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:36:51,684 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42037'
2023-10-06 05:36:53,056 - distributed.scheduler - INFO - Receive client connection: Client-58918c21-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:53,067 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35106
2023-10-06 05:36:53,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:36:53,514 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:36:54,069 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:36:54,972 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40275
2023-10-06 05:36:54,973 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40275
2023-10-06 05:36:54,973 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39469
2023-10-06 05:36:54,973 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:36:54,973 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:54,973 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:36:54,973 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-06 05:36:54,973 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v81fy6bl
2023-10-06 05:36:54,973 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3aa8dfa1-e938-4610-97e1-a0363097b839
2023-10-06 05:36:54,974 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3edbfe3b-9c53-4572-a55d-d45e493cd1c6
2023-10-06 05:36:54,974 - distributed.worker - INFO - Starting Worker plugin PreImport-f77038fd-91ec-4cd7-be90-4262b1f858c5
2023-10-06 05:36:54,980 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:55,007 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40275', status: init, memory: 0, processing: 0>
2023-10-06 05:36:55,008 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40275
2023-10-06 05:36:55,008 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35126
2023-10-06 05:36:55,009 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:36:55,010 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:36:55,010 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:36:55,012 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:36:55,110 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:36:55,113 - distributed.scheduler - INFO - Remove client Client-58918c21-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:55,113 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35106; closing.
2023-10-06 05:36:55,113 - distributed.scheduler - INFO - Remove client Client-58918c21-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:55,113 - distributed.scheduler - INFO - Close client connection: Client-58918c21-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:36:55,114 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42037'. Reason: nanny-close
2023-10-06 05:36:55,115 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:36:55,116 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40275. Reason: nanny-close
2023-10-06 05:36:55,118 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35126; closing.
2023-10-06 05:36:55,118 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:36:55,119 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40275', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570615.119186')
2023-10-06 05:36:55,119 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:36:55,120 - distributed.nanny - INFO - Worker closed
2023-10-06 05:36:56,181 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:36:56,181 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:36:56,182 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:36:56,183 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:36:56,183 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-10-06 05:36:58,401 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:58,406 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33267 instead
  warnings.warn(
2023-10-06 05:36:58,409 - distributed.scheduler - INFO - State start
2023-10-06 05:36:58,535 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:36:58,536 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:36:58,536 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33267/status
2023-10-06 05:36:58,536 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:37:02,576 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:35138'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:35138>: Stream is closed
2023-10-06 05:37:02,869 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:37:02,869 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:37:02,870 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:37:02,871 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:37:02,871 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-10-06 05:37:04,999 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:37:05,004 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46673 instead
  warnings.warn(
2023-10-06 05:37:05,008 - distributed.scheduler - INFO - State start
2023-10-06 05:37:05,030 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:37:05,031 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-06 05:37:05,032 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46673/status
2023-10-06 05:37:05,032 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:37:05,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34439'
2023-10-06 05:37:05,188 - distributed.scheduler - INFO - Receive client connection: Client-60de2db4-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:05,203 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41742
2023-10-06 05:37:06,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:06,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:06,656 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:07,385 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37447
2023-10-06 05:37:07,386 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37447
2023-10-06 05:37:07,386 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33267
2023-10-06 05:37:07,386 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-06 05:37:07,386 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:07,386 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:07,386 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-06 05:37:07,386 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-dn01ac5u
2023-10-06 05:37:07,386 - distributed.worker - INFO - Starting Worker plugin RMMSetup-79ae9f0a-82e1-4679-b3f0-9e2a18e02956
2023-10-06 05:37:07,386 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2f3b25ea-6bb8-4538-b072-726adc6ff3b5
2023-10-06 05:37:07,387 - distributed.worker - INFO - Starting Worker plugin PreImport-0a8ac3e2-5940-4a48-9b51-9fddbc16bec7
2023-10-06 05:37:07,387 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:07,416 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37447', status: init, memory: 0, processing: 0>
2023-10-06 05:37:07,417 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37447
2023-10-06 05:37:07,417 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41774
2023-10-06 05:37:07,418 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:07,419 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-06 05:37:07,419 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:07,420 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-06 05:37:07,447 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:07,449 - distributed.scheduler - INFO - Remove client Client-60de2db4-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:07,450 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41742; closing.
2023-10-06 05:37:07,450 - distributed.scheduler - INFO - Remove client Client-60de2db4-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:07,450 - distributed.scheduler - INFO - Close client connection: Client-60de2db4-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:07,451 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34439'. Reason: nanny-close
2023-10-06 05:37:07,451 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:07,452 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37447. Reason: nanny-close
2023-10-06 05:37:07,454 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41774; closing.
2023-10-06 05:37:07,454 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-06 05:37:07,454 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37447', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570627.4548209')
2023-10-06 05:37:07,455 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:37:07,456 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:08,567 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:37:08,568 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:37:08,568 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:37:08,569 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-06 05:37:08,569 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-10-06 05:37:10,633 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:37:10,637 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35373 instead
  warnings.warn(
2023-10-06 05:37:10,641 - distributed.scheduler - INFO - State start
2023-10-06 05:37:10,728 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:37:10,729 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:37:10,729 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35373/status
2023-10-06 05:37:10,730 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:37:10,849 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36717'
2023-10-06 05:37:10,862 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35915'
2023-10-06 05:37:10,874 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37435'
2023-10-06 05:37:10,885 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41961'
2023-10-06 05:37:10,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36561'
2023-10-06 05:37:10,894 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37741'
2023-10-06 05:37:10,903 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40989'
2023-10-06 05:37:10,913 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40315'
2023-10-06 05:37:12,047 - distributed.scheduler - INFO - Receive client connection: Client-64486144-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:12,065 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41050
2023-10-06 05:37:12,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:12,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:12,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:12,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:12,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:12,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:12,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:12,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:12,743 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:12,743 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:12,743 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:12,744 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:12,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:12,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:12,779 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:12,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:12,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:12,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:12,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:12,786 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:12,788 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:12,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:12,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:12,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:15,690 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42585
2023-10-06 05:37:15,691 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42585
2023-10-06 05:37:15,691 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44829
2023-10-06 05:37:15,691 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,691 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,691 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:15,691 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:37:15,691 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qjz20d1_
2023-10-06 05:37:15,692 - distributed.worker - INFO - Starting Worker plugin RMMSetup-20ebb634-c43b-4205-95c8-5db34b15d48f
2023-10-06 05:37:15,697 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35409
2023-10-06 05:37:15,698 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35409
2023-10-06 05:37:15,698 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34407
2023-10-06 05:37:15,698 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,698 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,699 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:15,699 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:37:15,699 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-37qo7t85
2023-10-06 05:37:15,699 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bfaaa835-63fc-45bb-a694-3fd03c9489a7
2023-10-06 05:37:15,705 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41723
2023-10-06 05:37:15,706 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41723
2023-10-06 05:37:15,706 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37913
2023-10-06 05:37:15,706 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,706 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,706 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:15,707 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:37:15,707 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-x3mus27t
2023-10-06 05:37:15,707 - distributed.worker - INFO - Starting Worker plugin PreImport-92bc20ef-45b4-4ba7-a461-c06e9b4e500d
2023-10-06 05:37:15,707 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3c3d98be-de8f-4b25-8553-c41cd81d23bc
2023-10-06 05:37:15,708 - distributed.worker - INFO - Starting Worker plugin RMMSetup-59d6db2f-38cb-4332-b926-3f205c81bc56
2023-10-06 05:37:15,714 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39467
2023-10-06 05:37:15,715 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39467
2023-10-06 05:37:15,715 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36147
2023-10-06 05:37:15,715 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,715 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,715 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:15,715 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:37:15,715 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-70e8o_78
2023-10-06 05:37:15,716 - distributed.worker - INFO - Starting Worker plugin RMMSetup-504f51ee-0366-41e0-98f5-49ea1394daa1
2023-10-06 05:37:15,725 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34063
2023-10-06 05:37:15,725 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34063
2023-10-06 05:37:15,726 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37535
2023-10-06 05:37:15,726 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,726 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,726 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:15,725 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45495
2023-10-06 05:37:15,726 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:37:15,726 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45495
2023-10-06 05:37:15,726 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b6ksvvq0
2023-10-06 05:37:15,726 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37153
2023-10-06 05:37:15,726 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,726 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,726 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:15,726 - distributed.worker - INFO - Starting Worker plugin RMMSetup-02313c2f-79ed-4727-9c60-a7666bd09394
2023-10-06 05:37:15,727 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:37:15,727 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bovjha21
2023-10-06 05:37:15,727 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c2e27099-d8a4-4118-acee-bb1852091c35
2023-10-06 05:37:15,735 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41299
2023-10-06 05:37:15,736 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41299
2023-10-06 05:37:15,736 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36843
2023-10-06 05:37:15,736 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,736 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,736 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:15,736 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:37:15,736 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nhafdc6y
2023-10-06 05:37:15,736 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33031
2023-10-06 05:37:15,737 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33031
2023-10-06 05:37:15,737 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45203
2023-10-06 05:37:15,737 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,737 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,737 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ad48d445-9498-4e50-a7d6-564eac85705f
2023-10-06 05:37:15,737 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:15,737 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-06 05:37:15,737 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1q4y6xen
2023-10-06 05:37:15,737 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0bf8fb3d-3400-43df-b871-2a797aa7eafb
2023-10-06 05:37:15,738 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c4ff60d5-0d32-4c09-b21b-a9070ceec427
2023-10-06 05:37:15,874 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e941dc34-988a-45c6-a942-1c003b47c5a2
2023-10-06 05:37:15,874 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,874 - distributed.worker - INFO - Starting Worker plugin PreImport-8560fdac-251b-4cd7-8bd9-1d76a8f27dd4
2023-10-06 05:37:15,875 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,890 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d53815b6-e084-4078-b3f2-9bea603cab4c
2023-10-06 05:37:15,890 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2f9af7ea-5f33-4342-a139-28a739ce396b
2023-10-06 05:37:15,890 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-87d8d79e-a3ff-419d-aac1-630f50f861a6
2023-10-06 05:37:15,890 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37a86735-eec0-44b4-aecc-0ea1692f4e84
2023-10-06 05:37:15,890 - distributed.worker - INFO - Starting Worker plugin PreImport-82a1f30a-43eb-42cd-b432-dcf1a992e60e
2023-10-06 05:37:15,890 - distributed.worker - INFO - Starting Worker plugin PreImport-6c3ba006-74f9-404b-9dc7-390f8d7ea207
2023-10-06 05:37:15,890 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5eb02787-633c-4f3c-8b8f-1d98896380ae
2023-10-06 05:37:15,891 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,891 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,891 - distributed.worker - INFO - Starting Worker plugin PreImport-bec34af3-1880-4b20-9192-c7ad25902ae6
2023-10-06 05:37:15,891 - distributed.worker - INFO - Starting Worker plugin PreImport-c67e430e-d752-43a7-a74e-342ff2c1c8d1
2023-10-06 05:37:15,891 - distributed.worker - INFO - Starting Worker plugin PreImport-deb796bb-ca43-4c72-b153-cc59862599ca
2023-10-06 05:37:15,891 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,891 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,891 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,892 - distributed.worker - INFO - Starting Worker plugin PreImport-ef3fc2d4-c908-43f9-8ef1-ea755a05948d
2023-10-06 05:37:15,892 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,901 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42585', status: init, memory: 0, processing: 0>
2023-10-06 05:37:15,902 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42585
2023-10-06 05:37:15,902 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41070
2023-10-06 05:37:15,903 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:15,904 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,904 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,905 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:15,914 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41723', status: init, memory: 0, processing: 0>
2023-10-06 05:37:15,915 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41723
2023-10-06 05:37:15,915 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41078
2023-10-06 05:37:15,917 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:15,918 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33031', status: init, memory: 0, processing: 0>
2023-10-06 05:37:15,918 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,918 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,919 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33031
2023-10-06 05:37:15,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41080
2023-10-06 05:37:15,920 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:15,920 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34063', status: init, memory: 0, processing: 0>
2023-10-06 05:37:15,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:15,920 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34063
2023-10-06 05:37:15,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41088
2023-10-06 05:37:15,921 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,921 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:15,922 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:15,922 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39467', status: init, memory: 0, processing: 0>
2023-10-06 05:37:15,922 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,922 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,923 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39467
2023-10-06 05:37:15,923 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41104
2023-10-06 05:37:15,924 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:15,924 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:15,925 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,925 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,926 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41299', status: init, memory: 0, processing: 0>
2023-10-06 05:37:15,926 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41299
2023-10-06 05:37:15,926 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:15,926 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41118
2023-10-06 05:37:15,928 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:15,929 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35409', status: init, memory: 0, processing: 0>
2023-10-06 05:37:15,929 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,929 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,929 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35409
2023-10-06 05:37:15,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41130
2023-10-06 05:37:15,931 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:15,931 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:15,932 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,932 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,933 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45495', status: init, memory: 0, processing: 0>
2023-10-06 05:37:15,934 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45495
2023-10-06 05:37:15,934 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41134
2023-10-06 05:37:15,934 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:15,935 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:15,936 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:15,936 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:15,938 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:15,948 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:37:15,948 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:37:15,948 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:37:15,948 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:37:15,949 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:37:15,949 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:37:15,949 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:37:15,949 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-06 05:37:15,961 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:15,961 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:15,961 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:15,961 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:15,961 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:15,961 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:15,961 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:15,962 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:15,965 - distributed.scheduler - INFO - Remove client Client-64486144-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:15,965 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41050; closing.
2023-10-06 05:37:15,965 - distributed.scheduler - INFO - Remove client Client-64486144-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:15,967 - distributed.scheduler - INFO - Close client connection: Client-64486144-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:15,968 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36717'. Reason: nanny-close
2023-10-06 05:37:15,969 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:15,970 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35915'. Reason: nanny-close
2023-10-06 05:37:15,970 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:15,970 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45495. Reason: nanny-close
2023-10-06 05:37:15,971 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37435'. Reason: nanny-close
2023-10-06 05:37:15,971 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:15,971 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35409. Reason: nanny-close
2023-10-06 05:37:15,971 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41961'. Reason: nanny-close
2023-10-06 05:37:15,972 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:15,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33031. Reason: nanny-close
2023-10-06 05:37:15,972 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36561'. Reason: nanny-close
2023-10-06 05:37:15,972 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:15,972 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34063. Reason: nanny-close
2023-10-06 05:37:15,973 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37741'. Reason: nanny-close
2023-10-06 05:37:15,973 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:15,973 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:15,973 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41134; closing.
2023-10-06 05:37:15,973 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41723. Reason: nanny-close
2023-10-06 05:37:15,973 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40989'. Reason: nanny-close
2023-10-06 05:37:15,973 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45495', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570635.973683')
2023-10-06 05:37:15,973 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:15,973 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:15,973 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:15,974 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41299. Reason: nanny-close
2023-10-06 05:37:15,974 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40315'. Reason: nanny-close
2023-10-06 05:37:15,974 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:15,974 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:15,974 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39467. Reason: nanny-close
2023-10-06 05:37:15,975 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:15,975 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42585. Reason: nanny-close
2023-10-06 05:37:15,975 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41088; closing.
2023-10-06 05:37:15,975 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:15,975 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41130; closing.
2023-10-06 05:37:15,975 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41080; closing.
2023-10-06 05:37:15,975 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:15,976 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:15,976 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:15,976 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:15,976 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34063', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570635.9764307')
2023-10-06 05:37:15,976 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35409', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570635.9768178')
2023-10-06 05:37:15,976 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:15,977 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33031', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570635.9771595')
2023-10-06 05:37:15,977 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:15,977 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:15,977 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41078; closing.
2023-10-06 05:37:15,978 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:15,978 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41723', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570635.9785805')
2023-10-06 05:37:15,978 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:15,978 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:15,978 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41104; closing.
2023-10-06 05:37:15,979 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41118; closing.
2023-10-06 05:37:15,979 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39467', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570635.979542')
2023-10-06 05:37:15,981 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41299', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570635.9817834')
2023-10-06 05:37:15,982 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41070; closing.
2023-10-06 05:37:15,982 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42585', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570635.9828086')
2023-10-06 05:37:15,983 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:37:17,635 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:37:17,635 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:37:17,635 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:37:17,637 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:37:17,637 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-10-06 05:37:19,780 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:37:19,784 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-06 05:37:19,788 - distributed.scheduler - INFO - State start
2023-10-06 05:37:19,960 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:37:19,961 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:37:19,961 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-06 05:37:19,962 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:37:19,978 - distributed.scheduler - INFO - Receive client connection: Client-69bc0d3b-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:19,992 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38894
2023-10-06 05:37:20,045 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41491'
2023-10-06 05:37:21,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:21,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:21,697 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:22,779 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39057
2023-10-06 05:37:22,779 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39057
2023-10-06 05:37:22,779 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36197
2023-10-06 05:37:22,779 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:22,780 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:22,780 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:22,780 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-06 05:37:22,780 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nykfjdmy
2023-10-06 05:37:22,780 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2040a644-ba4b-4fbd-8408-eaf485559e2d
2023-10-06 05:37:22,780 - distributed.worker - INFO - Starting Worker plugin PreImport-e40d5f9d-3984-4e4b-93dd-643835c4c734
2023-10-06 05:37:22,780 - distributed.worker - INFO - Starting Worker plugin RMMSetup-31170e17-59ef-4242-8528-b10755c130ca
2023-10-06 05:37:22,903 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:22,934 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39057', status: init, memory: 0, processing: 0>
2023-10-06 05:37:22,936 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39057
2023-10-06 05:37:22,936 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38904
2023-10-06 05:37:22,937 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:22,937 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:22,937 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:22,939 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:22,962 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:37:22,970 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:22,971 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:22,974 - distributed.scheduler - INFO - Remove client Client-69bc0d3b-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:22,974 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38894; closing.
2023-10-06 05:37:22,974 - distributed.scheduler - INFO - Remove client Client-69bc0d3b-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:22,975 - distributed.scheduler - INFO - Close client connection: Client-69bc0d3b-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:22,975 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41491'. Reason: nanny-close
2023-10-06 05:37:22,983 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:22,984 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39057. Reason: nanny-close
2023-10-06 05:37:22,985 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:22,985 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38904; closing.
2023-10-06 05:37:22,986 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39057', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570642.986104')
2023-10-06 05:37:22,986 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:37:22,987 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:24,443 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:37:24,443 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:37:24,444 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:37:24,445 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:37:24,445 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-10-06 05:37:26,661 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:37:26,665 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-06 05:37:26,668 - distributed.scheduler - INFO - State start
2023-10-06 05:37:26,693 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-06 05:37:26,694 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-06 05:37:26,694 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-06 05:37:26,694 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-06 05:37:26,913 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43039'
2023-10-06 05:37:28,090 - distributed.scheduler - INFO - Receive client connection: Client-6dc5109e-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:28,103 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39014
2023-10-06 05:37:28,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-06 05:37:28,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-06 05:37:28,623 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-06 05:37:30,223 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33357
2023-10-06 05:37:30,223 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33357
2023-10-06 05:37:30,224 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44849
2023-10-06 05:37:30,224 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-06 05:37:30,224 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:30,224 - distributed.worker - INFO -               Threads:                          1
2023-10-06 05:37:30,224 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-06 05:37:30,224 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n6_ew47r
2023-10-06 05:37:30,224 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1d09a1a1-eaf4-4d70-928a-aabab19078c1
2023-10-06 05:37:30,225 - distributed.worker - INFO - Starting Worker plugin PreImport-47086e28-7827-41bd-9977-1d91899ffc99
2023-10-06 05:37:30,225 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b65b30c7-1b56-4d01-abdb-a4b0e78b5609
2023-10-06 05:37:30,350 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:30,391 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33357', status: init, memory: 0, processing: 0>
2023-10-06 05:37:30,392 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33357
2023-10-06 05:37:30,392 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45324
2023-10-06 05:37:30,394 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-06 05:37:30,395 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-06 05:37:30,395 - distributed.worker - INFO - -------------------------------------------------
2023-10-06 05:37:30,398 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-06 05:37:30,400 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-10-06 05:37:30,405 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-06 05:37:30,408 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:30,410 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-06 05:37:30,412 - distributed.scheduler - INFO - Remove client Client-6dc5109e-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:30,413 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39014; closing.
2023-10-06 05:37:30,413 - distributed.scheduler - INFO - Remove client Client-6dc5109e-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:30,413 - distributed.scheduler - INFO - Close client connection: Client-6dc5109e-640a-11ee-b017-d8c49764f6bb
2023-10-06 05:37:30,414 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43039'. Reason: nanny-close
2023-10-06 05:37:30,415 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-06 05:37:30,416 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33357. Reason: nanny-close
2023-10-06 05:37:30,419 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45324; closing.
2023-10-06 05:37:30,419 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-06 05:37:30,419 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33357', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1696570650.4193578')
2023-10-06 05:37:30,419 - distributed.scheduler - INFO - Lost all workers
2023-10-06 05:37:30,421 - distributed.nanny - INFO - Worker closed
2023-10-06 05:37:31,481 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-06 05:37:31,481 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-06 05:37:31,482 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-06 05:37:31,483 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-06 05:37:31,484 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46119 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43665 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35309 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46009 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44015 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46493 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45935 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36723 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38573 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37331 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43501 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46111 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45527 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45629 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45833 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45251 instead
  warnings.warn(
CUDA error at: /opt/conda/envs/gdf/include/rmm/cuda_stream_view.hpp:87: cudaErrorMemoryAllocation out of memory
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 19, in dask_serialize_cudf_object
    return x.host_serialize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 146, in host_serialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 147, in <listcomp>
    f.memoryview() if c else memoryview(f)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 275, in memoryview
    rmm._lib.device_buffer.copy_ptr_to_host(
  File "device_buffer.pyx", line 408, in rmm._lib.device_buffer.copy_ptr_to_host
  File "device_buffer.pyx", line 446, in rmm._lib.device_buffer.copy_ptr_to_host
  File "stream.pyx", line 71, in rmm._cuda.stream.Stream.c_synchronize
RuntimeError: CUDA error at: /opt/conda/envs/gdf/include/rmm/cuda_stream_view.hpp:87: cudaErrorMemoryAllocation out of memory
2023-10-06 05:41:32,020 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 81, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 507, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 434, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 184, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 352, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 49, in dask_dumps
    sub_header, frames = dumps(x)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 19, in dask_serialize_cudf_object
    return x.host_serialize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 146, in host_serialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 147, in <listcomp>
    f.memoryview() if c else memoryview(f)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 275, in memoryview
    rmm._lib.device_buffer.copy_ptr_to_host(
  File "device_buffer.pyx", line 408, in rmm._lib.device_buffer.copy_ptr_to_host
  File "device_buffer.pyx", line 446, in rmm._lib.device_buffer.copy_ptr_to_host
  File "stream.pyx", line 71, in rmm._cuda.stream.Stream.c_synchronize
RuntimeError: CUDA error at: /opt/conda/envs/gdf/include/rmm/cuda_stream_view.hpp:87: cudaErrorMemoryAllocation out of memory

Process SpawnProcess-17:
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_explicit_comms.py", line 140, in _test_dataframe_shuffle
    assert all(
  File "/usr/src/dask-cuda/dask_cuda/tests/test_explicit_comms.py", line 141, in <genexpr>
    len(ddf.partitions[i].compute()) == 0
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 342, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/base.py", line 628, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 81, in _decode_default
    return merge_and_deserialize(
  File "/opt/conda/envs/gdf/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 507, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 434, in deserialize
    return loads(header, frames)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 184, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 352, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/protocol/serialize.py", line 49, in dask_dumps
    sub_header, frames = dumps(x)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/comm/serialize.py", line 19, in dask_serialize_cudf_object
    return x.host_serialize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 146, in host_serialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 147, in <listcomp>
    f.memoryview() if c else memoryview(f)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 275, in memoryview
    rmm._lib.device_buffer.copy_ptr_to_host(
  File "device_buffer.pyx", line 408, in rmm._lib.device_buffer.copy_ptr_to_host
  File "device_buffer.pyx", line 446, in rmm._lib.device_buffer.copy_ptr_to_host
  File "stream.pyx", line 71, in rmm._cuda.stream.Stream.c_synchronize
RuntimeError: CUDA error at: /opt/conda/envs/gdf/include/rmm/cuda_stream_view.hpp:87: cudaErrorMemoryAllocation out of memory

FAILED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46309 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36957 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46119 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41399 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44679 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46079 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37601 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38967 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38581 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43111 instead
  warnings.warn(
2023-10-06 05:44:26,854 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 65, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-06 05:44:26,865 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:38745'.
2023-10-06 05:44:26,866 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:38745'. Shutting down.
2023-10-06 05:44:26,869 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fcb35663790>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 65, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 26, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 65, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 34, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-10-06 05:44:28,872 - distributed.nanny - ERROR - Worker process died unexpectedly
