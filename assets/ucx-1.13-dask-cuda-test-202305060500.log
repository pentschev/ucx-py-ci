============================= test session starts ==============================
platform linux -- Python 3.9.16, pytest-7.3.1, pluggy-1.0.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-05-06 05:35:32,760 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:35:32,764 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40323 instead
  warnings.warn(
2023-05-06 05:35:32,767 - distributed.scheduler - INFO - State start
2023-05-06 05:35:32,785 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:35:32,786 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-05-06 05:35:32,787 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40323/status
2023-05-06 05:35:32,892 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39443'
2023-05-06 05:35:32,910 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36445'
2023-05-06 05:35:32,912 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39839'
2023-05-06 05:35:32,919 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41477'
2023-05-06 05:35:34,165 - distributed.scheduler - INFO - Receive client connection: Client-d0c9941b-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:34,180 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53412
2023-05-06 05:35:34,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:34,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:34,434 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:34,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:34,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:34,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:34,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:34,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:34,471 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:34,473 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:34,473 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:34,477 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-05-06 05:35:34,489 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40715
2023-05-06 05:35:34,489 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40715
2023-05-06 05:35:34,489 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36679
2023-05-06 05:35:34,489 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-05-06 05:35:34,489 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:34,490 - distributed.worker - INFO -               Threads:                          4
2023-05-06 05:35:34,490 - distributed.worker - INFO -                Memory:                 251.95 GiB
2023-05-06 05:35:34,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-snvwy4ie
2023-05-06 05:35:34,490 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-884d6e9d-520e-43af-b4fa-7c6b55903a90
2023-05-06 05:35:34,490 - distributed.worker - INFO - Starting Worker plugin PreImport-63769428-fa64-4981-bdc1-88cc17641762
2023-05-06 05:35:34,490 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fb24f764-6423-4259-afe8-281dbf0b2055
2023-05-06 05:35:34,490 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:34,504 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40715', status: init, memory: 0, processing: 0>
2023-05-06 05:35:34,505 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40715
2023-05-06 05:35:34,505 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56342
2023-05-06 05:35:34,506 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-05-06 05:35:34,506 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:34,508 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-05-06 05:35:35,232 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37817
2023-05-06 05:35:35,232 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37817
2023-05-06 05:35:35,232 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39971
2023-05-06 05:35:35,232 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-05-06 05:35:35,232 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:35,232 - distributed.worker - INFO -               Threads:                          4
2023-05-06 05:35:35,232 - distributed.worker - INFO -                Memory:                 251.95 GiB
2023-05-06 05:35:35,233 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-fh8jmkux
2023-05-06 05:35:35,233 - distributed.worker - INFO - Starting Worker plugin RMMSetup-406a5ac5-ea0b-40b2-b532-94a148fe5453
2023-05-06 05:35:35,233 - distributed.worker - INFO - Starting Worker plugin PreImport-f10254a7-ad08-40ab-898e-4a898970f0e4
2023-05-06 05:35:35,233 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e95c3dcf-53ff-4b27-8147-25b44a1099fd
2023-05-06 05:35:35,233 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:35,253 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34829
2023-05-06 05:35:35,253 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34829
2023-05-06 05:35:35,253 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42945
2023-05-06 05:35:35,253 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-05-06 05:35:35,253 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:35,253 - distributed.worker - INFO -               Threads:                          4
2023-05-06 05:35:35,253 - distributed.worker - INFO -                Memory:                 251.95 GiB
2023-05-06 05:35:35,253 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-k2wc9xpy
2023-05-06 05:35:35,254 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d9b7080c-37c0-4e86-b0fb-17ff6cb17496
2023-05-06 05:35:35,254 - distributed.worker - INFO - Starting Worker plugin PreImport-166ca4c1-46b9-49d4-a665-62929c366d42
2023-05-06 05:35:35,254 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32781
2023-05-06 05:35:35,254 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c7479c61-cd7f-4a21-a791-c2523178c8df
2023-05-06 05:35:35,254 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32781
2023-05-06 05:35:35,254 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38951
2023-05-06 05:35:35,254 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:35,254 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-05-06 05:35:35,254 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:35,255 - distributed.worker - INFO -               Threads:                          4
2023-05-06 05:35:35,255 - distributed.worker - INFO -                Memory:                 251.95 GiB
2023-05-06 05:35:35,255 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pu69y95z
2023-05-06 05:35:35,255 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-269aa1d6-e34b-4df2-908a-38fe8267d1c6
2023-05-06 05:35:35,255 - distributed.worker - INFO - Starting Worker plugin PreImport-6aaff215-6606-4a50-88b9-dceb7d442da2
2023-05-06 05:35:35,255 - distributed.worker - INFO - Starting Worker plugin RMMSetup-795b56d5-269b-41f9-b534-f822fd26e9b7
2023-05-06 05:35:35,256 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:35,256 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37817', status: init, memory: 0, processing: 0>
2023-05-06 05:35:35,257 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37817
2023-05-06 05:35:35,257 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56350
2023-05-06 05:35:35,258 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-05-06 05:35:35,258 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:35,261 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-05-06 05:35:35,282 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32781', status: init, memory: 0, processing: 0>
2023-05-06 05:35:35,283 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32781
2023-05-06 05:35:35,283 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56364
2023-05-06 05:35:35,284 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-05-06 05:35:35,284 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:35,286 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34829', status: init, memory: 0, processing: 0>
2023-05-06 05:35:35,287 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-05-06 05:35:35,287 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34829
2023-05-06 05:35:35,287 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56360
2023-05-06 05:35:35,287 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-05-06 05:35:35,288 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:35,290 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-05-06 05:35:35,311 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-05-06 05:35:35,311 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-05-06 05:35:35,311 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-05-06 05:35:35,311 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-05-06 05:35:35,316 - distributed.scheduler - INFO - Remove client Client-d0c9941b-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:35,316 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53412; closing.
2023-05-06 05:35:35,317 - distributed.scheduler - INFO - Remove client Client-d0c9941b-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:35,317 - distributed.scheduler - INFO - Close client connection: Client-d0c9941b-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:35,318 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36445'. Reason: nanny-close
2023-05-06 05:35:35,318 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:35,319 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39443'. Reason: nanny-close
2023-05-06 05:35:35,319 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:35,320 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39839'. Reason: nanny-close
2023-05-06 05:35:35,320 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32781. Reason: nanny-close
2023-05-06 05:35:35,320 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:35,320 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37817. Reason: nanny-close
2023-05-06 05:35:35,320 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41477'. Reason: nanny-close
2023-05-06 05:35:35,320 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:35,321 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34829. Reason: nanny-close
2023-05-06 05:35:35,322 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40715. Reason: nanny-close
2023-05-06 05:35:35,322 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56364; closing.
2023-05-06 05:35:35,322 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-05-06 05:35:35,322 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-05-06 05:35:35,322 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32781', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:35,322 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:32781
2023-05-06 05:35:35,323 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-05-06 05:35:35,323 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56350; closing.
2023-05-06 05:35:35,323 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-05-06 05:35:35,323 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:35,324 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:35,324 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37817', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:35,324 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37817
2023-05-06 05:35:35,324 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56360; closing.
2023-05-06 05:35:35,324 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:35,324 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:35,325 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34829', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:35,325 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34829
2023-05-06 05:35:35,325 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56342; closing.
2023-05-06 05:35:35,326 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40715', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:35,326 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40715
2023-05-06 05:35:35,326 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:35:36,334 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:35:36,335 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:35:36,335 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:35:36,336 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-05-06 05:35:36,337 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-05-06 05:35:38,384 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:35:38,389 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33451 instead
  warnings.warn(
2023-05-06 05:35:38,392 - distributed.scheduler - INFO - State start
2023-05-06 05:35:38,412 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:35:38,413 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:35:38,413 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33451/status
2023-05-06 05:35:38,639 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35945'
2023-05-06 05:35:38,657 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46125'
2023-05-06 05:35:38,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40821'
2023-05-06 05:35:38,668 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38003'
2023-05-06 05:35:38,678 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42735'
2023-05-06 05:35:38,690 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43147'
2023-05-06 05:35:38,700 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37875'
2023-05-06 05:35:38,709 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38289'
2023-05-06 05:35:39,976 - distributed.scheduler - INFO - Receive client connection: Client-d426bccd-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:39,993 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43062
2023-05-06 05:35:40,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:40,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:40,165 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:40,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:40,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:40,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:40,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:40,322 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:40,322 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:40,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:40,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:40,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:40,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:40,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:40,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:40,388 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:40,391 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:40,392 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:40,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:40,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:40,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:40,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:40,468 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:40,468 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:40,961 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37335
2023-05-06 05:35:40,961 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37335
2023-05-06 05:35:40,962 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33527
2023-05-06 05:35:40,962 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:40,962 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:40,962 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:40,962 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:40,962 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ce75itlc
2023-05-06 05:35:40,962 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37d533cc-7b1f-4bdb-9bf4-e5f448f7b9a1
2023-05-06 05:35:40,962 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d86998d2-7657-41d9-9196-ed8bcf5ee70a
2023-05-06 05:35:41,296 - distributed.worker - INFO - Starting Worker plugin PreImport-1803ea5f-4169-4e99-aad7-eea2bac9ed6b
2023-05-06 05:35:41,296 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:41,327 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37335', status: init, memory: 0, processing: 0>
2023-05-06 05:35:41,328 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37335
2023-05-06 05:35:41,328 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43072
2023-05-06 05:35:41,329 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:41,329 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:41,331 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:42,226 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39391
2023-05-06 05:35:42,226 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39391
2023-05-06 05:35:42,226 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35651
2023-05-06 05:35:42,226 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,226 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,226 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:42,226 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:42,226 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lmpk5v3b
2023-05-06 05:35:42,227 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-93c7512a-74b6-4e50-8999-c902c6c458d8
2023-05-06 05:35:42,227 - distributed.worker - INFO - Starting Worker plugin PreImport-7cb53ae9-8775-483e-90c7-6c1146d5ca48
2023-05-06 05:35:42,227 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ed4e7050-c6d4-4cc7-b066-6b64eeb4336d
2023-05-06 05:35:42,239 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36313
2023-05-06 05:35:42,239 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44475
2023-05-06 05:35:42,239 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36313
2023-05-06 05:35:42,240 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44475
2023-05-06 05:35:42,240 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46487
2023-05-06 05:35:42,240 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35693
2023-05-06 05:35:42,240 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,240 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,240 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,240 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,240 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:42,240 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:42,240 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:42,240 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:42,240 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-86na_hng
2023-05-06 05:35:42,240 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9_ptk9pi
2023-05-06 05:35:42,240 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e5ec893e-769b-47c1-a7d8-a8ab9e6c517d
2023-05-06 05:35:42,240 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5116feec-a496-4e52-9160-9e2f298b96be
2023-05-06 05:35:42,241 - distributed.worker - INFO - Starting Worker plugin PreImport-d4e2c840-6feb-4a67-bf87-a2ce8161f1aa
2023-05-06 05:35:42,241 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d9fdb3df-25c8-4b2a-a320-2b5be4d31baa
2023-05-06 05:35:42,284 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39149
2023-05-06 05:35:42,285 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39149
2023-05-06 05:35:42,285 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38471
2023-05-06 05:35:42,285 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,285 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,285 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:42,285 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:42,285 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l7avmnh6
2023-05-06 05:35:42,286 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-132fd37d-7f32-4c10-b73a-f54bb0d6ff1f
2023-05-06 05:35:42,286 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab8e9f2f-08bd-412f-bc02-91f918acad51
2023-05-06 05:35:42,288 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35271
2023-05-06 05:35:42,288 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35271
2023-05-06 05:35:42,288 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41049
2023-05-06 05:35:42,288 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,288 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,288 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:42,288 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:42,289 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_j1gdifq
2023-05-06 05:35:42,289 - distributed.worker - INFO - Starting Worker plugin PreImport-4d2df133-d334-42c0-a1fe-a27747bc3734
2023-05-06 05:35:42,289 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8bcc274e-2b02-4e7c-82be-f5e6f008c4ea
2023-05-06 05:35:42,289 - distributed.worker - INFO - Starting Worker plugin RMMSetup-508cfbaa-ca84-480a-b49b-103e6610695b
2023-05-06 05:35:42,297 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34587
2023-05-06 05:35:42,297 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34587
2023-05-06 05:35:42,297 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36685
2023-05-06 05:35:42,297 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,297 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,298 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:42,298 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:42,298 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h3p_cx5r
2023-05-06 05:35:42,298 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2ff878c4-374f-4145-adaf-519b13e9b336
2023-05-06 05:35:42,299 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b4e7c10b-7198-419e-989c-bd6fa73d9b50
2023-05-06 05:35:42,306 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38055
2023-05-06 05:35:42,306 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38055
2023-05-06 05:35:42,306 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38699
2023-05-06 05:35:42,306 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,306 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,306 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:42,306 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:42,306 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0m4ycns4
2023-05-06 05:35:42,307 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-68ac2412-7b8f-4c5a-a08b-b826dc355ab6
2023-05-06 05:35:42,307 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fbf494c2-904b-40d8-ac03-25e5f1c4b915
2023-05-06 05:35:42,376 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,384 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,385 - distributed.worker - INFO - Starting Worker plugin PreImport-93125380-2468-4459-b34b-6e8c19131d0e
2023-05-06 05:35:42,385 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4c527018-d424-4b4e-aa31-f2f5833131d1
2023-05-06 05:35:42,385 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,404 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39391', status: init, memory: 0, processing: 0>
2023-05-06 05:35:42,405 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39391
2023-05-06 05:35:42,405 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43086
2023-05-06 05:35:42,406 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,406 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,407 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:42,417 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44475', status: init, memory: 0, processing: 0>
2023-05-06 05:35:42,418 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44475
2023-05-06 05:35:42,419 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43106
2023-05-06 05:35:42,419 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,419 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,420 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36313', status: init, memory: 0, processing: 0>
2023-05-06 05:35:42,421 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36313
2023-05-06 05:35:42,421 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43094
2023-05-06 05:35:42,421 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,422 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,422 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:42,424 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:42,436 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,436 - distributed.worker - INFO - Starting Worker plugin PreImport-9b30d913-0466-4770-a2a5-dcbfabc3e364
2023-05-06 05:35:42,436 - distributed.worker - INFO - Starting Worker plugin PreImport-bdcd9623-d09b-4e83-a4ac-f4bdf17537f8
2023-05-06 05:35:42,436 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,436 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,441 - distributed.worker - INFO - Starting Worker plugin PreImport-1598e9db-9b6c-430d-897c-0a7ca267c9e4
2023-05-06 05:35:42,442 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,464 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34587', status: init, memory: 0, processing: 0>
2023-05-06 05:35:42,465 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34587
2023-05-06 05:35:42,465 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43122
2023-05-06 05:35:42,466 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,466 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,467 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38055', status: init, memory: 0, processing: 0>
2023-05-06 05:35:42,467 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38055
2023-05-06 05:35:42,467 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43150
2023-05-06 05:35:42,468 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,468 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,468 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:42,470 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:42,471 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35271', status: init, memory: 0, processing: 0>
2023-05-06 05:35:42,472 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35271
2023-05-06 05:35:42,472 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43110
2023-05-06 05:35:42,472 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,472 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,475 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39149', status: init, memory: 0, processing: 0>
2023-05-06 05:35:42,475 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:42,475 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39149
2023-05-06 05:35:42,475 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43134
2023-05-06 05:35:42,476 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:42,476 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:42,478 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:42,556 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:42,557 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:42,557 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:42,557 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:42,557 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:42,557 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:42,557 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:42,558 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:42,562 - distributed.scheduler - INFO - Remove client Client-d426bccd-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:42,562 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43062; closing.
2023-05-06 05:35:42,563 - distributed.scheduler - INFO - Remove client Client-d426bccd-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:42,563 - distributed.scheduler - INFO - Close client connection: Client-d426bccd-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:42,564 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38003'. Reason: nanny-close
2023-05-06 05:35:42,565 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:42,566 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35945'. Reason: nanny-close
2023-05-06 05:35:42,566 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:42,567 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35271. Reason: nanny-close
2023-05-06 05:35:42,567 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46125'. Reason: nanny-close
2023-05-06 05:35:42,567 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:42,568 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44475. Reason: nanny-close
2023-05-06 05:35:42,568 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40821'. Reason: nanny-close
2023-05-06 05:35:42,568 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:42,569 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:42,569 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38055. Reason: nanny-close
2023-05-06 05:35:42,569 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43110; closing.
2023-05-06 05:35:42,569 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42735'. Reason: nanny-close
2023-05-06 05:35:42,569 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:42,569 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35271', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:42,570 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:42,570 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35271
2023-05-06 05:35:42,570 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37335. Reason: nanny-close
2023-05-06 05:35:42,570 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43147'. Reason: nanny-close
2023-05-06 05:35:42,570 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:42,570 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:42,571 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36313. Reason: nanny-close
2023-05-06 05:35:42,571 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37875'. Reason: nanny-close
2023-05-06 05:35:42,571 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:42,571 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:42,571 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35271
2023-05-06 05:35:42,571 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:42,572 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39149. Reason: nanny-close
2023-05-06 05:35:42,572 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35271
2023-05-06 05:35:42,572 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38289'. Reason: nanny-close
2023-05-06 05:35:42,572 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35271
2023-05-06 05:35:42,572 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:42,572 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:42,572 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43106; closing.
2023-05-06 05:35:42,572 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34587. Reason: nanny-close
2023-05-06 05:35:42,573 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35271
2023-05-06 05:35:42,573 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:42,573 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44475', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:42,573 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44475
2023-05-06 05:35:42,573 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:42,573 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35271
2023-05-06 05:35:42,574 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:42,574 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39391. Reason: nanny-close
2023-05-06 05:35:42,574 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:42,574 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43150; closing.
2023-05-06 05:35:42,574 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:42,574 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43072; closing.
2023-05-06 05:35:42,575 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:42,575 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:42,575 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38055', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:42,575 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:42,575 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38055
2023-05-06 05:35:42,575 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:42,576 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37335', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:42,576 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37335
2023-05-06 05:35:42,576 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43094; closing.
2023-05-06 05:35:42,577 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43134; closing.
2023-05-06 05:35:42,577 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:42,577 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43122; closing.
2023-05-06 05:35:42,577 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36313', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:42,577 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36313
2023-05-06 05:35:42,578 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39149', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:42,578 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39149
2023-05-06 05:35:42,578 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34587', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:42,579 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34587
2023-05-06 05:35:42,579 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43086; closing.
2023-05-06 05:35:42,580 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39391', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:42,580 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39391
2023-05-06 05:35:42,580 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:35:42,580 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43086>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-05-06 05:35:43,981 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:35:43,982 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:35:43,982 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:35:43,983 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:35:43,984 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-05-06 05:35:45,832 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:35:45,836 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44269 instead
  warnings.warn(
2023-05-06 05:35:45,840 - distributed.scheduler - INFO - State start
2023-05-06 05:35:45,858 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:35:45,859 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:35:45,860 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44269/status
2023-05-06 05:35:46,037 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46091'
2023-05-06 05:35:46,050 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40251'
2023-05-06 05:35:46,069 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38011'
2023-05-06 05:35:46,071 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44743'
2023-05-06 05:35:46,079 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41145'
2023-05-06 05:35:46,089 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43293'
2023-05-06 05:35:46,100 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45705'
2023-05-06 05:35:46,108 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40487'
2023-05-06 05:35:47,591 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:47,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:47,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:47,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:47,629 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:47,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:47,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:47,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:47,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:47,648 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:47,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:47,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:47,664 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:47,665 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:47,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:47,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:47,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:47,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:47,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:47,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:47,682 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:47,710 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:47,712 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:47,713 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:47,740 - distributed.scheduler - INFO - Receive client connection: Client-d89eaa2c-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:47,756 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47222
2023-05-06 05:35:49,411 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43725
2023-05-06 05:35:49,411 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43725
2023-05-06 05:35:49,411 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33503
2023-05-06 05:35:49,412 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,412 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,412 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:49,412 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:49,412 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0fw7tfpj
2023-05-06 05:35:49,412 - distributed.worker - INFO - Starting Worker plugin PreImport-62235e1f-684b-47ac-870b-5f4b179a185c
2023-05-06 05:35:49,413 - distributed.worker - INFO - Starting Worker plugin RMMSetup-758338bc-fbd6-45eb-b32c-faca705eaa24
2023-05-06 05:35:49,416 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41329
2023-05-06 05:35:49,416 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41329
2023-05-06 05:35:49,417 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36097
2023-05-06 05:35:49,417 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,417 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,417 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:49,417 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:49,417 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1kany9p3
2023-05-06 05:35:49,417 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce3dcee1-d993-49c1-bf49-1731842fd1fa
2023-05-06 05:35:49,418 - distributed.worker - INFO - Starting Worker plugin PreImport-42fc8b5c-dc20-469b-8abb-9f034b5f6f43
2023-05-06 05:35:49,418 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fa170e41-2835-4a5d-8a4e-88781269e567
2023-05-06 05:35:49,432 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34159
2023-05-06 05:35:49,432 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34159
2023-05-06 05:35:49,433 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38577
2023-05-06 05:35:49,433 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,433 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,433 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:49,433 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:49,433 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-90b568je
2023-05-06 05:35:49,433 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ad7308cf-f119-44b3-a1c9-c28a2dc393c5
2023-05-06 05:35:49,438 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd649c90-3583-4881-b993-1c98379b03fe
2023-05-06 05:35:49,438 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,444 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,445 - distributed.worker - INFO - Starting Worker plugin PreImport-d3099c6d-37e9-490d-854f-db3e3d21d7dd
2023-05-06 05:35:49,445 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-226a7135-bcf8-404a-bfef-eee14046fb4f
2023-05-06 05:35:49,445 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,468 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43725', status: init, memory: 0, processing: 0>
2023-05-06 05:35:49,469 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43725
2023-05-06 05:35:49,469 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47250
2023-05-06 05:35:49,470 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,470 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,470 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41329', status: init, memory: 0, processing: 0>
2023-05-06 05:35:49,471 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41329
2023-05-06 05:35:49,471 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47260
2023-05-06 05:35:49,471 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,472 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,472 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34159', status: init, memory: 0, processing: 0>
2023-05-06 05:35:49,472 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34159
2023-05-06 05:35:49,472 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47272
2023-05-06 05:35:49,473 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:49,473 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,473 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,473 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:49,475 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:49,571 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36653
2023-05-06 05:35:49,572 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36653
2023-05-06 05:35:49,572 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42843
2023-05-06 05:35:49,572 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,572 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,572 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:49,572 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:49,572 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-s3wwzqy0
2023-05-06 05:35:49,572 - distributed.worker - INFO - Starting Worker plugin PreImport-beb2ed4f-315a-4bd1-8637-65ac7e29c104
2023-05-06 05:35:49,573 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5ca38ebb-63a3-450d-add5-841f3d332656
2023-05-06 05:35:49,573 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3b158c61-ba27-42bc-a0b4-55c0416a1db4
2023-05-06 05:35:49,577 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43509
2023-05-06 05:35:49,577 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43509
2023-05-06 05:35:49,577 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42823
2023-05-06 05:35:49,577 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42823
2023-05-06 05:35:49,577 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41211
2023-05-06 05:35:49,577 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,578 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46523
2023-05-06 05:35:49,578 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,578 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,578 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:49,578 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,578 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:49,578 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:49,578 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ulxmbezl
2023-05-06 05:35:49,578 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:49,578 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4bmfpy3g
2023-05-06 05:35:49,578 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c12a6ee9-1c17-4459-9e77-8242c9a5144d
2023-05-06 05:35:49,578 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f879354d-d12e-4487-bd7b-092b50465ea6
2023-05-06 05:35:49,578 - distributed.worker - INFO - Starting Worker plugin PreImport-46e2521e-4e5c-419a-85cb-6d00bc9ac4a5
2023-05-06 05:35:49,578 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e7da0b57-100e-4bf1-aeb5-66002414c25e
2023-05-06 05:35:49,579 - distributed.worker - INFO - Starting Worker plugin PreImport-7896cb9c-7a4d-4647-afe5-3bd85642bf6e
2023-05-06 05:35:49,579 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d5020044-851a-45ef-8197-0c033f74ae77
2023-05-06 05:35:49,579 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44483
2023-05-06 05:35:49,580 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44483
2023-05-06 05:35:49,580 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36937
2023-05-06 05:35:49,580 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,580 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,580 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:49,580 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:49,580 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-cj1sm41f
2023-05-06 05:35:49,581 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d6b423f7-b7aa-48ba-b36f-33ae07b56fef
2023-05-06 05:35:49,581 - distributed.worker - INFO - Starting Worker plugin PreImport-1ea92203-2ee3-4287-9161-20102b032e6f
2023-05-06 05:35:49,582 - distributed.worker - INFO - Starting Worker plugin RMMSetup-621665ac-1f64-4c66-ae63-ea486d93a356
2023-05-06 05:35:49,581 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36573
2023-05-06 05:35:49,582 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36573
2023-05-06 05:35:49,582 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41345
2023-05-06 05:35:49,582 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,582 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,582 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:49,582 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:49,582 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-k2cw_q37
2023-05-06 05:35:49,583 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9c58b88d-50ef-4a32-93e6-030b0affc35a
2023-05-06 05:35:49,583 - distributed.worker - INFO - Starting Worker plugin PreImport-25d72792-29a3-49b9-bff7-84c246d6da9c
2023-05-06 05:35:49,583 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b64e6f96-1a2c-4bb3-9bd0-64d9422f02c3
2023-05-06 05:35:49,601 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,602 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,602 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,603 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,603 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,625 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36653', status: init, memory: 0, processing: 0>
2023-05-06 05:35:49,626 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36653
2023-05-06 05:35:49,627 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47286
2023-05-06 05:35:49,627 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,627 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,628 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42823', status: init, memory: 0, processing: 0>
2023-05-06 05:35:49,628 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42823
2023-05-06 05:35:49,629 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47294
2023-05-06 05:35:49,629 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,629 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,629 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:49,629 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44483', status: init, memory: 0, processing: 0>
2023-05-06 05:35:49,630 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44483
2023-05-06 05:35:49,630 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47314
2023-05-06 05:35:49,630 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,631 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,631 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:49,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:49,635 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36573', status: init, memory: 0, processing: 0>
2023-05-06 05:35:49,636 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36573
2023-05-06 05:35:49,636 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47320
2023-05-06 05:35:49,636 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,637 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,637 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43509', status: init, memory: 0, processing: 0>
2023-05-06 05:35:49,637 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43509
2023-05-06 05:35:49,637 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47298
2023-05-06 05:35:49,638 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:49,638 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:49,639 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:49,640 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:49,703 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:49,704 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:49,704 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:49,704 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:49,704 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:49,704 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:49,704 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:49,704 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:49,708 - distributed.scheduler - INFO - Remove client Client-d89eaa2c-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:49,709 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47222; closing.
2023-05-06 05:35:49,709 - distributed.scheduler - INFO - Remove client Client-d89eaa2c-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:49,709 - distributed.scheduler - INFO - Close client connection: Client-d89eaa2c-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:49,710 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44743'. Reason: nanny-close
2023-05-06 05:35:49,711 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:49,711 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46091'. Reason: nanny-close
2023-05-06 05:35:49,712 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:49,713 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36653. Reason: nanny-close
2023-05-06 05:35:49,713 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40251'. Reason: nanny-close
2023-05-06 05:35:49,713 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:49,713 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41329. Reason: nanny-close
2023-05-06 05:35:49,713 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38011'. Reason: nanny-close
2023-05-06 05:35:49,714 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:49,714 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44483. Reason: nanny-close
2023-05-06 05:35:49,714 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41145'. Reason: nanny-close
2023-05-06 05:35:49,714 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47286; closing.
2023-05-06 05:35:49,714 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:49,714 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:49,715 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36653', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:49,715 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43725. Reason: nanny-close
2023-05-06 05:35:49,715 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36653
2023-05-06 05:35:49,715 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43293'. Reason: nanny-close
2023-05-06 05:35:49,715 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:49,715 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:49,715 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36573. Reason: nanny-close
2023-05-06 05:35:49,715 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45705'. Reason: nanny-close
2023-05-06 05:35:49,716 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:49,716 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:49,716 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:49,716 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43509. Reason: nanny-close
2023-05-06 05:35:49,716 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40487'. Reason: nanny-close
2023-05-06 05:35:49,716 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36653
2023-05-06 05:35:49,716 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:49,716 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:49,716 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36653
2023-05-06 05:35:49,716 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47260; closing.
2023-05-06 05:35:49,716 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36653
2023-05-06 05:35:49,717 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:49,717 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:49,717 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42823. Reason: nanny-close
2023-05-06 05:35:49,717 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36653
2023-05-06 05:35:49,717 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41329', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:49,717 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41329
2023-05-06 05:35:49,717 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:49,717 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47314; closing.
2023-05-06 05:35:49,717 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36653
2023-05-06 05:35:49,718 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34159. Reason: nanny-close
2023-05-06 05:35:49,718 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44483', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:49,718 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44483
2023-05-06 05:35:49,718 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:49,718 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:49,718 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:49,718 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47250; closing.
2023-05-06 05:35:49,719 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:49,719 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43725', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:49,719 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43725
2023-05-06 05:35:49,719 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47320; closing.
2023-05-06 05:35:49,719 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:49,719 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47298; closing.
2023-05-06 05:35:49,719 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:49,720 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36573', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:49,720 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36573
2023-05-06 05:35:49,720 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:49,720 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43509', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:49,720 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43509
2023-05-06 05:35:49,721 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47294; closing.
2023-05-06 05:35:49,721 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:49,721 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42823', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:49,721 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42823
2023-05-06 05:35:49,722 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47272; closing.
2023-05-06 05:35:49,722 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34159', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:49,722 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34159
2023-05-06 05:35:49,722 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:35:51,078 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:35:51,078 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:35:51,079 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:35:51,080 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:35:51,080 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-05-06 05:35:52,981 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:35:52,985 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36291 instead
  warnings.warn(
2023-05-06 05:35:52,988 - distributed.scheduler - INFO - State start
2023-05-06 05:35:53,009 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:35:53,010 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:35:53,010 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36291/status
2023-05-06 05:35:53,288 - distributed.scheduler - INFO - Receive client connection: Client-dceac6f1-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:53,304 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47418
2023-05-06 05:35:53,357 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33999'
2023-05-06 05:35:53,370 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39985'
2023-05-06 05:35:53,377 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46333'
2023-05-06 05:35:53,385 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37135'
2023-05-06 05:35:53,395 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42113'
2023-05-06 05:35:53,403 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43707'
2023-05-06 05:35:53,414 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42177'
2023-05-06 05:35:53,425 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35875'
2023-05-06 05:35:55,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:55,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:55,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:55,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:55,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:55,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:55,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:55,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:55,084 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:55,084 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:55,085 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:55,089 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:55,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:55,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:55,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:55,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:55,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:55,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:55,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:35:55,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:35:55,157 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:55,160 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:55,176 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:55,186 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:35:56,907 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39221
2023-05-06 05:35:56,907 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39221
2023-05-06 05:35:56,907 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32817
2023-05-06 05:35:56,907 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:56,907 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:56,907 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:56,907 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:56,907 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-aos2vl4a
2023-05-06 05:35:56,908 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eb52a384-f443-449c-b944-01f7a65c26ac
2023-05-06 05:35:56,908 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0a5f8398-a8c8-442a-89c6-93caf3eed2b3
2023-05-06 05:35:56,913 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43501
2023-05-06 05:35:56,913 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43501
2023-05-06 05:35:56,913 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34153
2023-05-06 05:35:56,913 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:56,913 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:56,913 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:56,913 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:56,913 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-daiexuu2
2023-05-06 05:35:56,914 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f627b73f-2db9-4af8-b74e-67b2916f661f
2023-05-06 05:35:56,914 - distributed.worker - INFO - Starting Worker plugin PreImport-b82607c6-89e6-4951-8174-6b336c876191
2023-05-06 05:35:56,914 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e544c66e-143a-4884-a127-ff10c582faf5
2023-05-06 05:35:56,988 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42959
2023-05-06 05:35:56,989 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42959
2023-05-06 05:35:56,989 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34453
2023-05-06 05:35:56,989 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:56,989 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:56,989 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:56,989 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:56,989 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-r5n_3ifk
2023-05-06 05:35:56,990 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dda766e5-7ed6-4e26-8444-4c08c56fe90f
2023-05-06 05:35:56,997 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33199
2023-05-06 05:35:56,997 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33199
2023-05-06 05:35:56,997 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40839
2023-05-06 05:35:56,997 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:56,997 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:56,998 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:56,998 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:56,998 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2814c_n4
2023-05-06 05:35:56,998 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-84e81ca9-aae3-434b-9338-a9607d16835a
2023-05-06 05:35:56,998 - distributed.worker - INFO - Starting Worker plugin RMMSetup-04c6d104-8d4f-427b-9009-1389ac412518
2023-05-06 05:35:57,000 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43217
2023-05-06 05:35:57,001 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43217
2023-05-06 05:35:57,001 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39651
2023-05-06 05:35:57,001 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,001 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,001 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:57,001 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:57,001 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_eiffr6r
2023-05-06 05:35:57,001 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e4964953-9c43-46a5-9f61-46a5bd5a8713
2023-05-06 05:35:57,002 - distributed.worker - INFO - Starting Worker plugin RMMSetup-90a70562-254d-4275-8ca2-ba00068ce216
2023-05-06 05:35:57,007 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38437
2023-05-06 05:35:57,007 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38437
2023-05-06 05:35:57,008 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40685
2023-05-06 05:35:57,008 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,008 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,008 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:57,008 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:57,008 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-84it47v1
2023-05-06 05:35:57,008 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a988d565-bdf1-4285-91f2-9dfe417526ae
2023-05-06 05:35:57,009 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b949b12-fdf8-436a-94e7-7bc910267a60
2023-05-06 05:35:57,095 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39703
2023-05-06 05:35:57,095 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39703
2023-05-06 05:35:57,095 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41121
2023-05-06 05:35:57,095 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,095 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,095 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:57,096 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:57,096 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h3h2uy50
2023-05-06 05:35:57,096 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f52013bc-cff6-4451-90bd-a56a6fcde889
2023-05-06 05:35:57,096 - distributed.worker - INFO - Starting Worker plugin PreImport-9997a775-34b2-4a21-9a05-787959ec5bc9
2023-05-06 05:35:57,096 - distributed.worker - INFO - Starting Worker plugin RMMSetup-092a6e3d-5bc8-4aa5-b12d-dee0d181910f
2023-05-06 05:35:57,136 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41351
2023-05-06 05:35:57,136 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41351
2023-05-06 05:35:57,136 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40691
2023-05-06 05:35:57,137 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,137 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,137 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:35:57,137 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:35:57,137 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-s4jr_oz4
2023-05-06 05:35:57,137 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a156ee9f-818b-444e-991e-344a39b96b62
2023-05-06 05:35:57,194 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,228 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43501', status: init, memory: 0, processing: 0>
2023-05-06 05:35:57,230 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43501
2023-05-06 05:35:57,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42074
2023-05-06 05:35:57,231 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,231 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,231 - distributed.worker - INFO - Starting Worker plugin PreImport-0209914a-418e-4876-bed1-35489e9f4b88
2023-05-06 05:35:57,233 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,233 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:57,238 - distributed.worker - INFO - Starting Worker plugin PreImport-100813bb-8812-42f2-b00b-a977fa0bfce0
2023-05-06 05:35:57,239 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,243 - distributed.worker - INFO - Starting Worker plugin PreImport-bf498cf2-d7b6-42b8-846c-7294deebf34a
2023-05-06 05:35:57,244 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,253 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-839f79f5-5af2-4c18-a00f-2c730c854458
2023-05-06 05:35:57,255 - distributed.worker - INFO - Starting Worker plugin PreImport-8a058cdc-6e47-4579-81f7-183418353941
2023-05-06 05:35:57,256 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,271 - distributed.worker - INFO - Starting Worker plugin PreImport-c95f7039-0b32-4fbf-a8f1-7b182a6f2f0f
2023-05-06 05:35:57,271 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,272 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43217', status: init, memory: 0, processing: 0>
2023-05-06 05:35:57,272 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43217
2023-05-06 05:35:57,273 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42098
2023-05-06 05:35:57,273 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,273 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,275 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:57,278 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39221', status: init, memory: 0, processing: 0>
2023-05-06 05:35:57,279 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39221
2023-05-06 05:35:57,279 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42090
2023-05-06 05:35:57,279 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,280 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,281 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,281 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33199', status: init, memory: 0, processing: 0>
2023-05-06 05:35:57,282 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33199
2023-05-06 05:35:57,282 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42106
2023-05-06 05:35:57,283 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:57,283 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,283 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,285 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42959', status: init, memory: 0, processing: 0>
2023-05-06 05:35:57,286 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42959
2023-05-06 05:35:57,286 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42112
2023-05-06 05:35:57,286 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:57,286 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,286 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,288 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:57,291 - distributed.worker - INFO - Starting Worker plugin PreImport-ffe32132-5929-4cf3-97a3-f2027de7abeb
2023-05-06 05:35:57,291 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6f643d80-f926-41b4-a638-d14059961280
2023-05-06 05:35:57,291 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,305 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38437', status: init, memory: 0, processing: 0>
2023-05-06 05:35:57,306 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38437
2023-05-06 05:35:57,306 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42122
2023-05-06 05:35:57,307 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,307 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,309 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:57,317 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41351', status: init, memory: 0, processing: 0>
2023-05-06 05:35:57,317 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41351
2023-05-06 05:35:57,317 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42136
2023-05-06 05:35:57,318 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,318 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,318 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39703', status: init, memory: 0, processing: 0>
2023-05-06 05:35:57,319 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39703
2023-05-06 05:35:57,319 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42134
2023-05-06 05:35:57,320 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:35:57,320 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:57,320 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:35:57,323 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:35:57,389 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:57,389 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:57,389 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:57,389 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:57,389 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:57,390 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:57,390 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:57,390 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:35:57,400 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:35:57,401 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:35:57,401 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:35:57,401 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:35:57,401 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:35:57,401 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:35:57,401 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:35:57,401 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:35:57,407 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:35:57,408 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:35:57,410 - distributed.scheduler - INFO - Remove client Client-dceac6f1-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:57,411 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47418; closing.
2023-05-06 05:35:57,411 - distributed.scheduler - INFO - Remove client Client-dceac6f1-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:57,411 - distributed.scheduler - INFO - Close client connection: Client-dceac6f1-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:35:57,412 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39985'. Reason: nanny-close
2023-05-06 05:35:57,412 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:57,413 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42113'. Reason: nanny-close
2023-05-06 05:35:57,413 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:57,414 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33999'. Reason: nanny-close
2023-05-06 05:35:57,414 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42959. Reason: nanny-close
2023-05-06 05:35:57,414 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:57,414 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46333'. Reason: nanny-close
2023-05-06 05:35:57,414 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41351. Reason: nanny-close
2023-05-06 05:35:57,415 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:57,415 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37135'. Reason: nanny-close
2023-05-06 05:35:57,415 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39221. Reason: nanny-close
2023-05-06 05:35:57,415 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:57,416 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38437. Reason: nanny-close
2023-05-06 05:35:57,416 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43707'. Reason: nanny-close
2023-05-06 05:35:57,416 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:57,416 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42112; closing.
2023-05-06 05:35:57,416 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:57,416 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42177'. Reason: nanny-close
2023-05-06 05:35:57,416 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:57,416 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42959', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:57,416 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43501. Reason: nanny-close
2023-05-06 05:35:57,416 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42959
2023-05-06 05:35:57,417 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:57,417 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35875'. Reason: nanny-close
2023-05-06 05:35:57,417 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43217. Reason: nanny-close
2023-05-06 05:35:57,417 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:35:57,417 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42136; closing.
2023-05-06 05:35:57,417 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:57,417 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:57,418 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:57,418 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33199. Reason: nanny-close
2023-05-06 05:35:57,418 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:57,418 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:57,418 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42959
2023-05-06 05:35:57,418 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41351', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:57,418 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41351
2023-05-06 05:35:57,419 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42959
2023-05-06 05:35:57,419 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:57,419 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:57,419 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:57,419 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39703. Reason: nanny-close
2023-05-06 05:35:57,419 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42122; closing.
2023-05-06 05:35:57,419 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:57,419 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42090; closing.
2023-05-06 05:35:57,420 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42959
2023-05-06 05:35:57,420 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38437', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:57,420 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38437
2023-05-06 05:35:57,420 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39221', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:57,420 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:57,420 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39221
2023-05-06 05:35:57,421 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:57,421 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42074; closing.
2023-05-06 05:35:57,421 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42098; closing.
2023-05-06 05:35:57,421 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:35:57,421 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43501', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:57,422 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43501
2023-05-06 05:35:57,422 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43217', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:57,422 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:57,422 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43217
2023-05-06 05:35:57,422 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42106; closing.
2023-05-06 05:35:57,423 - distributed.nanny - INFO - Worker closed
2023-05-06 05:35:57,423 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33199', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:57,423 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33199
2023-05-06 05:35:57,423 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42134; closing.
2023-05-06 05:35:57,424 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39703', status: closing, memory: 0, processing: 0>
2023-05-06 05:35:57,424 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39703
2023-05-06 05:35:57,424 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:35:58,879 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:35:58,880 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:35:58,880 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:35:58,881 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:35:58,882 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-05-06 05:36:00,703 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:00,707 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40995 instead
  warnings.warn(
2023-05-06 05:36:00,710 - distributed.scheduler - INFO - State start
2023-05-06 05:36:00,730 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:00,731 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:36:00,731 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40995/status
2023-05-06 05:36:00,999 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36089'
2023-05-06 05:36:01,009 - distributed.scheduler - INFO - Receive client connection: Client-e1877984-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:01,013 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43387'
2023-05-06 05:36:01,021 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42338
2023-05-06 05:36:01,022 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46587'
2023-05-06 05:36:01,034 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37059'
2023-05-06 05:36:01,045 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36801'
2023-05-06 05:36:01,060 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38697'
2023-05-06 05:36:01,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32771'
2023-05-06 05:36:01,076 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41243'
2023-05-06 05:36:02,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:02,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:02,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:02,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:02,633 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:02,637 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:02,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:02,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:02,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:02,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:02,668 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:02,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:02,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:02,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:02,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:02,692 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:02,702 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:02,722 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:02,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:02,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:02,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:02,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:02,781 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:02,817 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:04,300 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34715
2023-05-06 05:36:04,300 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34715
2023-05-06 05:36:04,301 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43547
2023-05-06 05:36:04,301 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,301 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,301 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:04,301 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:04,301 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ovwprmdp
2023-05-06 05:36:04,301 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1c115f7a-2589-4040-b8de-34b02b3631b5
2023-05-06 05:36:04,302 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b9402b7b-6b48-4845-9dac-4ad9832d3dc9
2023-05-06 05:36:04,317 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35419
2023-05-06 05:36:04,317 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35419
2023-05-06 05:36:04,317 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46417
2023-05-06 05:36:04,317 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,318 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,318 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:04,318 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:04,318 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-om3s_b2q
2023-05-06 05:36:04,318 - distributed.worker - INFO - Starting Worker plugin RMMSetup-26078b8e-f3dd-48e2-86a5-edcccc684f05
2023-05-06 05:36:04,349 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37999
2023-05-06 05:36:04,350 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37999
2023-05-06 05:36:04,350 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35377
2023-05-06 05:36:04,350 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,350 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,350 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:04,350 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:04,350 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-r4upjq9f
2023-05-06 05:36:04,350 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2d3371eb-c54f-43e9-99d5-5eb1824df35f
2023-05-06 05:36:04,382 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40987
2023-05-06 05:36:04,382 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40987
2023-05-06 05:36:04,382 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43283
2023-05-06 05:36:04,382 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,383 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,383 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:04,383 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:04,383 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-c1d10rnk
2023-05-06 05:36:04,383 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4793c58c-f602-4869-8802-913ec3b9e110
2023-05-06 05:36:04,383 - distributed.worker - INFO - Starting Worker plugin RMMSetup-85accb5a-3abf-45c0-8828-7244fe7c1a85
2023-05-06 05:36:04,407 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39151
2023-05-06 05:36:04,408 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39151
2023-05-06 05:36:04,408 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38393
2023-05-06 05:36:04,408 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,408 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,408 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:04,408 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:04,408 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-cbs5wa77
2023-05-06 05:36:04,409 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fb218720-0f1e-470d-bd14-79490b6e8b2b
2023-05-06 05:36:04,409 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a103a241-8424-40a4-8104-1e6da137af3c
2023-05-06 05:36:04,443 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46489
2023-05-06 05:36:04,443 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46489
2023-05-06 05:36:04,443 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39805
2023-05-06 05:36:04,443 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,443 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,443 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:04,443 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:04,443 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6hdwp47p
2023-05-06 05:36:04,444 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-319a8e75-1122-4772-a8c3-1dfba582a7af
2023-05-06 05:36:04,444 - distributed.worker - INFO - Starting Worker plugin PreImport-5d4bac6d-79f4-4467-ad4c-0a9b8b2ab3f1
2023-05-06 05:36:04,445 - distributed.worker - INFO - Starting Worker plugin RMMSetup-46ca485c-91f0-4a5c-812b-d330cad6ac2f
2023-05-06 05:36:04,542 - distributed.worker - INFO - Starting Worker plugin PreImport-a2d96709-2304-4c36-b9bf-33479c84869d
2023-05-06 05:36:04,542 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,555 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5bbcbf13-285e-49e5-9b61-964aafb75563
2023-05-06 05:36:04,556 - distributed.worker - INFO - Starting Worker plugin PreImport-2f2ac9e3-5874-4edf-b451-66a1c7ee393d
2023-05-06 05:36:04,556 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,568 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43423
2023-05-06 05:36:04,569 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43423
2023-05-06 05:36:04,569 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38613
2023-05-06 05:36:04,569 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,569 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,569 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:04,569 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:04,569 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mo5tuyx0
2023-05-06 05:36:04,570 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-430d7466-d034-4f2e-8335-6e6a91897267
2023-05-06 05:36:04,570 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36375
2023-05-06 05:36:04,571 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36375
2023-05-06 05:36:04,571 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46747
2023-05-06 05:36:04,571 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,571 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,571 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:04,571 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:04,571 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rtlj_e6p
2023-05-06 05:36:04,572 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3ef2d846-219d-4a5e-a8d7-f4bf4e91ac01
2023-05-06 05:36:04,571 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b2751ec3-cf34-4ad0-86bb-772002d249e8
2023-05-06 05:36:04,572 - distributed.worker - INFO - Starting Worker plugin PreImport-eee8ff6c-d762-4a65-85fb-7a5020c7774f
2023-05-06 05:36:04,572 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ef70f5cc-1ac6-4201-8d80-2b789e0332a6
2023-05-06 05:36:04,573 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34715', status: init, memory: 0, processing: 0>
2023-05-06 05:36:04,575 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34715
2023-05-06 05:36:04,575 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58970
2023-05-06 05:36:04,575 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,575 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:04,594 - distributed.worker - INFO - Starting Worker plugin PreImport-3a837610-5696-43b5-8e65-9d5d9c3a26ac
2023-05-06 05:36:04,594 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cbda1317-4fc9-4431-af0d-e1ecfcbe2188
2023-05-06 05:36:04,594 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,597 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37999', status: init, memory: 0, processing: 0>
2023-05-06 05:36:04,598 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37999
2023-05-06 05:36:04,598 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58976
2023-05-06 05:36:04,599 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,599 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,601 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:04,605 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,606 - distributed.worker - INFO - Starting Worker plugin PreImport-a752244a-a727-4ba9-86a6-8897b602d8d6
2023-05-06 05:36:04,606 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,618 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35419', status: init, memory: 0, processing: 0>
2023-05-06 05:36:04,619 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35419
2023-05-06 05:36:04,619 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58992
2023-05-06 05:36:04,620 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,620 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,622 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:04,630 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46489', status: init, memory: 0, processing: 0>
2023-05-06 05:36:04,631 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46489
2023-05-06 05:36:04,631 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59002
2023-05-06 05:36:04,631 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,631 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,633 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:04,635 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40987', status: init, memory: 0, processing: 0>
2023-05-06 05:36:04,635 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40987
2023-05-06 05:36:04,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59014
2023-05-06 05:36:04,636 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,636 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,638 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:04,651 - distributed.worker - INFO - Starting Worker plugin PreImport-9c9e4514-5b2a-4d36-929e-314264e8a2bc
2023-05-06 05:36:04,652 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,688 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39151', status: init, memory: 0, processing: 0>
2023-05-06 05:36:04,689 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39151
2023-05-06 05:36:04,689 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59028
2023-05-06 05:36:04,690 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,690 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,693 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:04,694 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,716 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36375', status: init, memory: 0, processing: 0>
2023-05-06 05:36:04,717 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36375
2023-05-06 05:36:04,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59044
2023-05-06 05:36:04,718 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,718 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,720 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:04,722 - distributed.worker - INFO - Starting Worker plugin PreImport-114103e1-1ece-4ac6-92f4-74b1640cf3cb
2023-05-06 05:36:04,722 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,743 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43423', status: init, memory: 0, processing: 0>
2023-05-06 05:36:04,744 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43423
2023-05-06 05:36:04,744 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59054
2023-05-06 05:36:04,744 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:04,744 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:04,746 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:04,806 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:04,806 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:04,806 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:04,806 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:04,807 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:04,807 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:04,807 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:04,807 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:04,812 - distributed.scheduler - INFO - Remove client Client-e1877984-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:04,812 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42338; closing.
2023-05-06 05:36:04,813 - distributed.scheduler - INFO - Remove client Client-e1877984-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:04,813 - distributed.scheduler - INFO - Close client connection: Client-e1877984-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:04,814 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36089'. Reason: nanny-close
2023-05-06 05:36:04,814 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:04,815 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43387'. Reason: nanny-close
2023-05-06 05:36:04,816 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:04,816 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37999. Reason: nanny-close
2023-05-06 05:36:04,816 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46587'. Reason: nanny-close
2023-05-06 05:36:04,816 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:04,817 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35419. Reason: nanny-close
2023-05-06 05:36:04,817 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37059'. Reason: nanny-close
2023-05-06 05:36:04,817 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:04,818 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36801'. Reason: nanny-close
2023-05-06 05:36:04,818 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40987. Reason: nanny-close
2023-05-06 05:36:04,818 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:04,818 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38697'. Reason: nanny-close
2023-05-06 05:36:04,818 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39151. Reason: nanny-close
2023-05-06 05:36:04,818 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:04,818 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:04,818 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58992; closing.
2023-05-06 05:36:04,818 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:04,819 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58976; closing.
2023-05-06 05:36:04,819 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32771'. Reason: nanny-close
2023-05-06 05:36:04,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46489. Reason: nanny-close
2023-05-06 05:36:04,819 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:04,819 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35419', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:04,819 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35419
2023-05-06 05:36:04,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34715. Reason: nanny-close
2023-05-06 05:36:04,819 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41243'. Reason: nanny-close
2023-05-06 05:36:04,819 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:04,820 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:04,820 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37999', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:04,820 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37999
2023-05-06 05:36:04,820 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:04,820 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:04,820 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:04,820 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43423. Reason: nanny-close
2023-05-06 05:36:04,820 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:04,821 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:04,821 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35419
2023-05-06 05:36:04,821 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59014; closing.
2023-05-06 05:36:04,821 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37999
2023-05-06 05:36:04,821 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59028; closing.
2023-05-06 05:36:04,822 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:04,822 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:04,822 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40987', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:04,822 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:04,822 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40987
2023-05-06 05:36:04,822 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39151', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:04,822 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39151
2023-05-06 05:36:04,823 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59002; closing.
2023-05-06 05:36:04,823 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:04,823 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35419
2023-05-06 05:36:04,823 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46489', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:04,823 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46489
2023-05-06 05:36:04,823 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37999
2023-05-06 05:36:04,824 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58970; closing.
2023-05-06 05:36:04,824 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36375. Reason: nanny-close
2023-05-06 05:36:04,824 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34715', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:04,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:04,824 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34715
2023-05-06 05:36:04,825 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59054; closing.
2023-05-06 05:36:04,825 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43423', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:04,825 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43423
2023-05-06 05:36:04,826 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:04,826 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35419
2023-05-06 05:36:04,826 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37999
2023-05-06 05:36:04,826 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40987
2023-05-06 05:36:04,827 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39151
2023-05-06 05:36:04,827 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46489
2023-05-06 05:36:04,827 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34715
2023-05-06 05:36:04,827 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43423
2023-05-06 05:36:04,828 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59044; closing.
2023-05-06 05:36:04,828 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:04,828 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36375', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:04,828 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36375
2023-05-06 05:36:04,828 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:36:04,829 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:06,081 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:36:06,081 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:36:06,082 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:36:06,083 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:36:06,083 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-05-06 05:36:08,062 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:08,067 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35687 instead
  warnings.warn(
2023-05-06 05:36:08,071 - distributed.scheduler - INFO - State start
2023-05-06 05:36:08,092 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:08,094 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:36:08,094 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35687/status
2023-05-06 05:36:08,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33407'
2023-05-06 05:36:09,207 - distributed.scheduler - INFO - Receive client connection: Client-e5d242d4-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:09,222 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59160
2023-05-06 05:36:09,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:09,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:09,924 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:10,932 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37741
2023-05-06 05:36:10,933 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37741
2023-05-06 05:36:10,933 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-05-06 05:36:10,933 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:10,933 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:10,933 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:10,933 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-05-06 05:36:10,933 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xiklke25
2023-05-06 05:36:10,933 - distributed.worker - INFO - Starting Worker plugin RMMSetup-44cb602b-8e3e-494d-a120-78ab8bab7b70
2023-05-06 05:36:10,933 - distributed.worker - INFO - Starting Worker plugin PreImport-a472933a-49ba-4ad6-b5cc-8735f80ff30a
2023-05-06 05:36:10,934 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-810567e6-244d-4633-aca8-55b6c13cbd86
2023-05-06 05:36:10,934 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:10,959 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37741', status: init, memory: 0, processing: 0>
2023-05-06 05:36:10,960 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37741
2023-05-06 05:36:10,960 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59184
2023-05-06 05:36:10,961 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:10,961 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:10,963 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:11,059 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:11,062 - distributed.scheduler - INFO - Remove client Client-e5d242d4-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:11,062 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59160; closing.
2023-05-06 05:36:11,063 - distributed.scheduler - INFO - Remove client Client-e5d242d4-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:11,063 - distributed.scheduler - INFO - Close client connection: Client-e5d242d4-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:11,064 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33407'. Reason: nanny-close
2023-05-06 05:36:11,064 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:11,065 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37741. Reason: nanny-close
2023-05-06 05:36:11,067 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:11,067 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59184; closing.
2023-05-06 05:36:11,067 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37741', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:11,067 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37741
2023-05-06 05:36:11,067 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:36:11,068 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:12,030 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:36:12,030 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:36:12,031 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:36:12,032 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:36:12,032 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-05-06 05:36:15,719 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:15,723 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34161 instead
  warnings.warn(
2023-05-06 05:36:15,726 - distributed.scheduler - INFO - State start
2023-05-06 05:36:15,746 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:15,746 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:36:15,747 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34161/status
2023-05-06 05:36:15,849 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37945'
2023-05-06 05:36:17,041 - distributed.scheduler - INFO - Receive client connection: Client-ea6a325d-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:17,054 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49792
2023-05-06 05:36:17,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:17,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:17,461 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:18,137 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44159
2023-05-06 05:36:18,137 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44159
2023-05-06 05:36:18,137 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36077
2023-05-06 05:36:18,137 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:18,137 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:18,137 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:18,138 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-05-06 05:36:18,138 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ytmtfs0c
2023-05-06 05:36:18,138 - distributed.worker - INFO - Starting Worker plugin RMMSetup-572c938a-9005-4897-9914-18aeed9c425f
2023-05-06 05:36:18,138 - distributed.worker - INFO - Starting Worker plugin PreImport-afcfd140-9e7e-48e5-8df7-cad79ae646f0
2023-05-06 05:36:18,249 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e3ce6331-4183-4d28-a990-a0d407d2ea9d
2023-05-06 05:36:18,250 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:18,277 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44159', status: init, memory: 0, processing: 0>
2023-05-06 05:36:18,278 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44159
2023-05-06 05:36:18,278 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49816
2023-05-06 05:36:18,279 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:18,279 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:18,280 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:18,387 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:18,389 - distributed.scheduler - INFO - Remove client Client-ea6a325d-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:18,390 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49792; closing.
2023-05-06 05:36:18,390 - distributed.scheduler - INFO - Remove client Client-ea6a325d-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:18,390 - distributed.scheduler - INFO - Close client connection: Client-ea6a325d-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:18,391 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37945'. Reason: nanny-close
2023-05-06 05:36:18,392 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:18,393 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44159. Reason: nanny-close
2023-05-06 05:36:18,395 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:18,395 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49816; closing.
2023-05-06 05:36:18,395 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44159', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:18,396 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44159
2023-05-06 05:36:18,396 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:36:18,397 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:19,357 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:36:19,358 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:36:19,358 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:36:19,359 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:36:19,359 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-05-06 05:36:21,320 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:21,324 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35047 instead
  warnings.warn(
2023-05-06 05:36:21,328 - distributed.scheduler - INFO - State start
2023-05-06 05:36:21,349 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:21,350 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:36:21,350 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35047/status
2023-05-06 05:36:24,798 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:36:24,798 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:36:24,799 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:36:24,799 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:36:24,800 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-05-06 05:36:26,826 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:26,830 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39567 instead
  warnings.warn(
2023-05-06 05:36:26,834 - distributed.scheduler - INFO - State start
2023-05-06 05:36:26,853 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:26,854 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-05-06 05:36:26,854 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39567/status
2023-05-06 05:36:26,994 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35749'
2023-05-06 05:36:28,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:28,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:28,412 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:28,736 - distributed.scheduler - INFO - Receive client connection: Client-f0fc1777-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:28,751 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60660
2023-05-06 05:36:29,073 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41019
2023-05-06 05:36:29,073 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41019
2023-05-06 05:36:29,073 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46511
2023-05-06 05:36:29,073 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-05-06 05:36:29,073 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:29,073 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:29,073 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-05-06 05:36:29,073 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ihg15pqu
2023-05-06 05:36:29,074 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-013a3adc-f9ab-4093-9ba8-6377c4bcfecb
2023-05-06 05:36:29,074 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0bbd8d42-029e-4928-af4c-f855cbdd4b76
2023-05-06 05:36:29,074 - distributed.worker - INFO - Starting Worker plugin PreImport-c450d66d-0399-4547-b581-fac3acdb55e0
2023-05-06 05:36:29,074 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:29,096 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41019', status: init, memory: 0, processing: 0>
2023-05-06 05:36:29,097 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41019
2023-05-06 05:36:29,097 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60672
2023-05-06 05:36:29,098 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-05-06 05:36:29,098 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:29,100 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-05-06 05:36:29,169 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:29,172 - distributed.scheduler - INFO - Remove client Client-f0fc1777-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:29,172 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60660; closing.
2023-05-06 05:36:29,172 - distributed.scheduler - INFO - Remove client Client-f0fc1777-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:29,173 - distributed.scheduler - INFO - Close client connection: Client-f0fc1777-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:29,174 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35749'. Reason: nanny-close
2023-05-06 05:36:29,174 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:29,175 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41019. Reason: nanny-close
2023-05-06 05:36:29,177 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-05-06 05:36:29,177 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60672; closing.
2023-05-06 05:36:29,177 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41019', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:29,177 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41019
2023-05-06 05:36:29,178 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:36:29,178 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:30,140 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:36:30,140 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:36:30,141 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:36:30,142 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-05-06 05:36:30,142 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-05-06 05:36:32,126 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:32,130 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34097 instead
  warnings.warn(
2023-05-06 05:36:32,134 - distributed.scheduler - INFO - State start
2023-05-06 05:36:32,155 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:32,156 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:36:32,156 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34097/status
2023-05-06 05:36:32,377 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44943'
2023-05-06 05:36:32,394 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42281'
2023-05-06 05:36:32,396 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44213'
2023-05-06 05:36:32,404 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34723'
2023-05-06 05:36:32,412 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41143'
2023-05-06 05:36:32,420 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33493'
2023-05-06 05:36:32,428 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41149'
2023-05-06 05:36:32,436 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44143'
2023-05-06 05:36:33,804 - distributed.scheduler - INFO - Receive client connection: Client-f4214629-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:33,817 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39824
2023-05-06 05:36:34,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:34,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:34,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:34,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:34,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:34,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:34,088 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:34,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:34,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:34,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:34,106 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:34,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:34,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:34,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:34,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:34,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:34,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:34,116 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:34,124 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:34,127 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:34,146 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:34,156 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:34,158 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:34,159 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:35,977 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33763
2023-05-06 05:36:35,977 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33763
2023-05-06 05:36:35,977 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45703
2023-05-06 05:36:35,977 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:35,977 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:35,977 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:35,977 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:35,978 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-je5qk3x_
2023-05-06 05:36:35,978 - distributed.worker - INFO - Starting Worker plugin RMMSetup-16108d1b-56bc-4659-aa3e-7b7eab0636a0
2023-05-06 05:36:35,990 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40619
2023-05-06 05:36:35,990 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40619
2023-05-06 05:36:35,990 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46739
2023-05-06 05:36:35,991 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:35,991 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:35,991 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:35,991 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:35,991 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lis4nzr7
2023-05-06 05:36:35,991 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33639
2023-05-06 05:36:35,991 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33639
2023-05-06 05:36:35,991 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a0eebb5d-2e1c-4428-a848-62c9c3ead413
2023-05-06 05:36:35,991 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39141
2023-05-06 05:36:35,991 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:35,991 - distributed.worker - INFO - Starting Worker plugin RMMSetup-560e3722-fea0-43c0-8a39-1a622a920205
2023-05-06 05:36:35,991 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:35,991 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:35,991 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:35,991 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3y_8ewi5
2023-05-06 05:36:35,992 - distributed.worker - INFO - Starting Worker plugin RMMSetup-517ee988-c5fc-4987-a668-0bcf1b423f4c
2023-05-06 05:36:35,995 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45143
2023-05-06 05:36:35,995 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45143
2023-05-06 05:36:35,995 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45587
2023-05-06 05:36:35,995 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38401
2023-05-06 05:36:35,995 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45587
2023-05-06 05:36:35,995 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:35,995 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:35,995 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37629
2023-05-06 05:36:35,995 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:35,995 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:35,995 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:35,995 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:35,995 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6y4ecpfz
2023-05-06 05:36:35,995 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:35,995 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:35,996 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-30bjbak0
2023-05-06 05:36:35,996 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-138fa155-4e56-4375-a779-c47a1094444b
2023-05-06 05:36:35,996 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d7d57156-12c4-4194-ab52-634e7e7c48a9
2023-05-06 05:36:35,996 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7193cc45-a795-4b80-8fca-376fc85115bf
2023-05-06 05:36:35,996 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ae66bcbd-3efa-4045-b168-ba94bf12ed40
2023-05-06 05:36:36,014 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40399
2023-05-06 05:36:36,014 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40399
2023-05-06 05:36:36,014 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38463
2023-05-06 05:36:36,014 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,014 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,014 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:36,014 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:36,014 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-parpuk9n
2023-05-06 05:36:36,015 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c6443cc7-d40a-45e0-b6c6-9dbf94568f54
2023-05-06 05:36:36,015 - distributed.worker - INFO - Starting Worker plugin PreImport-18051856-5aae-4b50-91bb-7b65c0eaff42
2023-05-06 05:36:36,015 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f998f518-3ecb-4d85-a83f-d105d1e6c659
2023-05-06 05:36:36,025 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39309
2023-05-06 05:36:36,025 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39309
2023-05-06 05:36:36,025 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33395
2023-05-06 05:36:36,025 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36609
2023-05-06 05:36:36,025 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33395
2023-05-06 05:36:36,025 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,025 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,025 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46253
2023-05-06 05:36:36,025 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:36,025 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,025 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:36,025 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,025 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-94aq2jih
2023-05-06 05:36:36,025 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:36,025 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-05-06 05:36:36,025 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gjunx6q7
2023-05-06 05:36:36,026 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-84d78063-9c41-4f2d-8f63-d60d15d4d634
2023-05-06 05:36:36,026 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3251c28a-1d68-4251-a30c-988372be2961
2023-05-06 05:36:36,027 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9ecf1dea-769a-452f-a704-8cc8b9f876f3
2023-05-06 05:36:36,028 - distributed.worker - INFO - Starting Worker plugin PreImport-6fb3b4d3-8039-4476-95a6-8934f15c21b7
2023-05-06 05:36:36,028 - distributed.worker - INFO - Starting Worker plugin RMMSetup-648f334f-97a3-4bcc-82e8-3253a5b0ecc2
2023-05-06 05:36:36,149 - distributed.worker - INFO - Starting Worker plugin PreImport-0d814ee6-e48e-4963-9758-340493b01526
2023-05-06 05:36:36,150 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,159 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,159 - distributed.worker - INFO - Starting Worker plugin PreImport-e4b30bfa-a53f-47fe-bde9-4580ee170469
2023-05-06 05:36:36,160 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,160 - distributed.worker - INFO - Starting Worker plugin PreImport-225ffa22-4918-4a5d-a413-280968c2e17f
2023-05-06 05:36:36,160 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,172 - distributed.worker - INFO - Starting Worker plugin PreImport-df525a9b-b698-4c3c-9639-e0127611ad2c
2023-05-06 05:36:36,172 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,175 - distributed.worker - INFO - Starting Worker plugin PreImport-d8a7ba0e-979b-4d22-a1a6-99347c26998f
2023-05-06 05:36:36,175 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e030495a-6b17-4666-9edb-329adcc3cf80
2023-05-06 05:36:36,176 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,182 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6ff62ece-7d04-48f0-999a-e6104ba712d9
2023-05-06 05:36:36,182 - distributed.worker - INFO - Starting Worker plugin PreImport-b2de3943-5921-4c12-94c1-f27f83846118
2023-05-06 05:36:36,183 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,189 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40619', status: init, memory: 0, processing: 0>
2023-05-06 05:36:36,191 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40619
2023-05-06 05:36:36,191 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45444
2023-05-06 05:36:36,191 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45143', status: init, memory: 0, processing: 0>
2023-05-06 05:36:36,191 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,192 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,192 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45143
2023-05-06 05:36:36,192 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45472
2023-05-06 05:36:36,192 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,192 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,193 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,193 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33395', status: init, memory: 0, processing: 0>
2023-05-06 05:36:36,194 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33395
2023-05-06 05:36:36,194 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45480
2023-05-06 05:36:36,195 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:36,194 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,195 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:36,195 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,195 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40399', status: init, memory: 0, processing: 0>
2023-05-06 05:36:36,196 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40399
2023-05-06 05:36:36,196 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45456
2023-05-06 05:36:36,196 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:36,196 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,197 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,199 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:36,205 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45587', status: init, memory: 0, processing: 0>
2023-05-06 05:36:36,205 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45587
2023-05-06 05:36:36,205 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45484
2023-05-06 05:36:36,206 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,206 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,208 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:36,208 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33639', status: init, memory: 0, processing: 0>
2023-05-06 05:36:36,209 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33639
2023-05-06 05:36:36,209 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45496
2023-05-06 05:36:36,209 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,210 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,212 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:36,222 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33763', status: init, memory: 0, processing: 0>
2023-05-06 05:36:36,223 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33763
2023-05-06 05:36:36,223 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45510
2023-05-06 05:36:36,223 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,224 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,224 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39309', status: init, memory: 0, processing: 0>
2023-05-06 05:36:36,224 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39309
2023-05-06 05:36:36,224 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45518
2023-05-06 05:36:36,225 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:36,225 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:36,226 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:36,226 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:36,278 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:36,279 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:36,279 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:36,279 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:36,279 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:36,279 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:36,279 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:36,280 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-05-06 05:36:36,294 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:36,294 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:36,294 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:36,294 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:36,294 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:36,294 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:36,294 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:36,295 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:36,298 - distributed.scheduler - INFO - Remove client Client-f4214629-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:36,298 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39824; closing.
2023-05-06 05:36:36,299 - distributed.scheduler - INFO - Remove client Client-f4214629-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:36,299 - distributed.scheduler - INFO - Close client connection: Client-f4214629-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:36,300 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34723'. Reason: nanny-close
2023-05-06 05:36:36,301 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:36,301 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44943'. Reason: nanny-close
2023-05-06 05:36:36,302 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:36,302 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33763. Reason: nanny-close
2023-05-06 05:36:36,302 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42281'. Reason: nanny-close
2023-05-06 05:36:36,303 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:36,303 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44213'. Reason: nanny-close
2023-05-06 05:36:36,303 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33639. Reason: nanny-close
2023-05-06 05:36:36,304 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:36,304 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45587. Reason: nanny-close
2023-05-06 05:36:36,304 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41143'. Reason: nanny-close
2023-05-06 05:36:36,304 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:36,305 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45143. Reason: nanny-close
2023-05-06 05:36:36,305 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33493'. Reason: nanny-close
2023-05-06 05:36:36,305 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:36,305 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:36,305 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45510; closing.
2023-05-06 05:36:36,305 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:36,305 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40399. Reason: nanny-close
2023-05-06 05:36:36,305 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41149'. Reason: nanny-close
2023-05-06 05:36:36,305 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45496; closing.
2023-05-06 05:36:36,306 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33763', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:36,306 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:36,306 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:36,306 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33763
2023-05-06 05:36:36,306 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40619. Reason: nanny-close
2023-05-06 05:36:36,306 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44143'. Reason: nanny-close
2023-05-06 05:36:36,306 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:36,306 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33639', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:36,306 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:36,306 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:36,306 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33639
2023-05-06 05:36:36,306 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33395. Reason: nanny-close
2023-05-06 05:36:36,306 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:36,307 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:36,307 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:36,307 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45484; closing.
2023-05-06 05:36:36,307 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:36,307 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39309. Reason: nanny-close
2023-05-06 05:36:36,308 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45587', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:36,308 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33763
2023-05-06 05:36:36,308 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45587
2023-05-06 05:36:36,308 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33639
2023-05-06 05:36:36,308 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33763
2023-05-06 05:36:36,308 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:36,308 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45472; closing.
2023-05-06 05:36:36,308 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33639
2023-05-06 05:36:36,309 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:36,309 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33763
2023-05-06 05:36:36,309 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:36,309 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33639
2023-05-06 05:36:36,309 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45143', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:36,309 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45143
2023-05-06 05:36:36,309 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:36,310 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45456; closing.
2023-05-06 05:36:36,310 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:36,310 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40399', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:36,310 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40399
2023-05-06 05:36:36,311 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:36,311 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45480; closing.
2023-05-06 05:36:36,311 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:36,311 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45444; closing.
2023-05-06 05:36:36,311 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33395', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:36,312 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33395
2023-05-06 05:36:36,312 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40619', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:36,312 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40619
2023-05-06 05:36:36,312 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45518; closing.
2023-05-06 05:36:36,313 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39309', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:36,313 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39309
2023-05-06 05:36:36,313 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:36:37,668 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:36:37,668 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:36:37,668 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:36:37,669 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:36:37,670 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-05-06 05:36:39,485 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:39,489 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40095 instead
  warnings.warn(
2023-05-06 05:36:39,492 - distributed.scheduler - INFO - State start
2023-05-06 05:36:39,511 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:39,512 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:36:39,512 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40095/status
2023-05-06 05:36:39,695 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38509'
2023-05-06 05:36:40,876 - distributed.scheduler - INFO - Receive client connection: Client-f8a0ecff-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:40,893 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45618
2023-05-06 05:36:41,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:41,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:41,164 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:41,771 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36769
2023-05-06 05:36:41,771 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36769
2023-05-06 05:36:41,771 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42873
2023-05-06 05:36:41,771 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:41,771 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:41,771 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:41,771 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-05-06 05:36:41,771 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-amrlk_a1
2023-05-06 05:36:41,772 - distributed.worker - INFO - Starting Worker plugin RMMSetup-45edd674-69ed-4b25-81ff-0e885442f649
2023-05-06 05:36:41,873 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1d504f08-d688-46c5-9ebe-8d52aa5b4a44
2023-05-06 05:36:41,873 - distributed.worker - INFO - Starting Worker plugin PreImport-91e8f7db-df2f-4998-8d1c-89ac9abae098
2023-05-06 05:36:41,873 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:41,899 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36769', status: init, memory: 0, processing: 0>
2023-05-06 05:36:41,900 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36769
2023-05-06 05:36:41,900 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45642
2023-05-06 05:36:41,900 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:41,901 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:41,902 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:41,914 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:36:41,918 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:41,919 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:41,922 - distributed.scheduler - INFO - Remove client Client-f8a0ecff-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:41,922 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45618; closing.
2023-05-06 05:36:41,922 - distributed.scheduler - INFO - Remove client Client-f8a0ecff-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:41,922 - distributed.scheduler - INFO - Close client connection: Client-f8a0ecff-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:41,924 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38509'. Reason: nanny-close
2023-05-06 05:36:41,926 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:41,927 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36769. Reason: nanny-close
2023-05-06 05:36:41,928 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:41,928 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45642; closing.
2023-05-06 05:36:41,929 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36769', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:41,929 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36769
2023-05-06 05:36:41,929 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:36:41,929 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:42,840 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:36:42,840 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:36:42,840 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:36:42,841 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:36:42,842 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-05-06 05:36:44,858 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:44,863 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36231 instead
  warnings.warn(
2023-05-06 05:36:44,867 - distributed.scheduler - INFO - State start
2023-05-06 05:36:44,887 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-06 05:36:44,888 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-06 05:36:44,889 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36231/status
2023-05-06 05:36:45,004 - distributed.scheduler - INFO - Receive client connection: Client-fbc1ca0e-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:45,020 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49152
2023-05-06 05:36:45,045 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46167'
2023-05-06 05:36:46,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:46,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:46,478 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-06 05:36:47,134 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35977
2023-05-06 05:36:47,134 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35977
2023-05-06 05:36:47,134 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42215
2023-05-06 05:36:47,134 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-05-06 05:36:47,134 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:47,134 - distributed.worker - INFO -               Threads:                          1
2023-05-06 05:36:47,134 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-05-06 05:36:47,134 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tu6ypn2x
2023-05-06 05:36:47,135 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0af11a54-aa13-4686-b5a2-2f6213276815
2023-05-06 05:36:47,240 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a70be1c9-452b-4676-bb81-a77d5f37c25f
2023-05-06 05:36:47,241 - distributed.worker - INFO - Starting Worker plugin PreImport-d82af9a0-c4f7-4cd1-acd6-c2ee9e83edfd
2023-05-06 05:36:47,241 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:47,286 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35977', status: init, memory: 0, processing: 0>
2023-05-06 05:36:47,287 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35977
2023-05-06 05:36:47,287 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49176
2023-05-06 05:36:47,287 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-05-06 05:36:47,288 - distributed.worker - INFO - -------------------------------------------------
2023-05-06 05:36:47,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-05-06 05:36:47,365 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-05-06 05:36:47,369 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-05-06 05:36:47,373 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:47,374 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-05-06 05:36:47,377 - distributed.scheduler - INFO - Remove client Client-fbc1ca0e-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:47,377 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49152; closing.
2023-05-06 05:36:47,377 - distributed.scheduler - INFO - Remove client Client-fbc1ca0e-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:47,377 - distributed.scheduler - INFO - Close client connection: Client-fbc1ca0e-ebcf-11ed-a381-d8c49764f6bb
2023-05-06 05:36:47,378 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46167'. Reason: nanny-close
2023-05-06 05:36:47,378 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-06 05:36:47,380 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35977. Reason: nanny-close
2023-05-06 05:36:47,381 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-05-06 05:36:47,381 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49176; closing.
2023-05-06 05:36:47,382 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35977', status: closing, memory: 0, processing: 0>
2023-05-06 05:36:47,382 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35977
2023-05-06 05:36:47,382 - distributed.scheduler - INFO - Lost all workers
2023-05-06 05:36:47,383 - distributed.nanny - INFO - Worker closed
2023-05-06 05:36:48,344 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-06 05:36:48,345 - distributed.scheduler - INFO - Scheduler closing...
2023-05-06 05:36:48,345 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-06 05:36:48,346 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-06 05:36:48,346 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] FAILED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41609 instead
  warnings.warn(
2023-05-06 05:36:57,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:57,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:57,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:57,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:57,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:57,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:57,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:57,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:57,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:57,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:57,591 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:57,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:57,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:57,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:36:57,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:36:57,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41807 instead
  warnings.warn(
2023-05-06 05:37:05,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:05,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:05,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:05,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:05,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:05,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:05,549 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:05,549 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:05,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:05,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:05,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:05,561 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:05,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:05,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:05,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:05,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33705 instead
  warnings.warn(
2023-05-06 05:37:12,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:12,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:12,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:12,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:12,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:12,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:12,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:12,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:12,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:12,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:12,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:12,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:12,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:12,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:12,701 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:12,701 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44765 instead
  warnings.warn(
2023-05-06 05:37:20,392 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:20,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:20,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:20,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:20,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:20,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:20,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:20,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:20,638 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:20,638 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:20,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:20,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:20,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:20,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:20,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:20,656 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:23,468 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f70429f6100, tag: 0x54dc9ea34e1e8df, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1244, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1265, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f70429f6100, tag: 0x54dc9ea34e1e8df, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-06 05:37:23,483 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1244, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1262, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-05-06 05:37:23,487 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1244, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1262, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
Task exception was never retrieved
future: <Task finished name='Task-218' coro=<UCX.read() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py:750> exception=CommClosedError('Connection closed by writer.\nInner exception: CancelledError()')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CancelledError()
Task exception was never retrieved
future: <Task finished name='Task-215' coro=<UCX.read() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py:750> exception=CommClosedError('Connection closed by writer.\nInner exception: CancelledError()')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CancelledError()
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36069 instead
  warnings.warn(
2023-05-06 05:37:29,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:29,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:29,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:29,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:29,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:29,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:29,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:29,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:29,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:29,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:29,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:29,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:29,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:29,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:29,437 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:29,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35729 instead
  warnings.warn(
2023-05-06 05:37:38,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:38,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:38,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:38,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:38,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:38,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:38,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:38,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:38,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:38,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:38,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:38,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:38,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:38,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:38,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:38,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38719 instead
  warnings.warn(
2023-05-06 05:37:47,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:47,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:48,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:48,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:48,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:48,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:48,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:48,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:48,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:48,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:48,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:48,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:48,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:48,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:48,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:48,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:51,339 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #006] ep: 0x7f31c59240c0, tag: 0xe1f9b9c547a3c149, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1244, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1265, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #006] ep: 0x7f31c59240c0, tag: 0xe1f9b9c547a3c149, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46315 instead
  warnings.warn(
2023-05-06 05:37:57,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:57,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:57,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:57,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:57,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:57,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:57,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:57,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:57,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:57,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:57,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:57,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:57,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:57,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:37:57,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-06 05:37:57,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-06 05:38:00,420 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1244, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1265, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.33.225.163:53640 remote=tcp://10.33.225.163:37665>: Stream is closed
2023-05-06 05:38:00,424 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://10.33.225.163:35759'.
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34127 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43619 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37971 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46023 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40349 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36557 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37763 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38075 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34355 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35435 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35865 instead
  warnings.warn(
2023-05-06 05:42:36,283 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-8f6d6976-bc74-4a7d-8939-cd079e8e5c08
Function:  _run_coroutine_on_worker
args:      (313209097936619662714089697783943651124, <function shuffle_task at 0x7f11e5b74940>, ('explicit-comms-shuffle-8a9c181b2d24bc345fc4f6aca80171aa', {0: {"('from_pandas-eaba71b388f24e387b93842f216e4045', 0)", "('from_pandas-eaba71b388f24e387b93842f216e4045', 4)"}, 1: {"('from_pandas-eaba71b388f24e387b93842f216e4045', 2)"}, 2: {"('from_pandas-eaba71b388f24e387b93842f216e4045', 1)"}, 3: {"('from_pandas-eaba71b388f24e387b93842f216e4045', 3)"}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 24 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
