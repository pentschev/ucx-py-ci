============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-11 06:32:08,268 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:08,273 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40841 instead
  warnings.warn(
2024-01-11 06:32:08,279 - distributed.scheduler - INFO - State start
2024-01-11 06:32:08,303 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:08,305 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-11 06:32:08,306 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40841/status
2024-01-11 06:32:08,306 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:32:08,384 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46687'
2024-01-11 06:32:08,406 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44455'
2024-01-11 06:32:08,410 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44507'
2024-01-11 06:32:08,418 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38945'
2024-01-11 06:32:10,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:10,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:10,224 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:10,225 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35963
2024-01-11 06:32:10,225 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35963
2024-01-11 06:32:10,225 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43359
2024-01-11 06:32:10,225 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-11 06:32:10,225 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,225 - distributed.worker - INFO -               Threads:                          4
2024-01-11 06:32:10,225 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-11 06:32:10,225 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-jlm3aj6o
2024-01-11 06:32:10,225 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ce801984-c3b4-4ffc-a14d-92cea03f1a9d
2024-01-11 06:32:10,225 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8712b90b-bda0-47a2-8a98-e378aa6e92a8
2024-01-11 06:32:10,226 - distributed.worker - INFO - Starting Worker plugin PreImport-aac12d16-04d3-416b-b51d-541825b8a933
2024-01-11 06:32:10,226 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:10,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:10,245 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:10,246 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46731
2024-01-11 06:32:10,246 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46731
2024-01-11 06:32:10,246 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36445
2024-01-11 06:32:10,246 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-11 06:32:10,246 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,247 - distributed.worker - INFO -               Threads:                          4
2024-01-11 06:32:10,247 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-11 06:32:10,247 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-52myohwg
2024-01-11 06:32:10,247 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0cc13e89-d0a9-4e11-aa90-da61f214fdd5
2024-01-11 06:32:10,247 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bdc9fb3c-079f-4af8-ba3b-5ee237b19eac
2024-01-11 06:32:10,247 - distributed.worker - INFO - Starting Worker plugin PreImport-929cd2c6-b4d0-49be-b486-30098addb67e
2024-01-11 06:32:10,248 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,276 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35963', status: init, memory: 0, processing: 0>
2024-01-11 06:32:10,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:10,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:10,287 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:10,288 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35681
2024-01-11 06:32:10,288 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35681
2024-01-11 06:32:10,288 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37555
2024-01-11 06:32:10,288 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-11 06:32:10,288 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,288 - distributed.worker - INFO -               Threads:                          4
2024-01-11 06:32:10,289 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-11 06:32:10,289 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-2mb2lvv9
2024-01-11 06:32:10,289 - distributed.worker - INFO - Starting Worker plugin RMMSetup-60e7f82c-8ae4-4eb4-bf63-279ecf3f6ea3
2024-01-11 06:32:10,289 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8f66e833-a0b9-4a04-87c5-f4e100da2c55
2024-01-11 06:32:10,291 - distributed.worker - INFO - Starting Worker plugin PreImport-c373a36d-3cf8-4794-ab68-8abb254e7631
2024-01-11 06:32:10,291 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,301 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35963
2024-01-11 06:32:10,301 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45018
2024-01-11 06:32:10,301 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:10,302 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-11 06:32:10,302 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,304 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-11 06:32:10,305 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46731', status: init, memory: 0, processing: 0>
2024-01-11 06:32:10,305 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46731
2024-01-11 06:32:10,305 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45028
2024-01-11 06:32:10,306 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:10,308 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-11 06:32:10,308 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,309 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:10,309 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:10,309 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-11 06:32:10,314 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:10,315 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43725
2024-01-11 06:32:10,315 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43725
2024-01-11 06:32:10,315 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42437
2024-01-11 06:32:10,315 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-11 06:32:10,315 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,315 - distributed.worker - INFO -               Threads:                          4
2024-01-11 06:32:10,315 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-11 06:32:10,315 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-zaqzj59f
2024-01-11 06:32:10,315 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e8030340-c6b6-412f-9dbc-4cd4ae6ce9d0
2024-01-11 06:32:10,315 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cd284962-9ec9-4774-8e9c-6a1388325558
2024-01-11 06:32:10,315 - distributed.worker - INFO - Starting Worker plugin PreImport-f2222a28-573d-4856-b645-2d43ec4b9cbd
2024-01-11 06:32:10,316 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,376 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35681', status: init, memory: 0, processing: 0>
2024-01-11 06:32:10,383 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35681
2024-01-11 06:32:10,383 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45034
2024-01-11 06:32:10,391 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:10,393 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-11 06:32:10,397 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,399 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-11 06:32:10,402 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43725', status: init, memory: 0, processing: 0>
2024-01-11 06:32:10,403 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43725
2024-01-11 06:32:10,404 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:10,406 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-11 06:32:10,406 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45036
2024-01-11 06:32:10,407 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:10,409 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-11 06:32:13,118 - distributed.scheduler - INFO - Receive client connection: Client-23a29589-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:13,119 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45084
2024-01-11 06:32:13,128 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-11 06:32:13,128 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-11 06:32:13,128 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-11 06:32:13,543 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-11 06:32:13,548 - distributed.scheduler - INFO - Remove client Client-23a29589-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:13,548 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45084; closing.
2024-01-11 06:32:13,549 - distributed.scheduler - INFO - Remove client Client-23a29589-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:13,549 - distributed.scheduler - INFO - Close client connection: Client-23a29589-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:13,550 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46687'. Reason: nanny-close
2024-01-11 06:32:13,550 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:13,551 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44455'. Reason: nanny-close
2024-01-11 06:32:13,551 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:13,551 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44507'. Reason: nanny-close
2024-01-11 06:32:13,551 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46731. Reason: nanny-close
2024-01-11 06:32:13,552 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:13,552 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38945'. Reason: nanny-close
2024-01-11 06:32:13,552 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:13,552 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35963. Reason: nanny-close
2024-01-11 06:32:13,552 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43725. Reason: nanny-close
2024-01-11 06:32:13,553 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35681. Reason: nanny-close
2024-01-11 06:32:13,554 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45028; closing.
2024-01-11 06:32:13,554 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-11 06:32:13,554 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46731', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954733.5545518')
2024-01-11 06:32:13,555 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-11 06:32:13,555 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45034; closing.
2024-01-11 06:32:13,555 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-11 06:32:13,555 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-11 06:32:13,555 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:13,556 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35681', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954733.55657')
2024-01-11 06:32:13,556 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:13,556 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45036; closing.
2024-01-11 06:32:13,557 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45018; closing.
2024-01-11 06:32:13,557 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:13,557 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:13,557 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43725', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954733.5576127')
2024-01-11 06:32:13,558 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35963', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954733.5579672')
2024-01-11 06:32:13,558 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:32:14,265 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:32:14,266 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:32:14,266 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:32:14,268 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-11 06:32:14,268 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-11 06:32:16,751 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:16,756 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34779 instead
  warnings.warn(
2024-01-11 06:32:16,760 - distributed.scheduler - INFO - State start
2024-01-11 06:32:16,783 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:16,784 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-11 06:32:16,785 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34779/status
2024-01-11 06:32:16,785 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:32:17,029 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43517'
2024-01-11 06:32:17,042 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39305'
2024-01-11 06:32:17,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45033'
2024-01-11 06:32:17,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40705'
2024-01-11 06:32:17,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40829'
2024-01-11 06:32:17,075 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38581'
2024-01-11 06:32:17,084 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40363'
2024-01-11 06:32:17,093 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43399'
2024-01-11 06:32:18,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:18,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:18,972 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:18,973 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39737
2024-01-11 06:32:18,973 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39737
2024-01-11 06:32:18,973 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43505
2024-01-11 06:32:18,973 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:18,973 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:18,973 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:18,973 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:18,973 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0_tiixb5
2024-01-11 06:32:18,973 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c52393ad-52ab-4c4c-bfc9-d3c3e7cd745c
2024-01-11 06:32:18,974 - distributed.worker - INFO - Starting Worker plugin PreImport-f2c1e74a-6fd7-44ca-b76c-b571b1fae623
2024-01-11 06:32:18,974 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7ea719c3-d3f0-4ae5-80d9-a85cb83a80c0
2024-01-11 06:32:18,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:18,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:18,997 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:18,998 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35743
2024-01-11 06:32:18,998 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35743
2024-01-11 06:32:18,998 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35305
2024-01-11 06:32:18,998 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:18,998 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:18,998 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:18,998 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:18,998 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8ny5h5by
2024-01-11 06:32:18,998 - distributed.worker - INFO - Starting Worker plugin PreImport-ffc8fca6-0d2e-47ab-a26f-e0844a870032
2024-01-11 06:32:18,999 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8c5d0e3a-055d-4124-a4d3-75398cc7e545
2024-01-11 06:32:18,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:18,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:19,004 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:19,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:19,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:19,005 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38269
2024-01-11 06:32:19,005 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38269
2024-01-11 06:32:19,005 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40107
2024-01-11 06:32:19,005 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:19,005 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:19,005 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:19,005 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:19,005 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gyjobyjp
2024-01-11 06:32:19,005 - distributed.worker - INFO - Starting Worker plugin RMMSetup-edf9c945-04cc-4c04-989c-d889e13ca308
2024-01-11 06:32:19,009 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:19,009 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34245
2024-01-11 06:32:19,010 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34245
2024-01-11 06:32:19,010 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38161
2024-01-11 06:32:19,010 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:19,010 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:19,010 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:19,010 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:19,010 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-he3p75p3
2024-01-11 06:32:19,010 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d75c2b05-cd55-45e6-90de-ca5636acbe26
2024-01-11 06:32:19,011 - distributed.worker - INFO - Starting Worker plugin PreImport-e9dfdda4-5306-4d47-b53d-57f0163eaff4
2024-01-11 06:32:19,012 - distributed.worker - INFO - Starting Worker plugin RMMSetup-99c2ccea-fe7f-45c1-b1c8-949228977090
2024-01-11 06:32:19,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:19,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:19,024 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:19,025 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34557
2024-01-11 06:32:19,025 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34557
2024-01-11 06:32:19,025 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44113
2024-01-11 06:32:19,025 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:19,025 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:19,025 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:19,025 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:19,025 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f78yvhyy
2024-01-11 06:32:19,026 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-87375583-c94f-460d-b5c1-f14694f0cc34
2024-01-11 06:32:19,026 - distributed.worker - INFO - Starting Worker plugin PreImport-305b1f30-703c-4011-a7f7-c5f30a08a29c
2024-01-11 06:32:19,026 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8aba3284-19dc-420c-bf7e-4dcbd4780321
2024-01-11 06:32:19,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:19,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:19,076 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:19,076 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43377
2024-01-11 06:32:19,076 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43377
2024-01-11 06:32:19,076 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41719
2024-01-11 06:32:19,077 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:19,077 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:19,077 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:19,077 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:19,077 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r24kz7xq
2024-01-11 06:32:19,077 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9e2da216-f33f-4213-aacb-4302dfe9787a
2024-01-11 06:32:19,079 - distributed.worker - INFO - Starting Worker plugin PreImport-9e4b8803-2135-4653-be11-d8064f109e94
2024-01-11 06:32:19,080 - distributed.worker - INFO - Starting Worker plugin RMMSetup-686fa8db-c3ba-4d55-9164-6f85fcb0ee4f
2024-01-11 06:32:19,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:19,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:19,091 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:19,093 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44961
2024-01-11 06:32:19,093 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44961
2024-01-11 06:32:19,093 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33313
2024-01-11 06:32:19,093 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:19,093 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:19,093 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:19,093 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:19,093 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r8vvdhui
2024-01-11 06:32:19,093 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-71f07dae-dbc2-41b9-891a-912c436d6923
2024-01-11 06:32:19,094 - distributed.worker - INFO - Starting Worker plugin PreImport-725c8888-a461-4294-a822-1da4a691ee2a
2024-01-11 06:32:19,094 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1d8356e5-f48c-409e-8dc4-160e17f85a98
2024-01-11 06:32:19,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:19,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:19,113 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:19,114 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38113
2024-01-11 06:32:19,114 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38113
2024-01-11 06:32:19,114 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41957
2024-01-11 06:32:19,114 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:19,114 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:19,114 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:19,114 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:19,114 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wb9cfb5a
2024-01-11 06:32:19,115 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-28a1ed49-68ee-49f9-895d-5d6faa8b5373
2024-01-11 06:32:19,120 - distributed.worker - INFO - Starting Worker plugin PreImport-c4a3f406-f69a-4b0c-a84a-4ad966695a1c
2024-01-11 06:32:19,120 - distributed.worker - INFO - Starting Worker plugin RMMSetup-063a5187-bbdf-4392-919e-52f73a2673ba
2024-01-11 06:32:21,246 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,280 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39737', status: init, memory: 0, processing: 0>
2024-01-11 06:32:21,293 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39737
2024-01-11 06:32:21,293 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39100
2024-01-11 06:32:21,294 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:21,296 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:21,296 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,298 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:21,392 - distributed.worker - INFO - Starting Worker plugin PreImport-873d2f05-0612-4545-9aaa-9b2161e7f287
2024-01-11 06:32:21,393 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-23a2d204-ed1c-43df-baa1-e23e782587e5
2024-01-11 06:32:21,394 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,434 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38269', status: init, memory: 0, processing: 0>
2024-01-11 06:32:21,435 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38269
2024-01-11 06:32:21,435 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39108
2024-01-11 06:32:21,437 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:21,438 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:21,439 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,441 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:21,443 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,498 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34245', status: init, memory: 0, processing: 0>
2024-01-11 06:32:21,499 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34245
2024-01-11 06:32:21,499 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39118
2024-01-11 06:32:21,501 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:21,503 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:21,503 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,506 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:21,519 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5f026848-7390-4721-a141-34e436b72c62
2024-01-11 06:32:21,520 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,546 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,546 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35743', status: init, memory: 0, processing: 0>
2024-01-11 06:32:21,547 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35743
2024-01-11 06:32:21,547 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39132
2024-01-11 06:32:21,548 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:21,549 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:21,549 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,550 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:21,561 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,569 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44961', status: init, memory: 0, processing: 0>
2024-01-11 06:32:21,570 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44961
2024-01-11 06:32:21,570 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39148
2024-01-11 06:32:21,571 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:21,572 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:21,572 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,572 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,574 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:21,596 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38113', status: init, memory: 0, processing: 0>
2024-01-11 06:32:21,597 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38113
2024-01-11 06:32:21,597 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39158
2024-01-11 06:32:21,598 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:21,600 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:21,600 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,603 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:21,606 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43377', status: init, memory: 0, processing: 0>
2024-01-11 06:32:21,606 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43377
2024-01-11 06:32:21,606 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39174
2024-01-11 06:32:21,608 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:21,609 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:21,609 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,611 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:21,624 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,647 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34557', status: init, memory: 0, processing: 0>
2024-01-11 06:32:21,647 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34557
2024-01-11 06:32:21,647 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39184
2024-01-11 06:32:21,648 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:21,649 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:21,649 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:21,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:29,330 - distributed.scheduler - INFO - Receive client connection: Client-28b30969-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:29,331 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39272
2024-01-11 06:32:29,342 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:29,343 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:29,343 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:29,343 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:29,343 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:29,344 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:29,344 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:29,344 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:29,348 - distributed.scheduler - INFO - Remove client Client-28b30969-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:29,348 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39272; closing.
2024-01-11 06:32:29,348 - distributed.scheduler - INFO - Remove client Client-28b30969-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:29,349 - distributed.scheduler - INFO - Close client connection: Client-28b30969-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:29,350 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43517'. Reason: nanny-close
2024-01-11 06:32:29,351 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:29,351 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39305'. Reason: nanny-close
2024-01-11 06:32:29,352 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:29,352 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45033'. Reason: nanny-close
2024-01-11 06:32:29,352 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35743. Reason: nanny-close
2024-01-11 06:32:29,352 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:29,352 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40705'. Reason: nanny-close
2024-01-11 06:32:29,353 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34557. Reason: nanny-close
2024-01-11 06:32:29,353 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:29,353 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40829'. Reason: nanny-close
2024-01-11 06:32:29,353 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:29,353 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39737. Reason: nanny-close
2024-01-11 06:32:29,353 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38581'. Reason: nanny-close
2024-01-11 06:32:29,354 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:29,354 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40363'. Reason: nanny-close
2024-01-11 06:32:29,354 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34245. Reason: nanny-close
2024-01-11 06:32:29,354 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44961. Reason: nanny-close
2024-01-11 06:32:29,354 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:29,354 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43399'. Reason: nanny-close
2024-01-11 06:32:29,354 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38269. Reason: nanny-close
2024-01-11 06:32:29,354 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39184; closing.
2024-01-11 06:32:29,354 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:29,354 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:29,355 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:29,355 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34557', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954749.355087')
2024-01-11 06:32:29,355 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39132; closing.
2024-01-11 06:32:29,355 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43377. Reason: nanny-close
2024-01-11 06:32:29,356 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35743', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954749.35615')
2024-01-11 06:32:29,356 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38113. Reason: nanny-close
2024-01-11 06:32:29,356 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:29,356 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:29,357 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:29,357 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:29,357 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:29,357 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39100; closing.
2024-01-11 06:32:29,358 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:29,358 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:29,359 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:29,359 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:29,359 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:29,359 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:29,358 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39132>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-11 06:32:29,360 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:29,360 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39737', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954749.3606062')
2024-01-11 06:32:29,361 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39148; closing.
2024-01-11 06:32:29,361 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39108; closing.
2024-01-11 06:32:29,361 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39118; closing.
2024-01-11 06:32:29,361 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:29,362 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:29,362 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44961', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954749.362153')
2024-01-11 06:32:29,362 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38269', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954749.3624635')
2024-01-11 06:32:29,362 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34245', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954749.3627365')
2024-01-11 06:32:29,363 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39174; closing.
2024-01-11 06:32:29,363 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43377', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954749.3637962')
2024-01-11 06:32:29,364 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39158; closing.
2024-01-11 06:32:29,364 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38113', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954749.3645804')
2024-01-11 06:32:29,364 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:32:29,364 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:39158>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-11 06:32:30,566 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:32:30,567 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:32:30,567 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:32:30,568 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-11 06:32:30,569 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-11 06:32:32,755 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:32,760 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38245 instead
  warnings.warn(
2024-01-11 06:32:32,764 - distributed.scheduler - INFO - State start
2024-01-11 06:32:32,787 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:32,788 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-11 06:32:32,789 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38245/status
2024-01-11 06:32:32,789 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:32:33,191 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44789'
2024-01-11 06:32:33,215 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46491'
2024-01-11 06:32:33,224 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39743'
2024-01-11 06:32:33,235 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38979'
2024-01-11 06:32:33,249 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43545'
2024-01-11 06:32:33,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33263'
2024-01-11 06:32:33,262 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44959'
2024-01-11 06:32:33,271 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37647'
2024-01-11 06:32:33,952 - distributed.scheduler - INFO - Receive client connection: Client-32650330-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:33,971 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50178
2024-01-11 06:32:35,856 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:35,856 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:35,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:35,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:35,861 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:35,862 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46499
2024-01-11 06:32:35,862 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46499
2024-01-11 06:32:35,862 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34851
2024-01-11 06:32:35,862 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:35,862 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:35,862 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:35,863 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:35,863 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ynrut2jg
2024-01-11 06:32:35,863 - distributed.worker - INFO - Starting Worker plugin PreImport-b98a0f50-29ac-4312-88db-a2bc1872e9f6
2024-01-11 06:32:35,863 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-90a0038b-adbc-448f-a29a-52cc1966157a
2024-01-11 06:32:35,863 - distributed.worker - INFO - Starting Worker plugin RMMSetup-62e3efb1-24de-43b3-ba83-7480fe1ab2fb
2024-01-11 06:32:35,865 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:35,866 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40009
2024-01-11 06:32:35,866 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40009
2024-01-11 06:32:35,866 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34481
2024-01-11 06:32:35,866 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:35,866 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:35,866 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:35,866 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:35,866 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6o6ss0nx
2024-01-11 06:32:35,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:35,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:35,867 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c8879f7a-7193-4e6e-800e-3f67e9ec9dd2
2024-01-11 06:32:35,872 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:35,874 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36319
2024-01-11 06:32:35,874 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36319
2024-01-11 06:32:35,874 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40951
2024-01-11 06:32:35,874 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:35,874 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:35,874 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:35,874 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:35,874 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s_5607ey
2024-01-11 06:32:35,874 - distributed.worker - INFO - Starting Worker plugin RMMSetup-63f89c0a-75d9-4262-b8f6-2716792ec55b
2024-01-11 06:32:35,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:35,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:35,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:35,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:35,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:35,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:35,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:35,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:35,884 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:35,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:35,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:35,884 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:35,884 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:35,885 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35555
2024-01-11 06:32:35,885 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43917
2024-01-11 06:32:35,885 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35555
2024-01-11 06:32:35,885 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43917
2024-01-11 06:32:35,885 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46033
2024-01-11 06:32:35,885 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41395
2024-01-11 06:32:35,885 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:35,885 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:35,885 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:35,885 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:35,885 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39321
2024-01-11 06:32:35,885 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:35,885 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:35,885 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39321
2024-01-11 06:32:35,885 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:35,885 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:35,885 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41035
2024-01-11 06:32:35,886 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rt3tsu66
2024-01-11 06:32:35,886 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4b35du44
2024-01-11 06:32:35,886 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:35,886 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:35,886 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:35,886 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:35,886 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-adr8kuza
2024-01-11 06:32:35,886 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6aa2bd2c-6f26-4617-acf3-afe996fe19c3
2024-01-11 06:32:35,886 - distributed.worker - INFO - Starting Worker plugin RMMSetup-75df056e-c87e-4ace-bf12-69629ea17195
2024-01-11 06:32:35,886 - distributed.worker - INFO - Starting Worker plugin RMMSetup-42414978-ddb6-4085-ade9-35793360ec61
2024-01-11 06:32:35,886 - distributed.worker - INFO - Starting Worker plugin PreImport-4b113176-1ddb-40e2-a1cb-3deb41181eec
2024-01-11 06:32:35,886 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:35,886 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b44c0de3-bf56-4236-ac7d-6a80941faa9a
2024-01-11 06:32:35,887 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45219
2024-01-11 06:32:35,887 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45219
2024-01-11 06:32:35,888 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33681
2024-01-11 06:32:35,888 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:35,888 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:35,888 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:35,888 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:35,888 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z5um4tr1
2024-01-11 06:32:35,888 - distributed.worker - INFO - Starting Worker plugin PreImport-d46a9d19-7dbf-4a02-b7b6-d6dcd60604bd
2024-01-11 06:32:35,888 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-491ad6cd-6bb7-4a70-aa40-86124762aa3f
2024-01-11 06:32:35,888 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ddfcd735-9a6e-42f3-ad05-102b1d3294f6
2024-01-11 06:32:35,889 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:35,890 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43109
2024-01-11 06:32:35,890 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43109
2024-01-11 06:32:35,890 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42163
2024-01-11 06:32:35,890 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:35,890 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:35,890 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:35,890 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:35,890 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r811cf96
2024-01-11 06:32:35,891 - distributed.worker - INFO - Starting Worker plugin PreImport-b4281339-d1db-401c-b9ba-dc78ac9f7324
2024-01-11 06:32:35,891 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cb14e2d9-d553-4813-a20a-420924d69a15
2024-01-11 06:32:35,891 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fab4b593-1a86-4d57-82e6-d118683c586d
2024-01-11 06:32:38,217 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,243 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46499', status: init, memory: 0, processing: 0>
2024-01-11 06:32:38,244 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46499
2024-01-11 06:32:38,244 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50196
2024-01-11 06:32:38,245 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:38,246 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:38,246 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,247 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:38,296 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,321 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45219', status: init, memory: 0, processing: 0>
2024-01-11 06:32:38,322 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45219
2024-01-11 06:32:38,322 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50212
2024-01-11 06:32:38,323 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:38,324 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:38,324 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,325 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:38,361 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-12a806f1-8672-4e7f-bce9-1f7bc35f77f5
2024-01-11 06:32:38,362 - distributed.worker - INFO - Starting Worker plugin PreImport-e6990144-06b1-4b82-af7e-d02f0f175e77
2024-01-11 06:32:38,363 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,363 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cafc77e5-a2a1-4e70-b1d7-1a7aff8a874c
2024-01-11 06:32:38,365 - distributed.worker - INFO - Starting Worker plugin PreImport-6b06e523-1087-46d4-9580-4c4ce2259a6f
2024-01-11 06:32:38,365 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,370 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,381 - distributed.worker - INFO - Starting Worker plugin PreImport-afb74c6a-0a0e-49bd-bc1c-e05511fa863c
2024-01-11 06:32:38,382 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-98a4ec00-b68d-40c4-b37a-1b3f789f88fd
2024-01-11 06:32:38,384 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,384 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b267247-ba53-42d9-8c17-cbec0f1660c9
2024-01-11 06:32:38,387 - distributed.worker - INFO - Starting Worker plugin PreImport-7337b83d-25f6-4e6c-a4ed-adadb473a6aa
2024-01-11 06:32:38,387 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,395 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43917', status: init, memory: 0, processing: 0>
2024-01-11 06:32:38,396 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43917
2024-01-11 06:32:38,396 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50222
2024-01-11 06:32:38,397 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:38,398 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:38,398 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,399 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43109', status: init, memory: 0, processing: 0>
2024-01-11 06:32:38,399 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43109
2024-01-11 06:32:38,399 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50232
2024-01-11 06:32:38,400 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:38,400 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:38,401 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:38,401 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,402 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:38,411 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39321', status: init, memory: 0, processing: 0>
2024-01-11 06:32:38,412 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39321
2024-01-11 06:32:38,412 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50214
2024-01-11 06:32:38,414 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:38,416 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:38,416 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,419 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:38,422 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40009', status: init, memory: 0, processing: 0>
2024-01-11 06:32:38,422 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40009
2024-01-11 06:32:38,422 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50244
2024-01-11 06:32:38,421 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,424 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:38,425 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:38,425 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,427 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:38,432 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36319', status: init, memory: 0, processing: 0>
2024-01-11 06:32:38,432 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36319
2024-01-11 06:32:38,432 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50234
2024-01-11 06:32:38,434 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:38,436 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:38,436 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,439 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:38,464 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35555', status: init, memory: 0, processing: 0>
2024-01-11 06:32:38,464 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35555
2024-01-11 06:32:38,465 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50256
2024-01-11 06:32:38,466 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:38,468 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:38,468 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:38,470 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:38,476 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:38,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:38,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:38,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:38,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:38,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:38,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:38,477 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:38,483 - distributed.scheduler - INFO - Remove client Client-32650330-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:38,483 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50178; closing.
2024-01-11 06:32:38,484 - distributed.scheduler - INFO - Remove client Client-32650330-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:38,484 - distributed.scheduler - INFO - Close client connection: Client-32650330-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:38,485 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44789'. Reason: nanny-close
2024-01-11 06:32:38,486 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46491'. Reason: nanny-close
2024-01-11 06:32:38,486 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:38,486 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39743'. Reason: nanny-close
2024-01-11 06:32:38,487 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:38,487 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38979'. Reason: nanny-close
2024-01-11 06:32:38,487 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40009. Reason: nanny-close
2024-01-11 06:32:38,487 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:38,487 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43545'. Reason: nanny-close
2024-01-11 06:32:38,488 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:38,488 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43917. Reason: nanny-close
2024-01-11 06:32:38,488 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33263'. Reason: nanny-close
2024-01-11 06:32:38,488 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45219. Reason: nanny-close
2024-01-11 06:32:38,488 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:38,488 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44959'. Reason: nanny-close
2024-01-11 06:32:38,488 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:38,488 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39321. Reason: nanny-close
2024-01-11 06:32:38,489 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37647'. Reason: nanny-close
2024-01-11 06:32:38,489 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:38,489 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43109. Reason: nanny-close
2024-01-11 06:32:38,489 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36319. Reason: nanny-close
2024-01-11 06:32:38,489 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:38,489 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50244; closing.
2024-01-11 06:32:38,490 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:38,490 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46499. Reason: nanny-close
2024-01-11 06:32:38,490 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:38,490 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40009', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954758.4902163')
2024-01-11 06:32:38,491 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:38,491 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:38,491 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50222; closing.
2024-01-11 06:32:38,491 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:38,491 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:38,491 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:38,491 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50212; closing.
2024-01-11 06:32:38,491 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:38,492 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:38,492 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43917', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954758.4927673')
2024-01-11 06:32:38,493 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:38,493 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45219', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954758.4931357')
2024-01-11 06:32:38,493 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:38,493 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50214; closing.
2024-01-11 06:32:38,493 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:38,494 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39321', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954758.4943507')
2024-01-11 06:32:38,494 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50232; closing.
2024-01-11 06:32:38,494 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50196; closing.
2024-01-11 06:32:38,495 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43109', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954758.4953008')
2024-01-11 06:32:38,495 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:38,495 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46499', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954758.4956954')
2024-01-11 06:32:38,496 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50234; closing.
2024-01-11 06:32:38,496 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36319', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954758.4964201')
2024-01-11 06:32:38,496 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:38,498 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35555. Reason: nanny-close
2024-01-11 06:32:38,500 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:38,500 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50256; closing.
2024-01-11 06:32:38,500 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35555', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954758.5006812')
2024-01-11 06:32:38,500 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:32:38,502 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:39,601 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:32:39,602 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:32:39,602 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:32:39,604 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-11 06:32:39,604 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-11 06:32:41,937 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:41,942 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42697 instead
  warnings.warn(
2024-01-11 06:32:41,946 - distributed.scheduler - INFO - State start
2024-01-11 06:32:41,985 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:41,986 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-11 06:32:41,986 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42697/status
2024-01-11 06:32:41,987 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:32:42,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39007'
2024-01-11 06:32:42,192 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36223'
2024-01-11 06:32:42,204 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41021'
2024-01-11 06:32:42,222 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44871'
2024-01-11 06:32:42,224 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46675'
2024-01-11 06:32:42,233 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46729'
2024-01-11 06:32:42,245 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38139'
2024-01-11 06:32:42,254 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44407'
2024-01-11 06:32:42,471 - distributed.scheduler - INFO - Receive client connection: Client-37ccbf80-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:42,485 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33428
2024-01-11 06:32:44,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:44,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:44,106 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:44,107 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42827
2024-01-11 06:32:44,107 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42827
2024-01-11 06:32:44,107 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43533
2024-01-11 06:32:44,107 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:44,107 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:44,107 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:44,107 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:44,107 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_oh660d1
2024-01-11 06:32:44,107 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-479e63e7-a489-4b16-9e25-97e870ea3647
2024-01-11 06:32:44,108 - distributed.worker - INFO - Starting Worker plugin PreImport-abcdbbe0-b789-4f0c-8f3d-21acd8518ec0
2024-01-11 06:32:44,109 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f25e8f75-90d4-48bf-9130-cace4d15beb1
2024-01-11 06:32:44,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:44,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:44,128 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:44,129 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33577
2024-01-11 06:32:44,129 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33577
2024-01-11 06:32:44,129 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43135
2024-01-11 06:32:44,129 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:44,129 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:44,129 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:44,129 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:44,129 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dek904sm
2024-01-11 06:32:44,130 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0c27a39-2562-4048-b6d6-a1e970b10fe3
2024-01-11 06:32:44,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:44,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:44,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:44,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:44,146 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:44,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:44,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:44,147 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33909
2024-01-11 06:32:44,148 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33909
2024-01-11 06:32:44,148 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33707
2024-01-11 06:32:44,148 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:44,148 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:44,148 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:44,148 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:44,148 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:44,148 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lirpxyq8
2024-01-11 06:32:44,148 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4a86d60b-3a0a-44f2-852b-fdb8316f83f3
2024-01-11 06:32:44,148 - distributed.worker - INFO - Starting Worker plugin PreImport-5956610a-f439-4a83-ad20-b7309c1c189e
2024-01-11 06:32:44,149 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff45eb63-5ea9-45ea-b171-b0500c1b1574
2024-01-11 06:32:44,149 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46619
2024-01-11 06:32:44,149 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46619
2024-01-11 06:32:44,149 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46787
2024-01-11 06:32:44,149 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:44,149 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:44,149 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:44,149 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:44,149 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wa0jr9fd
2024-01-11 06:32:44,149 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8dd2c117-c957-460e-af2f-98c57a6bfda2
2024-01-11 06:32:44,150 - distributed.worker - INFO - Starting Worker plugin PreImport-b092093e-40a7-4200-b63e-b36c664db2c7
2024-01-11 06:32:44,150 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cbe73e23-154c-43df-88ec-7205cc70c577
2024-01-11 06:32:44,152 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:44,153 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34615
2024-01-11 06:32:44,153 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34615
2024-01-11 06:32:44,153 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44967
2024-01-11 06:32:44,153 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:44,153 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:44,153 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:44,154 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:44,154 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-eroi0gla
2024-01-11 06:32:44,154 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b855480a-aea2-4907-895a-5daa6326a0ed
2024-01-11 06:32:44,154 - distributed.worker - INFO - Starting Worker plugin PreImport-ba8c3da3-5bce-4b98-b57e-acd0d46539d6
2024-01-11 06:32:44,154 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7452ce89-8b87-4523-8a31-102c82fb2c44
2024-01-11 06:32:44,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:44,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:44,161 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:44,162 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36339
2024-01-11 06:32:44,162 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36339
2024-01-11 06:32:44,162 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38583
2024-01-11 06:32:44,162 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:44,162 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:44,162 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:44,162 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:44,162 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v91g72f9
2024-01-11 06:32:44,162 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3726d5e7-b3eb-43f2-850b-30275b9284eb
2024-01-11 06:32:44,163 - distributed.worker - INFO - Starting Worker plugin PreImport-895b6bdc-7e69-4f11-936c-bd0b7f591caa
2024-01-11 06:32:44,163 - distributed.worker - INFO - Starting Worker plugin RMMSetup-efa768da-3698-4db9-b03f-1d6c0d2122a9
2024-01-11 06:32:44,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:44,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:44,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:44,173 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:44,174 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:44,175 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44335
2024-01-11 06:32:44,175 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44335
2024-01-11 06:32:44,175 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43645
2024-01-11 06:32:44,176 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:44,176 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:44,176 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:44,176 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:44,176 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z1eidqev
2024-01-11 06:32:44,176 - distributed.worker - INFO - Starting Worker plugin RMMSetup-394f5c69-29c3-4711-b034-4dd762c82ba4
2024-01-11 06:32:44,177 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:44,178 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33113
2024-01-11 06:32:44,178 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33113
2024-01-11 06:32:44,178 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33685
2024-01-11 06:32:44,178 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:44,178 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:44,178 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:44,178 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:44,178 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l40vfyzo
2024-01-11 06:32:44,179 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-55ee9453-8868-4010-9319-502b730894d0
2024-01-11 06:32:44,179 - distributed.worker - INFO - Starting Worker plugin PreImport-c5ec06d3-a3ba-4755-b435-00f94c89ba55
2024-01-11 06:32:44,179 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f977ed63-782f-4376-9d51-5bf58140fc87
2024-01-11 06:32:46,239 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b0448e08-cd10-465a-85df-eb9a63b16c6e
2024-01-11 06:32:46,241 - distributed.worker - INFO - Starting Worker plugin PreImport-7fd32805-5544-42a6-aa14-58b1e1f19e3e
2024-01-11 06:32:46,242 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,254 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,281 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33577', status: init, memory: 0, processing: 0>
2024-01-11 06:32:46,283 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33577
2024-01-11 06:32:46,283 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33438
2024-01-11 06:32:46,283 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,285 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:46,286 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:46,286 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,288 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:46,290 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42827', status: init, memory: 0, processing: 0>
2024-01-11 06:32:46,291 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42827
2024-01-11 06:32:46,291 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33444
2024-01-11 06:32:46,292 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:46,293 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:46,293 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,295 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:46,308 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46619', status: init, memory: 0, processing: 0>
2024-01-11 06:32:46,309 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46619
2024-01-11 06:32:46,309 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33448
2024-01-11 06:32:46,310 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,310 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:46,311 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:46,311 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,313 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:46,321 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,325 - distributed.worker - INFO - Starting Worker plugin PreImport-829930a0-215d-4b73-b0df-50637ec7bc8b
2024-01-11 06:32:46,325 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-53209029-6439-44ae-acb2-825464e40489
2024-01-11 06:32:46,327 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,328 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,332 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,345 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34615', status: init, memory: 0, processing: 0>
2024-01-11 06:32:46,345 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34615
2024-01-11 06:32:46,346 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33454
2024-01-11 06:32:46,347 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:46,348 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:46,348 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,350 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:46,356 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36339', status: init, memory: 0, processing: 0>
2024-01-11 06:32:46,357 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36339
2024-01-11 06:32:46,357 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33474
2024-01-11 06:32:46,358 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:46,359 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:46,359 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,360 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33909', status: init, memory: 0, processing: 0>
2024-01-11 06:32:46,360 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33909
2024-01-11 06:32:46,360 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33464
2024-01-11 06:32:46,361 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:46,362 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:46,363 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:46,363 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,363 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33113', status: init, memory: 0, processing: 0>
2024-01-11 06:32:46,364 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33113
2024-01-11 06:32:46,364 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33494
2024-01-11 06:32:46,365 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44335', status: init, memory: 0, processing: 0>
2024-01-11 06:32:46,365 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:46,365 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:46,365 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44335
2024-01-11 06:32:46,365 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33490
2024-01-11 06:32:46,366 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:46,366 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,367 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:46,367 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:46,368 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:46,368 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:46,370 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:46,462 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:46,463 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:46,463 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:46,463 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:46,463 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:46,463 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:46,463 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:46,463 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:46,474 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:46,475 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:46,475 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:46,475 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:46,475 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:46,475 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:46,475 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:46,475 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:46,483 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:46,485 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:46,487 - distributed.scheduler - INFO - Remove client Client-37ccbf80-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:46,487 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33428; closing.
2024-01-11 06:32:46,488 - distributed.scheduler - INFO - Remove client Client-37ccbf80-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:46,489 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39007'. Reason: nanny-close
2024-01-11 06:32:46,490 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:46,490 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36223'. Reason: nanny-close
2024-01-11 06:32:46,490 - distributed.scheduler - INFO - Close client connection: Client-37ccbf80-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:46,490 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:46,491 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41021'. Reason: nanny-close
2024-01-11 06:32:46,491 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:46,491 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33577. Reason: nanny-close
2024-01-11 06:32:46,491 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44871'. Reason: nanny-close
2024-01-11 06:32:46,491 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42827. Reason: nanny-close
2024-01-11 06:32:46,491 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:46,491 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46675'. Reason: nanny-close
2024-01-11 06:32:46,492 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33113. Reason: nanny-close
2024-01-11 06:32:46,492 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:46,492 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46729'. Reason: nanny-close
2024-01-11 06:32:46,492 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46619. Reason: nanny-close
2024-01-11 06:32:46,492 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:46,492 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38139'. Reason: nanny-close
2024-01-11 06:32:46,493 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33909. Reason: nanny-close
2024-01-11 06:32:46,493 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:46,493 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44407'. Reason: nanny-close
2024-01-11 06:32:46,493 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44335. Reason: nanny-close
2024-01-11 06:32:46,493 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:46,493 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:46,493 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33438; closing.
2024-01-11 06:32:46,493 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:46,493 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:46,494 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34615. Reason: nanny-close
2024-01-11 06:32:46,494 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33577', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954766.4940262')
2024-01-11 06:32:46,494 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:46,494 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33494; closing.
2024-01-11 06:32:46,494 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36339. Reason: nanny-close
2024-01-11 06:32:46,495 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33113', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954766.4950821')
2024-01-11 06:32:46,495 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:46,495 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:46,495 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33444; closing.
2024-01-11 06:32:46,495 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:46,495 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:46,495 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:46,495 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:46,496 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:46,496 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:46,496 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42827', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954766.4964464')
2024-01-11 06:32:46,496 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33448; closing.
2024-01-11 06:32:46,497 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:46,497 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:46,497 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:46,497 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:46,497 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:33494>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-11 06:32:46,498 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33464; closing.
2024-01-11 06:32:46,499 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46619', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954766.4991126')
2024-01-11 06:32:46,499 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33490; closing.
2024-01-11 06:32:46,500 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33909', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954766.5000613')
2024-01-11 06:32:46,500 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44335', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954766.5005462')
2024-01-11 06:32:46,501 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33454; closing.
2024-01-11 06:32:46,501 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33474; closing.
2024-01-11 06:32:46,501 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34615', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954766.5015054')
2024-01-11 06:32:46,501 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36339', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954766.5018756')
2024-01-11 06:32:46,502 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:32:47,555 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:32:47,556 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:32:47,556 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:32:47,558 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-11 06:32:47,558 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-11 06:32:49,730 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:49,735 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40611 instead
  warnings.warn(
2024-01-11 06:32:49,739 - distributed.scheduler - INFO - State start
2024-01-11 06:32:49,762 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:49,763 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-11 06:32:49,764 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40611/status
2024-01-11 06:32:49,764 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:32:50,013 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41371'
2024-01-11 06:32:50,033 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43711'
2024-01-11 06:32:50,048 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38035'
2024-01-11 06:32:50,051 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34227'
2024-01-11 06:32:50,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46485'
2024-01-11 06:32:50,068 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36769'
2024-01-11 06:32:50,076 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39795'
2024-01-11 06:32:50,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41463'
2024-01-11 06:32:51,240 - distributed.scheduler - INFO - Receive client connection: Client-3c820cb8-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:51,254 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50862
2024-01-11 06:32:51,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:51,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:51,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:51,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:51,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:51,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:51,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:51,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:51,938 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:51,939 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35173
2024-01-11 06:32:51,939 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35173
2024-01-11 06:32:51,939 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37237
2024-01-11 06:32:51,939 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:51,939 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:51,939 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:51,939 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:51,939 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-709g1rhf
2024-01-11 06:32:51,939 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b44b6f85-9a36-45fc-80e5-9db4fb4a70dc
2024-01-11 06:32:51,939 - distributed.worker - INFO - Starting Worker plugin PreImport-5602594c-67f3-4218-a422-f2ce1eb377c8
2024-01-11 06:32:51,940 - distributed.worker - INFO - Starting Worker plugin RMMSetup-914e9b7c-1766-4c57-9b89-bbedd695b323
2024-01-11 06:32:51,940 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:51,940 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:51,940 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41133
2024-01-11 06:32:51,940 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41133
2024-01-11 06:32:51,941 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34239
2024-01-11 06:32:51,941 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:51,941 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:51,941 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:51,941 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:51,941 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:51,941 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2m5gpg1n
2024-01-11 06:32:51,941 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8e3b8e69-1d29-4cbf-9bec-77af88ea3aff
2024-01-11 06:32:51,941 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34089
2024-01-11 06:32:51,941 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34089
2024-01-11 06:32:51,941 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42459
2024-01-11 06:32:51,941 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:51,941 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:51,941 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:51,941 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:51,941 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-65jz8d1t
2024-01-11 06:32:51,942 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46281
2024-01-11 06:32:51,942 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46281
2024-01-11 06:32:51,942 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44633
2024-01-11 06:32:51,942 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ef89ff09-1199-403b-bb0f-aa476ca79fa6
2024-01-11 06:32:51,942 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:51,942 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:51,942 - distributed.worker - INFO - Starting Worker plugin PreImport-30f22af3-4f30-48ce-98fe-c0b70ac384b5
2024-01-11 06:32:51,942 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:51,942 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:51,942 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a8d8c318-ca45-4d23-92e7-700e0d844824
2024-01-11 06:32:51,942 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h37_5fg0
2024-01-11 06:32:51,942 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6c252914-0e63-4360-a875-4ad5a42ee9fd
2024-01-11 06:32:51,942 - distributed.worker - INFO - Starting Worker plugin PreImport-ae760c25-4321-49aa-af5b-08f49f1a2d31
2024-01-11 06:32:51,943 - distributed.worker - INFO - Starting Worker plugin RMMSetup-83eb23d5-d372-4f3d-a179-d89158821991
2024-01-11 06:32:51,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:51,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:51,951 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:51,952 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44383
2024-01-11 06:32:51,952 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44383
2024-01-11 06:32:51,952 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34807
2024-01-11 06:32:51,952 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:51,952 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:51,952 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:51,952 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:51,952 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-buy3zys2
2024-01-11 06:32:51,952 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7b7ce543-49ee-44a8-9874-971c5bb07445
2024-01-11 06:32:51,953 - distributed.worker - INFO - Starting Worker plugin PreImport-bdd0e436-8ca3-414d-8b70-6b6c1fbaf401
2024-01-11 06:32:51,954 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d369fbc8-2421-4541-bf16-1c45bac1f45d
2024-01-11 06:32:51,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:51,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:51,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:51,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:51,995 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:51,996 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42285
2024-01-11 06:32:51,996 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:51,996 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42285
2024-01-11 06:32:51,996 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35493
2024-01-11 06:32:51,996 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:51,996 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:51,996 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:51,997 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:51,997 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g00gtae0
2024-01-11 06:32:51,997 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ebb76612-4fa3-41b2-af68-07b1cbca86cc
2024-01-11 06:32:51,997 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41185
2024-01-11 06:32:51,997 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41185
2024-01-11 06:32:51,997 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41181
2024-01-11 06:32:51,997 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:51,997 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:51,997 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:51,997 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:51,997 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_fpbbcm3
2024-01-11 06:32:51,998 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4a1661ba-b809-4e9f-bdc9-6ee3b34a512e
2024-01-11 06:32:51,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:32:51,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:32:51,999 - distributed.worker - INFO - Starting Worker plugin PreImport-24f9bba3-088a-412e-b6a2-6021dab2c05c
2024-01-11 06:32:52,000 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c987ba36-8f82-4b0c-b2fe-3702880afcf7
2024-01-11 06:32:52,002 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:32:52,003 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39875
2024-01-11 06:32:52,003 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39875
2024-01-11 06:32:52,003 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46501
2024-01-11 06:32:52,004 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:32:52,004 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:52,004 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:32:52,004 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:32:52,004 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3ek6kv2m
2024-01-11 06:32:52,004 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-37ad9f7f-e2a1-4bf9-bc61-842f57003535
2024-01-11 06:32:52,005 - distributed.worker - INFO - Starting Worker plugin PreImport-af496f60-b2d1-441d-85a6-788c11c9655a
2024-01-11 06:32:52,006 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c0bb400c-7c82-487c-b922-328e0d87a4c2
2024-01-11 06:32:53,136 - distributed.scheduler - INFO - Receive client connection: Client-3f9c5c4e-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:32:53,137 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50894
2024-01-11 06:32:54,434 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:54,465 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34089', status: init, memory: 0, processing: 0>
2024-01-11 06:32:54,466 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34089
2024-01-11 06:32:54,467 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50914
2024-01-11 06:32:54,467 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:54,468 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:54,468 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:54,470 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:54,624 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:54,657 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46281', status: init, memory: 0, processing: 0>
2024-01-11 06:32:54,658 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46281
2024-01-11 06:32:54,658 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50916
2024-01-11 06:32:54,659 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:54,660 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:54,660 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:54,662 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:55,022 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,027 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-27959987-913f-4128-a4bd-3dc091b25b00
2024-01-11 06:32:55,027 - distributed.worker - INFO - Starting Worker plugin PreImport-cdeefe83-806a-41ce-b0a1-67f4054c5246
2024-01-11 06:32:55,027 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,041 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,052 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41133', status: init, memory: 0, processing: 0>
2024-01-11 06:32:55,053 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41133
2024-01-11 06:32:55,053 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50922
2024-01-11 06:32:55,054 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:55,054 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:55,054 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,056 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44383', status: init, memory: 0, processing: 0>
2024-01-11 06:32:55,056 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:55,056 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44383
2024-01-11 06:32:55,056 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50920
2024-01-11 06:32:55,057 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:55,058 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:55,058 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,061 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:55,065 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35173', status: init, memory: 0, processing: 0>
2024-01-11 06:32:55,066 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35173
2024-01-11 06:32:55,066 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50934
2024-01-11 06:32:55,067 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:55,068 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:55,068 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,069 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:55,175 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,194 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,200 - distributed.worker - INFO - Starting Worker plugin PreImport-48ae1335-fd02-4a12-baad-87f328e111e8
2024-01-11 06:32:55,201 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b911dc5-a681-40c5-9695-019d99f981a0
2024-01-11 06:32:55,201 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,213 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39875', status: init, memory: 0, processing: 0>
2024-01-11 06:32:55,214 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39875
2024-01-11 06:32:55,214 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50942
2024-01-11 06:32:55,215 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:55,216 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:55,217 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,219 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:55,226 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41185', status: init, memory: 0, processing: 0>
2024-01-11 06:32:55,226 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41185
2024-01-11 06:32:55,226 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50972
2024-01-11 06:32:55,227 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:55,228 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:55,228 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,229 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42285', status: init, memory: 0, processing: 0>
2024-01-11 06:32:55,229 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:55,230 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42285
2024-01-11 06:32:55,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50956
2024-01-11 06:32:55,231 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:32:55,232 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:32:55,232 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:32:55,234 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:32:55,317 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:55,317 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:55,317 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:55,317 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:55,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:55,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:55,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:55,318 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:32:55,320 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,320 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,320 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,321 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,321 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,321 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,321 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,321 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,326 - distributed.scheduler - INFO - Remove client Client-3f9c5c4e-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:32:55,326 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50894; closing.
2024-01-11 06:32:55,327 - distributed.scheduler - INFO - Remove client Client-3f9c5c4e-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:32:55,327 - distributed.scheduler - INFO - Close client connection: Client-3f9c5c4e-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:32:55,335 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:55,335 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:55,335 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:55,335 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:55,335 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:55,335 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:55,335 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:55,335 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:32:55,344 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,345 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:32:55,348 - distributed.scheduler - INFO - Remove client Client-3c820cb8-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:55,348 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50862; closing.
2024-01-11 06:32:55,348 - distributed.scheduler - INFO - Remove client Client-3c820cb8-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:55,348 - distributed.scheduler - INFO - Close client connection: Client-3c820cb8-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:32:55,349 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41371'. Reason: nanny-close
2024-01-11 06:32:55,350 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:55,350 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43711'. Reason: nanny-close
2024-01-11 06:32:55,351 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:55,351 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38035'. Reason: nanny-close
2024-01-11 06:32:55,351 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41133. Reason: nanny-close
2024-01-11 06:32:55,351 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:55,351 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34227'. Reason: nanny-close
2024-01-11 06:32:55,351 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35173. Reason: nanny-close
2024-01-11 06:32:55,352 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:55,352 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46485'. Reason: nanny-close
2024-01-11 06:32:55,352 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:55,352 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44383. Reason: nanny-close
2024-01-11 06:32:55,352 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36769'. Reason: nanny-close
2024-01-11 06:32:55,352 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:55,352 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46281. Reason: nanny-close
2024-01-11 06:32:55,353 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39795'. Reason: nanny-close
2024-01-11 06:32:55,353 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34089. Reason: nanny-close
2024-01-11 06:32:55,353 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:55,353 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:55,353 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50922; closing.
2024-01-11 06:32:55,353 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41463'. Reason: nanny-close
2024-01-11 06:32:55,353 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41185. Reason: nanny-close
2024-01-11 06:32:55,353 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:55,353 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41133', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954775.3536217')
2024-01-11 06:32:55,353 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:32:55,354 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42285. Reason: nanny-close
2024-01-11 06:32:55,354 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50934; closing.
2024-01-11 06:32:55,354 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39875. Reason: nanny-close
2024-01-11 06:32:55,354 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:55,354 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:55,354 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:55,354 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:55,355 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:55,355 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:55,355 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35173', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954775.3555593')
2024-01-11 06:32:55,356 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:55,356 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:55,356 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50920; closing.
2024-01-11 06:32:55,356 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:55,357 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50914; closing.
2024-01-11 06:32:55,357 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:55,357 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50916; closing.
2024-01-11 06:32:55,357 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:55,357 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:32:55,357 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44383', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954775.3576357')
2024-01-11 06:32:55,358 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34089', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954775.3579838')
2024-01-11 06:32:55,358 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46281', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954775.3582637')
2024-01-11 06:32:55,358 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50972; closing.
2024-01-11 06:32:55,359 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:55,359 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41185', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954775.3591707')
2024-01-11 06:32:55,359 - distributed.nanny - INFO - Worker closed
2024-01-11 06:32:55,359 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50956; closing.
2024-01-11 06:32:55,359 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50942; closing.
2024-01-11 06:32:55,360 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42285', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954775.3600917')
2024-01-11 06:32:55,360 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39875', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954775.3604906')
2024-01-11 06:32:55,360 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:32:56,301 - distributed.scheduler - INFO - Receive client connection: Client-417f2742-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:32:56,301 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50982
2024-01-11 06:32:56,567 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:32:56,567 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:32:56,568 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:32:56,570 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-11 06:32:56,570 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-11 06:32:59,003 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:59,008 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44193 instead
  warnings.warn(
2024-01-11 06:32:59,012 - distributed.scheduler - INFO - State start
2024-01-11 06:32:59,035 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:32:59,036 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-11 06:32:59,037 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:32:59,037 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-11 06:32:59,285 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33241'
2024-01-11 06:32:59,314 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42941'
2024-01-11 06:32:59,317 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45395'
2024-01-11 06:32:59,326 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34749'
2024-01-11 06:32:59,336 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39155'
2024-01-11 06:32:59,345 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46823'
2024-01-11 06:32:59,355 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39873'
2024-01-11 06:32:59,364 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43973'
2024-01-11 06:33:02,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:02,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:02,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:02,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:02,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:02,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:02,165 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:02,166 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:02,166 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34621
2024-01-11 06:33:02,166 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34621
2024-01-11 06:33:02,166 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42409
2024-01-11 06:33:02,166 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:02,166 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:02,167 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:02,167 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:02,167 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9xfutddh
2024-01-11 06:33:02,167 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38527
2024-01-11 06:33:02,167 - distributed.worker - INFO - Starting Worker plugin RMMSetup-369bf3d4-b6b7-45ed-b8bd-6a2647977b4c
2024-01-11 06:33:02,167 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38527
2024-01-11 06:33:02,167 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35831
2024-01-11 06:33:02,167 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:02,167 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:02,167 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:02,167 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:02,168 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3gq0gfx3
2024-01-11 06:33:02,168 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:02,168 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38f37f5e-d2f3-474f-b260-887aab31ecfe
2024-01-11 06:33:02,169 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40445
2024-01-11 06:33:02,169 - distributed.worker - INFO - Starting Worker plugin PreImport-3ddee382-fb91-4389-bd1a-fd9d158badb4
2024-01-11 06:33:02,169 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40445
2024-01-11 06:33:02,169 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33409
2024-01-11 06:33:02,169 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:02,169 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a8352500-64c7-4b39-9606-18af58362a38
2024-01-11 06:33:02,169 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:02,169 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:02,169 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:02,169 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lp2v18bu
2024-01-11 06:33:02,169 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-57e301f7-3d4c-4e52-bad0-aeb3240b801e
2024-01-11 06:33:02,170 - distributed.worker - INFO - Starting Worker plugin PreImport-95368b3c-f4c8-4f1d-a637-e9b242bba754
2024-01-11 06:33:02,171 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d50d0e8a-ab2b-4b74-86fe-37f4bbd56ad2
2024-01-11 06:33:02,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:02,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:02,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:02,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:02,176 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:02,177 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40207
2024-01-11 06:33:02,177 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40207
2024-01-11 06:33:02,177 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36363
2024-01-11 06:33:02,177 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:02,177 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:02,178 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:02,178 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:02,178 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2g1r6_0b
2024-01-11 06:33:02,178 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d89ad943-f6b6-48af-91e0-41d0916fe86e
2024-01-11 06:33:02,179 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a2375c61-75cc-41db-95d0-54d500e3e987
2024-01-11 06:33:02,180 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:02,181 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39383
2024-01-11 06:33:02,181 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39383
2024-01-11 06:33:02,182 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39307
2024-01-11 06:33:02,182 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:02,182 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:02,182 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:02,182 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:02,182 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w4miub4y
2024-01-11 06:33:02,182 - distributed.worker - INFO - Starting Worker plugin PreImport-c27b28e8-4427-4752-b8cd-fcad3bbc5aa5
2024-01-11 06:33:02,182 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b77a3b9d-a9c4-406b-8fb2-6e0086f25e58
2024-01-11 06:33:02,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:02,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:02,205 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:02,205 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:02,206 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:02,207 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40067
2024-01-11 06:33:02,207 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40067
2024-01-11 06:33:02,207 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40107
2024-01-11 06:33:02,207 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:02,207 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:02,207 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:02,207 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:02,207 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7095j4s8
2024-01-11 06:33:02,208 - distributed.worker - INFO - Starting Worker plugin RMMSetup-60c96c67-eab4-4b51-804f-798e073ffa69
2024-01-11 06:33:02,210 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:02,211 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42933
2024-01-11 06:33:02,211 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42933
2024-01-11 06:33:02,211 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44387
2024-01-11 06:33:02,211 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:02,211 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:02,211 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:02,211 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:02,211 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ubuqn3jl
2024-01-11 06:33:02,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:02,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:02,212 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a5eefa15-1264-446d-b840-eef2418c5b9e
2024-01-11 06:33:02,216 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:02,218 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42217
2024-01-11 06:33:02,218 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42217
2024-01-11 06:33:02,218 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33243
2024-01-11 06:33:02,218 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:02,218 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:02,218 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:02,218 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:02,218 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f1qvud1y
2024-01-11 06:33:02,218 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7cfbba7c-6675-4d00-937e-482e4e895ac4
2024-01-11 06:33:02,218 - distributed.worker - INFO - Starting Worker plugin PreImport-e36ea1e0-69e5-42ec-aaac-1c66a76e7240
2024-01-11 06:33:02,218 - distributed.worker - INFO - Starting Worker plugin RMMSetup-204269df-dd1f-48dd-a3e7-10f187bc944d
2024-01-11 06:33:02,857 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33241'. Reason: nanny-close
2024-01-11 06:33:02,858 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42941'. Reason: nanny-close
2024-01-11 06:33:02,858 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45395'. Reason: nanny-close
2024-01-11 06:33:02,858 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34749'. Reason: nanny-close
2024-01-11 06:33:02,858 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39155'. Reason: nanny-close
2024-01-11 06:33:02,858 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46823'. Reason: nanny-close
2024-01-11 06:33:02,858 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39873'. Reason: nanny-close
2024-01-11 06:33:02,859 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43973'. Reason: nanny-close
2024-01-11 06:33:05,036 - distributed.worker - INFO - Starting Worker plugin PreImport-d044c122-63cd-4f19-b875-f64ec15983ea
2024-01-11 06:33:05,038 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:05,046 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:05,062 - distributed.worker - INFO - Starting Worker plugin PreImport-4bb48865-efc7-4646-9180-689273098975
2024-01-11 06:33:05,063 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-297584dd-6454-4e47-8d67-a12e849e3b95
2024-01-11 06:33:05,063 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:05,079 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:05,083 - distributed.worker - INFO - Starting Worker plugin PreImport-4dde4ce7-4767-4959-8e8b-a3091e7d9220
2024-01-11 06:33:05,084 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-55452862-3613-4adb-9bec-dbe89bd215e9
2024-01-11 06:33:05,084 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:05,087 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:05,092 - distributed.worker - INFO - Starting Worker plugin PreImport-425031f3-7e87-4e70-95da-8ea25cc3c618
2024-01-11 06:33:05,093 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fe909c5b-c4bd-4f53-9936-8bf1eed7bfdb
2024-01-11 06:33:05,093 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:05,112 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-31ccd773-f792-4a8c-9e11-54c885c29864
2024-01-11 06:33:05,113 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:07,190 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:07,191 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:07,191 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:07,193 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:07,244 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:07,245 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39383. Reason: nanny-close
2024-01-11 06:33:07,248 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:07,250 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:07,257 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:07,257 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:07,258 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:07,259 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:07,288 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:07,289 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:07,289 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:07,291 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:07,296 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:07,296 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:07,297 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40445. Reason: nanny-close
2024-01-11 06:33:07,297 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42217. Reason: nanny-close
2024-01-11 06:33:07,299 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:07,299 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:07,300 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:07,301 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:07,323 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:07,324 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:07,324 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:07,325 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:07,347 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:07,348 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34621. Reason: nanny-close
2024-01-11 06:33:07,350 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:07,351 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:07,443 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:07,444 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:07,444 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:07,446 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:07,449 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:07,450 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38527. Reason: nanny-close
2024-01-11 06:33:07,452 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:07,454 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:07,554 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:07,554 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:07,554 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:07,556 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:07,601 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:07,602 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42933. Reason: nanny-close
2024-01-11 06:33:07,604 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:07,605 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 383, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:51388 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 242, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2024-01-11 06:33:07,686 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64557 parent=64360 started daemon>
2024-01-11 06:33:07,687 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64553 parent=64360 started daemon>
2024-01-11 06:33:07,687 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64549 parent=64360 started daemon>
2024-01-11 06:33:07,687 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64545 parent=64360 started daemon>
2024-01-11 06:33:07,687 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64540 parent=64360 started daemon>
2024-01-11 06:33:07,687 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64535 parent=64360 started daemon>
2024-01-11 06:33:07,687 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=64530 parent=64360 started daemon>
2024-01-11 06:33:07,727 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64535 exit status was already read will report exitcode 255
2024-01-11 06:33:07,897 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64530 exit status was already read will report exitcode 255
2024-01-11 06:33:07,957 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 64549 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-11 06:33:10,559 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:10,564 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44477 instead
  warnings.warn(
2024-01-11 06:33:10,568 - distributed.scheduler - INFO - State start
2024-01-11 06:33:10,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-2g1r6_0b', purging
2024-01-11 06:33:10,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-7095j4s8', purging
2024-01-11 06:33:10,645 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:10,646 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-11 06:33:10,646 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:33:10,647 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-11 06:33:10,729 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40603'
2024-01-11 06:33:12,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:12,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:13,228 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:13,229 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35347
2024-01-11 06:33:13,229 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35347
2024-01-11 06:33:13,229 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-11 06:33:13,230 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:13,230 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:13,230 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:13,230 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-11 06:33:13,230 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p34tey5d
2024-01-11 06:33:13,230 - distributed.worker - INFO - Starting Worker plugin PreImport-f3fdeb7d-d793-40c9-86c2-6ea06d3cf581
2024-01-11 06:33:13,230 - distributed.worker - INFO - Starting Worker plugin RMMSetup-51ed30de-d96c-447b-ab0f-688e11a41756
2024-01-11 06:33:13,230 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-47d126a8-b2cf-46d0-adb3-3a9f1ca9c324
2024-01-11 06:33:13,231 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:15,374 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:15,375 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:15,375 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:15,376 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:15,380 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40603'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2024-01-11 06:33:15,381 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2024-01-11 06:33:15,382 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35347. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2024-01-11 06:33:15,383 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:15,385 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 383, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:47584 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 242, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-11 06:33:23,203 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:23,208 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43211 instead
  warnings.warn(
2024-01-11 06:33:23,213 - distributed.scheduler - INFO - State start
2024-01-11 06:33:23,236 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:23,237 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-11 06:33:23,238 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43211/status
2024-01-11 06:33:23,238 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:33:23,248 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42955'
2024-01-11 06:33:23,292 - distributed.scheduler - INFO - Receive client connection: Client-507fd865-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:23,308 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43008
2024-01-11 06:33:24,135 - distributed.scheduler - INFO - Receive client connection: Client-50551c5d-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:24,136 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43086
2024-01-11 06:33:25,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:25,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:25,597 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:25,598 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45821
2024-01-11 06:33:25,598 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45821
2024-01-11 06:33:25,598 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33365
2024-01-11 06:33:25,598 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:25,598 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:25,598 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:25,598 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-11 06:33:25,598 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-io5nicub
2024-01-11 06:33:25,598 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ae609865-e0be-4d79-8a4b-1b22766603e9
2024-01-11 06:33:25,599 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8b3def9e-dc9a-4b09-8ca3-33d432e2c859
2024-01-11 06:33:25,600 - distributed.worker - INFO - Starting Worker plugin PreImport-dd22b843-6bc9-427b-b8cb-4f5cafb1ae71
2024-01-11 06:33:25,603 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:26,164 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45821', status: init, memory: 0, processing: 0>
2024-01-11 06:33:26,165 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45821
2024-01-11 06:33:26,165 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43110
2024-01-11 06:33:26,166 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:26,167 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:26,167 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:26,169 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:26,176 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:26,179 - distributed.scheduler - INFO - Remove client Client-50551c5d-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:26,179 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43086; closing.
2024-01-11 06:33:26,179 - distributed.scheduler - INFO - Remove client Client-50551c5d-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:26,180 - distributed.scheduler - INFO - Close client connection: Client-50551c5d-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:26,181 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42955'. Reason: nanny-close
2024-01-11 06:33:26,188 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:26,189 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45821. Reason: nanny-close
2024-01-11 06:33:26,191 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43110; closing.
2024-01-11 06:33:26,191 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:26,192 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45821', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954806.1920578')
2024-01-11 06:33:26,192 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:33:26,193 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:26,266 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41659', status: init, memory: 0, processing: 0>
2024-01-11 06:33:26,267 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41659
2024-01-11 06:33:26,267 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43122
2024-01-11 06:33:27,046 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:33:27,047 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:33:27,047 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:33:27,048 - distributed.core - INFO - Connection to tcp://127.0.0.1:43122 has been closed.
2024-01-11 06:33:27,048 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41659', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954807.048679')
2024-01-11 06:33:27,048 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:33:27,051 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-11 06:33:27,051 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-11 06:33:29,345 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:29,350 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-11 06:33:29,353 - distributed.scheduler - INFO - State start
2024-01-11 06:33:29,394 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:29,395 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-11 06:33:29,395 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-11 06:33:29,396 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:33:29,683 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44347', status: init, memory: 0, processing: 0>
2024-01-11 06:33:29,697 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44347
2024-01-11 06:33:29,697 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43974
2024-01-11 06:33:29,715 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43974; closing.
2024-01-11 06:33:29,715 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44347', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954809.7154539')
2024-01-11 06:33:29,715 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:33:29,911 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41725', status: init, memory: 0, processing: 0>
2024-01-11 06:33:29,911 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41725
2024-01-11 06:33:29,912 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43986
2024-01-11 06:33:29,968 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43986; closing.
2024-01-11 06:33:29,969 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41725', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954809.969304')
2024-01-11 06:33:29,969 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:33:29,998 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42785', status: init, memory: 0, processing: 0>
2024-01-11 06:33:29,999 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42785
2024-01-11 06:33:29,999 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48126
2024-01-11 06:33:30,019 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48126; closing.
2024-01-11 06:33:30,019 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42785', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954810.0197496')
2024-01-11 06:33:30,019 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:33:30,965 - distributed.scheduler - INFO - Receive client connection: Client-507fd865-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:30,966 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48146
2024-01-11 06:33:31,977 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:43968'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 969, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4428, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43968>: Stream is closed
2024-01-11 06:33:32,294 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:33:32,295 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:33:32,295 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:33:32,296 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-11 06:33:32,297 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-11 06:33:34,505 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:34,510 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-11 06:33:34,513 - distributed.scheduler - INFO - State start
2024-01-11 06:33:34,534 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:34,535 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-11 06:33:34,536 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-11 06:33:34,536 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:33:34,632 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42429'
2024-01-11 06:33:36,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:36,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:36,400 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:36,401 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36417
2024-01-11 06:33:36,401 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36417
2024-01-11 06:33:36,401 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37721
2024-01-11 06:33:36,401 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-11 06:33:36,401 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:36,402 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:36,402 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-11 06:33:36,402 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-pffnhl3x
2024-01-11 06:33:36,402 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5dcbac4b-7312-4c16-8e85-e800beed95f4
2024-01-11 06:33:36,402 - distributed.worker - INFO - Starting Worker plugin PreImport-d042cb5e-34e7-4832-9af9-7c08c7ba01a8
2024-01-11 06:33:36,402 - distributed.worker - INFO - Starting Worker plugin RMMSetup-efc84c04-9e89-499d-a587-35acdab694e5
2024-01-11 06:33:36,402 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:36,456 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36417', status: init, memory: 0, processing: 0>
2024-01-11 06:33:36,470 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36417
2024-01-11 06:33:36,470 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44948
2024-01-11 06:33:36,470 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:36,471 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-11 06:33:36,471 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:36,472 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-11 06:33:36,595 - distributed.scheduler - INFO - Receive client connection: Client-5734e37c-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:36,596 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44960
2024-01-11 06:33:36,602 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:36,609 - distributed.scheduler - INFO - Remove client Client-5734e37c-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:36,609 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44960; closing.
2024-01-11 06:33:36,609 - distributed.scheduler - INFO - Remove client Client-5734e37c-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:36,610 - distributed.scheduler - INFO - Close client connection: Client-5734e37c-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:36,610 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42429'. Reason: nanny-close
2024-01-11 06:33:36,611 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:36,612 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36417. Reason: nanny-close
2024-01-11 06:33:36,614 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-11 06:33:36,614 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44948; closing.
2024-01-11 06:33:36,614 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36417', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954816.6144361')
2024-01-11 06:33:36,614 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:33:36,615 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:37,226 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:33:37,227 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:33:37,228 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:33:37,229 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-11 06:33:37,229 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-11 06:33:39,444 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:39,449 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-11 06:33:39,452 - distributed.scheduler - INFO - State start
2024-01-11 06:33:39,474 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:39,475 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-11 06:33:39,476 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-11 06:33:39,476 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:33:39,636 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41921'
2024-01-11 06:33:39,653 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41469'
2024-01-11 06:33:39,667 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46145'
2024-01-11 06:33:39,678 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35971'
2024-01-11 06:33:39,681 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43551'
2024-01-11 06:33:39,690 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36363'
2024-01-11 06:33:39,702 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44995'
2024-01-11 06:33:39,713 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42795'
2024-01-11 06:33:39,928 - distributed.scheduler - INFO - Receive client connection: Client-5b8033ba-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:39,943 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50422
2024-01-11 06:33:40,060 - distributed.scheduler - INFO - Receive client connection: Client-5a24c899-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:40,061 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50440
2024-01-11 06:33:41,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:41,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:41,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:41,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:41,560 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:41,560 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:41,561 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36237
2024-01-11 06:33:41,561 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34033
2024-01-11 06:33:41,561 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36237
2024-01-11 06:33:41,561 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34033
2024-01-11 06:33:41,561 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36599
2024-01-11 06:33:41,561 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:41,561 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37967
2024-01-11 06:33:41,561 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:41,561 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:41,561 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:41,561 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:41,561 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:41,561 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wwvnlg4j
2024-01-11 06:33:41,561 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:41,561 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:41,561 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i7ggbqhe
2024-01-11 06:33:41,561 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6c86980b-cbfb-4a54-92dd-8d8aa436a169
2024-01-11 06:33:41,561 - distributed.worker - INFO - Starting Worker plugin RMMSetup-41b8cdd1-8c85-42b2-888b-25fe479cb749
2024-01-11 06:33:41,562 - distributed.worker - INFO - Starting Worker plugin PreImport-17de8494-86c4-4de2-aeb0-9f3085f85e3b
2024-01-11 06:33:41,562 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f82fb156-18bd-4cc0-8772-01dcc5e36030
2024-01-11 06:33:41,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:41,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:41,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:41,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:41,605 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:41,606 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38079
2024-01-11 06:33:41,606 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38079
2024-01-11 06:33:41,606 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39119
2024-01-11 06:33:41,606 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:41,606 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:41,606 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:41,606 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:41,606 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ofckuiw6
2024-01-11 06:33:41,606 - distributed.worker - INFO - Starting Worker plugin RMMSetup-237f8004-cb6e-4489-ba4b-682caa0a4517
2024-01-11 06:33:41,607 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:41,608 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44519
2024-01-11 06:33:41,608 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44519
2024-01-11 06:33:41,609 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43099
2024-01-11 06:33:41,609 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:41,609 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:41,609 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:41,609 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:41,609 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ysif24pc
2024-01-11 06:33:41,609 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6e82f9ce-6419-4f62-85d6-6138e01a396f
2024-01-11 06:33:41,609 - distributed.worker - INFO - Starting Worker plugin PreImport-90f16a07-267b-4464-bfa3-76f50f260a18
2024-01-11 06:33:41,610 - distributed.worker - INFO - Starting Worker plugin RMMSetup-63ba7611-a02f-4f1f-8a0d-fea009f17393
2024-01-11 06:33:41,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:41,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:41,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:41,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:41,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:41,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:41,634 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:41,635 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45513
2024-01-11 06:33:41,635 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45513
2024-01-11 06:33:41,635 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40243
2024-01-11 06:33:41,635 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:41,635 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:41,636 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:41,636 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:41,636 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wqd4azle
2024-01-11 06:33:41,636 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dc6e0057-9dbd-4ba4-9351-213caf3a38a3
2024-01-11 06:33:41,636 - distributed.worker - INFO - Starting Worker plugin PreImport-a92db3a5-dc17-4dd2-a36d-5ced659f826a
2024-01-11 06:33:41,636 - distributed.worker - INFO - Starting Worker plugin RMMSetup-79092525-f65c-4fb8-b3ee-94f83d56b3e8
2024-01-11 06:33:41,637 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:41,638 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:41,638 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45235
2024-01-11 06:33:41,638 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45235
2024-01-11 06:33:41,638 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33295
2024-01-11 06:33:41,638 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:41,638 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:41,638 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:41,638 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:41,639 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-waey444u
2024-01-11 06:33:41,639 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3d57284e-5b7b-4c26-b687-1e4704eaeb76
2024-01-11 06:33:41,639 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38299
2024-01-11 06:33:41,639 - distributed.worker - INFO - Starting Worker plugin PreImport-f4a47121-7852-4a87-8420-355581f43ec8
2024-01-11 06:33:41,639 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38299
2024-01-11 06:33:41,639 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a346cc88-6527-4a2c-9b4a-5a74981fceee
2024-01-11 06:33:41,639 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35211
2024-01-11 06:33:41,639 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:41,639 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:41,639 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:41,639 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:41,639 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_soh_z12
2024-01-11 06:33:41,640 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a3b6f9b2-85e8-4c9a-8023-35ffaf19c4b0
2024-01-11 06:33:41,640 - distributed.worker - INFO - Starting Worker plugin PreImport-bfaef325-e5d9-42d9-bf25-1061df643106
2024-01-11 06:33:41,640 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eb7aab15-2cf8-47a4-b763-86f0e9cdcdf4
2024-01-11 06:33:41,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:41,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:41,650 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:41,651 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33707
2024-01-11 06:33:41,651 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33707
2024-01-11 06:33:41,652 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44889
2024-01-11 06:33:41,652 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:41,652 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:41,652 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:41,652 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-11 06:33:41,652 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-llfax12b
2024-01-11 06:33:41,652 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-82f6942f-dc16-46b1-ad5d-d6e1b1d01440
2024-01-11 06:33:41,653 - distributed.worker - INFO - Starting Worker plugin PreImport-ea879426-77ed-414d-a19f-553aabf1cf99
2024-01-11 06:33:41,653 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a90d1b27-8654-4af7-a02e-0cb75fd3f65c
2024-01-11 06:33:43,636 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,646 - distributed.worker - INFO - Starting Worker plugin PreImport-f3ab3d11-064d-453e-9b30-108ef94b1546
2024-01-11 06:33:43,646 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ba93f16c-d389-4146-8348-cb1be1e63e6b
2024-01-11 06:33:43,647 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,670 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36237', status: init, memory: 0, processing: 0>
2024-01-11 06:33:43,671 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36237
2024-01-11 06:33:43,672 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50460
2024-01-11 06:33:43,673 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ae2e1fe0-3fc4-446f-a346-679f0ff0c45c
2024-01-11 06:33:43,673 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:43,674 - distributed.worker - INFO - Starting Worker plugin PreImport-fedea1b9-dff4-4f63-b36e-1cb6efb3bd9b
2024-01-11 06:33:43,674 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:43,675 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,675 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,677 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:43,682 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38079', status: init, memory: 0, processing: 0>
2024-01-11 06:33:43,682 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38079
2024-01-11 06:33:43,683 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50468
2024-01-11 06:33:43,684 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:43,685 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:43,685 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,687 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:43,707 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34033', status: init, memory: 0, processing: 0>
2024-01-11 06:33:43,707 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34033
2024-01-11 06:33:43,708 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50478
2024-01-11 06:33:43,709 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:43,710 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:43,710 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:43,728 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,733 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,739 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,745 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,751 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38299', status: init, memory: 0, processing: 0>
2024-01-11 06:33:43,752 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38299
2024-01-11 06:33:43,752 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50486
2024-01-11 06:33:43,753 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:43,754 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:43,754 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,754 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,755 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:43,757 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45513', status: init, memory: 0, processing: 0>
2024-01-11 06:33:43,758 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45513
2024-01-11 06:33:43,758 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50502
2024-01-11 06:33:43,759 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:43,760 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:43,760 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,761 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:43,764 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45235', status: init, memory: 0, processing: 0>
2024-01-11 06:33:43,765 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45235
2024-01-11 06:33:43,765 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50504
2024-01-11 06:33:43,766 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:43,767 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:43,767 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,768 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:43,769 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44519', status: init, memory: 0, processing: 0>
2024-01-11 06:33:43,770 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44519
2024-01-11 06:33:43,770 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50516
2024-01-11 06:33:43,771 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:43,772 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:43,772 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,774 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:43,791 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33707', status: init, memory: 0, processing: 0>
2024-01-11 06:33:43,792 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33707
2024-01-11 06:33:43,792 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50524
2024-01-11 06:33:43,793 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:43,795 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:43,795 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:43,797 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:43,837 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:33:43,838 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:33:43,837 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:33:43,838 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:33:43,838 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:33:43,838 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:33:43,838 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:33:43,838 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-11 06:33:43,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:43,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:43,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:43,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:43,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:43,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:43,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:43,857 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:43,864 - distributed.scheduler - INFO - Remove client Client-5a24c899-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:43,864 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50440; closing.
2024-01-11 06:33:43,865 - distributed.scheduler - INFO - Remove client Client-5a24c899-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:43,865 - distributed.scheduler - INFO - Close client connection: Client-5a24c899-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:43,866 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41921'. Reason: nanny-close
2024-01-11 06:33:43,867 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:43,867 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41469'. Reason: nanny-close
2024-01-11 06:33:43,868 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:43,868 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46145'. Reason: nanny-close
2024-01-11 06:33:43,868 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:43,868 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34033. Reason: nanny-close
2024-01-11 06:33:43,868 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35971'. Reason: nanny-close
2024-01-11 06:33:43,869 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:43,869 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36237. Reason: nanny-close
2024-01-11 06:33:43,869 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43551'. Reason: nanny-close
2024-01-11 06:33:43,869 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44519. Reason: nanny-close
2024-01-11 06:33:43,869 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:43,869 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36363'. Reason: nanny-close
2024-01-11 06:33:43,869 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38299. Reason: nanny-close
2024-01-11 06:33:43,870 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:43,870 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44995'. Reason: nanny-close
2024-01-11 06:33:43,870 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:43,870 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33707. Reason: nanny-close
2024-01-11 06:33:43,870 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42795'. Reason: nanny-close
2024-01-11 06:33:43,870 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:43,870 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38079. Reason: nanny-close
2024-01-11 06:33:43,871 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45235. Reason: nanny-close
2024-01-11 06:33:43,871 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:43,871 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:43,871 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50478; closing.
2024-01-11 06:33:43,871 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45513. Reason: nanny-close
2024-01-11 06:33:43,871 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:43,871 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:43,871 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34033', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954823.871858')
2024-01-11 06:33:43,872 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50516; closing.
2024-01-11 06:33:43,873 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:43,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:43,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:43,873 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:43,873 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:43,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:43,873 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44519', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954823.8736954')
2024-01-11 06:33:43,873 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:43,874 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:43,874 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50460; closing.
2024-01-11 06:33:43,874 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50486; closing.
2024-01-11 06:33:43,874 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:43,875 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:43,875 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:43,875 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:43,876 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36237', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954823.8759918')
2024-01-11 06:33:43,876 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38299', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954823.8764527')
2024-01-11 06:33:43,876 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50524; closing.
2024-01-11 06:33:43,877 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:50516>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-11 06:33:43,880 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33707', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954823.8803303')
2024-01-11 06:33:43,880 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50504; closing.
2024-01-11 06:33:43,881 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50468; closing.
2024-01-11 06:33:43,881 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50502; closing.
2024-01-11 06:33:43,881 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45235', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954823.8818655')
2024-01-11 06:33:43,882 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38079', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954823.882331')
2024-01-11 06:33:43,882 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45513', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954823.882813')
2024-01-11 06:33:43,883 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:33:44,661 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34277', status: init, memory: 0, processing: 0>
2024-01-11 06:33:44,662 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34277
2024-01-11 06:33:44,662 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50528
2024-01-11 06:33:44,747 - distributed.scheduler - INFO - Remove client Client-5b8033ba-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:44,748 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50422; closing.
2024-01-11 06:33:44,748 - distributed.scheduler - INFO - Remove client Client-5b8033ba-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:44,748 - distributed.scheduler - INFO - Close client connection: Client-5b8033ba-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:44,752 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50528; closing.
2024-01-11 06:33:44,753 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34277', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954824.7532423')
2024-01-11 06:33:44,753 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:33:44,983 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:33:44,983 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:33:44,984 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:33:44,985 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-11 06:33:44,985 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-11 06:33:47,264 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:47,269 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-11 06:33:47,273 - distributed.scheduler - INFO - State start
2024-01-11 06:33:47,295 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:47,296 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-11 06:33:47,297 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-11 06:33:47,297 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-11 06:33:47,369 - distributed.scheduler - INFO - Receive client connection: Client-5ec72bc2-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:47,384 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50620
2024-01-11 06:33:47,396 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39427'
2024-01-11 06:33:47,672 - distributed.scheduler - INFO - Receive client connection: Client-601dccbf-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:47,673 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50630
2024-01-11 06:33:49,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:49,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:49,169 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:49,170 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35305
2024-01-11 06:33:49,170 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35305
2024-01-11 06:33:49,170 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42763
2024-01-11 06:33:49,170 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:49,170 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:49,170 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:49,170 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-11 06:33:49,171 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-efo_rgb4
2024-01-11 06:33:49,171 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c418ab82-dc70-49d0-828d-830fa2f50e6e
2024-01-11 06:33:49,171 - distributed.worker - INFO - Starting Worker plugin PreImport-64a92dfd-c041-414e-b3e3-10c340703093
2024-01-11 06:33:49,171 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bc06e4ac-be2b-48a4-8f10-2890eb60f632
2024-01-11 06:33:49,488 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:49,567 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35305', status: init, memory: 0, processing: 0>
2024-01-11 06:33:49,569 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35305
2024-01-11 06:33:49,569 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50644
2024-01-11 06:33:49,570 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-11 06:33:49,571 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-11 06:33:49,571 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:49,573 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-11 06:33:49,603 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-11 06:33:49,606 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:49,608 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:49,608 - distributed.scheduler - INFO - Remove client Client-601dccbf-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:49,609 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50630; closing.
2024-01-11 06:33:49,609 - distributed.scheduler - INFO - Remove client Client-601dccbf-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:49,609 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-11 06:33:49,610 - distributed.scheduler - INFO - Close client connection: Client-601dccbf-b04b-11ee-ba52-d8c49764f6bb
2024-01-11 06:33:49,612 - distributed.scheduler - INFO - Remove client Client-5ec72bc2-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:49,612 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50620; closing.
2024-01-11 06:33:49,612 - distributed.scheduler - INFO - Remove client Client-5ec72bc2-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:49,613 - distributed.scheduler - INFO - Close client connection: Client-5ec72bc2-b04b-11ee-b556-d8c49764f6bb
2024-01-11 06:33:49,614 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39427'. Reason: nanny-close
2024-01-11 06:33:49,614 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-11 06:33:49,615 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35305. Reason: nanny-close
2024-01-11 06:33:49,617 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-11 06:33:49,617 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50644; closing.
2024-01-11 06:33:49,617 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35305', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704954829.6174433')
2024-01-11 06:33:49,617 - distributed.scheduler - INFO - Lost all workers
2024-01-11 06:33:49,618 - distributed.nanny - INFO - Worker closed
2024-01-11 06:33:50,430 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-11 06:33:50,430 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-11 06:33:50,431 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:33:50,432 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-11 06:33:50,432 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-11 06:33:52,804 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:52,812 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45769 instead
  warnings.warn(
2024-01-11 06:33:52,819 - distributed.scheduler - INFO - State start
2024-01-11 06:33:52,852 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-11 06:33:52,854 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2024-01-11 06:33:52,854 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-11 06:33:52,855 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4027, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 858, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 630, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2024-01-11 06:33:52,958 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43689'
2024-01-11 06:33:54,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-11 06:33:54,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-11 06:33:54,634 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-11 06:33:54,635 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41333
2024-01-11 06:33:54,635 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41333
2024-01-11 06:33:54,635 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33439
2024-01-11 06:33:54,635 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-11 06:33:54,635 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:33:54,635 - distributed.worker - INFO -               Threads:                          1
2024-01-11 06:33:54,635 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-11 06:33:54,635 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5yztu87w
2024-01-11 06:33:54,636 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7dbdd8de-76e2-483f-8ad3-fc91c08094b0
2024-01-11 06:33:54,636 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eea4c570-e2d1-4be7-a427-c3263d443499
2024-01-11 06:33:54,950 - distributed.worker - INFO - Starting Worker plugin PreImport-c85dc354-d8fc-4dc7-9493-6fbb55006d0a
2024-01-11 06:33:54,950 - distributed.worker - INFO - -------------------------------------------------
2024-01-11 06:34:02,913 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43689'. Reason: nanny-close
2024-01-11 06:34:24,950 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34819 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34381 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36083 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32937 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36687 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36451 instead
  warnings.warn(
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 51 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
