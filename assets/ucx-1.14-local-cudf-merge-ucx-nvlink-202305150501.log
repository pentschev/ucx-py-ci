2023-05-15 06:27:49,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:49,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:49,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:49,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:49,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:49,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:49,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:49,950 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:49,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:49,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:49,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:49,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:49,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:49,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:50,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:50,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:68744:0:68744] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  68744) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fe0405a5c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7fe0405a5dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7fe0405a6134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe0df6d6420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7fe04062faa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fe040660b48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7fe040556427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7fe040556a08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7fe040558f2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fe0405b0539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fe040558fdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fe04062c28a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fe0406ea6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55f7a0e14b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55f7a0e05112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f7a0dfe27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f7a0e0fc05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f7a0dff81b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f7a0e0fef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55f7a0e1da16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55f7a0f2d9b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55f7a0dbb817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55f7a0e06f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55f7a0e04d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f7a0e0fef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f7a0dff81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f7a0e0fef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f7a0dff81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f7a0e0fef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f7a0dff81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f7a0e0fef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f7a0dff81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f7a0dfe27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f7a0e0fc05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55f7a0e03fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f7a0dfe27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55f7a0e1d935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55f7a0e1e104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55f7a0ee4fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55f7a0e082bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f7a0e031bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f7a0e0fef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55f7a0e1dc72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55f7a0e031bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f7a0e0fef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f7a0dff81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f7a0dfe27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f7a0e0fc05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55f7a0dff81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55f7a0e0fef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55f7a0dff568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f7a0dfe27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55f7a0e0fc05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55f7a0e003cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55f7a0dfe27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55f7a0dfdf07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55f7a0dfdeb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55f7a0eae8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55f7a0edcadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55f7a0ed8c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55f7a0ed07ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55f7a0ed06bd]
=================================
[dgx13:68757:0:68757] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  68757) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fdd65889c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7fdd65889dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7fdd6588a134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fde0ab53420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7fdd65913aa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fdd65944b48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7fdd6583a427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7fdd6583aa08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7fdd6583cf2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fdd65894539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fdd6583cfdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fdd6591028a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fdd659ce6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55681cebbb08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55681ceac112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55681cea527a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55681ceb6c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55681cea681b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55681ceb6ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55681cec4a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55681cfd49b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55681ce62817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55681ceadf83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55681ceabd36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55681ceb6ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55681cea681b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55681ceb6ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55681cea681b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55681ceb6ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55681cea681b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55681ceb6ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55681cea681b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55681cea527a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55681ceb6c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55681ceaafa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55681cea527a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55681cec4935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55681cec5104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55681cf8bfc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55681ceaf2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55681ceaa1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55681ceb6ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55681cec4c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55681ceaa1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55681ceb6ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55681cea681b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55681cea527a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55681ceb6c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55681cea681b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55681ceb6ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55681cea6568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55681cea527a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55681ceb6c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55681cea73cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55681cea527a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55681cea4f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55681cea4eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55681cf558bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55681cf83adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55681cf7fc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55681cf777ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55681cf776bd]
=================================
[dgx13:68754:0:68754] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  68754) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fb7e9a52c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7fb7e9a52dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7fb7e9a53134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fb88cd2a420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7fb7e9adcaa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fb7e9b0db48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7fb7e9a03427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7fb7e9a03a08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7fb7e9a05f2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fb7e9a5d539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fb7e9a05fdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fb7e9ad928a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fb7e9b976e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55e0e13c7b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55e0e13b8112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e0e13b127a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e0e13c2c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e0e13b281b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55e0e13d770e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fb8802312fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55e0e13bb2bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55e0e136e817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55e0e13b9f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55e0e13b7d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e0e13c2ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e0e13b281b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e0e13c2ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e0e13b281b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e0e13c2ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e0e13b281b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e0e13c2ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e0e13b281b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e0e13b127a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e0e13c2c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55e0e13b6fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e0e13b127a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55e0e13d0935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55e0e13d1104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55e0e1497fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55e0e13bb2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e0e13b61bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e0e13c2ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55e0e13d0c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e0e13b61bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e0e13c2ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e0e13b281b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e0e13b127a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e0e13c2c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e0e13b281b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e0e13c2ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55e0e13b2568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e0e13b127a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e0e13c2c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55e0e13b33cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e0e13b127a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55e0e13b0f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55e0e13b0eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55e0e14618bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55e0e148fadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55e0e148bc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55e0e14837ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55e0e14836bd]
=================================
[dgx13:68751:0:68751] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  68751) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f9b277c8c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7f9b277c8dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7f9b277c9134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f9bdeabd420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f9b27852aa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f9b27883b48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7f9b27779427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7f9b27779a08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7f9b2777bf2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f9b277d3539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f9b2777bfdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f9b2784f28a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f9b2790d6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55c5d3540b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55c5d3531112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c5d352a27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55c5d353bc05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c5d352b81b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c5d353bef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55c5d3549a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55c5d36599b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55c5d34e7817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55c5d3532f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55c5d3530d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c5d353bef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c5d352b81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c5d353bef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c5d352b81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c5d353bef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c5d352b81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c5d353bef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c5d352b81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c5d352a27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55c5d353bc05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55c5d352ffa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c5d352a27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55c5d3549935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55c5d354a104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55c5d3610fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55c5d35342bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55c5d352f1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c5d353bef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55c5d3549c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55c5d352f1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c5d353bef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c5d352b81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c5d352a27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55c5d353bc05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c5d352b81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c5d353bef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55c5d352b568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c5d352a27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55c5d353bc05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55c5d352c3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c5d352a27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55c5d3529f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55c5d3529eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55c5d35da8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55c5d3608adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55c5d3604c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55c5d35fc7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55c5d35fc6bd]
=================================
Task exception was never retrieved
future: <Task finished name='Task-931' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-05-15 06:27:58,017 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55105
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8c1c86d280, tag: 0xc533c0014f9227c1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8c1c86d280, tag: 0xc533c0014f9227c1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:27:58,017 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55105
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f5f62776280, tag: 0x8be998153104b2f7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f5f62776280, tag: 0x8be998153104b2f7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-05-15 06:27:58,018 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35963 -> ucx://127.0.0.1:55105
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8c1c86d380, tag: 0x98bceaaecb93aaa6, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:27:58,024 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55105
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-15 06:27:58,045 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f5f62776180, tag: 0x4617d1917a908e16, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f5f62776180, tag: 0x4617d1917a908e16, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:27:58,046 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52309
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f55d10c6140, tag: 0x138f08d2495f4cb7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f55d10c6140, tag: 0x138f08d2495f4cb7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-15 06:27:58,046 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52309
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f5f62776100, tag: 0x8ff7795c288cfbee, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f5f62776100, tag: 0x8ff7795c288cfbee, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:27:58,050 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-15 06:27:58,052 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43033
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f55d10c61c0, tag: 0x9b7f02166d6eeb6, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f55d10c61c0, tag: 0x9b7f02166d6eeb6, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-841' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-833' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-05-15 06:27:58,073 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35963 -> ucx://127.0.0.1:43033
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8c1c86d300, tag: 0x6b1136ccf290ea2f, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:27:58,082 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43033
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f8c1c86d1c0, tag: 0xdec7066e7227973a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f8c1c86d1c0, tag: 0xdec7066e7227973a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-05-15 06:27:58,092 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:52309
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f8c1c86d100, tag: 0x3ff54eaee2b5cc04, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f8c1c86d100, tag: 0x3ff54eaee2b5cc04, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-15 06:27:58,098 - distributed.nanny - WARNING - Restarting worker
Task exception was never retrieved
future: <Task finished name='Task-835' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-05-15 06:27:58,103 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43033
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7fc91049c1c0, tag: 0x96ef970e75ffb570, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7fc91049c1c0, tag: 0x96ef970e75ffb570, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
[dgx13:68746:0:68746] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  68746) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fc9107d3c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7fc9107d3dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7fc9107d4134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc9afa8d420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7fc91085daa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fc91088eb48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7fc910784427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7fc910784a08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7fc910786f2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fc9107de539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fc910786fdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fc91085a28a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fc9109186e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55c143f8ab08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55c143f7b112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c143f7427a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55c143f85c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c143f7581b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55c143f9a70e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fc92f50f2fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55c143f7e2bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55c143f31817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55c143f7cf83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55c143f7ad36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c143f85ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c143f7581b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c143f85ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c143f7581b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c143f85ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c143f7581b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c143f85ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c143f7581b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c143f7427a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55c143f85c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55c143f79fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c143f7427a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55c143f93935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55c143f94104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55c14405afc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55c143f7e2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55c143f791bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c143f85ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55c143f93c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55c143f791bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c143f85ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c143f7581b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c143f7427a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55c143f85c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55c143f7581b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55c143f85ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55c143f75568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c143f7427a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55c143f85c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55c143f763cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55c143f7427a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55c143f73f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55c143f73eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55c1440248bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55c144052adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55c14404ec24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55c1440467ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55c1440466bd]
=================================
2023-05-15 06:27:58,166 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:43033
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f5f62776200, tag: 0x58015ba16c14d00, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f5f62776200, tag: 0x58015ba16c14d00, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-15 06:27:58,194 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:27:58,241 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:27:58,279 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:27:58,346 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:27:58,346 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34085
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7f8c1c86d240, tag: 0x9926ce3e7efec2aa, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7f8c1c86d240, tag: 0x9926ce3e7efec2aa, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-876' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_recv>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 52, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer
2023-05-15 06:27:58,375 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34085
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-05-15 06:27:58,377 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46259 -> ucx://127.0.0.1:34085
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f55d10c6400, tag: 0xdcb9cb150a5538fe, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:27:58,377 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34085
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f55d10c6180, tag: 0x156c189bf091f6cf, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f55d10c6180, tag: 0x156c189bf091f6cf, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-05-15 06:27:59,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:59,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:59,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:59,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:59,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:59,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:59,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:59,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:27:59,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:27:59,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:28:27,546 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37531
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 490, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:37531 after 30 s
[dgx13:69269:0:69269] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  69269) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f1384037c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7f1384037dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7f1384038134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f14149fa420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f13718efaa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f1371920b48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7f137187e427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7f137187ea08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7f1371880f2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f1384042539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f1371880fdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f13718ec28a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f13719aa6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x563fac309b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x563fac2fa112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563fac2f327a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563fac304c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563fac2f481b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563fac304ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x563fac312a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x563fac4229b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x563fac2b0817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x563fac2fbf83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x563fac2f9d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563fac304ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563fac2f481b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563fac304ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563fac2f481b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563fac304ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563fac2f481b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563fac304ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563fac2f481b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563fac2f327a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563fac304c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x563fac2f8fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563fac2f327a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x563fac312935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x563fac313104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x563fac3d9fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x563fac2fd2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x563fac2f81bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563fac304ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x563fac312c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x563fac2f81bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563fac304ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563fac2f481b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563fac2f327a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563fac304c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563fac2f481b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563fac304ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x563fac2f4568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563fac2f327a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563fac304c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x563fac2f53cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563fac2f327a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x563fac2f2f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x563fac2f2eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x563fac3a38bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x563fac3d1adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x563fac3cdc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x563fac3c57ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x563fac3c56bd]
=================================
2023-05-15 06:28:28,578 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46259 -> ucx://127.0.0.1:41489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f55d10c6400, tag: 0x6f76982aef125e61, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:28,621 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:28:28,890 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-0ea0fecc141b0a99fba07242f43fbda1', 7)
Function:  <dask.layers.CallableLazyImport object at 0x7f5ad4
args:      (               key   payload
shuffle                     
7            11306  52335585
7            11310  20663788
7            31875  25182442
7            11322  21116206
7            43235  22535336
...            ...       ...
7        799995530  98141916
7        799995549  81161463
7        799995621  77691799
7        799995633   2420249
7        799995646  61437624

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-15 06:28:30,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:28:30,173 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:69281:0:69281] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  69281) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7fed88066c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7fed88066dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7fed88067134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fee270aa420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7fed81f6daa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fed81f9eb48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7fed81efc427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7fed81efca08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7fed81efef2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7fed88071539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fed81efefdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fed81f6a28a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7fed880c66e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x563d48b1cb08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x563d48b0d112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563d48b0627a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563d48b17c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563d48b0781b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x563d48b2c70e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7feda6b302fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x563d48b102bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x563d48ac3817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x563d48b0ef83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x563d48b0cd36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563d48b17ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563d48b0781b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563d48b17ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563d48b0781b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563d48b17ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563d48b0781b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563d48b17ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563d48b0781b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563d48b0627a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563d48b17c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x563d48b0bfa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563d48b0627a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x563d48b25935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x563d48b26104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x563d48becfc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x563d48b102bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x563d48b0b1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563d48b17ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x563d48b25c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x563d48b0b1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563d48b17ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563d48b0781b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563d48b0627a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563d48b17c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x563d48b0781b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x563d48b17ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x563d48b07568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563d48b0627a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x563d48b17c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x563d48b083cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x563d48b0627a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x563d48b05f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x563d48b05eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x563d48bb68bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x563d48be4adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x563d48be0c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x563d48bd87ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x563d48bd86bd]
=================================
[dgx13:69278:0:69278] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  69278) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f9f373d5c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7f9f373d5dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7f9f373d6134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f9fda527420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f9f3745faa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f9f37490b48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7f9f37386427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7f9f37386a08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7f9f37388f2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f9f373e0539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f9f37388fdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f9f3745c28a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f9f3751a6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x56077277fb08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x560772770112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56077276927a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56077277ac05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56077276a81b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x56077278f70e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f9f59fae2fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5607727732bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x560772726817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x560772771f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x56077276fd36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56077277aef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56077276a81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56077277aef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56077276a81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56077277aef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56077276a81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56077277aef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56077276a81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56077276927a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56077277ac05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x56077276efa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56077276927a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x560772788935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x560772789104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x56077284ffc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5607727732bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56077276e1bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56077277aef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x560772788c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56077276e1bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56077277aef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56077276a81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56077276927a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56077277ac05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56077276a81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56077277aef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x56077276a568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56077276927a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56077277ac05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x56077276b3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56077276927a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x560772768f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x560772768eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5607728198bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x560772847adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x560772843c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x56077283b7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x56077283b6bd]
=================================
[dgx13:69355:0:69355] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  69355) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7ff21d955c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7ff21d955dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7ff21d956134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7ff2c0aa7420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7ff21d9dfaa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7ff21da10b48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7ff21d906427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7ff21d906a08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7ff21d908f2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7ff21d960539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7ff21d908fdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7ff21d9dc28a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7ff21da9a6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x556087107b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5560870f8112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5560870f127a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556087102c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5560870f281b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55608711770e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7ff2b402e2fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5560870fb2bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5560870ae817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5560870f9f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5560870f7d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556087102ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5560870f281b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556087102ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5560870f281b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556087102ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5560870f281b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556087102ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5560870f281b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5560870f127a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556087102c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5560870f6fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5560870f127a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x556087110935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x556087111104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5560871d7fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5560870fb2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5560870f61bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556087102ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x556087110c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5560870f61bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556087102ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5560870f281b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5560870f127a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556087102c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5560870f281b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x556087102ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5560870f2568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5560870f127a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x556087102c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5560870f33cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5560870f127a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5560870f0f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5560870f0eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5560871a18bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5560871cfadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5560871cbc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5560871c37ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5560871c36bd]
=================================
2023-05-15 06:28:32,327 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45241
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f55d10c6440, tag: 0x6d9c8d87b92d7ac8, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f55d10c6440, tag: 0x6d9c8d87b92d7ac8, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:28:32,327 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45241
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f5f627763c0, tag: 0xccc7ab9d3189669a, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f5f627763c0, tag: 0xccc7ab9d3189669a, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:28:32,328 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45241
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8c1c86d1c0, tag: 0xca64029c06f3a06f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8c1c86d1c0, tag: 0xca64029c06f3a06f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:28:32,328 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46259 -> ucx://127.0.0.1:45241
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f55d10c63c0, tag: 0x293660911890b619, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:32,328 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45241
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f70a0001240, tag: 0x90e9f2ca6fff8d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f70a0001240, tag: 0x90e9f2ca6fff8d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:28:32,347 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f55d10c6380, tag: 0x11c24da1fcdf844f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f55d10c6380, tag: 0x11c24da1fcdf844f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:28:32,347 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40299 -> ucx://127.0.0.1:45189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70a0001340, tag: 0x1fc6ec2f7b443f87, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:32,347 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f5f62776440, tag: 0x3108aa29ae469a90, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f5f62776440, tag: 0x3108aa29ae469a90, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:28:32,348 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f70a0001200, tag: 0x4602b3dd25a04915, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f70a0001200, tag: 0x4602b3dd25a04915, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:28:32,348 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52173 -> ucx://127.0.0.1:40185
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f5f627764c0, tag: 0x3f6f47ea42d2895d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:32,348 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46259 -> ucx://127.0.0.1:40185
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f55d10c6500, tag: 0x92d7a7069577b889, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:32,388 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:28:32,401 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60581 -> ucx://127.0.0.1:45189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 353, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXConnectionReset: Endpoint 0x7f9752d61180 error: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-5357' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-5381' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
[dgx13:69272:0:69272] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  69272) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f9758042c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7f9758042dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7f9758043134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f97f6a15420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f97538efaa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f9753920b48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7f975387e427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7f975387ea08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7f9753880f2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f975804d539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f9753880fdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f97538ec28a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f97539aa6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x564d56032b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x564d56023112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564d5601c27a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564d5602dc05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564d5601d81b]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564d5604270e]
19  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f977649b2fe]
20  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x564d560262bc]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x564d55fd9817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x564d56024f83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x564d56022d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564d5602def3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564d5601d81b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564d5602def3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564d5601d81b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564d5602def3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564d5601d81b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564d5602def3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564d5601d81b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564d5601c27a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564d5602dc05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x564d56021fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564d5601c27a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x564d5603b935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x564d5603c104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x564d56102fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x564d560262bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x564d560211bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564d5602def3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x564d5603bc72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x564d560211bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564d5602def3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564d5601d81b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564d5601c27a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564d5602dc05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564d5601d81b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564d5602def3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x564d5601d568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564d5601c27a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564d5602dc05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x564d5601e3cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564d5601c27a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x564d5601bf07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x564d5601beb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x564d560cc8bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x564d560faadc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x564d560f6c24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x564d560ee7ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x564d560ee6bd]
=================================
2023-05-15 06:28:32,450 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35963 -> ucx://127.0.0.1:45189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8c1c86d480, tag: 0x168b720f76a17f91, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:32,450 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35963 -> ucx://127.0.0.1:40185
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8c1c86d500, tag: 0x304f9e4df01f8977, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:32,451 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8c1c86d300, tag: 0x3366baa7f5c01b3b, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8c1c86d300, tag: 0x3366baa7f5c01b3b, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:28:32,453 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:28:32,493 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:28:32,585 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35963 -> ucx://127.0.0.1:60581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8c1c86d4c0, tag: 0x20f042da77609ae1, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:32,585 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40299 -> ucx://127.0.0.1:60581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70a00013c0, tag: 0x39033a95994d438d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:32,585 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f55d10c6140, tag: 0xdbcc735fafa7b5c, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f55d10c6140, tag: 0xdbcc735fafa7b5c, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:60581 after 30 s
2023-05-15 06:28:32,586 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f8c1c86d140, tag: 0xd92c7e5a56b015f5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f8c1c86d140, tag: 0xd92c7e5a56b015f5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-05-15 06:28:32,585 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f5f62776100, tag: 0x67f0609ae0b9cb83, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f5f62776100, tag: 0x67f0609ae0b9cb83, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:60581 after 30 s
2023-05-15 06:28:32,586 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:60581
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f70a00011c0, tag: 0xf33793b58ff9d004, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f70a00011c0, tag: 0xf33793b58ff9d004, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-05-15 06:28:32,647 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:28:34,002 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:28:34,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:28:34,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:28:34,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:28:34,050 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-cc29681570222d40a8f7cbaccb4b14fe', 0)
Function:  <dask.layers.CallableLazyImport object at 0x7f87a0
args:      (               key   payload
shuffle                     
0            53893  24376480
0            40480   6060381
0            53894  40382370
0            40484  32216382
0            13829  90713806
...            ...       ...
0        799988403  15210604
0        799988412   3797717
0        799988415  96599625
0        799990414   1908821
0        799990431  94527653

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-15 06:28:34,102 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-cc29681570222d40a8f7cbaccb4b14fe', 2)
Function:  <dask.layers.CallableLazyImport object at 0x7f5150
args:      (               key   payload
shuffle                     
2            53896  67251865
2            40491  20351092
2            53901  52128004
2            80549   6154006
2            40492  94131803
...            ...       ...
2        799990411  66901352
2        799990417  49827709
2        799990421  18023809
2        799990422  15140958
2        799990429  61114979

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-15 06:28:34,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:28:34,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:28:34,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:28:34,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
[dgx13:69551:0:69551] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  69551) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7efc1cd48c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7efc1cd48dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7efc1cd49134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7efcade88420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7efc1cdd2aa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7efc1ce03b48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7efc1ccf9427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7efc1ccf9a08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7efc1ccfbf2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7efc1cd53539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7efc1ccfbfdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7efc1cdcf28a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7efc1ce8d6e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55881d1e9b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55881d1da112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55881d1d327a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55881d1e4c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55881d1d481b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55881d1e4ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55881d1f2a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55881d3029b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55881d190817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55881d1dbf83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55881d1d9d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55881d1e4ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55881d1d481b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55881d1e4ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55881d1d481b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55881d1e4ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55881d1d481b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55881d1e4ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55881d1d481b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55881d1d327a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55881d1e4c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55881d1d8fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55881d1d327a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55881d1f2935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55881d1f3104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55881d2b9fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55881d1dd2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55881d1d81bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55881d1e4ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55881d1f2c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55881d1d81bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55881d1e4ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55881d1d481b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55881d1d327a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55881d1e4c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55881d1d481b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55881d1e4ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55881d1d4568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55881d1d327a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55881d1e4c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55881d1d53cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55881d1d327a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55881d1d2f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55881d1d2eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55881d2838bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55881d2b1adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55881d2adc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55881d2a57ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55881d2a56bd]
=================================
[dgx13:69555:0:69555] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  69555) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2dc) [0x7f3af05f0c1c]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x30dff) [0x7f3af05f0dff]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x31134) [0x7f3af05f1134]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f3b8f72c420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x18) [0x7f3af067aaa8]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f3af06abb48]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23427) [0x7f3af05a1427]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a08) [0x7f3af05a1a08]
 8  /opt/conda/envs/gdf/lib/libuct.so.0(+0x25f2c) [0x7f3af05a3f2c]
 9  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xf9) [0x7f3af05fb539]
10  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f3af05a3fdb]
11  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f3af067728a]
12  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x286e1) [0x7f3af07356e1]
13  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x564fc8889b08]
14  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x564fc887a112]
15  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564fc887327a]
16  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564fc8884c05]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564fc887481b]
18  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564fc8884ef3]
19  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x564fc8892a16]
20  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x564fc89a29b1]
21  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x564fc8830817]
22  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x564fc887bf83]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x564fc8879d36]
24  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564fc8884ef3]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564fc887481b]
26  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564fc8884ef3]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564fc887481b]
28  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564fc8884ef3]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564fc887481b]
30  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564fc8884ef3]
31  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564fc887481b]
32  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564fc887327a]
33  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564fc8884c05]
34  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x564fc8878fa7]
35  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564fc887327a]
36  /opt/conda/envs/gdf/bin/python(+0x147935) [0x564fc8892935]
37  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x564fc8893104]
38  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x564fc8959fc8]
39  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x564fc887d2bc]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x564fc88781bb]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564fc8884ef3]
42  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x564fc8892c72]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x564fc88781bb]
44  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564fc8884ef3]
45  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564fc887481b]
46  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564fc887327a]
47  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564fc8884c05]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564fc887481b]
49  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564fc8884ef3]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x564fc8874568]
51  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564fc887327a]
52  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564fc8884c05]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x564fc88753cb]
54  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564fc887327a]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x564fc8872f07]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x564fc8872eb9]
57  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x564fc89238bb]
58  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x564fc8951adc]
59  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x564fc894dc24]
60  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x564fc89457ed]
61  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x564fc89456bd]
=================================
2023-05-15 06:28:35,554 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:46259
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #121] ep: 0x7f5f62776140, tag: 0xd954675933a5eda5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #121] ep: 0x7f5f62776140, tag: 0xd954675933a5eda5, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-15 06:28:35,554 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:46259
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #056] ep: 0x7f70a0001180, tag: 0x1b84fed98c216280, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #056] ep: 0x7f70a0001180, tag: 0x1b84fed98c216280, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-15 06:28:35,554 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:46259
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #142] ep: 0x7f8c1c86d180, tag: 0x2623424d35d44158, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #142] ep: 0x7f8c1c86d180, tag: 0x2623424d35d44158, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-05-15 06:28:35,621 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40299 -> ucx://127.0.0.1:42555
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70a00013c0, tag: 0xa4d4abc426e72e92, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:35,621 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:40299 -> ucx://127.0.0.1:55695
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f70a00011c0, tag: 0xd48e9ccdb0c9a0af, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:35,624 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:28:35,675 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52173 -> ucx://127.0.0.1:55695
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f5f62776480, tag: 0xdafab81cbea7448a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:35,676 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35963 -> ucx://127.0.0.1:55695
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8c1c86d140, tag: 0xfde5e99d2b462964, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:35,677 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35963 -> ucx://127.0.0.1:42555
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8c1c86d4c0, tag: 0x2744dc85ffbb32fd, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-05-15 06:28:35,704 - distributed.nanny - WARNING - Restarting worker
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Exception ignored in: 'cupy.cuda.thrust.cupy_malloc'
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-15 06:28:35,766 - distributed.nanny - WARNING - Restarting worker
2023-05-15 06:28:35,835 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-5366301a596b755bb8c33997d3ce7726', 2)
Function:  generate_chunk
args:      (2, 100000000, 8, 'build', 0.3, True)
kwargs:    {}
Exception: "RuntimeError('transform: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered')"

2023-05-15 06:28:35,839 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-5366301a596b755bb8c33997d3ce7726', 3)
Function:  generate_chunk
args:      (3, 100000000, 8, 'build', 0.3, True)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Exception ignored in: 'cupy.cuda.thrust.cupy_malloc'
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-05-15 06:28:35,953 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-3393696d3757f92da87d0dddd0c6ae01', 6)
Function:  generate_chunk
args:      (6, 100000000, 8, 'other', 0.3, True)
kwargs:    {}
Exception: "RuntimeError('transform: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered')"

2023-05-15 06:28:35,966 - distributed.worker - WARNING - Compute Failed
Key:       ('assign-3a80c18c141237beba0aaaa0231a1f69', 5)
Function:  subgraph_callable-3bebd282-e073-4bb1-aafe-bcf8f127
args:      (< could not convert arg to str >)
kwargs:    {}
Exception: "RuntimeError('Fatal CUDA error encountered at: /opt/conda/conda-bld/work/cpp/include/cudf/table/table_device_view.cuh:269: 700 cudaErrorIllegalAddress an illegal memory access was encountered')"

2023-05-15 06:28:35,970 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-3393696d3757f92da87d0dddd0c6ae01', 2)
Function:  generate_chunk
args:      (2, 100000000, 8, 'other', 0.3, True)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-05-15 06:28:36,097 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-15 06:28:36,098 - distributed.core - ERROR - Exception while handling op get_data
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 830, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 987, in wrapper
    return await func(self, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 330, in write
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2230, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 320, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 388, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-05-15 06:28:36,260 - distributed.core - ERROR - std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-15 06:28:36,261 - distributed.worker - ERROR - std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-15 06:28:36,268 - distributed.core - ERROR - std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-15 06:28:36,269 - distributed.worker - ERROR - std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-15 06:28:36,275 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:35963
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #064] ep: 0x7f70a0001140, tag: 0xcb8eb72bd80aca6f, nbytes: 165, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #064] ep: 0x7f70a0001140, tag: 0xcb8eb72bd80aca6f, nbytes: 165, type: <class 'numpy.ndarray'>>: Message truncated")
2023-05-15 06:28:36,748 - distributed.core - ERROR - std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-15 06:28:36,749 - distributed.worker - ERROR - std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-15 06:28:36,757 - distributed.core - ERROR - std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-15 06:28:36,757 - distributed.worker - ERROR - std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-05-15 06:28:37,137 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:28:37,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:28:37,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:28:37,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-15 06:28:37,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-15 06:28:37,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
