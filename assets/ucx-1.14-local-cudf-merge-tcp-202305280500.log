2023-05-28 07:16:33,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ezrl48p0', purging
2023-05-28 07:16:33,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ewkhvmc', purging
2023-05-28 07:16:33,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25jlh3d0', purging
2023-05-28 07:16:33,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ifmpuf70', purging
2023-05-28 07:16:33,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zjll5z5u', purging
2023-05-28 07:16:33,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1hqy7kp', purging
2023-05-28 07:16:33,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j3raub8a', purging
2023-05-28 07:16:33,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sr6j6afy', purging
2023-05-28 07:16:33,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:33,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:33,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:33,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:33,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:33,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:33,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:33,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:33,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:33,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:33,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:33,317 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:33,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:33,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:33,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:33,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:35,381 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:35,449 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:35,474 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:35,501 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:35,525 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:35,578 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:35,580 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:35,723 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:36,865 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gq7h_2sd', purging
2023-05-28 07:16:36,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-091270qz', purging
2023-05-28 07:16:36,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nfgax2ce', purging
2023-05-28 07:16:36,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0qgz294m', purging
2023-05-28 07:16:36,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_i6njq9', purging
2023-05-28 07:16:36,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-shejjlhb', purging
2023-05-28 07:16:36,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zg87pqok', purging
2023-05-28 07:16:36,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-97m4zavd', purging
2023-05-28 07:16:36,869 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:36,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:36,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:36,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:36,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:36,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:37,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:37,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:37,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:37,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:37,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:37,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:37,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:37,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:37,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:37,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:39,097 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:39,127 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:39,156 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:39,204 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:39,230 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:39,253 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:39,279 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:39,461 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:40,607 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wcntduif', purging
2023-05-28 07:16:40,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9qfphirq', purging
2023-05-28 07:16:40,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-62xn97of', purging
2023-05-28 07:16:40,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bt4gqunf', purging
2023-05-28 07:16:40,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7wajb9tj', purging
2023-05-28 07:16:40,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uc7sduf2', purging
2023-05-28 07:16:40,610 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-36wrxmzt', purging
2023-05-28 07:16:40,610 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1p2vhynm', purging
2023-05-28 07:16:40,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:40,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:40,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:40,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:40,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:40,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:40,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:40,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:40,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:40,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:40,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:40,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:40,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:40,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:40,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:40,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:42,802 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:42,829 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:42,855 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:42,882 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:42,908 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:42,936 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:42,961 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:43,109 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:44,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aw3fcm6p', purging
2023-05-28 07:16:44,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5iyy37lz', purging
2023-05-28 07:16:44,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xv9kg0z7', purging
2023-05-28 07:16:44,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j6zvanz7', purging
2023-05-28 07:16:44,354 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-acf28sgs', purging
2023-05-28 07:16:44,354 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g8yq_on7', purging
2023-05-28 07:16:44,354 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-az_vra4g', purging
2023-05-28 07:16:44,354 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-meapbvt8', purging
2023-05-28 07:16:44,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:44,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:44,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:44,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:44,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:44,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:44,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:44,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:44,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:44,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:44,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:44,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:44,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:44,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:44,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:44,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:46,605 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:46,629 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:46,655 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:46,680 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:46,705 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:46,731 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:46,755 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:46,903 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:48,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w1jo03jo', purging
2023-05-28 07:16:48,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1rzbd_v5', purging
2023-05-28 07:16:48,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-svs6u0m4', purging
2023-05-28 07:16:48,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0gdl9j12', purging
2023-05-28 07:16:48,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5hmcrskn', purging
2023-05-28 07:16:48,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k9sdhw_r', purging
2023-05-28 07:16:48,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rnql3tyh', purging
2023-05-28 07:16:48,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jcs1y94e', purging
2023-05-28 07:16:48,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:48,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:48,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:48,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:48,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:48,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:48,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:48,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:48,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:48,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:48,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:48,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:48,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:48,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:48,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:48,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:50,312 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:50,362 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:50,410 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:50,435 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:50,460 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:50,484 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:50,511 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:50,660 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:51,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ukwgu4xp', purging
2023-05-28 07:16:51,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b6r4hyv5', purging
2023-05-28 07:16:51,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pmze1ew8', purging
2023-05-28 07:16:51,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4djjw3qm', purging
2023-05-28 07:16:51,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0nzylzyb', purging
2023-05-28 07:16:51,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n4ktudsw', purging
2023-05-28 07:16:51,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_z3pu76', purging
2023-05-28 07:16:51,880 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uba39u9s', purging
2023-05-28 07:16:51,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:51,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:51,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:51,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:51,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:51,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:52,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:52,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:52,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:52,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:52,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:52,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:52,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:52,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:52,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:52,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:54,142 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:54,165 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:54,205 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:54,237 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:54,261 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:54,285 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:54,307 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:54,473 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:55,711 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b0vl3ib7', purging
2023-05-28 07:16:55,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r02a83xh', purging
2023-05-28 07:16:55,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9j1iwsn2', purging
2023-05-28 07:16:55,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8il1wivb', purging
2023-05-28 07:16:55,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xoam6d6l', purging
2023-05-28 07:16:55,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6dnele8c', purging
2023-05-28 07:16:55,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8gbotkt8', purging
2023-05-28 07:16:55,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gks1g4ta', purging
2023-05-28 07:16:55,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:55,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:55,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:55,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:55,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:55,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:55,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:55,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:55,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:55,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:55,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:55,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:55,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:55,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:56,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:56,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:57,893 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:57,962 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:57,984 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:58,009 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:58,081 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:58,083 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:58,095 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:58,238 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:59,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v4hlc0he', purging
2023-05-28 07:16:59,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2o5_t5x', purging
2023-05-28 07:16:59,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ynw5p_jq', purging
2023-05-28 07:16:59,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ywqi22lx', purging
2023-05-28 07:16:59,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6q9hqwjm', purging
2023-05-28 07:16:59,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qybxuyh_', purging
2023-05-28 07:16:59,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g39qjg4w', purging
2023-05-28 07:16:59,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2qk__t_7', purging
2023-05-28 07:16:59,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:59,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:59,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:59,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:59,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:59,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:59,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:59,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:59,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:59,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:59,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:59,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:59,643 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:59,643 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:59,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:59,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:01,634 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:01,661 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:01,719 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:01,746 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:01,773 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:01,794 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:01,831 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:01,994 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:03,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-531vqsdx', purging
2023-05-28 07:17:03,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tqlpfsgl', purging
2023-05-28 07:17:03,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-id0tj4st', purging
2023-05-28 07:17:03,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xf4bykvp', purging
2023-05-28 07:17:03,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-86lo44vw', purging
2023-05-28 07:17:03,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lf1ejss7', purging
2023-05-28 07:17:03,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1kpn9cfm', purging
2023-05-28 07:17:03,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zy9h1eea', purging
2023-05-28 07:17:03,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:03,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:03,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:03,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:03,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:03,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:03,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:03,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:03,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:03,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:03,329 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:03,329 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:03,433 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:03,433 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:03,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:03,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:05,345 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:05,420 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:05,439 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:05,468 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:05,489 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:05,515 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:05,540 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:05,708 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:06,750 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c2pj6ibq', purging
2023-05-28 07:17:06,750 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ozk3t0ou', purging
2023-05-28 07:17:06,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i588b7th', purging
2023-05-28 07:17:06,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2v0wte5z', purging
2023-05-28 07:17:06,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mdeh9zzr', purging
2023-05-28 07:17:06,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oc983kj4', purging
2023-05-28 07:17:06,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a35x7ngr', purging
2023-05-28 07:17:06,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ltzg_jg', purging
2023-05-28 07:17:06,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:06,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:06,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:06,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:07,017 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:07,017 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:07,032 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:07,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:07,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:07,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:07,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:07,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:07,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:07,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:07,247 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:07,247 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:08,577 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:08,796 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:09,038 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:09,066 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:09,109 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:09,158 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:09,184 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:09,369 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:10,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5q6kpwgl', purging
2023-05-28 07:17:10,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dtzzti1p', purging
2023-05-28 07:17:10,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j8aal211', purging
2023-05-28 07:17:10,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fqi56eok', purging
2023-05-28 07:17:10,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qstdcgww', purging
2023-05-28 07:17:10,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ms0wztu5', purging
2023-05-28 07:17:10,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s2vh08fd', purging
2023-05-28 07:17:10,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zte16p40', purging
2023-05-28 07:17:10,169 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:10,169 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:10,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:10,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:10,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:10,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:10,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:10,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:10,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:10,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:10,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:10,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:10,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:10,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:10,887 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:10,887 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:12,013 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:12,177 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:12,205 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:12,489 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:12,589 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:12,590 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:12,603 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:12,764 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:13,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wc9mkaoo', purging
2023-05-28 07:17:13,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tt_9pxhr', purging
2023-05-28 07:17:13,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1kn6b8f4', purging
2023-05-28 07:17:13,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tkcg6hxg', purging
2023-05-28 07:17:13,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n8xqvjmn', purging
2023-05-28 07:17:13,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-on7b5vm9', purging
2023-05-28 07:17:13,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dqpuh3_0', purging
2023-05-28 07:17:13,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pdod2wjd', purging
2023-05-28 07:17:13,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:13,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:13,700 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:13,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:13,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:13,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:14,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:14,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:14,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:14,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:14,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:14,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:14,125 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:14,125 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:14,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:14,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:14,523 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:15,354 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:15,414 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:15,831 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:15,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0qm1yele', purging
2023-05-28 07:17:15,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eszdzgk5', purging
2023-05-28 07:17:15,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pvulicqa', purging
2023-05-28 07:17:15,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u3ancl5o', purging
2023-05-28 07:17:15,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fo0emxp3', purging
2023-05-28 07:17:15,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:15,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:15,909 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:15,949 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:15,978 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:16,168 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:16,840 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:16,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_rhplmx', purging
2023-05-28 07:17:16,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jn9vl_nl', purging
2023-05-28 07:17:16,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yt8vgcgt', purging
2023-05-28 07:17:16,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nu3x26sv', purging
2023-05-28 07:17:16,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:16,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:16,953 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:16,953 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:17,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:17,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:17,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:17,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:17,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:17,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:17,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:17,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:17,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:17,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:18,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yt8t6u1_', purging
2023-05-28 07:17:18,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:18,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:18,671 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:18,718 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:19,182 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:19,233 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:19,262 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:19,287 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:19,330 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:19,617 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:20,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mdlbq5r9', purging
2023-05-28 07:17:20,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-snugjznz', purging
2023-05-28 07:17:20,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k1sxoal_', purging
2023-05-28 07:17:20,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fqpqxjm8', purging
2023-05-28 07:17:20,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-71ptd2fy', purging
2023-05-28 07:17:20,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u1nzbe9s', purging
2023-05-28 07:17:20,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7abkg5sl', purging
2023-05-28 07:17:20,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:20,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:20,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:20,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:20,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:20,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:20,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:20,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:20,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:20,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:20,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:20,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:20,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:20,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:21,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:21,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:21,896 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:21,923 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:22,442 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:22,467 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:22,499 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:22,526 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:22,566 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:22,856 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:23,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r_ne8efy', purging
2023-05-28 07:17:23,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ubau0vca', purging
2023-05-28 07:17:23,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ihj30omw', purging
2023-05-28 07:17:23,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j6xy2hn4', purging
2023-05-28 07:17:23,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_zr8du4p', purging
2023-05-28 07:17:23,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ghkz9jkg', purging
2023-05-28 07:17:23,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9cnvegsw', purging
2023-05-28 07:17:23,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ygls1qg', purging
2023-05-28 07:17:23,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:23,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:23,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:23,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:23,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:23,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:23,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:23,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:23,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:23,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:24,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:24,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:24,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:24,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:24,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:24,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:25,117 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:25,172 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:25,673 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:25,700 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:25,729 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:25,757 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:25,798 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:26,084 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:26,540 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k8zhks8j', purging
2023-05-28 07:17:26,541 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tfqhx6aj', purging
2023-05-28 07:17:26,541 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-riyv98q1', purging
2023-05-28 07:17:26,541 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ac5q4ys7', purging
2023-05-28 07:17:26,542 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rtvy40oo', purging
2023-05-28 07:17:26,542 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pl3j2v9h', purging
2023-05-28 07:17:26,542 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24q5dj2i', purging
2023-05-28 07:17:26,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jlh80cx5', purging
2023-05-28 07:17:26,543 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:26,543 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:26,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:26,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:27,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:27,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:27,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:27,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:27,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:27,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:27,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:27,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:27,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:27,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:27,623 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-do1pa8ha', purging
2023-05-28 07:17:27,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:27,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:27,687 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:28,072 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:28,900 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:28,960 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:28,991 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:29,017 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:29,058 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:29,140 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k9os32_n', purging
2023-05-28 07:17:29,140 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a6290av7', purging
2023-05-28 07:17:29,140 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-guwojabz', purging
2023-05-28 07:17:29,141 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-di6burzm', purging
2023-05-28 07:17:29,141 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o7u_xt4k', purging
2023-05-28 07:17:29,141 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-49197p87', purging
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:29,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:29,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:29,350 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:29,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-36a1ilwv', purging
2023-05-28 07:17:29,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:29,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:30,085 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:30,386 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:30,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-chx_dle_', purging
2023-05-28 07:17:30,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h3obn3ma', purging
2023-05-28 07:17:30,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:30,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:30,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:30,509 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:30,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:30,512 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:30,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:30,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:30,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:30,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:30,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:30,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:31,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:31,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:31,824 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:31,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:32,463 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:32,487 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:32,514 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:32,550 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:32,567 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:32,926 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:32,964 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:33,195 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:33,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j82kaldx', purging
2023-05-28 07:17:33,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cko6dds6', purging
2023-05-28 07:17:33,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fq5rer1s', purging
2023-05-28 07:17:33,943 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i3n7qo95', purging
2023-05-28 07:17:33,943 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ssd7lrd9', purging
2023-05-28 07:17:33,943 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9s_f8heu', purging
2023-05-28 07:17:33,943 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lc4oeg6h', purging
2023-05-28 07:17:33,944 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_tb7s4k8', purging
2023-05-28 07:17:33,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:33,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:34,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:34,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:34,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:34,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:34,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:34,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:34,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:34,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:34,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:34,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:34,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:34,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:34,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:34,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:36,081 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:36,117 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:36,143 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:36,170 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:36,223 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:36,453 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:36,478 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:36,627 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:37,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-himcpsm1', purging
2023-05-28 07:17:37,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jzx4vp4f', purging
2023-05-28 07:17:37,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-suv42u_6', purging
2023-05-28 07:17:37,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k1op7mmq', purging
2023-05-28 07:17:37,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ktqv_g2', purging
2023-05-28 07:17:37,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-smu899p8', purging
2023-05-28 07:17:37,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p6x2tyfv', purging
2023-05-28 07:17:37,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-itkwogtm', purging
2023-05-28 07:17:37,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:37,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:37,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:37,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:37,602 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:37,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:37,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:37,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:37,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:37,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:37,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:37,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:37,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:37,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:38,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:38,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:39,654 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:39,676 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:39,704 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:39,761 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:39,795 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:39,961 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:39,987 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:40,167 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:41,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-37mhu9ka', purging
2023-05-28 07:17:41,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xs8z7ge6', purging
2023-05-28 07:17:41,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-74ceki7d', purging
2023-05-28 07:17:41,094 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r4f3szn8', purging
2023-05-28 07:17:41,094 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-646ak6z6', purging
2023-05-28 07:17:41,094 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9aj2104c', purging
2023-05-28 07:17:41,094 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3puouwcb', purging
2023-05-28 07:17:41,095 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z_5ouau6', purging
2023-05-28 07:17:41,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:41,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:41,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:41,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:41,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:41,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:41,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:41,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:41,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:41,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:41,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:41,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:41,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:41,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:41,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:41,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:43,215 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:43,235 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:43,258 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:43,286 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:43,310 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:43,498 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:43,524 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:43,686 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:44,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d431c0np', purging
2023-05-28 07:17:44,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-40n5ma5f', purging
2023-05-28 07:17:44,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j66_u35m', purging
2023-05-28 07:17:44,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ryhe45fi', purging
2023-05-28 07:17:44,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wm6uhzlr', purging
2023-05-28 07:17:44,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m5ohzw6z', purging
2023-05-28 07:17:44,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k4xdz4qt', purging
2023-05-28 07:17:44,675 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rzjkr1fz', purging
2023-05-28 07:17:44,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:44,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:44,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:44,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:44,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:44,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:44,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:44,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:44,862 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:44,862 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:45,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:45,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:45,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:45,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:45,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:45,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:46,703 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:46,729 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:46,753 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:46,780 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:46,802 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:47,062 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:47,104 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:47,347 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:48,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r5p3erdu', purging
2023-05-28 07:17:48,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-57_r6eoq', purging
2023-05-28 07:17:48,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n1o3vlzv', purging
2023-05-28 07:17:48,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1emu4ywo', purging
2023-05-28 07:17:48,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xvbtwj_z', purging
2023-05-28 07:17:48,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bkai9qu6', purging
2023-05-28 07:17:48,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ycgb94dc', purging
2023-05-28 07:17:48,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m4ig7ua1', purging
2023-05-28 07:17:48,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:48,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:48,265 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:48,265 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:48,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:48,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:48,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:48,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:48,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:48,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:48,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:48,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:48,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:48,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:48,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:48,863 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:50,052 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:50,229 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:50,256 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:50,313 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:50,357 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:50,585 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:50,610 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:50,775 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:51,459 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-suh5zcq5', purging
2023-05-28 07:17:51,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cdyf65dv', purging
2023-05-28 07:17:51,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5l5phaqs', purging
2023-05-28 07:17:51,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-861hpaik', purging
2023-05-28 07:17:51,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yl_e_h62', purging
2023-05-28 07:17:51,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rapek8ef', purging
2023-05-28 07:17:51,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i1phrxvq', purging
2023-05-28 07:17:51,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-li0kefbf', purging
2023-05-28 07:17:51,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:51,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:51,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:51,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:51,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:51,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:51,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:51,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:51,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:51,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:52,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:52,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:52,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:52,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:52,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:52,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:52,932 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:53,046 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:53,759 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:53,815 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:53,863 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:53,951 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:53,974 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:54,165 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:54,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lw464ib3', purging
2023-05-28 07:17:54,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5mekes6t', purging
2023-05-28 07:17:54,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d88b_wxb', purging
2023-05-28 07:17:54,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nfm7w4v3', purging
2023-05-28 07:17:54,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3f882xm', purging
2023-05-28 07:17:54,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gna3lgqn', purging
2023-05-28 07:17:54,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dlipm7oe', purging
2023-05-28 07:17:54,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i1tizlum', purging
2023-05-28 07:17:54,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:54,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:54,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:54,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:55,103 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:55,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-06yyg8qz', purging
2023-05-28 07:17:55,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:55,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:55,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:55,362 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:55,405 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rnpc4ojq', purging
2023-05-28 07:17:55,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:55,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:55,413 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:55,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:55,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:55,529 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:55,529 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:55,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:55,691 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:56,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:56,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:56,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:56,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:57,406 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:57,431 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:57,456 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:57,479 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:57,532 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:57,565 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:17:57,912 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:58,096 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:17:58,870 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5alx7v7s', purging
2023-05-28 07:17:58,870 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yuoqdh19', purging
2023-05-28 07:17:58,870 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f42sdzda', purging
2023-05-28 07:17:58,871 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psb9jnlm', purging
2023-05-28 07:17:58,871 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iuc2v9ij', purging
2023-05-28 07:17:58,872 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mvb4gnpz', purging
2023-05-28 07:17:58,872 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8jtxoez9', purging
2023-05-28 07:17:58,872 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iycohexe', purging
2023-05-28 07:17:58,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:58,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:58,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:58,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:59,039 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:59,039 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:59,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:59,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:59,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:59,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:59,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:59,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:59,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:59,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:17:59,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:17:59,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:00,858 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:00,881 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:01,086 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:01,128 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:01,156 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:01,191 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:01,384 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:01,563 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:02,261 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6nw4sjrz', purging
2023-05-28 07:18:02,261 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ruvut4j1', purging
2023-05-28 07:18:02,261 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1dliqghg', purging
2023-05-28 07:18:02,262 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7kzpk9q', purging
2023-05-28 07:18:02,262 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h3pn2pkj', purging
2023-05-28 07:18:02,262 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bquwesiv', purging
2023-05-28 07:18:02,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xbh1bsqu', purging
2023-05-28 07:18:02,263 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h8bdnu5j', purging
2023-05-28 07:18:02,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:02,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:02,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:02,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:02,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:02,588 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:02,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:02,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:02,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:02,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:02,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:02,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:02,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:02,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:03,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:03,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:03,392 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:04,481 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:04,631 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:04,667 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:04,695 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:04,729 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:04,761 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:04,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b2edm_tt', purging
2023-05-28 07:18:04,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fxd_e5_e', purging
2023-05-28 07:18:04,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bbhxk5cj', purging
2023-05-28 07:18:04,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-87exntiu', purging
2023-05-28 07:18:04,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ot5vpvs_', purging
2023-05-28 07:18:04,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gj6jbbxi', purging
2023-05-28 07:18:04,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nz70nfi1', purging
2023-05-28 07:18:04,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:04,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:04,986 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:05,674 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:06,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p17tb6ot', purging
2023-05-28 07:18:06,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kh1a8awf', purging
2023-05-28 07:18:06,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:06,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:06,092 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:06,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:06,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:06,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:06,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:06,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:06,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:06,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:06,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:06,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:06,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:06,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:07,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:07,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:08,075 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:08,150 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:08,175 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:08,199 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:08,222 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:08,248 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:08,525 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:08,712 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:09,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vskr6ir3', purging
2023-05-28 07:18:09,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7wjsp_a6', purging
2023-05-28 07:18:09,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j1o4aulb', purging
2023-05-28 07:18:09,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mq5y7t9s', purging
2023-05-28 07:18:09,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dzb6e1n4', purging
2023-05-28 07:18:09,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1uhnvd1i', purging
2023-05-28 07:18:09,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qjc1r28s', purging
2023-05-28 07:18:09,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p6582cbx', purging
2023-05-28 07:18:09,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:09,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:09,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:09,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:09,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:09,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:09,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:09,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:09,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:09,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:09,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:09,751 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:10,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:10,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:10,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:10,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:11,724 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:11,761 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:11,782 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:11,814 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:11,834 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:11,866 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:12,029 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:12,211 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:13,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ds2m_t61', purging
2023-05-28 07:18:13,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7nl7zb9j', purging
2023-05-28 07:18:13,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xojrj9fa', purging
2023-05-28 07:18:13,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xpodbp5_', purging
2023-05-28 07:18:13,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uu1muflg', purging
2023-05-28 07:18:13,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tqpaxaqn', purging
2023-05-28 07:18:13,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tvncgg2s', purging
2023-05-28 07:18:13,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wnpadcpf', purging
2023-05-28 07:18:13,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:13,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:13,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:13,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:13,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:13,374 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:13,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:13,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:13,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:13,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:13,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:13,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:13,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:13,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:13,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:13,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:15,500 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:15,522 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:15,576 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:15,603 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:15,627 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:15,671 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:15,703 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:15,854 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:16,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sas8k1xj', purging
2023-05-28 07:18:16,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-go8d4oaq', purging
2023-05-28 07:18:16,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:16,938 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xoe40vkw', purging
2023-05-28 07:18:16,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:16,938 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o8imqj4g', purging
2023-05-28 07:18:16,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xiipnwr3', purging
2023-05-28 07:18:16,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mleruizd', purging
2023-05-28 07:18:16,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6haemcca', purging
2023-05-28 07:18:16,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-35qjveko', purging
2023-05-28 07:18:16,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:16,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:17,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:17,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:17,050 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:17,050 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:17,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:17,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:17,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:17,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:17,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:17,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:17,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:17,362 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:19,132 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:19,190 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:19,232 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:19,252 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:19,273 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:19,299 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:19,323 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:19,569 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:20,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xi84o1xl', purging
2023-05-28 07:18:20,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p3wctf_z', purging
2023-05-28 07:18:20,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ea5ujgfx', purging
2023-05-28 07:18:20,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xxc8066h', purging
2023-05-28 07:18:20,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-88tzxu0m', purging
2023-05-28 07:18:20,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8nvs74u0', purging
2023-05-28 07:18:20,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hkqskfp8', purging
2023-05-28 07:18:20,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ucmjhtis', purging
2023-05-28 07:18:20,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:20,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:20,774 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:20,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:20,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:20,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:20,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:20,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:20,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:20,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:20,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:20,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:20,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:20,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:21,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:21,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:22,928 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:22,955 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:23,015 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:23,121 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:18:23,336 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:24,316 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5cyw0lwa', purging
2023-05-28 07:18:24,316 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8s3jr3c1', purging
2023-05-28 07:18:24,317 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8zbx0nhl', purging
2023-05-28 07:18:24,317 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-47rsrxuo', purging
2023-05-28 07:18:24,317 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jv93pxqr', purging
2023-05-28 07:18:24,318 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fuh7h53o', purging
2023-05-28 07:18:24,318 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v2s0rd6q', purging
2023-05-28 07:18:24,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3c5dnsvr', purging
2023-05-28 07:18:24,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:24,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:24,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:24,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:24,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:24,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:24,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:24,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:24,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:24,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:25,775 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:25,797 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:25,819 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:25,841 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:26,138 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:27,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zwo044x8', purging
2023-05-28 07:18:27,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4bnllwub', purging
2023-05-28 07:18:27,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ll5ku91y', purging
2023-05-28 07:18:27,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2taxz6ou', purging
2023-05-28 07:18:27,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tlz7wiwf', purging
2023-05-28 07:18:27,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:27,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:27,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:27,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:27,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:27,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:27,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:27,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:27,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:27,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:28,682 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:28,744 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:28,766 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:28,794 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:29,043 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:30,141 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c3fltjwf', purging
2023-05-28 07:18:30,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lxusem_v', purging
2023-05-28 07:18:30,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-offbue_7', purging
2023-05-28 07:18:30,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cvdvzzuj', purging
2023-05-28 07:18:30,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iro42vkc', purging
2023-05-28 07:18:30,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:30,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:30,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:30,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:30,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:30,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:30,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:30,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:30,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:30,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:31,633 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:31,669 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:31,692 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:31,723 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:31,964 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:33,081 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25230zyt', purging
2023-05-28 07:18:33,081 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wh2w9bee', purging
2023-05-28 07:18:33,082 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ktyjow_7', purging
2023-05-28 07:18:33,082 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mmotl5i3', purging
2023-05-28 07:18:33,082 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lbfqvgem', purging
2023-05-28 07:18:33,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:33,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:33,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:33,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:33,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:33,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:33,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:33,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:33,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:33,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:34,607 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:34,632 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:34,673 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:34,697 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:34,852 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:36,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j1rqwbeg', purging
2023-05-28 07:18:36,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r340rwvz', purging
2023-05-28 07:18:36,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gb4fkfdw', purging
2023-05-28 07:18:36,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j1tyyw08', purging
2023-05-28 07:18:36,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_16envo2', purging
2023-05-28 07:18:36,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:36,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:36,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:36,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:36,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:36,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:36,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:36,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:36,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:36,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:37,604 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:37,634 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:37,658 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:37,679 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:37,835 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:39,038 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9gbxaf9i', purging
2023-05-28 07:18:39,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gjtz092z', purging
2023-05-28 07:18:39,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dww0sqoc', purging
2023-05-28 07:18:39,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xpnhnwzg', purging
2023-05-28 07:18:39,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g3hjzlgb', purging
2023-05-28 07:18:39,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:39,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:39,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:39,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:39,092 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:39,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:39,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:39,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:39,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:39,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:40,573 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:40,600 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:40,626 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:40,790 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:41,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u0exhxgt', purging
2023-05-28 07:18:41,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nvwqlxit', purging
2023-05-28 07:18:41,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hbc7miob', purging
2023-05-28 07:18:41,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ig1776cz', purging
2023-05-28 07:18:41,976 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gd_79zxl', purging
2023-05-28 07:18:41,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:41,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:42,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:42,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:42,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:42,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:42,154 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:42,154 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:43,244 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:43,289 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:43,314 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:43,470 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:44,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-98i4rn5h', purging
2023-05-28 07:18:44,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wpvx26sv', purging
2023-05-28 07:18:44,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ly8spbu', purging
2023-05-28 07:18:44,618 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0jjwq77o', purging
2023-05-28 07:18:44,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:44,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:44,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:44,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:44,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:44,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:44,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:44,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:45,906 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:45,931 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:45,956 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:46,110 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:47,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ybhuy82t', purging
2023-05-28 07:18:47,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-enfiwx2b', purging
2023-05-28 07:18:47,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xzneder3', purging
2023-05-28 07:18:47,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xdpuldjo', purging
2023-05-28 07:18:47,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:47,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:47,322 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:47,322 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:47,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:47,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:47,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:47,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:48,541 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:48,586 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:48,615 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:48,768 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:49,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rjjnrcc_', purging
2023-05-28 07:18:49,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dm9fqe_x', purging
2023-05-28 07:18:49,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0874p00v', purging
2023-05-28 07:18:49,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-go73a1e7', purging
2023-05-28 07:18:49,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:49,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:50,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:50,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:50,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:50,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:50,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:50,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:51,219 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:51,245 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:51,269 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:51,449 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:52,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-49z3bdea', purging
2023-05-28 07:18:52,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b90nguiz', purging
2023-05-28 07:18:52,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ue470iry', purging
2023-05-28 07:18:52,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rq9nlz57', purging
2023-05-28 07:18:52,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:52,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:52,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:52,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:52,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:52,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:52,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:52,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:53,928 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:53,952 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:53,982 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:54,154 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:55,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4_svaxb9', purging
2023-05-28 07:18:55,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wu77y56v', purging
2023-05-28 07:18:55,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tu635e7u', purging
2023-05-28 07:18:55,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijhgsvcj', purging
2023-05-28 07:18:55,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:55,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:55,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:55,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:55,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:55,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:55,592 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:55,592 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:56,586 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:56,618 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:56,650 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:56,810 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:58,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zg2env9h', purging
2023-05-28 07:18:58,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qezg4rop', purging
2023-05-28 07:18:58,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-chu750d_', purging
2023-05-28 07:18:58,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c_wlxb2b', purging
2023-05-28 07:18:58,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:58,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:58,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:58,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:58,070 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:58,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:18:58,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:18:58,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:18:59,264 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:59,311 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:59,334 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:18:59,499 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:00,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h6fuyhzd', purging
2023-05-28 07:19:00,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-juiaer6u', purging
2023-05-28 07:19:00,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uqr9sya4', purging
2023-05-28 07:19:00,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mc0_pm83', purging
2023-05-28 07:19:00,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:00,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:00,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:00,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:00,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:00,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:00,889 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:00,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:01,930 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:01,978 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:02,002 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:02,168 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:03,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s28qcf1i', purging
2023-05-28 07:19:03,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qi562w2f', purging
2023-05-28 07:19:03,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hc7kt7p8', purging
2023-05-28 07:19:03,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whq_36x6', purging
2023-05-28 07:19:03,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:03,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:03,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:03,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:03,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:03,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:03,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:03,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:04,662 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:04,693 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:04,711 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:04,877 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:06,056 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q8uxf1j4', purging
2023-05-28 07:19:06,056 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fohpuf_s', purging
2023-05-28 07:19:06,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p1iamt7_', purging
2023-05-28 07:19:06,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s17mug5t', purging
2023-05-28 07:19:06,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:06,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:06,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:06,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:06,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:06,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:06,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:06,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:07,309 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:07,355 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:07,385 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:07,559 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:08,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3z8a7pj5', purging
2023-05-28 07:19:08,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vlnvutnc', purging
2023-05-28 07:19:08,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ts137fgg', purging
2023-05-28 07:19:08,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vxqlvk_o', purging
2023-05-28 07:19:08,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:08,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:08,818 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:08,818 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:08,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:08,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:08,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:08,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:09,945 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:09,992 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:10,017 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:10,188 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:11,368 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yam3ql5d', purging
2023-05-28 07:19:11,368 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lor9hq5b', purging
2023-05-28 07:19:11,368 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e6wi5yp0', purging
2023-05-28 07:19:11,369 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t1t92j8q', purging
2023-05-28 07:19:11,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:11,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:11,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:11,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:11,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:11,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:11,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:11,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:12,640 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:12,687 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:12,714 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:12,886 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:14,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q4i0_ykv', purging
2023-05-28 07:19:14,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-en4c_kmm', purging
2023-05-28 07:19:14,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1s50wbrq', purging
2023-05-28 07:19:14,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zlt8isba', purging
2023-05-28 07:19:14,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:14,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:14,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:14,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:14,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:14,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:14,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:14,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:15,276 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:15,320 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:15,344 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:15,511 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:16,652 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yd5hubup', purging
2023-05-28 07:19:16,652 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jlh6hip5', purging
2023-05-28 07:19:16,652 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5dwofqwo', purging
2023-05-28 07:19:16,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_1w8ntwk', purging
2023-05-28 07:19:16,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:16,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:16,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:16,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:16,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:16,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:16,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:16,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:17,944 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:17,969 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:17,994 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:18,156 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:19,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mu7jqbh7', purging
2023-05-28 07:19:19,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xy2q6_iq', purging
2023-05-28 07:19:19,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ig6hfy1', purging
2023-05-28 07:19:19,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4puch7iq', purging
2023-05-28 07:19:19,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:19,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:19,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:19,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:19,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:19,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:19,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:19,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:20,623 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:20,660 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:20,683 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:20,845 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:22,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zqjbu2qw', purging
2023-05-28 07:19:22,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t5fnpi1m', purging
2023-05-28 07:19:22,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fauz8hi5', purging
2023-05-28 07:19:22,049 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f1on1fmz', purging
2023-05-28 07:19:22,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:22,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:22,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:22,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:22,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:22,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:22,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:22,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:23,331 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:23,374 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:23,406 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:23,559 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:24,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvpcv1b_', purging
2023-05-28 07:19:24,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iuzhdjek', purging
2023-05-28 07:19:24,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9jhrg_5v', purging
2023-05-28 07:19:24,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2wjrym1s', purging
2023-05-28 07:19:24,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:24,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:24,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:24,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:24,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:24,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:25,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:25,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:26,028 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:26,077 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:26,093 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:26,253 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:27,422 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sxleeduk', purging
2023-05-28 07:19:27,422 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vuio8vhf', purging
2023-05-28 07:19:27,423 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9f60evx_', purging
2023-05-28 07:19:27,423 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-63pjpd9v', purging
2023-05-28 07:19:27,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:27,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:27,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:27,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:27,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:27,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:27,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:27,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:28,658 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:28,703 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:28,724 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:28,884 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:30,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3o8lewj0', purging
2023-05-28 07:19:30,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fwhgy22y', purging
2023-05-28 07:19:30,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nnk2fzev', purging
2023-05-28 07:19:30,029 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ke0ooc3', purging
2023-05-28 07:19:30,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:30,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:30,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:30,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:30,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:30,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:30,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:30,302 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:31,305 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:31,336 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:31,381 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:31,533 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:32,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u7nr46ia', purging
2023-05-28 07:19:32,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mhkyy9xe', purging
2023-05-28 07:19:32,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-omkd6rn5', purging
2023-05-28 07:19:32,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ti5jczt9', purging
2023-05-28 07:19:32,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:32,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:32,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:32,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:32,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:32,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:32,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:32,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:34,272 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:34,298 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:34,329 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:34,498 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:35,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5p_48991', purging
2023-05-28 07:19:35,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2eicocbo', purging
2023-05-28 07:19:35,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3shs7jr', purging
2023-05-28 07:19:35,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:35,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xg2r012i', purging
2023-05-28 07:19:35,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:35,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:35,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:35,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:35,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:35,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:35,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:37,051 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:37,053 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:37,082 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:37,240 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:38,420 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_7fopym', purging
2023-05-28 07:19:38,420 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dwtuxtwp', purging
2023-05-28 07:19:38,421 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i4t2hmvn', purging
2023-05-28 07:19:38,421 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04gvx0bf', purging
2023-05-28 07:19:38,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:38,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:38,460 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:38,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:38,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:38,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:38,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:38,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:39,705 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:39,729 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:39,757 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:39,921 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:41,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-czo4qpcc', purging
2023-05-28 07:19:41,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b05v0ahw', purging
2023-05-28 07:19:41,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bqw1q815', purging
2023-05-28 07:19:41,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7k9p0zl_', purging
2023-05-28 07:19:41,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:41,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:41,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:41,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:41,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:41,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:41,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:41,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:42,395 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:42,434 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:42,458 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:42,626 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:43,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_w7r0is', purging
2023-05-28 07:19:43,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0j0ot8iz', purging
2023-05-28 07:19:43,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-efuhn1be', purging
2023-05-28 07:19:43,794 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n96gu9b_', purging
2023-05-28 07:19:43,794 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:43,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:43,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:43,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:43,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:43,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:44,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:44,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:45,078 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:45,120 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:45,144 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:45,309 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:46,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aarx7y5d', purging
2023-05-28 07:19:46,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ln2zzral', purging
2023-05-28 07:19:46,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eowdnoyu', purging
2023-05-28 07:19:46,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tzt46ufh', purging
2023-05-28 07:19:46,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:46,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:46,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:46,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:46,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:46,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:46,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:46,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:47,800 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:47,832 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:47,855 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:48,030 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:49,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-10t8_wjv', purging
2023-05-28 07:19:49,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vybk6sks', purging
2023-05-28 07:19:49,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-75zlv3km', purging
2023-05-28 07:19:49,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-asu_dsii', purging
2023-05-28 07:19:49,188 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:49,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:49,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:49,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:49,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:49,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:49,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:49,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:50,494 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:50,516 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:50,542 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:50,705 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:51,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5_quhs13', purging
2023-05-28 07:19:51,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t66vsyru', purging
2023-05-28 07:19:51,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7qix7zw8', purging
2023-05-28 07:19:51,931 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7r37y5qz', purging
2023-05-28 07:19:51,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:51,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:51,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:51,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:51,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:51,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:52,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:52,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:53,210 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:53,248 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:53,270 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:53,450 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:54,613 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-duk6sbw5', purging
2023-05-28 07:19:54,613 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5z1bhupp', purging
2023-05-28 07:19:54,614 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vv1gi0v7', purging
2023-05-28 07:19:54,614 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cczmbn2a', purging
2023-05-28 07:19:54,615 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:54,615 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:54,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:54,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:54,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:54,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:54,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:54,862 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:55,901 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:55,933 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:55,957 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:56,137 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:57,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fwyh52t1', purging
2023-05-28 07:19:57,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f991s0zy', purging
2023-05-28 07:19:57,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0a3x3pfr', purging
2023-05-28 07:19:57,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_n57cyi', purging
2023-05-28 07:19:57,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:57,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:57,350 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:57,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:57,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:57,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:19:57,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:57,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:19:58,546 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:58,577 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:58,602 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:58,760 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:19:59,966 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5hj8mpnj', purging
2023-05-28 07:19:59,967 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aln0imo8', purging
2023-05-28 07:19:59,967 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fcngzkyg', purging
2023-05-28 07:19:59,967 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ht508bl6', purging
2023-05-28 07:19:59,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:19:59,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:00,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:00,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:00,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:00,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:00,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:00,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:01,259 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:01,283 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:01,307 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:01,487 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:02,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sb86emmc', purging
2023-05-28 07:20:02,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ngikwab', purging
2023-05-28 07:20:02,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v7ju8ysy', purging
2023-05-28 07:20:02,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k9nhiplz', purging
2023-05-28 07:20:02,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:02,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:02,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:02,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:02,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:02,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:02,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:02,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:03,862 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:03,903 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:03,924 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:04,081 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:05,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-440bhk9d', purging
2023-05-28 07:20:05,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ymbg8dv', purging
2023-05-28 07:20:05,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rt062q47', purging
2023-05-28 07:20:05,286 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ngz63qqb', purging
2023-05-28 07:20:05,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:05,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:05,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:05,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:05,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:05,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:05,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:05,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:06,574 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:06,615 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:06,632 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:06,810 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:07,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n8waq2zx', purging
2023-05-28 07:20:07,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i53a0g5y', purging
2023-05-28 07:20:07,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0e6s6j31', purging
2023-05-28 07:20:07,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4wmzc2jm', purging
2023-05-28 07:20:07,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:07,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:08,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:08,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:08,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:08,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:08,255 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:08,255 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:09,289 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:09,322 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:09,356 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:09,513 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:10,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8rls8f_d', purging
2023-05-28 07:20:10,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g8wbrcgj', purging
2023-05-28 07:20:10,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6w3r70ke', purging
2023-05-28 07:20:10,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ahoqk88x', purging
2023-05-28 07:20:10,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:10,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:10,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:10,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:10,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:10,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:10,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:10,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:12,072 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:12,092 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:12,116 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:12,278 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:13,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d5s_th_y', purging
2023-05-28 07:20:13,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w36864od', purging
2023-05-28 07:20:13,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u952fe3g', purging
2023-05-28 07:20:13,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lz7ht4h2', purging
2023-05-28 07:20:13,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:13,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:13,506 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:13,506 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:13,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:13,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:13,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:13,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:14,779 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:14,820 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:14,856 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:15,013 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:16,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yb_oz0fc', purging
2023-05-28 07:20:16,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vi4maxsv', purging
2023-05-28 07:20:16,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-naja_ev1', purging
2023-05-28 07:20:16,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k1oag5m2', purging
2023-05-28 07:20:16,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:16,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:16,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:16,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:16,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:16,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:16,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:16,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:17,483 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:17,510 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:17,528 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:17,692 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:18,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6ahicf1h', purging
2023-05-28 07:20:18,889 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xo8h782r', purging
2023-05-28 07:20:18,889 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d1p900ba', purging
2023-05-28 07:20:18,890 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dbj5x9e7', purging
2023-05-28 07:20:18,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:18,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:18,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:18,950 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:18,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:18,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:19,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:19,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:20,167 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:20,214 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:20,239 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:20,400 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:21,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n9hfa5gt', purging
2023-05-28 07:20:21,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7gdju53_', purging
2023-05-28 07:20:21,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d_ky5vrk', purging
2023-05-28 07:20:21,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ca30dzv5', purging
2023-05-28 07:20:21,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:21,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:21,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:21,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:21,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:21,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:21,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:21,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:22,931 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:22,957 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:22,993 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:23,163 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:24,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7r7a12y0', purging
2023-05-28 07:20:24,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_8icaok', purging
2023-05-28 07:20:24,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0y7l55n2', purging
2023-05-28 07:20:24,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2aoxo205', purging
2023-05-28 07:20:24,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:24,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:24,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:24,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:24,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:24,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:24,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:24,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:25,638 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:25,665 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:25,694 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:25,867 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:27,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgv1s5cg', purging
2023-05-28 07:20:27,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f35ioen6', purging
2023-05-28 07:20:27,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h4829wk4', purging
2023-05-28 07:20:27,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5yhho0dh', purging
2023-05-28 07:20:27,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:27,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:27,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:27,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:27,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:27,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:27,265 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:27,265 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:28,291 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:28,335 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:28,357 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:28,532 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:29,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0k8aa1a9', purging
2023-05-28 07:20:29,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qq548yqh', purging
2023-05-28 07:20:29,703 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s8xu5_gg', purging
2023-05-28 07:20:29,703 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zyc9bbft', purging
2023-05-28 07:20:29,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:29,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:29,749 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:29,749 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:29,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:29,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:29,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:29,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:30,984 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:31,025 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:31,054 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:31,226 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:32,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f6ffa1fb', purging
2023-05-28 07:20:32,418 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8eoqbpsl', purging
2023-05-28 07:20:32,418 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mn7aln81', purging
2023-05-28 07:20:32,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xnastq7x', purging
2023-05-28 07:20:32,419 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:32,419 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:32,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:32,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:32,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:32,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:32,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:32,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:33,736 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:33,762 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:33,781 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:33,949 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:35,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vwtstvwz', purging
2023-05-28 07:20:35,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oaym03wj', purging
2023-05-28 07:20:35,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qka6edyy', purging
2023-05-28 07:20:35,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-59r045uk', purging
2023-05-28 07:20:35,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:35,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:35,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:35,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:35,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:35,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:35,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:35,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:36,462 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:36,491 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:36,514 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:36,681 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:37,883 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9djtl063', purging
2023-05-28 07:20:37,884 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bjxvab02', purging
2023-05-28 07:20:37,884 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4gxbbab7', purging
2023-05-28 07:20:37,884 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1k1wm59o', purging
2023-05-28 07:20:37,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:37,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:37,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:37,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:37,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:37,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:38,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:38,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:39,192 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:39,223 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:39,257 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:39,437 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:40,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m5n6d1ko', purging
2023-05-28 07:20:40,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_aylcmax', purging
2023-05-28 07:20:40,681 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0yi5c1oo', purging
2023-05-28 07:20:40,682 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-en06byh2', purging
2023-05-28 07:20:40,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:40,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:40,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:40,682 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:40,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:40,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:40,818 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:40,818 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:41,992 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:42,020 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:42,041 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:42,206 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:43,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ug7k9gw', purging
2023-05-28 07:20:43,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:43,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:43,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_50lhsh5', purging
2023-05-28 07:20:43,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oq2hyyw6', purging
2023-05-28 07:20:43,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-791clcma', purging
2023-05-28 07:20:43,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:43,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:43,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:43,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:43,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:43,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:44,670 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:44,695 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:44,720 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:44,880 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:46,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bqb0z6y9', purging
2023-05-28 07:20:46,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v4ngc0hw', purging
2023-05-28 07:20:46,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cuketj6d', purging
2023-05-28 07:20:46,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lvwptihv', purging
2023-05-28 07:20:46,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:46,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:46,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:46,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:46,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:46,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:46,292 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:46,292 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:47,329 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:47,365 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:47,390 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:47,572 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:48,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6e6inmsv', purging
2023-05-28 07:20:48,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2k618a87', purging
2023-05-28 07:20:48,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8aowe7hz', purging
2023-05-28 07:20:48,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6of8uz9u', purging
2023-05-28 07:20:48,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:48,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:48,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:48,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:48,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:48,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:48,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:48,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:50,039 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:50,060 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:50,096 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:50,259 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:51,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dsvb8l0q', purging
2023-05-28 07:20:51,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3e7ch0do', purging
2023-05-28 07:20:51,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s_f9q3xg', purging
2023-05-28 07:20:51,483 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p0hysmio', purging
2023-05-28 07:20:51,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:51,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:51,488 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:51,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:51,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:51,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:51,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:51,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:52,790 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:52,814 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:52,841 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:53,006 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:54,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_cregny', purging
2023-05-28 07:20:54,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g4bnto5l', purging
2023-05-28 07:20:54,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sf44mfdg', purging
2023-05-28 07:20:54,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_xvrkbo', purging
2023-05-28 07:20:54,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:54,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:54,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:54,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:54,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:54,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:54,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:54,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:55,431 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:55,468 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:55,494 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:55,655 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:56,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kpma3_vh', purging
2023-05-28 07:20:56,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5_iv6s7d', purging
2023-05-28 07:20:56,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-px66ikx8', purging
2023-05-28 07:20:56,852 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v_p0zo3a', purging
2023-05-28 07:20:56,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:56,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:56,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:56,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:56,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:56,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:57,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:57,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:20:58,140 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:58,192 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:58,209 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:58,380 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:20:59,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u9f9gxm3', purging
2023-05-28 07:20:59,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nnjovszp', purging
2023-05-28 07:20:59,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tdrgxrc6', purging
2023-05-28 07:20:59,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p9fnkm5k', purging
2023-05-28 07:20:59,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:59,561 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:59,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:59,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:59,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:59,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:20:59,794 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:20:59,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:00,806 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:00,851 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:00,886 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:01,030 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:02,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dg9bc1ts', purging
2023-05-28 07:21:02,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-86r8ulf4', purging
2023-05-28 07:21:02,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dsnxd7g9', purging
2023-05-28 07:21:02,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rsxp1e85', purging
2023-05-28 07:21:02,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:02,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:02,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:02,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:02,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:02,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:02,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:02,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:03,474 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:03,508 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:03,546 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:03,705 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:04,922 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o0npqtr8', purging
2023-05-28 07:21:04,922 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-av3zm_gp', purging
2023-05-28 07:21:04,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:04,922 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2uf3cs6', purging
2023-05-28 07:21:04,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:04,923 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qf9amrz0', purging
2023-05-28 07:21:04,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:04,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:04,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:04,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:05,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:05,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:06,192 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:06,243 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:06,252 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:06,412 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:07,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ftd03ent', purging
2023-05-28 07:21:07,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cy22dpyf', purging
2023-05-28 07:21:07,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v9sg30r4', purging
2023-05-28 07:21:07,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ouwfckr8', purging
2023-05-28 07:21:07,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:07,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:07,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:07,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:07,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:07,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:07,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:07,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:08,830 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:08,851 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:08,890 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:09,055 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:10,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cwlrp26f', purging
2023-05-28 07:21:10,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wz4hb5b', purging
2023-05-28 07:21:10,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ab62iec5', purging
2023-05-28 07:21:10,273 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b9din53n', purging
2023-05-28 07:21:10,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:10,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:10,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:10,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:10,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:10,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:10,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:10,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:11,597 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:11,633 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:11,658 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:11,837 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:12,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l35cso0i', purging
2023-05-28 07:21:12,974 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-85sttdg1', purging
2023-05-28 07:21:12,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a0oxlp7x', purging
2023-05-28 07:21:12,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bzn5o9k0', purging
2023-05-28 07:21:12,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:12,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:13,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:13,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:13,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:13,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:13,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:13,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:14,208 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:14,253 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:14,283 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:14,447 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:15,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-avl021w6', purging
2023-05-28 07:21:15,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8vegc5io', purging
2023-05-28 07:21:15,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-695bw378', purging
2023-05-28 07:21:15,561 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ktjchf8', purging
2023-05-28 07:21:15,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:15,561 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:15,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:15,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:15,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:15,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:15,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:15,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:16,815 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:16,842 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:16,868 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:17,058 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:18,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0hb7fx8r', purging
2023-05-28 07:21:18,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lmknsn8m', purging
2023-05-28 07:21:18,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hkhqicw0', purging
2023-05-28 07:21:18,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zb0d9jt3', purging
2023-05-28 07:21:18,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:18,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:18,224 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:18,224 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:18,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:18,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:18,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:18,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:19,486 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:19,548 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:19,549 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:19,715 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:20,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6b4cbhrn', purging
2023-05-28 07:21:20,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3zaf3mob', purging
2023-05-28 07:21:20,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c3hr0_0z', purging
2023-05-28 07:21:20,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n9as8289', purging
2023-05-28 07:21:20,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:20,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:20,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:20,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:20,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:20,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:21,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:21,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:22,224 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:22,270 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:22,294 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:22,453 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:23,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gd579ds0', purging
2023-05-28 07:21:23,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jev6dq1r', purging
2023-05-28 07:21:23,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m8in5ta4', purging
2023-05-28 07:21:23,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gku9id2r', purging
2023-05-28 07:21:23,670 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:23,670 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:23,694 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:23,694 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:23,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:23,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:23,794 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:23,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:24,937 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:24,987 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:25,006 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:25,181 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:26,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y3yfns75', purging
2023-05-28 07:21:26,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9mwnbehm', purging
2023-05-28 07:21:26,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xnt899ce', purging
2023-05-28 07:21:26,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mu402_00', purging
2023-05-28 07:21:26,350 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:26,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:26,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:26,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:26,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:26,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:26,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:26,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:27,629 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:27,653 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:27,680 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:27,856 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:29,060 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xc4i1sm2', purging
2023-05-28 07:21:29,060 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_q79hxqk', purging
2023-05-28 07:21:29,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0xk4hn16', purging
2023-05-28 07:21:29,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u7ihsozn', purging
2023-05-28 07:21:29,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:29,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:29,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:29,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:29,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:29,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:29,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:29,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:30,377 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:30,407 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:30,428 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:30,599 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:31,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m50shx8t', purging
2023-05-28 07:21:31,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x9pavsq5', purging
2023-05-28 07:21:31,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ityg5js0', purging
2023-05-28 07:21:31,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-naoz5jn3', purging
2023-05-28 07:21:31,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:31,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:31,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:31,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:31,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:31,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:31,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:31,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:33,156 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:33,173 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:33,195 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:33,367 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:34,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y8vcqg6s', purging
2023-05-28 07:21:34,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-81nw4wbz', purging
2023-05-28 07:21:34,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7umxvrnb', purging
2023-05-28 07:21:34,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufav3x94', purging
2023-05-28 07:21:34,538 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:34,538 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:34,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:34,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:34,635 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:34,635 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:34,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:34,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:35,798 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:35,845 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:35,868 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:36,056 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:37,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qj78nyy6', purging
2023-05-28 07:21:37,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-99dbxsma', purging
2023-05-28 07:21:37,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-23s81_oe', purging
2023-05-28 07:21:37,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fylnaey_', purging
2023-05-28 07:21:37,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:37,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:37,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:37,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:37,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:37,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:37,468 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:37,468 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:38,456 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:38,482 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:38,511 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:38,693 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:39,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-denlgo6l', purging
2023-05-28 07:21:39,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:39,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:39,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-np8_vgmy', purging
2023-05-28 07:21:39,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pf4doy2k', purging
2023-05-28 07:21:39,893 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ncupsvp', purging
2023-05-28 07:21:39,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:39,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:39,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:39,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:40,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:40,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:41,178 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:41,197 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:41,230 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:41,387 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:42,593 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bx6y47a5', purging
2023-05-28 07:21:42,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w9_h5qie', purging
2023-05-28 07:21:42,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufd2a6qf', purging
2023-05-28 07:21:42,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y6aj75po', purging
2023-05-28 07:21:42,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:42,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:42,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:42,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:42,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:42,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:42,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:42,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:43,876 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:43,920 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:43,948 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:44,107 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:45,255 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wjtvths6', purging
2023-05-28 07:21:45,256 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xe4n8cr8', purging
2023-05-28 07:21:45,256 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9mo1gc3z', purging
2023-05-28 07:21:45,256 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ita2_emt', purging
2023-05-28 07:21:45,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:45,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:45,322 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:45,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:45,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:45,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:45,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:45,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:46,531 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:46,557 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:46,584 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:46,737 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:47,905 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6ql100cz', purging
2023-05-28 07:21:47,905 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-argzjte_', purging
2023-05-28 07:21:47,906 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dqh1t9_d', purging
2023-05-28 07:21:47,906 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9o5my9ob', purging
2023-05-28 07:21:47,907 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:47,907 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:47,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:47,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:47,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:47,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:48,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:48,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:49,186 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:49,223 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:49,272 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:49,425 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:50,634 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ommx5wam', purging
2023-05-28 07:21:50,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-td830u4u', purging
2023-05-28 07:21:50,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mxbnq1qn', purging
2023-05-28 07:21:50,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k7e_3ccf', purging
2023-05-28 07:21:50,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:50,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:50,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:50,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:50,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:50,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:50,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:50,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:51,919 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:51,954 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:51,968 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:52,151 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:53,334 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i1e64afa', purging
2023-05-28 07:21:53,334 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gusm7oyr', purging
2023-05-28 07:21:53,334 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yl61s53d', purging
2023-05-28 07:21:53,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-edo2cnn9', purging
2023-05-28 07:21:53,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:53,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:53,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:53,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:53,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:53,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:53,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:53,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:54,583 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:54,629 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:54,656 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:54,828 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:55,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ap3jo5ok', purging
2023-05-28 07:21:55,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f6i65tre', purging
2023-05-28 07:21:55,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f9i3yy5b', purging
2023-05-28 07:21:55,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_f3woimn', purging
2023-05-28 07:21:55,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:55,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:56,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:56,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:56,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:56,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:56,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:56,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:57,221 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:57,249 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:57,280 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:57,445 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:58,586 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9sod9jxy', purging
2023-05-28 07:21:58,586 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-62xnkqo_', purging
2023-05-28 07:21:58,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqq426uk', purging
2023-05-28 07:21:58,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oduwrs92', purging
2023-05-28 07:21:58,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:58,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:58,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:58,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:58,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:58,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:21:58,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:21:58,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:21:59,811 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:59,862 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:21:59,877 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:00,094 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:01,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7cgeby6d', purging
2023-05-28 07:22:01,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0o6tx8dd', purging
2023-05-28 07:22:01,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rzr2haqz', purging
2023-05-28 07:22:01,244 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q4wix4ie', purging
2023-05-28 07:22:01,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:01,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:01,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:01,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:01,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:01,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:01,463 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:01,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:02,486 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:02,555 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:02,575 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:02,715 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:03,945 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tq1fofpf', purging
2023-05-28 07:22:03,946 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mammaswn', purging
2023-05-28 07:22:03,946 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gspb3p79', purging
2023-05-28 07:22:03,946 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fwfw39jk', purging
2023-05-28 07:22:03,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:03,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:03,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:03,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:03,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:03,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:04,153 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:04,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:05,255 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:05,290 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:05,304 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:05,471 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:06,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bo1leapg', purging
2023-05-28 07:22:06,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6_u8r15n', purging
2023-05-28 07:22:06,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr7l4qzx', purging
2023-05-28 07:22:06,675 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zw4qcoe_', purging
2023-05-28 07:22:06,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:06,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:06,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:06,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:06,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:06,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:06,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:06,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:07,943 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:07,983 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:07,999 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:08,179 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:09,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fder8_4d', purging
2023-05-28 07:22:09,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-awsrc3pi', purging
2023-05-28 07:22:09,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-672757kb', purging
2023-05-28 07:22:09,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qzqo5d3y', purging
2023-05-28 07:22:09,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:09,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:09,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:09,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:09,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:09,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:09,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:09,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:10,603 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:10,635 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:10,675 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:10,844 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:12,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-soqtfhqm', purging
2023-05-28 07:22:12,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wbek50_h', purging
2023-05-28 07:22:12,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psv6k7oh', purging
2023-05-28 07:22:12,042 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jmpozogz', purging
2023-05-28 07:22:12,042 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:12,042 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:12,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:12,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:12,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:12,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:12,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:12,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:13,320 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:13,365 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:13,405 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:13,563 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:14,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ij7i5w8q', purging
2023-05-28 07:22:14,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s7txilsy', purging
2023-05-28 07:22:14,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ya58kkow', purging
2023-05-28 07:22:14,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y4klhogs', purging
2023-05-28 07:22:14,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:14,745 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:14,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:14,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:14,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:14,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:15,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:15,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:16,037 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:16,071 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:16,096 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:16,275 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:17,445 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-glk3fa7t', purging
2023-05-28 07:22:17,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mar8xqmz', purging
2023-05-28 07:22:17,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xrsk5zmp', purging
2023-05-28 07:22:17,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_d7mpmq', purging
2023-05-28 07:22:17,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:17,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:17,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:17,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:17,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:17,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:17,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:17,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:18,721 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:18,767 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:18,805 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:18,957 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:20,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iavssmk1', purging
2023-05-28 07:22:20,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aqtul8dm', purging
2023-05-28 07:22:20,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-41mmndm4', purging
2023-05-28 07:22:20,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m629rh2h', purging
2023-05-28 07:22:20,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:20,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:20,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:20,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:20,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:20,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:20,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:20,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:21,358 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:21,395 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:21,420 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:21,592 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:22,813 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7enywmhx', purging
2023-05-28 07:22:22,814 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xiu1mxd_', purging
2023-05-28 07:22:22,814 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n0dvli_4', purging
2023-05-28 07:22:22,814 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1400t2jq', purging
2023-05-28 07:22:22,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:22,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:22,822 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:22,822 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:22,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:22,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:23,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:23,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:24,077 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:24,094 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:24,133 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:24,291 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:25,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rhegv4ff', purging
2023-05-28 07:22:25,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-er5xwqs2', purging
2023-05-28 07:22:25,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q159vjkm', purging
2023-05-28 07:22:25,441 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mo2j9gw6', purging
2023-05-28 07:22:25,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:25,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:25,488 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:25,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:25,521 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:25,521 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:25,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:25,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:26,708 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:26,727 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:26,767 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:26,925 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:28,098 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-siffvdst', purging
2023-05-28 07:22:28,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3gvkcjfg', purging
2023-05-28 07:22:28,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ezv999mx', purging
2023-05-28 07:22:28,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n1bezid0', purging
2023-05-28 07:22:28,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:28,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:28,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:28,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:28,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:28,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:28,360 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:28,360 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:29,371 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:29,417 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:29,440 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:29,623 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:30,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fa_n9dvn', purging
2023-05-28 07:22:30,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5uu7fwu', purging
2023-05-28 07:22:30,828 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ykf95n55', purging
2023-05-28 07:22:30,828 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l34687f9', purging
2023-05-28 07:22:30,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:30,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:30,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:30,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:30,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:30,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:30,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:30,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:32,124 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:32,145 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:32,178 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:32,348 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:33,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1k0xh62g', purging
2023-05-28 07:22:33,523 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ooj19dpu', purging
2023-05-28 07:22:33,523 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6sy40gbn', purging
2023-05-28 07:22:33,523 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8be98kly', purging
2023-05-28 07:22:33,524 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:33,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:33,524 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:33,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:33,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:33,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:33,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:33,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:34,794 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:34,840 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:34,879 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:35,048 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:36,204 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f5rdwim7', purging
2023-05-28 07:22:36,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8mic5s_y', purging
2023-05-28 07:22:36,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_uc58fno', purging
2023-05-28 07:22:36,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8p5e_jlm', purging
2023-05-28 07:22:36,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:36,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:36,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:36,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:36,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:36,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:36,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:36,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:37,448 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:37,475 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:37,509 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:37,680 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:38,834 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8e74mpgh', purging
2023-05-28 07:22:38,834 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3mf0m31l', purging
2023-05-28 07:22:38,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psf94cvw', purging
2023-05-28 07:22:38,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ptgh5832', purging
2023-05-28 07:22:38,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:38,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:38,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:38,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:38,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:38,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:39,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:39,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:40,100 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:40,141 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:40,175 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:40,343 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:41,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jwbtvr03', purging
2023-05-28 07:22:41,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qmm97elf', purging
2023-05-28 07:22:41,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l0cagmyn', purging
2023-05-28 07:22:41,520 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2xukcq8c', purging
2023-05-28 07:22:41,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:41,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:41,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:41,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:41,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:41,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:41,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:41,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:42,855 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:42,881 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:42,901 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:43,066 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:44,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yzompy_l', purging
2023-05-28 07:22:44,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oyqnd4cy', purging
2023-05-28 07:22:44,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_g_k_cs', purging
2023-05-28 07:22:44,314 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cetm0xq_', purging
2023-05-28 07:22:44,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:44,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:44,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:44,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:44,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:44,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:44,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:44,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:45,598 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:45,622 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:45,653 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:45,816 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:47,069 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pzmqkjfi', purging
2023-05-28 07:22:47,069 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0316h95c', purging
2023-05-28 07:22:47,070 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qqcolkql', purging
2023-05-28 07:22:47,070 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:47,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:47,070 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-awez4wk8', purging
2023-05-28 07:22:47,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:47,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:47,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:47,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:47,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:47,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:48,330 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:48,371 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:48,402 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:48,556 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:49,774 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vd51lu2e', purging
2023-05-28 07:22:49,774 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yfr3fxt5', purging
2023-05-28 07:22:49,774 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s4it6gh7', purging
2023-05-28 07:22:49,775 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cu01orbb', purging
2023-05-28 07:22:49,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:49,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:49,824 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:49,824 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:49,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:49,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:49,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:49,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:51,064 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:51,079 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:51,120 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:51,274 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:52,445 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5fditwx', purging
2023-05-28 07:22:52,445 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dvnwfak9', purging
2023-05-28 07:22:52,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jps1x4uy', purging
2023-05-28 07:22:52,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-80zhykwv', purging
2023-05-28 07:22:52,446 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:52,446 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:52,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:52,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:52,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:52,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:52,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:52,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:53,782 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:53,808 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:53,844 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:54,004 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:55,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wrki2tiz', purging
2023-05-28 07:22:55,218 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_w8w7jh3', purging
2023-05-28 07:22:55,218 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z2fn5q66', purging
2023-05-28 07:22:55,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lmmdx7ig', purging
2023-05-28 07:22:55,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:55,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:55,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:55,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:55,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:55,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:55,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:55,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:56,491 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:56,520 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:56,543 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:56,723 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:57,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vdubo1kb', purging
2023-05-28 07:22:57,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hsbbh344', purging
2023-05-28 07:22:57,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-imqnk08y', purging
2023-05-28 07:22:57,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iipd9m47', purging
2023-05-28 07:22:57,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:57,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:57,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:57,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:57,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:57,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:22:58,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:22:58,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:22:59,185 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:59,216 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:59,241 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:22:59,421 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:00,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufigl1l5', purging
2023-05-28 07:23:00,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yklxaprr', purging
2023-05-28 07:23:00,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i3j4gaqm', purging
2023-05-28 07:23:00,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lxd9kq9k', purging
2023-05-28 07:23:00,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:00,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:00,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:00,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:00,635 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:00,635 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:00,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:00,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:01,885 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:01,933 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:01,955 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:02,113 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:03,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-duadxj_k', purging
2023-05-28 07:23:03,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pjys0aro', purging
2023-05-28 07:23:03,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1789r6bp', purging
2023-05-28 07:23:03,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kjg2pu_2', purging
2023-05-28 07:23:03,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:03,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:03,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:03,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:03,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:03,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:03,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:03,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:04,609 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:04,655 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:04,679 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:04,852 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:05,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yt0556p7', purging
2023-05-28 07:23:05,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6azd260a', purging
2023-05-28 07:23:05,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6xj8fny6', purging
2023-05-28 07:23:05,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-td6tjz88', purging
2023-05-28 07:23:05,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:05,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:06,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:06,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:06,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:06,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:06,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:06,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:07,262 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:07,299 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:07,331 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:07,491 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:08,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hr4ptqex', purging
2023-05-28 07:23:08,665 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uyrnlz70', purging
2023-05-28 07:23:08,665 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4697dnjv', purging
2023-05-28 07:23:08,666 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-itqmiqcv', purging
2023-05-28 07:23:08,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:08,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:08,735 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:08,735 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:08,768 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:08,768 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:08,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:08,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:09,981 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:10,024 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:10,052 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:10,205 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:11,407 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pczvj2te', purging
2023-05-28 07:23:11,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gfavr27p', purging
2023-05-28 07:23:11,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_hx6ydon', purging
2023-05-28 07:23:11,409 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5k1s30g8', purging
2023-05-28 07:23:11,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:11,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:11,446 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:11,446 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:11,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:11,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:11,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:11,643 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:12,704 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:12,724 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:12,761 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:12,922 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:14,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zg5a5ggh', purging
2023-05-28 07:23:14,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jjoj_r5s', purging
2023-05-28 07:23:14,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-to1gb2r3', purging
2023-05-28 07:23:14,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dma4d2bo', purging
2023-05-28 07:23:14,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:14,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:14,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:14,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:14,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:14,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:14,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:14,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:15,407 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:15,457 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:15,469 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:15,625 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:16,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e23403hj', purging
2023-05-28 07:23:16,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nw4lutl6', purging
2023-05-28 07:23:16,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u64i8awa', purging
2023-05-28 07:23:16,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6uow4ht4', purging
2023-05-28 07:23:16,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:16,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:16,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:16,871 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:16,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:16,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:17,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:17,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:18,075 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:18,106 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:18,137 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:18,308 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:19,549 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dhmajn_t', purging
2023-05-28 07:23:19,549 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0fki4mw', purging
2023-05-28 07:23:19,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ynncqy0r', purging
2023-05-28 07:23:19,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k4ilz3am', purging
2023-05-28 07:23:19,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:19,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:19,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:19,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:19,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:19,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:19,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:19,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:20,849 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:20,878 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:20,912 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:21,107 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:22,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kxry8p01', purging
2023-05-28 07:23:22,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xr9xisnp', purging
2023-05-28 07:23:22,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5li158r', purging
2023-05-28 07:23:22,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b9m6ekw9', purging
2023-05-28 07:23:22,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:22,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:22,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:22,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:22,346 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:22,346 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:22,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:22,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:23,552 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:23,583 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:23,599 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:23,736 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:24,926 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kewqevvl', purging
2023-05-28 07:23:24,926 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k09gvoi7', purging
2023-05-28 07:23:24,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_wdwtd0d', purging
2023-05-28 07:23:24,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v5u6bik3', purging
2023-05-28 07:23:24,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:24,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:25,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:25,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:25,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:25,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:25,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:25,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:26,218 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:26,256 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:26,285 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:26,456 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:27,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9mo_thxx', purging
2023-05-28 07:23:27,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1cpxcpla', purging
2023-05-28 07:23:27,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j8lvqfrn', purging
2023-05-28 07:23:27,606 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dsxq2pb0', purging
2023-05-28 07:23:27,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:27,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:27,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:27,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:27,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:27,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:27,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:27,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:28,886 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:28,910 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:28,949 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:29,114 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:30,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-21tx2yt5', purging
2023-05-28 07:23:30,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qi6itzv4', purging
2023-05-28 07:23:30,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c9wkhpp0', purging
2023-05-28 07:23:30,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ck19en2a', purging
2023-05-28 07:23:30,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:30,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:30,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:30,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:30,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:30,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:30,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:30,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:31,572 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:31,621 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:23:31,762 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:32,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-prj8_zg7', purging
2023-05-28 07:23:32,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ommfsifq', purging
2023-05-28 07:23:32,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5dj5mxh', purging
2023-05-28 07:23:32,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y95nkhxo', purging
2023-05-28 07:23:32,960 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:32,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:32,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:32,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:33,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:33,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:34,000 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:34,028 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:34,196 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:35,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3cbqv1hz', purging
2023-05-28 07:23:35,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pcxale59', purging
2023-05-28 07:23:35,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_xfvte0', purging
2023-05-28 07:23:35,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:35,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:35,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:35,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:35,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:35,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:36,415 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:36,453 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:36,619 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:37,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d1_r3ew6', purging
2023-05-28 07:23:37,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0_vlsub0', purging
2023-05-28 07:23:37,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aj6ti4cf', purging
2023-05-28 07:23:37,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:37,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:37,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:37,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:37,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:37,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:38,806 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:38,825 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:38,993 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:40,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l77n1yi8', purging
2023-05-28 07:23:40,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ic_cr_pu', purging
2023-05-28 07:23:40,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yxgs7i8f', purging
2023-05-28 07:23:40,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:40,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:40,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:40,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:40,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:40,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:41,238 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:41,277 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:41,440 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:42,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7bpo32t4', purging
2023-05-28 07:23:42,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5j45rfpd', purging
2023-05-28 07:23:42,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r53e5z06', purging
2023-05-28 07:23:42,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:42,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:42,682 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:42,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:42,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:42,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:43,672 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:43,685 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:43,853 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:45,006 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i654f5u3', purging
2023-05-28 07:23:45,006 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qaz8sspb', purging
2023-05-28 07:23:45,007 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6u78mib6', purging
2023-05-28 07:23:45,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:45,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:45,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:45,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:45,242 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:45,242 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:46,036 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:46,076 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:46,238 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:47,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c5mpv07v', purging
2023-05-28 07:23:47,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a6oem8jc', purging
2023-05-28 07:23:47,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xvr4bidg', purging
2023-05-28 07:23:47,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:47,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:47,443 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:47,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:47,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:47,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:48,458 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:48,499 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:48,645 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:49,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-32c5vnce', purging
2023-05-28 07:23:49,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p1n7jnr_', purging
2023-05-28 07:23:49,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-40g8d515', purging
2023-05-28 07:23:49,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:49,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:49,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:49,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:50,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:50,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:50,905 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:50,935 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:51,097 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:52,291 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-br17uhnd', purging
2023-05-28 07:23:52,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5jv50zbu', purging
2023-05-28 07:23:52,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h3wi2kud', purging
2023-05-28 07:23:52,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:52,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:52,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:52,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:52,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:52,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:53,366 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:53,387 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:53,581 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:54,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:54,795 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vwh3b768', purging
2023-05-28 07:23:54,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:54,795 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ischq7dj', purging
2023-05-28 07:23:54,795 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m2ebzrif', purging
2023-05-28 07:23:54,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:54,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:54,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:54,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:55,832 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:55,854 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:56,041 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:57,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zwg1haup', purging
2023-05-28 07:23:57,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rxgp9ck9', purging
2023-05-28 07:23:57,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4jo9dgj2', purging
2023-05-28 07:23:57,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:57,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:57,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:57,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:57,422 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:57,422 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:23:58,213 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:58,251 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:58,419 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:23:59,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bekjdlgk', purging
2023-05-28 07:23:59,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wb5hk8u_', purging
2023-05-28 07:23:59,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-syefvcdj', purging
2023-05-28 07:23:59,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:59,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:59,670 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:59,670 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:23:59,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:23:59,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:00,643 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:00,666 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:00,847 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:02,007 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qn2uqaos', purging
2023-05-28 07:24:02,008 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vy3eg7am', purging
2023-05-28 07:24:02,008 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5hzq3w0g', purging
2023-05-28 07:24:02,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:02,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:02,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:02,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:02,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:02,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:03,071 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:24:03,237 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:04,415 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uys1zc_b', purging
2023-05-28 07:24:04,415 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2w_j6i6', purging
2023-05-28 07:24:04,415 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7xfjtggy', purging
2023-05-28 07:24:04,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:04,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:04,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:04,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:05,251 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:05,420 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:06,600 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t38vxr5c', purging
2023-05-28 07:24:06,600 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gv9jvfmx', purging
2023-05-28 07:24:06,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:06,601 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:06,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:06,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:07,423 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:07,584 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:08,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tmu62bj2', purging
2023-05-28 07:24:08,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h4xbwyb0', purging
2023-05-28 07:24:08,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:08,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:08,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:08,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:09,623 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:09,798 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:10,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ypweqje', purging
2023-05-28 07:24:10,984 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sdu4wyr2', purging
2023-05-28 07:24:10,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:10,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:11,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:11,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:11,814 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:11,982 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:13,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n09ovd1m', purging
2023-05-28 07:24:13,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bdgt98iu', purging
2023-05-28 07:24:13,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:13,161 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:13,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:13,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:13,996 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:14,158 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:15,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-32hvez86', purging
2023-05-28 07:24:15,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0x9h31a9', purging
2023-05-28 07:24:15,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:15,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:15,489 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:15,489 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:16,179 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:16,347 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:17,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tgs0pg65', purging
2023-05-28 07:24:17,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cnlqzi96', purging
2023-05-28 07:24:17,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:17,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:17,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:17,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:18,381 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:18,546 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:19,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-004dy62z', purging
2023-05-28 07:24:19,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ugr8hd9', purging
2023-05-28 07:24:19,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:19,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:19,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:19,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:20,579 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:20,753 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:21,945 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_t4oj55t', purging
2023-05-28 07:24:21,946 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fux8zejs', purging
2023-05-28 07:24:21,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:21,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:22,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:22,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:22,802 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:22,967 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:24,239 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_qh1c2m', purging
2023-05-28 07:24:24,239 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5mia9245', purging
2023-05-28 07:24:24,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:24,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:24,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:24,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:25,068 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:25,238 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:26,450 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oylljymw', purging
2023-05-28 07:24:26,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yrj89ymh', purging
2023-05-28 07:24:26,451 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:26,451 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:26,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:26,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:27,275 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:27,449 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:28,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cu9pm6e8', purging
2023-05-28 07:24:28,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d_3aupze', purging
2023-05-28 07:24:28,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:28,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:28,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:28,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:29,464 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:29,635 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:30,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-76f7bwaw', purging
2023-05-28 07:24:30,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ujs744v', purging
2023-05-28 07:24:30,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:30,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:30,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:30,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:31,623 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:31,782 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:32,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nwznw15d', purging
2023-05-28 07:24:32,984 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v28w8nvq', purging
2023-05-28 07:24:32,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:32,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:33,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:33,173 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:33,828 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:33,989 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:35,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3htt5c13', purging
2023-05-28 07:24:35,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-az_b9ew_', purging
2023-05-28 07:24:35,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:35,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:35,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:35,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:36,008 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:36,172 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:37,360 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-56gk1qn5', purging
2023-05-28 07:24:37,361 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-flxmdr29', purging
2023-05-28 07:24:37,361 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:37,361 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:37,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:37,487 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:38,192 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:38,364 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:39,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-stszrj9a', purging
2023-05-28 07:24:39,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvdgpstf', purging
2023-05-28 07:24:39,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:39,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:39,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:39,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:40,360 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:40,541 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:41,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yln3ws_l', purging
2023-05-28 07:24:41,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-im12x8mt', purging
2023-05-28 07:24:41,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:41,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:41,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:41,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:42,565 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:42,741 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:43,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ll632gqv', purging
2023-05-28 07:24:43,915 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nmx4hw60', purging
2023-05-28 07:24:43,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:43,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:44,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:44,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:44,759 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:44,921 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:46,117 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ftyatihv', purging
2023-05-28 07:24:46,117 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zhvsksy1', purging
2023-05-28 07:24:46,117 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:46,117 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:46,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:46,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:46,960 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:47,130 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:48,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9q8a9f1s', purging
2023-05-28 07:24:48,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4xlbqe8h', purging
2023-05-28 07:24:48,295 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:48,295 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:48,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:48,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:49,121 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:49,292 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:50,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1fm6k17d', purging
2023-05-28 07:24:50,457 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sp_s__9z', purging
2023-05-28 07:24:50,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:50,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:50,649 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:50,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:51,295 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:51,466 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:52,659 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_xg2449', purging
2023-05-28 07:24:52,659 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7y75i4a', purging
2023-05-28 07:24:52,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:52,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:52,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:52,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:53,480 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:53,649 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:54,823 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jeeih60c', purging
2023-05-28 07:24:54,823 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o3nf94cb', purging
2023-05-28 07:24:54,824 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:54,824 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:54,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:54,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:55,675 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:55,839 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:57,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jzbkl9qb', purging
2023-05-28 07:24:57,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gt4b6mb4', purging
2023-05-28 07:24:57,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:57,052 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:57,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:57,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:24:57,887 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:58,051 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:24:59,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-prr7kjom', purging
2023-05-28 07:24:59,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tmzv96hu', purging
2023-05-28 07:24:59,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:59,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:24:59,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:24:59,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:00,030 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:00,208 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:01,407 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-616t26dd', purging
2023-05-28 07:25:01,407 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-23hu2dth', purging
2023-05-28 07:25:01,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:01,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:01,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:01,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:02,250 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:02,422 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:03,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b0ljw_77', purging
2023-05-28 07:25:03,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pfn4askz', purging
2023-05-28 07:25:03,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:03,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:03,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:03,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:04,463 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:04,622 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:05,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-apk1fdy2', purging
2023-05-28 07:25:05,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d8eliiu4', purging
2023-05-28 07:25:05,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:05,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:05,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:05,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:06,654 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:06,814 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:07,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9oamdlrr', purging
2023-05-28 07:25:07,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-grzseuvh', purging
2023-05-28 07:25:07,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:07,970 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:08,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:08,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:08,792 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:08,961 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:10,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_fcdmimc', purging
2023-05-28 07:25:10,154 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sm8vghuw', purging
2023-05-28 07:25:10,155 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:10,155 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:10,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:10,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:10,982 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:11,154 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:12,324 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0hn7kps', purging
2023-05-28 07:25:12,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-er9ldreg', purging
2023-05-28 07:25:12,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:12,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:12,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:12,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:13,187 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:13,363 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:14,508 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xudywbs7', purging
2023-05-28 07:25:14,508 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0tw4b8e_', purging
2023-05-28 07:25:14,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:14,509 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:14,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:14,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:15,328 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:15,514 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:16,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5uows0a', purging
2023-05-28 07:25:16,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-blts3tvn', purging
2023-05-28 07:25:16,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:16,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:16,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:16,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:17,459 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:17,633 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:18,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a4bxil6k', purging
2023-05-28 07:25:18,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3f2om80b', purging
2023-05-28 07:25:18,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:18,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:18,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:18,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:19,600 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:19,773 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:20,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gtchv66l', purging
2023-05-28 07:25:20,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rimelk_i', purging
2023-05-28 07:25:20,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:20,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:21,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:21,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:21,743 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:21,916 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:23,095 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tm7vd_6w', purging
2023-05-28 07:25:23,095 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_8ea8sds', purging
2023-05-28 07:25:23,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:23,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:23,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:23,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:23,936 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:24,104 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:25,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l3v7dr82', purging
2023-05-28 07:25:25,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k51igei7', purging
2023-05-28 07:25:25,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:25,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:25,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:25,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:26,110 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:26,286 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:27,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u0_lp6un', purging
2023-05-28 07:25:27,553 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-23_wy0wq', purging
2023-05-28 07:25:27,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:27,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:27,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:27,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:28,404 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:28,578 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:29,785 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6fon7o64', purging
2023-05-28 07:25:29,785 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kcsaykgu', purging
2023-05-28 07:25:29,786 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:29,786 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:29,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:29,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:30,621 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:30,796 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:31,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l5j5fqc7', purging
2023-05-28 07:25:31,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lq58fniy', purging
2023-05-28 07:25:31,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:31,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:32,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:32,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:32,815 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:32,986 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:34,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yud8281s', purging
2023-05-28 07:25:34,202 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rzvm25b5', purging
2023-05-28 07:25:34,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:34,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:34,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:34,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:35,061 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:35,225 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:36,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xje5dpq1', purging
2023-05-28 07:25:36,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jtur3omb', purging
2023-05-28 07:25:36,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:36,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:36,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:36,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:37,253 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:37,426 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:38,620 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y0kh4g02', purging
2023-05-28 07:25:38,620 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pn6g0770', purging
2023-05-28 07:25:38,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:38,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:38,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:38,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:39,498 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:39,673 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:40,845 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dbk117rf', purging
2023-05-28 07:25:40,845 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ea45ht8', purging
2023-05-28 07:25:40,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:40,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:41,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:41,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:41,679 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:41,869 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:43,037 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lop05_3x', purging
2023-05-28 07:25:43,037 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gpc6yj0d', purging
2023-05-28 07:25:43,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:43,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:43,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:43,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:43,880 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:44,053 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:45,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pnb4058t', purging
2023-05-28 07:25:45,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lz24o58i', purging
2023-05-28 07:25:45,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:45,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:45,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:45,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:46,072 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:46,248 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:47,423 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-thsks1i0', purging
2023-05-28 07:25:47,423 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ya2an7g4', purging
2023-05-28 07:25:47,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:47,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:47,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:47,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:48,263 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:48,427 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:49,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kueaidf9', purging
2023-05-28 07:25:49,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-50hpky8l', purging
2023-05-28 07:25:49,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:49,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:49,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:49,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:50,427 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:50,587 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:51,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3f8svp39', purging
2023-05-28 07:25:51,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tk3mla2k', purging
2023-05-28 07:25:51,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:51,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:51,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:51,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:52,606 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:52,774 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:53,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xnhmp9b_', purging
2023-05-28 07:25:53,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q15zrfcc', purging
2023-05-28 07:25:53,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:53,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:54,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:54,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:54,808 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:54,982 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:56,146 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fw60_hvd', purging
2023-05-28 07:25:56,147 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1zg2rhne', purging
2023-05-28 07:25:56,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:56,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:56,322 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:56,322 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:57,001 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:57,161 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:58,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m_7umemd', purging
2023-05-28 07:25:58,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ia63uy83', purging
2023-05-28 07:25:58,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:58,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:25:58,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:25:58,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:25:59,184 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:25:59,346 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:00,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vuqyhlw9', purging
2023-05-28 07:26:00,598 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8xhrt55z', purging
2023-05-28 07:26:00,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:00,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:00,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:00,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:01,458 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:01,630 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:02,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-671dhts7', purging
2023-05-28 07:26:02,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3o4qzj7a', purging
2023-05-28 07:26:02,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:02,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:02,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:02,996 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:03,648 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:03,803 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:04,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-791zikv1', purging
2023-05-28 07:26:04,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1oxjucz2', purging
2023-05-28 07:26:04,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:04,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:05,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:05,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:05,797 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:05,960 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:07,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-96o_nmbg', purging
2023-05-28 07:26:07,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z2jg2c5t', purging
2023-05-28 07:26:07,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:07,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:07,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:07,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:07,989 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:08,163 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:09,334 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psv8ebh4', purging
2023-05-28 07:26:09,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05v2f8so', purging
2023-05-28 07:26:09,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:09,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:09,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:09,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:10,171 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:10,346 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:11,507 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zvh_kj9j', purging
2023-05-28 07:26:11,507 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g33za0p5', purging
2023-05-28 07:26:11,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:11,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:11,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:11,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:12,340 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:12,508 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:13,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nbevc978', purging
2023-05-28 07:26:13,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2v16c_6f', purging
2023-05-28 07:26:13,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:13,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:13,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:13,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:14,498 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:14,679 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:15,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rfm71b0k', purging
2023-05-28 07:26:15,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cst0rzfg', purging
2023-05-28 07:26:15,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:15,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:16,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:16,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:16,680 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:16,848 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:18,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xucpyo08', purging
2023-05-28 07:26:18,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dlbfg6qj', purging
2023-05-28 07:26:18,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:18,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:18,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:18,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:18,851 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:19,021 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:20,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oqiuc9je', purging
2023-05-28 07:26:20,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ixlp1vjg', purging
2023-05-28 07:26:20,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:20,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:20,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:20,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:21,053 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:21,215 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:22,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ppbsqslo', purging
2023-05-28 07:26:22,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5mybcy63', purging
2023-05-28 07:26:22,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:22,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:22,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:22,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:23,257 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:23,419 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:24,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w0sywag1', purging
2023-05-28 07:26:24,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wb2zjpgq', purging
2023-05-28 07:26:24,638 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:24,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:24,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:24,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:25,471 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:25,646 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:26,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xn9otxv_', purging
2023-05-28 07:26:26,820 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a84ygskl', purging
2023-05-28 07:26:26,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:26,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:26,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:26,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:27,658 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:27,825 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:29,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-og4xf4eg', purging
2023-05-28 07:26:29,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bs6mfbs8', purging
2023-05-28 07:26:29,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:29,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:29,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:29,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:29,866 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:30,034 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:31,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zyenmvt0', purging
2023-05-28 07:26:31,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-toqkbbmh', purging
2023-05-28 07:26:31,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:31,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:31,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:31,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:32,121 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:32,299 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:33,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1a5oijxu', purging
2023-05-28 07:26:33,505 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgxz7afg', purging
2023-05-28 07:26:33,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:33,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:33,670 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:33,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:34,338 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:34,502 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:35,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8cjr97tf', purging
2023-05-28 07:26:35,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xyxv1he_', purging
2023-05-28 07:26:35,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:35,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:35,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:35,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:36,568 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:36,725 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:37,921 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9514oevd', purging
2023-05-28 07:26:37,922 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bwakwuvn', purging
2023-05-28 07:26:37,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:37,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:38,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:38,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:38,767 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:38,934 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:40,145 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2vz2mhhh', purging
2023-05-28 07:26:40,146 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ydvl4ibg', purging
2023-05-28 07:26:40,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:40,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:40,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:40,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:40,980 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:41,147 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:42,369 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ebzpwv3s', purging
2023-05-28 07:26:42,369 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-axm9k52b', purging
2023-05-28 07:26:42,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:42,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:42,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:42,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:43,226 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:43,388 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:44,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7c_78m2m', purging
2023-05-28 07:26:44,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iw54jdbs', purging
2023-05-28 07:26:44,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:44,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:44,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:44,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:45,469 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:45,636 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:46,846 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whq03udw', purging
2023-05-28 07:26:46,846 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6_nv3tt3', purging
2023-05-28 07:26:46,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:46,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:47,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:47,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:47,700 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:47,872 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:49,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rvwositv', purging
2023-05-28 07:26:49,079 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rtwlhsih', purging
2023-05-28 07:26:49,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:49,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:49,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:49,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:49,926 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:50,099 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:51,289 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3wlz9tai', purging
2023-05-28 07:26:51,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fcdsbhab', purging
2023-05-28 07:26:51,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:51,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:51,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:51,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:52,123 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:52,289 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:53,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nxdqlykj', purging
2023-05-28 07:26:53,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ncioqjg7', purging
2023-05-28 07:26:53,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:53,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:53,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:53,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:54,329 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:54,503 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:55,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l4sdppq6', purging
2023-05-28 07:26:55,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fgfxo630', purging
2023-05-28 07:26:55,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:55,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:55,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:55,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:56,598 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:56,768 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:57,946 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fgsj8ktp', purging
2023-05-28 07:26:57,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ksczt_za', purging
2023-05-28 07:26:57,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:57,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:26:58,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:26:58,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:26:58,782 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:26:58,950 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:00,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-grucbi3a', purging
2023-05-28 07:27:00,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z463m70u', purging
2023-05-28 07:27:00,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:00,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:00,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:00,317 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:01,015 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:01,177 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:02,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p1y19llh', purging
2023-05-28 07:27:02,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uff_4biw', purging
2023-05-28 07:27:02,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:02,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:02,514 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:02,514 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:03,218 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:03,382 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:04,593 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1if1vidq', purging
2023-05-28 07:27:04,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ilvc9_rg', purging
2023-05-28 07:27:04,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:04,594 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:04,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:04,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:05,429 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:05,596 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:06,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d80fo8sx', purging
2023-05-28 07:27:06,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f2ho7o_b', purging
2023-05-28 07:27:06,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:06,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:06,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:06,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:07,572 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:07,747 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:08,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-56uj9mzz', purging
2023-05-28 07:27:08,918 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whl6upoe', purging
2023-05-28 07:27:08,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:08,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:09,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:09,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:09,760 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:09,931 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:11,120 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ts6c60i', purging
2023-05-28 07:27:11,120 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hjl_0vle', purging
2023-05-28 07:27:11,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:11,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:11,287 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:11,287 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:11,962 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:12,135 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:13,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hjpuruko', purging
2023-05-28 07:27:13,326 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_rw_a376', purging
2023-05-28 07:27:13,327 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:13,327 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:13,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:13,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:14,147 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:14,307 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:15,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1c1vem33', purging
2023-05-28 07:27:15,496 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dtr5t20l', purging
2023-05-28 07:27:15,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:15,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:15,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:15,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:16,331 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:16,499 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:17,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6okb8952', purging
2023-05-28 07:27:17,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hsrq4jdh', purging
2023-05-28 07:27:17,638 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:17,638 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:17,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:17,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:18,459 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:18,609 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:19,811 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5pblh8m', purging
2023-05-28 07:27:19,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-187v9hom', purging
2023-05-28 07:27:19,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:19,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:19,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:19,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:20,658 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:20,829 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:22,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z7grkh7j', purging
2023-05-28 07:27:22,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pst4tn99', purging
2023-05-28 07:27:22,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:22,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:22,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:22,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:22,829 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:22,990 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:24,178 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2yzeurd5', purging
2023-05-28 07:27:24,178 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tehm6bcl', purging
2023-05-28 07:27:24,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:24,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:24,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:24,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:25,071 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:25,246 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:26,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b9vea4p6', purging
2023-05-28 07:27:26,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d4xnlaaf', purging
2023-05-28 07:27:26,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:26,430 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:26,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:26,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:27,263 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:27,422 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:28,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oisaypu8', purging
2023-05-28 07:27:28,583 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-355d1uq1', purging
2023-05-28 07:27:28,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:28,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:28,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:28,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:29,427 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:29,588 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:30,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3gcuvbg_', purging
2023-05-28 07:27:30,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qieprbrh', purging
2023-05-28 07:27:30,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:30,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:30,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:30,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:31,617 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:31,781 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:32,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4at8ad_7', purging
2023-05-28 07:27:32,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rh756mxl', purging
2023-05-28 07:27:32,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:32,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:33,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:33,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:33,797 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:33,969 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:35,156 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2zv8xeaj', purging
2023-05-28 07:27:35,157 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zimi5vay', purging
2023-05-28 07:27:35,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:35,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:35,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:35,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:35,991 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:36,167 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:37,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0fi4ij8n', purging
2023-05-28 07:27:37,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z7ssaex0', purging
2023-05-28 07:27:37,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:37,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:37,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:37,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:38,219 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:38,387 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:39,586 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vs2fj7bk', purging
2023-05-28 07:27:39,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mru08t0_', purging
2023-05-28 07:27:39,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:39,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:39,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:39,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:40,413 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:40,581 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:41,767 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yc82g8ms', purging
2023-05-28 07:27:41,767 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wl6dh4zi', purging
2023-05-28 07:27:41,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:41,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:41,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:41,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:42,596 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:42,764 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:43,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y7cbxyzu', purging
2023-05-28 07:27:43,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qt_c6umm', purging
2023-05-28 07:27:43,953 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:43,953 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:44,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:44,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:44,784 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:44,946 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:46,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s_ulfp1q', purging
2023-05-28 07:27:46,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i40dd2l0', purging
2023-05-28 07:27:46,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:46,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:46,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:46,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:46,977 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:47,127 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:48,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i35rt5m2', purging
2023-05-28 07:27:48,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-az0ro6e5', purging
2023-05-28 07:27:48,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:48,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:48,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:48,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:49,167 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:49,340 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:50,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7a2q6j66', purging
2023-05-28 07:27:50,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-htpvrl6t', purging
2023-05-28 07:27:50,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:50,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:50,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:50,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:51,324 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:51,498 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:52,668 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eqbbu86v', purging
2023-05-28 07:27:52,668 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fq_uwndy', purging
2023-05-28 07:27:52,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:52,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:52,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:52,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:53,495 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:53,675 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:54,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wo2q2051', purging
2023-05-28 07:27:54,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5xaape89', purging
2023-05-28 07:27:54,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:54,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:55,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:55,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:55,696 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:55,865 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:57,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xlc6qeht', purging
2023-05-28 07:27:57,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9rv2b9ow', purging
2023-05-28 07:27:57,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:57,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:57,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:57,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:27:57,889 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:58,062 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:27:59,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rzauhahy', purging
2023-05-28 07:27:59,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-77k7kn0v', purging
2023-05-28 07:27:59,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:59,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:27:59,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:27:59,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:00,065 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:00,224 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:01,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-48yhhh7n', purging
2023-05-28 07:28:01,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_qs43swd', purging
2023-05-28 07:28:01,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:01,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:01,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:01,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:02,250 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:02,431 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:03,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cwxzrsw', purging
2023-05-28 07:28:03,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ppme8c_f', purging
2023-05-28 07:28:03,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:03,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:03,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:03,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:04,454 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:04,626 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:05,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mkfr2g8_', purging
2023-05-28 07:28:05,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cok6vxkm', purging
2023-05-28 07:28:05,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:05,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:05,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:05,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:06,665 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:06,840 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:08,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3l9g70rt', purging
2023-05-28 07:28:08,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9i65px68', purging
2023-05-28 07:28:08,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:08,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:08,265 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:08,265 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:08,937 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:09,104 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:10,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wtbpvmd4', purging
2023-05-28 07:28:10,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6o97fu7f', purging
2023-05-28 07:28:10,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:10,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:10,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:10,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:11,576 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:11,942 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:12,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_62gyg_', purging
2023-05-28 07:28:12,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-46neuqnf', purging
2023-05-28 07:28:12,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:12,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:13,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:13,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:13,721 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:14,013 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:15,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-enq8j3bp', purging
2023-05-28 07:28:15,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-26pbk6ta', purging
2023-05-28 07:28:15,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:15,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:15,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:15,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:15,919 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:16,103 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:17,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ohajdo6f', purging
2023-05-28 07:28:17,273 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zhg19db6', purging
2023-05-28 07:28:17,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:17,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:17,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:17,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:18,111 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:18,289 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:19,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dylrzttx', purging
2023-05-28 07:28:19,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mpnzdu7d', purging
2023-05-28 07:28:19,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:19,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:19,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:19,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:20,318 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:20,473 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:21,655 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vymu7oz9', purging
2023-05-28 07:28:21,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvon550j', purging
2023-05-28 07:28:21,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:21,656 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:21,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:21,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:22,474 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:22,659 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:23,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e80osorb', purging
2023-05-28 07:28:23,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wip9g_cz', purging
2023-05-28 07:28:23,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:23,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:23,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:23,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:24,674 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:24,833 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:26,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ea9xzz4s', purging
2023-05-28 07:28:26,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-okancohe', purging
2023-05-28 07:28:26,032 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:26,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:26,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:26,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:26,858 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:27,022 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:28,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pasz_0wv', purging
2023-05-28 07:28:28,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h0dj2kcg', purging
2023-05-28 07:28:28,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:28,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:28,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:28,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:29,073 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:29,234 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:30,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03jfak79', purging
2023-05-28 07:28:30,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jy5a9luh', purging
2023-05-28 07:28:30,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:30,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:30,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:30,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:31,248 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:31,423 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:32,628 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yh1c18n0', purging
2023-05-28 07:28:32,628 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-075hwt_j', purging
2023-05-28 07:28:32,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:32,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:32,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:32,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:33,497 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:33,670 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:34,845 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vdny5qzn', purging
2023-05-28 07:28:34,845 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-66se66yn', purging
2023-05-28 07:28:34,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:34,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:35,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:35,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:35,688 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:35,867 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:37,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xw60bqvc', purging
2023-05-28 07:28:37,036 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nfnltdwm', purging
2023-05-28 07:28:37,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:37,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:37,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:37,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:37,869 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:38,030 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:39,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-834mgrbt', purging
2023-05-28 07:28:39,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_bra9lo3', purging
2023-05-28 07:28:39,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:39,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:39,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:39,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:40,113 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:40,281 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:41,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xkirmp2_', purging
2023-05-28 07:28:41,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dhjvu694', purging
2023-05-28 07:28:41,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:41,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:41,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:41,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:42,305 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:42,470 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:43,652 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7x0onke5', purging
2023-05-28 07:28:43,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u8las6e5', purging
2023-05-28 07:28:43,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:43,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:43,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:43,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:44,493 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:44,668 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:45,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aelf3z6t', purging
2023-05-28 07:28:45,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6p5qeyi8', purging
2023-05-28 07:28:45,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:45,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:46,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:46,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:46,643 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:46,819 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:47,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6n8e5wtw', purging
2023-05-28 07:28:47,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dfpkp0c5', purging
2023-05-28 07:28:47,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:47,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:48,154 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:48,154 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:48,835 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:49,001 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:50,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ttkioty6', purging
2023-05-28 07:28:50,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jmvvcun3', purging
2023-05-28 07:28:50,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:50,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:50,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:50,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:51,015 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:51,188 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:52,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0qwfzbd_', purging
2023-05-28 07:28:52,358 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7hep4aim', purging
2023-05-28 07:28:52,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:52,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:52,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:52,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:53,223 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:53,383 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:54,599 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s9k73cof', purging
2023-05-28 07:28:54,599 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pa6l4ck4', purging
2023-05-28 07:28:54,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:54,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:54,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:54,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:55,453 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:55,624 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:56,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7bnt8ya7', purging
2023-05-28 07:28:56,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_skwfgx', purging
2023-05-28 07:28:56,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:56,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:56,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:56,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:57,606 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:57,772 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:58,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7h7pwwa5', purging
2023-05-28 07:28:58,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-do8htu11', purging
2023-05-28 07:28:58,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:58,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:28:59,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:28:59,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:28:59,834 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:28:59,997 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:01,203 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gqa8vap0', purging
2023-05-28 07:29:01,204 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4qa2fy5k', purging
2023-05-28 07:29:01,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:01,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:01,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:01,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:02,041 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:02,212 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:03,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-erowytrb', purging
2023-05-28 07:29:03,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_2zxvm0a', purging
2023-05-28 07:29:03,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:03,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:03,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:03,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:04,233 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:04,392 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:05,616 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x3h4zg99', purging
2023-05-28 07:29:05,616 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7bg7r951', purging
2023-05-28 07:29:05,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:05,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:05,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:05,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:06,465 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:06,629 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:07,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b4uxbvbl', purging
2023-05-28 07:29:07,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ffhtp_pb', purging
2023-05-28 07:29:07,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:07,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:08,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:08,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:08,679 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:08,840 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:10,015 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pndor8gp', purging
2023-05-28 07:29:10,015 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8tvakn35', purging
2023-05-28 07:29:10,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:10,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:10,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:10,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:10,879 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:11,051 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:12,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qpgiu_qf', purging
2023-05-28 07:29:12,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1jelgnau', purging
2023-05-28 07:29:12,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:12,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:12,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:12,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:13,074 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:13,304 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:14,457 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uqwd8cbv', purging
2023-05-28 07:29:14,457 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3z71jfib', purging
2023-05-28 07:29:14,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:14,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:14,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:14,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:15,282 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:15,455 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:16,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fao0_a4g', purging
2023-05-28 07:29:16,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ht_qrhc3', purging
2023-05-28 07:29:16,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:16,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:16,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:16,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:17,495 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:17,667 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:18,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rf3etrod', purging
2023-05-28 07:29:18,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2e73hcov', purging
2023-05-28 07:29:18,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:18,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:19,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:19,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:19,715 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:19,880 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:21,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yzlv8pui', purging
2023-05-28 07:29:21,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-blgentg9', purging
2023-05-28 07:29:21,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:21,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:21,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:21,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:21,933 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:22,091 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:23,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4je6h2ep', purging
2023-05-28 07:29:23,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vo4n50_2', purging
2023-05-28 07:29:23,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:23,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:23,437 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:23,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:24,154 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:24,328 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:25,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yhu9fnqb', purging
2023-05-28 07:29:25,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7y__nuax', purging
2023-05-28 07:29:25,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:25,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:25,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:25,712 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:26,410 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:26,569 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:27,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cq6i8pdd', purging
2023-05-28 07:29:27,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0ziwz40', purging
2023-05-28 07:29:27,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:27,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:27,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:27,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:28,657 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:28,826 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:30,014 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x974k_93', purging
2023-05-28 07:29:30,015 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lrg2bgdu', purging
2023-05-28 07:29:30,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:30,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:30,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:30,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:30,853 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:31,013 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:32,218 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03kh9ay2', purging
2023-05-28 07:29:32,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jry_ctmx', purging
2023-05-28 07:29:32,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:32,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:32,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:32,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:33,076 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:33,243 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:34,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p454uea0', purging
2023-05-28 07:29:34,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-seznapob', purging
2023-05-28 07:29:34,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:34,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:34,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:34,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:35,297 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:35,489 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:36,654 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-46mnh5ui', purging
2023-05-28 07:29:36,655 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bsb021kn', purging
2023-05-28 07:29:36,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:36,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:36,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:36,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:37,487 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:37,649 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:38,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hw4fsbei', purging
2023-05-28 07:29:38,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ct85q13', purging
2023-05-28 07:29:38,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:38,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:39,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:39,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:39,708 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:39,869 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:41,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_vmki52', purging
2023-05-28 07:29:41,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5dish_y2', purging
2023-05-28 07:29:41,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:41,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:41,247 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:41,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:41,962 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:42,128 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:43,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-su33mbsb', purging
2023-05-28 07:29:43,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qwjyqsyl', purging
2023-05-28 07:29:43,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:43,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:43,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:43,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:44,239 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:44,416 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:45,641 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9atra0p4', purging
2023-05-28 07:29:45,641 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z93txp8f', purging
2023-05-28 07:29:45,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:45,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:45,810 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:45,810 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:46,498 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:46,663 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:47,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ip1pfiwj', purging
2023-05-28 07:29:47,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_1pgtm33', purging
2023-05-28 07:29:47,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:47,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:48,042 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:48,042 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:48,706 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:48,877 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:50,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fbyqwp7o', purging
2023-05-28 07:29:50,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-atz2ytoq', purging
2023-05-28 07:29:50,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:50,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:50,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:50,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:50,918 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:51,082 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:52,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u2jnkaor', purging
2023-05-28 07:29:52,280 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r_wob8id', purging
2023-05-28 07:29:52,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:52,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:52,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:52,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:53,128 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:53,288 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:54,486 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v4x22ic9', purging
2023-05-28 07:29:54,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r856xbg6', purging
2023-05-28 07:29:54,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:54,487 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:54,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:54,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:55,334 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:55,529 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:56,724 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0by4frn', purging
2023-05-28 07:29:56,725 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4tvmxrv8', purging
2023-05-28 07:29:56,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:56,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:56,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:56,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:57,562 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:57,729 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:58,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1ta_6xa', purging
2023-05-28 07:29:58,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nyw0fsyn', purging
2023-05-28 07:29:58,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:58,918 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:29:59,070 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:29:59,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:29:59,754 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:29:59,919 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:01,119 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9oknbqex', purging
2023-05-28 07:30:01,119 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3m_wfylu', purging
2023-05-28 07:30:01,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:01,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:01,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:01,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:01,978 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:02,156 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:03,346 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-og7bxgn9', purging
2023-05-28 07:30:03,346 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oa0_6q7t', purging
2023-05-28 07:30:03,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:03,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:03,541 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:03,541 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:04,202 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:04,385 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:05,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3bkm7flj', purging
2023-05-28 07:30:05,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tnj6a25f', purging
2023-05-28 07:30:05,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:05,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:05,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:05,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:06,421 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:06,580 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:07,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8la2k1vr', purging
2023-05-28 07:30:07,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8offj8he', purging
2023-05-28 07:30:07,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:07,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:07,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:07,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:08,628 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:08,786 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:09,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j951v46k', purging
2023-05-28 07:30:09,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3p3vszcz', purging
2023-05-28 07:30:09,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:09,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:10,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:10,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:10,839 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:11,007 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:12,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o6_gpurj', purging
2023-05-28 07:30:12,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g0fbnj61', purging
2023-05-28 07:30:12,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:12,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:12,379 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:12,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:13,056 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:13,229 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:14,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tx6piypx', purging
2023-05-28 07:30:14,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bm17g74l', purging
2023-05-28 07:30:14,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:14,438 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:14,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:14,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:15,300 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:15,466 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:16,699 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rkbz456g', purging
2023-05-28 07:30:16,699 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nd0fhd7s', purging
2023-05-28 07:30:16,700 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:16,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:16,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:16,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:17,562 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:17,716 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:18,936 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ykprfii', purging
2023-05-28 07:30:18,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sjoy_vqi', purging
2023-05-28 07:30:18,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:18,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:19,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:19,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:19,780 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:19,945 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:21,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgdb51ep', purging
2023-05-28 07:30:21,139 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ovty4zki', purging
2023-05-28 07:30:21,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:21,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:21,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:21,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:21,982 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:22,148 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:23,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q2yjxgak', purging
2023-05-28 07:30:23,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8dt9rk21', purging
2023-05-28 07:30:23,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:23,374 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:23,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:23,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:24,213 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:24,388 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:25,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58bjyuft', purging
2023-05-28 07:30:25,580 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-969h4wwx', purging
2023-05-28 07:30:25,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:25,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:25,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:25,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:26,456 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:26,619 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:27,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g71leumr', purging
2023-05-28 07:30:27,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4yxqgwny', purging
2023-05-28 07:30:27,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:27,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:27,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:27,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:28,698 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:28,880 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:30,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-odk0u7eh', purging
2023-05-28 07:30:30,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d734qw1g', purging
2023-05-28 07:30:30,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:30,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:30,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:30,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:30,897 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:31,057 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:32,260 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ic8shgw', purging
2023-05-28 07:30:32,261 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6_i14ih_', purging
2023-05-28 07:30:32,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:32,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:32,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:32,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:33,112 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:33,289 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:34,476 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mu67s199', purging
2023-05-28 07:30:34,477 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1yo3j0yj', purging
2023-05-28 07:30:34,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:34,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:34,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:34,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:35,305 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:35,467 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:36,667 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qpjyn3zh', purging
2023-05-28 07:30:36,668 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a465d28r', purging
2023-05-28 07:30:36,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:36,668 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:36,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:36,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:37,499 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:37,669 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:38,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gbxiegar', purging
2023-05-28 07:30:38,848 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wfwwpni3', purging
2023-05-28 07:30:38,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:38,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:39,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:39,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:39,693 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:39,848 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:41,056 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-axs63hyb', purging
2023-05-28 07:30:41,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fz9wylxu', purging
2023-05-28 07:30:41,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:41,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:41,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:41,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:41,908 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:42,076 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:43,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ml_d8x85', purging
2023-05-28 07:30:43,286 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iw_z17w2', purging
2023-05-28 07:30:43,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:43,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:43,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:43,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:44,131 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:44,304 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:45,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wlxiawmb', purging
2023-05-28 07:30:45,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o4y_80kh', purging
2023-05-28 07:30:45,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:45,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:45,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:45,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:46,335 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:46,508 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:47,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lc9hvekz', purging
2023-05-28 07:30:47,717 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-efrv4vxr', purging
2023-05-28 07:30:47,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:47,718 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:47,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:47,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:48,591 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:48,757 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:49,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ms9di2hk', purging
2023-05-28 07:30:49,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sbhz3caw', purging
2023-05-28 07:30:49,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:49,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:50,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:50,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:50,828 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:51,005 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:52,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-driv9a5t', purging
2023-05-28 07:30:52,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dswt5wmm', purging
2023-05-28 07:30:52,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:52,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:52,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:52,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:53,033 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:53,208 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:54,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cbvh3_g', purging
2023-05-28 07:30:54,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pgz6fi_o', purging
2023-05-28 07:30:54,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:54,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:54,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:54,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:55,302 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:55,475 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:56,700 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2qqi79b9', purging
2023-05-28 07:30:56,701 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wyr4sbmw', purging
2023-05-28 07:30:56,701 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:56,701 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:56,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:56,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:57,537 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:57,709 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:58,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uwccjiai', purging
2023-05-28 07:30:58,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_nsybu0s', purging
2023-05-28 07:30:58,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:58,918 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:30:59,068 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:30:59,068 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:30:59,784 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:30:59,956 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:01,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vc3j8sc5', purging
2023-05-28 07:31:01,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-41w38cnt', purging
2023-05-28 07:31:01,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:01,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:01,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:01,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:01,999 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:02,170 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:03,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vz1uv0l7', purging
2023-05-28 07:31:03,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q0yxg3pa', purging
2023-05-28 07:31:03,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:03,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:03,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:03,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:04,206 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:04,368 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:05,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qrzckwmm', purging
2023-05-28 07:31:05,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ge6wo221', purging
2023-05-28 07:31:05,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:05,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:31:05,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:05,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:06,393 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:31:07,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-40fifvp7', purging
2023-05-28 07:31:07,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fvcbtu4c', purging
2023-05-28 07:31:07,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:07,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:08,507 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:09,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0wxyeonh', purging
2023-05-28 07:31:09,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:09,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:10,584 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:11,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cbkmnixu', purging
2023-05-28 07:31:11,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:11,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:12,667 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:14,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-urxgi0e7', purging
2023-05-28 07:31:14,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:14,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:14,773 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:16,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-py4lkwkf', purging
2023-05-28 07:31:16,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:16,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:16,860 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:18,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hntlgf2n', purging
2023-05-28 07:31:18,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:18,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:18,987 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:20,406 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6fsgg0on', purging
2023-05-28 07:31:20,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:20,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:21,199 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:22,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v09gvorr', purging
2023-05-28 07:31:22,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:22,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:23,258 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:24,591 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sfnnzrye', purging
2023-05-28 07:31:24,591 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:24,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:25,375 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:26,719 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hvz8w_yn', purging
2023-05-28 07:31:26,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:26,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:27,483 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:31:28,792 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jd6n8nw_', purging
2023-05-28 07:31:28,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:31:28,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:31:29,562 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 837 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
