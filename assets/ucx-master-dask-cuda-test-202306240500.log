============================= test session starts ==============================
platform linux -- Python 3.9.16, pytest-7.3.2, pluggy-1.0.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-06-24 05:43:52,379 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:43:52,383 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:43:52,387 - distributed.scheduler - INFO - State start
2023-06-24 05:43:52,410 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:43:52,411 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-06-24 05:43:52,412 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:43:52,622 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38431'
2023-06-24 05:43:52,645 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34095'
2023-06-24 05:43:52,648 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39715'
2023-06-24 05:43:52,658 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34919'
2023-06-24 05:43:54,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:43:54,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:43:54,431 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:43:54,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:43:54,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:43:54,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:43:54,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:43:54,464 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:43:54,464 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:43:54,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:43:54,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:43:54,478 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-06-24 05:43:54,481 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41501
2023-06-24 05:43:54,481 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41501
2023-06-24 05:43:54,481 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40169
2023-06-24 05:43:54,481 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-06-24 05:43:54,482 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:54,482 - distributed.worker - INFO -               Threads:                          4
2023-06-24 05:43:54,482 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-06-24 05:43:54,482 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-c47avq1u
2023-06-24 05:43:54,482 - distributed.worker - INFO - Starting Worker plugin RMMSetup-35475f8f-da1e-461d-a8a6-df12706dd94c
2023-06-24 05:43:54,483 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7182ee2b-8776-491f-aace-54e3bb12a8d4
2023-06-24 05:43:54,483 - distributed.worker - INFO - Starting Worker plugin PreImport-9b5e4b00-c2e0-4437-8bdc-5dc16d82651c
2023-06-24 05:43:54,484 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:54,504 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41501', status: init, memory: 0, processing: 0>
2023-06-24 05:43:54,521 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41501
2023-06-24 05:43:54,521 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38444
2023-06-24 05:43:54,522 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-06-24 05:43:54,522 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:54,524 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-06-24 05:43:54,687 - distributed.scheduler - INFO - Receive client connection: Client-18b5c2a6-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:43:54,688 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38452
2023-06-24 05:43:55,731 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33387
2023-06-24 05:43:55,731 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33387
2023-06-24 05:43:55,732 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37977
2023-06-24 05:43:55,732 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-06-24 05:43:55,732 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:55,732 - distributed.worker - INFO -               Threads:                          4
2023-06-24 05:43:55,732 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-06-24 05:43:55,732 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-q65wdg27
2023-06-24 05:43:55,734 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a2df55fa-a9f5-458f-96c7-8d6e7f2be3d8
2023-06-24 05:43:55,734 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff4fd029-e159-49f9-a877-d6516f473523
2023-06-24 05:43:55,734 - distributed.worker - INFO - Starting Worker plugin PreImport-31d902e7-57ed-4563-b39f-5bd214cc4a05
2023-06-24 05:43:55,734 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:55,763 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33387', status: init, memory: 0, processing: 0>
2023-06-24 05:43:55,764 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33387
2023-06-24 05:43:55,764 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38480
2023-06-24 05:43:55,764 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-06-24 05:43:55,765 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:55,767 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-06-24 05:43:55,812 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39413
2023-06-24 05:43:55,812 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39413
2023-06-24 05:43:55,813 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43299
2023-06-24 05:43:55,813 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-06-24 05:43:55,813 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:55,813 - distributed.worker - INFO -               Threads:                          4
2023-06-24 05:43:55,813 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-06-24 05:43:55,813 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4hfw18y1
2023-06-24 05:43:55,813 - distributed.worker - INFO - Starting Worker plugin PreImport-846b098c-d8c8-47a8-be90-4ad45fcc537a
2023-06-24 05:43:55,813 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bff76835-c6f0-4e99-88a1-2788109591c7
2023-06-24 05:43:55,813 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1925cd54-86e2-4a4e-9751-fc96261827aa
2023-06-24 05:43:55,814 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:55,828 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35931
2023-06-24 05:43:55,829 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35931
2023-06-24 05:43:55,829 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45451
2023-06-24 05:43:55,829 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-06-24 05:43:55,829 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:55,829 - distributed.worker - INFO -               Threads:                          4
2023-06-24 05:43:55,829 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-06-24 05:43:55,829 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-r800i2ot
2023-06-24 05:43:55,829 - distributed.worker - INFO - Starting Worker plugin RMMSetup-217a8d55-37a6-4618-832f-4a2255bdfb69
2023-06-24 05:43:55,830 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-212f86de-4996-457c-8259-74284e82dc82
2023-06-24 05:43:55,830 - distributed.worker - INFO - Starting Worker plugin PreImport-050788c4-e596-4e87-af99-71d09ee572a0
2023-06-24 05:43:55,830 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:55,839 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39413', status: init, memory: 0, processing: 0>
2023-06-24 05:43:55,839 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39413
2023-06-24 05:43:55,839 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38488
2023-06-24 05:43:55,840 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-06-24 05:43:55,840 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:55,842 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-06-24 05:43:55,852 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35931', status: init, memory: 0, processing: 0>
2023-06-24 05:43:55,853 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35931
2023-06-24 05:43:55,853 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38496
2023-06-24 05:43:55,854 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-06-24 05:43:55,854 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:43:55,857 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-06-24 05:43:55,925 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-06-24 05:43:55,925 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-06-24 05:43:55,925 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-06-24 05:43:55,925 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-06-24 05:43:55,930 - distributed.scheduler - INFO - Remove client Client-18b5c2a6-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:43:55,931 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38452; closing.
2023-06-24 05:43:55,931 - distributed.scheduler - INFO - Remove client Client-18b5c2a6-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:43:55,931 - distributed.scheduler - INFO - Close client connection: Client-18b5c2a6-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:43:55,932 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38431'. Reason: nanny-close
2023-06-24 05:43:55,933 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:43:55,933 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34095'. Reason: nanny-close
2023-06-24 05:43:55,934 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:43:55,934 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39715'. Reason: nanny-close
2023-06-24 05:43:55,934 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33387. Reason: nanny-close
2023-06-24 05:43:55,934 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:43:55,935 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34919'. Reason: nanny-close
2023-06-24 05:43:55,935 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35931. Reason: nanny-close
2023-06-24 05:43:55,935 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:43:55,935 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39413. Reason: nanny-close
2023-06-24 05:43:55,936 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38480; closing.
2023-06-24 05:43:55,936 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-06-24 05:43:55,936 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41501. Reason: nanny-close
2023-06-24 05:43:55,936 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33387', status: closing, memory: 0, processing: 0>
2023-06-24 05:43:55,936 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33387
2023-06-24 05:43:55,937 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-06-24 05:43:55,937 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-06-24 05:43:55,937 - distributed.nanny - INFO - Worker closed
2023-06-24 05:43:55,938 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38496; closing.
2023-06-24 05:43:55,938 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38488; closing.
2023-06-24 05:43:55,938 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33387
2023-06-24 05:43:55,938 - distributed.nanny - INFO - Worker closed
2023-06-24 05:43:55,938 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-06-24 05:43:55,938 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35931', status: closing, memory: 0, processing: 0>
2023-06-24 05:43:55,938 - distributed.nanny - INFO - Worker closed
2023-06-24 05:43:55,938 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35931
2023-06-24 05:43:55,939 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39413', status: closing, memory: 0, processing: 0>
2023-06-24 05:43:55,939 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39413
2023-06-24 05:43:55,939 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38444; closing.
2023-06-24 05:43:55,940 - distributed.nanny - INFO - Worker closed
2023-06-24 05:43:55,940 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41501', status: closing, memory: 0, processing: 0>
2023-06-24 05:43:55,940 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41501
2023-06-24 05:43:55,940 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:43:57,150 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:43:57,151 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:43:57,151 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:43:57,152 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-06-24 05:43:57,153 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-06-24 05:43:59,327 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:43:59,331 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:43:59,335 - distributed.scheduler - INFO - State start
2023-06-24 05:43:59,356 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:43:59,357 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:43:59,357 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:43:59,609 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36407'
2023-06-24 05:43:59,626 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37783'
2023-06-24 05:43:59,655 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35119'
2023-06-24 05:43:59,658 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44591'
2023-06-24 05:43:59,675 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42753'
2023-06-24 05:43:59,693 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35489'
2023-06-24 05:43:59,714 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36899'
2023-06-24 05:43:59,727 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37245'
2023-06-24 05:44:00,642 - distributed.scheduler - INFO - Receive client connection: Client-1ce61ea5-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:00,655 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46426
2023-06-24 05:44:01,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:01,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:01,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:01,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:01,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:01,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:01,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:01,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:01,413 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:01,413 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:01,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:01,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:01,434 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:01,445 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:01,462 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:01,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:01,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:01,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:01,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:01,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:01,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:01,557 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:01,559 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:01,561 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:04,363 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42091
2023-06-24 05:44:04,364 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42091
2023-06-24 05:44:04,364 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46505
2023-06-24 05:44:04,364 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,364 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,364 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:04,364 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:04,364 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-oq8z1k3j
2023-06-24 05:44:04,365 - distributed.worker - INFO - Starting Worker plugin PreImport-a6e64a22-9470-4c1d-81d8-d2b707a609e3
2023-06-24 05:44:04,365 - distributed.worker - INFO - Starting Worker plugin RMMSetup-49e09c4d-090b-4ddb-b7e5-206642559c24
2023-06-24 05:44:04,368 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38247
2023-06-24 05:44:04,368 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38247
2023-06-24 05:44:04,368 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35817
2023-06-24 05:44:04,368 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,368 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,368 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:04,368 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:04,369 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o1fwdh2w
2023-06-24 05:44:04,369 - distributed.worker - INFO - Starting Worker plugin PreImport-6e798cdd-e93d-40f1-af19-d8daf7d12f2e
2023-06-24 05:44:04,369 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5152099e-30fa-4da8-b69c-27d6210e0bec
2023-06-24 05:44:04,369 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38325
2023-06-24 05:44:04,369 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38325
2023-06-24 05:44:04,369 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b9a71abd-feac-4c6c-b991-542dadae607b
2023-06-24 05:44:04,369 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38329
2023-06-24 05:44:04,370 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,370 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,370 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:04,370 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:04,370 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zlkgp9km
2023-06-24 05:44:04,370 - distributed.worker - INFO - Starting Worker plugin PreImport-f8ce45b7-184b-4920-bbaa-8d05e580080b
2023-06-24 05:44:04,371 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-654771c0-839f-44bc-9532-746c45ddbc58
2023-06-24 05:44:04,371 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b17d9a4f-6be3-470b-856a-231e92bdb41e
2023-06-24 05:44:04,385 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37329
2023-06-24 05:44:04,385 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37329
2023-06-24 05:44:04,385 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37523
2023-06-24 05:44:04,385 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,385 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,385 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:04,385 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:04,385 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-35_xdceh
2023-06-24 05:44:04,386 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d5785fc7-029f-4af8-b9e0-0c574b257ed1
2023-06-24 05:44:04,386 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2c32614e-3e09-436e-a664-e4b45d8ee7fc
2023-06-24 05:44:04,399 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35721
2023-06-24 05:44:04,399 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35721
2023-06-24 05:44:04,399 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42287
2023-06-24 05:44:04,399 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,399 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,399 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:04,399 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:04,399 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ik0m93fa
2023-06-24 05:44:04,400 - distributed.worker - INFO - Starting Worker plugin PreImport-e70dab2a-8b3d-454f-846a-9329bfd801cf
2023-06-24 05:44:04,400 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6d791649-808f-456a-bed6-fb36a06062f1
2023-06-24 05:44:04,475 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46483
2023-06-24 05:44:04,476 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46483
2023-06-24 05:44:04,476 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46065
2023-06-24 05:44:04,476 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,476 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,476 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:04,476 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:04,476 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-r_v_3tt4
2023-06-24 05:44:04,476 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-31265257-d4af-43bf-b40a-96148c623c0b
2023-06-24 05:44:04,476 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3b9ca772-6de4-4962-9e81-e27c4cda1fee
2023-06-24 05:44:04,477 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43147
2023-06-24 05:44:04,477 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43147
2023-06-24 05:44:04,478 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33531
2023-06-24 05:44:04,478 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,478 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,478 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:04,478 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:04,478 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jcrge1zd
2023-06-24 05:44:04,478 - distributed.worker - INFO - Starting Worker plugin PreImport-e4f811e1-bce1-42d7-8e93-f353771ae8e2
2023-06-24 05:44:04,478 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b83a5fd8-0e8e-4f40-a6d3-4a5fb60076d0
2023-06-24 05:44:04,483 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42623
2023-06-24 05:44:04,483 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42623
2023-06-24 05:44:04,483 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41633
2023-06-24 05:44:04,483 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,483 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,483 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:04,483 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:04,483 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o33grxu_
2023-06-24 05:44:04,484 - distributed.worker - INFO - Starting Worker plugin PreImport-fc8098d1-ff1a-40d5-a501-81e09c30672b
2023-06-24 05:44:04,484 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7d1e51d7-672e-4aa2-ada5-8ceefca789e7
2023-06-24 05:44:04,600 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4da53375-2076-43fe-96db-4abafe529121
2023-06-24 05:44:04,601 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,623 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,623 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,623 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5cf99ee4-59d5-4ae2-822d-18a6a0407cb4
2023-06-24 05:44:04,623 - distributed.worker - INFO - Starting Worker plugin PreImport-97c5a4a9-f6ff-463c-97c4-a5d05c37497a
2023-06-24 05:44:04,623 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,623 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,623 - distributed.worker - INFO - Starting Worker plugin PreImport-75b464ed-fa47-437f-a292-df7d8b6eae73
2023-06-24 05:44:04,623 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9b1668bc-0e7a-4262-95be-cbbec0e11f37
2023-06-24 05:44:04,623 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3dc2690f-0846-4a65-9f63-24e42f920296
2023-06-24 05:44:04,624 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,624 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,624 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,633 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42091', status: init, memory: 0, processing: 0>
2023-06-24 05:44:04,634 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42091
2023-06-24 05:44:04,634 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46450
2023-06-24 05:44:04,635 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,635 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,638 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:04,651 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46483', status: init, memory: 0, processing: 0>
2023-06-24 05:44:04,652 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46483
2023-06-24 05:44:04,652 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46494
2023-06-24 05:44:04,652 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,653 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,653 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35721', status: init, memory: 0, processing: 0>
2023-06-24 05:44:04,653 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35721
2023-06-24 05:44:04,653 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46468
2023-06-24 05:44:04,654 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,654 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42623', status: init, memory: 0, processing: 0>
2023-06-24 05:44:04,654 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,655 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42623
2023-06-24 05:44:04,655 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:04,655 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46492
2023-06-24 05:44:04,655 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,655 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,656 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43147', status: init, memory: 0, processing: 0>
2023-06-24 05:44:04,656 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43147
2023-06-24 05:44:04,656 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:04,656 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46502
2023-06-24 05:44:04,656 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,657 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38325', status: init, memory: 0, processing: 0>
2023-06-24 05:44:04,657 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,657 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:04,657 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38325
2023-06-24 05:44:04,657 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46462
2023-06-24 05:44:04,658 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,658 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,659 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:04,660 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:04,666 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37329', status: init, memory: 0, processing: 0>
2023-06-24 05:44:04,667 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37329
2023-06-24 05:44:04,667 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46514
2023-06-24 05:44:04,667 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,667 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,667 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38247', status: init, memory: 0, processing: 0>
2023-06-24 05:44:04,668 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38247
2023-06-24 05:44:04,668 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46476
2023-06-24 05:44:04,668 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:04,669 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:04,670 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:04,671 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:04,733 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:04,734 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:04,734 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:04,734 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:04,734 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:04,734 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:04,734 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:04,734 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:04,738 - distributed.scheduler - INFO - Remove client Client-1ce61ea5-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:04,739 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46426; closing.
2023-06-24 05:44:04,739 - distributed.scheduler - INFO - Remove client Client-1ce61ea5-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:04,739 - distributed.scheduler - INFO - Close client connection: Client-1ce61ea5-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:04,740 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44591'. Reason: nanny-close
2023-06-24 05:44:04,741 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:04,742 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42753'. Reason: nanny-close
2023-06-24 05:44:04,742 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:04,743 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37329. Reason: nanny-close
2023-06-24 05:44:04,743 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36407'. Reason: nanny-close
2023-06-24 05:44:04,743 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:04,743 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37783'. Reason: nanny-close
2023-06-24 05:44:04,743 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42091. Reason: nanny-close
2023-06-24 05:44:04,744 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:04,744 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43147. Reason: nanny-close
2023-06-24 05:44:04,744 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35119'. Reason: nanny-close
2023-06-24 05:44:04,744 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:04,744 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35721. Reason: nanny-close
2023-06-24 05:44:04,744 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35489'. Reason: nanny-close
2023-06-24 05:44:04,745 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46514; closing.
2023-06-24 05:44:04,745 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:04,745 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:04,745 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37329', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:04,745 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36899'. Reason: nanny-close
2023-06-24 05:44:04,745 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37329
2023-06-24 05:44:04,745 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38247. Reason: nanny-close
2023-06-24 05:44:04,745 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:04,745 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:04,745 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:04,746 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37245'. Reason: nanny-close
2023-06-24 05:44:04,746 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38325. Reason: nanny-close
2023-06-24 05:44:04,746 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:04,746 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:04,746 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46483. Reason: nanny-close
2023-06-24 05:44:04,746 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:04,747 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:04,747 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46450; closing.
2023-06-24 05:44:04,747 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:04,747 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37329
2023-06-24 05:44:04,747 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46502; closing.
2023-06-24 05:44:04,747 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:04,747 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37329
2023-06-24 05:44:04,747 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37329
2023-06-24 05:44:04,747 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42623. Reason: nanny-close
2023-06-24 05:44:04,747 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37329
2023-06-24 05:44:04,747 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42091', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:04,748 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42091
2023-06-24 05:44:04,748 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:04,748 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:04,748 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43147', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:04,748 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43147
2023-06-24 05:44:04,748 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:04,748 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46468; closing.
2023-06-24 05:44:04,749 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35721', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:04,749 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35721
2023-06-24 05:44:04,749 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:04,749 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:04,749 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:04,749 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46476; closing.
2023-06-24 05:44:04,749 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:04,750 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38247', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:04,750 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38247
2023-06-24 05:44:04,750 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46462; closing.
2023-06-24 05:44:04,750 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:04,750 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46494; closing.
2023-06-24 05:44:04,751 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38325', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:04,751 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38325
2023-06-24 05:44:04,751 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46483', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:04,751 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46483
2023-06-24 05:44:04,751 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46492; closing.
2023-06-24 05:44:04,752 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42623', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:04,752 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42623
2023-06-24 05:44:04,752 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:44:06,158 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:44:06,159 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:44:06,159 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:44:06,160 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:44:06,161 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-06-24 05:44:08,283 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:08,287 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:44:08,291 - distributed.scheduler - INFO - State start
2023-06-24 05:44:08,311 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:08,312 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:44:08,312 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:44:08,588 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33427'
2023-06-24 05:44:08,607 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44061'
2023-06-24 05:44:08,618 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32891'
2023-06-24 05:44:08,621 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39687'
2023-06-24 05:44:08,631 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37169'
2023-06-24 05:44:08,640 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44067'
2023-06-24 05:44:08,656 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41347'
2023-06-24 05:44:08,669 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44699'
2023-06-24 05:44:09,229 - distributed.scheduler - INFO - Receive client connection: Client-223cf6ca-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:09,240 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46660
2023-06-24 05:44:10,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:10,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:10,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:10,380 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:10,383 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:10,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:10,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:10,411 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:10,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:10,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:10,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:10,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:10,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:10,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:10,455 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:10,457 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:10,472 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:10,477 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:10,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:10,509 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:10,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:10,529 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:10,564 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:10,587 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:13,549 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40693
2023-06-24 05:44:13,549 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40693
2023-06-24 05:44:13,549 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33471
2023-06-24 05:44:13,550 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,550 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,550 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:13,550 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:13,550 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-oufmas34
2023-06-24 05:44:13,551 - distributed.worker - INFO - Starting Worker plugin PreImport-da0de78b-f66c-4037-b0a0-96debdc4b1a9
2023-06-24 05:44:13,551 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1c89a0cc-33bc-46d0-b16c-58ea5ec117e9
2023-06-24 05:44:13,553 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38053
2023-06-24 05:44:13,554 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38053
2023-06-24 05:44:13,554 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34411
2023-06-24 05:44:13,554 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,554 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,554 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:13,554 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:13,554 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ncqn20qo
2023-06-24 05:44:13,554 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-24a651ab-d32c-44e6-9a78-27ef903a15ea
2023-06-24 05:44:13,555 - distributed.worker - INFO - Starting Worker plugin RMMSetup-274c4859-fefa-4760-bb60-bd875b5673e8
2023-06-24 05:44:13,717 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40149
2023-06-24 05:44:13,717 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40149
2023-06-24 05:44:13,717 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36355
2023-06-24 05:44:13,717 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36029
2023-06-24 05:44:13,717 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36355
2023-06-24 05:44:13,717 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,717 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40617
2023-06-24 05:44:13,717 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,717 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,717 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:13,717 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,718 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:13,718 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:13,718 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-c1oxfpuz
2023-06-24 05:44:13,718 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:13,718 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8hpq8wjr
2023-06-24 05:44:13,718 - distributed.worker - INFO - Starting Worker plugin PreImport-df319ce3-398d-4de3-be3a-ed1e4fffeb3a
2023-06-24 05:44:13,718 - distributed.worker - INFO - Starting Worker plugin PreImport-84f78348-5e6b-402d-b63d-9d37549aa31d
2023-06-24 05:44:13,718 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-53bd21d6-3bcd-4d28-8313-0d3c9930bb8a
2023-06-24 05:44:13,718 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b766b27e-c22c-4ae1-92c1-d37727940c3d
2023-06-24 05:44:13,722 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b861ab66-648a-4cf2-aa2d-1602e0d139d8
2023-06-24 05:44:13,726 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36857
2023-06-24 05:44:13,726 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36857
2023-06-24 05:44:13,726 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42161
2023-06-24 05:44:13,726 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,726 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,726 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:13,726 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:13,726 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3_dbpdmt
2023-06-24 05:44:13,727 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fcd11722-bc9b-429f-9a46-8bccbc0ce14f
2023-06-24 05:44:13,727 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0eea7c50-1507-4741-b90f-7d6a0a19c94c
2023-06-24 05:44:13,751 - distributed.worker - INFO - Starting Worker plugin PreImport-b3388236-d168-487c-b623-f90fa722a38f
2023-06-24 05:44:13,752 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,755 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40543
2023-06-24 05:44:13,755 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40543
2023-06-24 05:44:13,755 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40461
2023-06-24 05:44:13,755 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,756 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,756 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:13,756 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:13,756 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7vtueb3c
2023-06-24 05:44:13,757 - distributed.worker - INFO - Starting Worker plugin PreImport-68d9f266-992b-4038-a2aa-b94eb205a0c2
2023-06-24 05:44:13,757 - distributed.worker - INFO - Starting Worker plugin RMMSetup-977d4fe8-9e44-434f-9c5e-a2745daf085a
2023-06-24 05:44:13,763 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39691
2023-06-24 05:44:13,763 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39691
2023-06-24 05:44:13,763 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46087
2023-06-24 05:44:13,763 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,763 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,764 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:13,764 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:13,764 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1i4penxg
2023-06-24 05:44:13,764 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45875
2023-06-24 05:44:13,764 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45875
2023-06-24 05:44:13,764 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36181
2023-06-24 05:44:13,764 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,764 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,765 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:13,765 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b7ade62e-5abb-457a-9532-e1c6d2dc32e1
2023-06-24 05:44:13,765 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:13,765 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ss_fhu4t
2023-06-24 05:44:13,765 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e9b09001-9255-4d21-ba75-5705e908f45b
2023-06-24 05:44:13,765 - distributed.worker - INFO - Starting Worker plugin PreImport-38a37872-5f00-40a7-81e8-c269a3399ce0
2023-06-24 05:44:13,765 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1a65c096-a12e-4aef-98cd-bd3dc1f61a54
2023-06-24 05:44:13,766 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-484e3952-9ddf-4a2a-9d19-12cfe67a2c48
2023-06-24 05:44:13,766 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,773 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,775 - distributed.worker - INFO - Starting Worker plugin PreImport-aebbdad1-8f04-4a7f-8b16-7a0090d05275
2023-06-24 05:44:13,775 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,781 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6df8946f-fcf7-4229-be89-1f02b26a1af7
2023-06-24 05:44:13,781 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,784 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9482f464-b5db-41b6-b355-7a0382c5ba3c
2023-06-24 05:44:13,785 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,785 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-975027df-a917-4030-bd27-b0f75da3f05a
2023-06-24 05:44:13,785 - distributed.worker - INFO - Starting Worker plugin PreImport-af60054b-0f32-4066-9b62-8d32eed44899
2023-06-24 05:44:13,786 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,786 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,787 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38053', status: init, memory: 0, processing: 0>
2023-06-24 05:44:13,789 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38053
2023-06-24 05:44:13,789 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48820
2023-06-24 05:44:13,789 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,789 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,792 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:13,801 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36857', status: init, memory: 0, processing: 0>
2023-06-24 05:44:13,802 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36857
2023-06-24 05:44:13,802 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48842
2023-06-24 05:44:13,802 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,802 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,804 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:13,808 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36355', status: init, memory: 0, processing: 0>
2023-06-24 05:44:13,808 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36355
2023-06-24 05:44:13,808 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48844
2023-06-24 05:44:13,809 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,809 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,809 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40693', status: init, memory: 0, processing: 0>
2023-06-24 05:44:13,810 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40693
2023-06-24 05:44:13,810 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48824
2023-06-24 05:44:13,811 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40149', status: init, memory: 0, processing: 0>
2023-06-24 05:44:13,811 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,811 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,811 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40149
2023-06-24 05:44:13,811 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:13,811 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48836
2023-06-24 05:44:13,812 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,812 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,815 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:13,815 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:13,816 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45875', status: init, memory: 0, processing: 0>
2023-06-24 05:44:13,816 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45875
2023-06-24 05:44:13,817 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48864
2023-06-24 05:44:13,817 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,817 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,819 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:13,822 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40543', status: init, memory: 0, processing: 0>
2023-06-24 05:44:13,822 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40543
2023-06-24 05:44:13,822 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48860
2023-06-24 05:44:13,823 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,823 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,823 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39691', status: init, memory: 0, processing: 0>
2023-06-24 05:44:13,823 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39691
2023-06-24 05:44:13,823 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48872
2023-06-24 05:44:13,824 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:13,824 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:13,825 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:13,826 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:13,926 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:13,926 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:13,927 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:13,927 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:13,927 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:13,927 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:13,927 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:13,928 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:13,935 - distributed.scheduler - INFO - Remove client Client-223cf6ca-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:13,936 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46660; closing.
2023-06-24 05:44:13,936 - distributed.scheduler - INFO - Remove client Client-223cf6ca-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:13,936 - distributed.scheduler - INFO - Close client connection: Client-223cf6ca-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:13,937 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33427'. Reason: nanny-close
2023-06-24 05:44:13,938 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:13,939 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39687'. Reason: nanny-close
2023-06-24 05:44:13,939 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:13,940 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37169'. Reason: nanny-close
2023-06-24 05:44:13,940 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38053. Reason: nanny-close
2023-06-24 05:44:13,940 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:13,940 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41347'. Reason: nanny-close
2023-06-24 05:44:13,940 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40149. Reason: nanny-close
2023-06-24 05:44:13,941 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:13,941 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36857. Reason: nanny-close
2023-06-24 05:44:13,941 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44699'. Reason: nanny-close
2023-06-24 05:44:13,941 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:13,941 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44061'. Reason: nanny-close
2023-06-24 05:44:13,941 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39691. Reason: nanny-close
2023-06-24 05:44:13,942 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:13,942 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32891'. Reason: nanny-close
2023-06-24 05:44:13,942 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48820; closing.
2023-06-24 05:44:13,942 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:13,942 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40543. Reason: nanny-close
2023-06-24 05:44:13,942 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:13,942 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38053', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:13,942 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38053
2023-06-24 05:44:13,942 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44067'. Reason: nanny-close
2023-06-24 05:44:13,943 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:13,943 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:13,943 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:13,943 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40693. Reason: nanny-close
2023-06-24 05:44:13,943 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45875. Reason: nanny-close
2023-06-24 05:44:13,943 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:13,943 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:13,944 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38053
2023-06-24 05:44:13,944 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:13,944 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:13,944 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48836; closing.
2023-06-24 05:44:13,944 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48842; closing.
2023-06-24 05:44:13,944 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38053
2023-06-24 05:44:13,944 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36355. Reason: nanny-close
2023-06-24 05:44:13,945 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:13,945 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38053
2023-06-24 05:44:13,945 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:13,945 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40149', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:13,945 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40149
2023-06-24 05:44:13,945 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:13,945 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36857', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:13,945 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36857
2023-06-24 05:44:13,946 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48872; closing.
2023-06-24 05:44:13,946 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:13,946 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:38053
2023-06-24 05:44:13,946 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:13,946 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39691', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:13,946 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39691
2023-06-24 05:44:13,946 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:13,946 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48860; closing.
2023-06-24 05:44:13,947 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:13,947 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:13,947 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40543', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:13,947 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40543
2023-06-24 05:44:13,947 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48864; closing.
2023-06-24 05:44:13,948 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48844; closing.
2023-06-24 05:44:13,948 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48824; closing.
2023-06-24 05:44:13,948 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45875', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:13,948 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:45875
2023-06-24 05:44:13,949 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36355', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:13,949 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36355
2023-06-24 05:44:13,949 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:13,949 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40693', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:13,949 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40693
2023-06-24 05:44:13,949 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:44:15,556 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:44:15,557 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:44:15,557 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:44:15,558 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:44:15,559 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-06-24 05:44:17,644 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:17,648 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:44:17,652 - distributed.scheduler - INFO - State start
2023-06-24 05:44:17,677 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:17,678 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:44:17,679 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:44:17,719 - distributed.scheduler - INFO - Receive client connection: Client-27d5553f-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:17,730 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48958
2023-06-24 05:44:17,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45553'
2023-06-24 05:44:17,977 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46525'
2023-06-24 05:44:17,988 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36909'
2023-06-24 05:44:17,990 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46413'
2023-06-24 05:44:17,999 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35971'
2023-06-24 05:44:18,008 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43135'
2023-06-24 05:44:18,019 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36591'
2023-06-24 05:44:18,029 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45673'
2023-06-24 05:44:19,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:19,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:19,746 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:19,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:19,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:19,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:19,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:19,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:19,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:19,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:19,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:19,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:19,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:19,807 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:19,809 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:19,815 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:19,817 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:19,831 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:19,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:19,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:19,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:19,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:19,902 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:19,922 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:22,571 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39885
2023-06-24 05:44:22,571 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39885
2023-06-24 05:44:22,571 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44833
2023-06-24 05:44:22,571 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,571 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,571 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:22,572 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:22,572 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ip09mrkc
2023-06-24 05:44:22,573 - distributed.worker - INFO - Starting Worker plugin PreImport-98c64aba-e1d5-42fa-8b43-4f346948a276
2023-06-24 05:44:22,573 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fd2faf5c-ab2a-4846-ab3f-29209d3573a2
2023-06-24 05:44:22,573 - distributed.worker - INFO - Starting Worker plugin RMMSetup-41e36aa5-08b3-4174-a93b-cb11b4701a67
2023-06-24 05:44:22,651 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34719
2023-06-24 05:44:22,651 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34719
2023-06-24 05:44:22,651 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38967
2023-06-24 05:44:22,651 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,651 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,651 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:22,652 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:22,652 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8ui_nv6b
2023-06-24 05:44:22,652 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4bc25613-47f4-4a55-b08b-626fa984af80
2023-06-24 05:44:22,652 - distributed.worker - INFO - Starting Worker plugin RMMSetup-354b01aa-37d2-4ac9-8bc0-f819bc9cc883
2023-06-24 05:44:22,793 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35481
2023-06-24 05:44:22,793 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35481
2023-06-24 05:44:22,793 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40317
2023-06-24 05:44:22,793 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,793 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,793 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:22,794 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:22,794 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-delreyjz
2023-06-24 05:44:22,794 - distributed.worker - INFO - Starting Worker plugin PreImport-d4e316d1-f8c1-4558-87a7-dd9b73651bef
2023-06-24 05:44:22,794 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ac15921a-5aad-439e-95a3-7c096b4fc367
2023-06-24 05:44:22,814 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42277
2023-06-24 05:44:22,814 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42277
2023-06-24 05:44:22,815 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34333
2023-06-24 05:44:22,815 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,815 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,815 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:22,815 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:22,815 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-umqjh2_1
2023-06-24 05:44:22,815 - distributed.worker - INFO - Starting Worker plugin PreImport-2d200ef7-a32a-4ebb-bb72-6287dd9ea445
2023-06-24 05:44:22,815 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-041d95af-9ca3-452c-ac3d-7c34b79d335e
2023-06-24 05:44:22,816 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8763dcde-5c85-43ea-9fc0-37a5dd2aa66b
2023-06-24 05:44:22,834 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42501
2023-06-24 05:44:22,834 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42501
2023-06-24 05:44:22,834 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39673
2023-06-24 05:44:22,834 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,835 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,835 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:22,835 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:22,835 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gqgf71ns
2023-06-24 05:44:22,836 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-af76c2cf-48d5-46e8-9758-14beca2d1da7
2023-06-24 05:44:22,836 - distributed.worker - INFO - Starting Worker plugin PreImport-429d8859-c575-4ba8-add8-40067f473104
2023-06-24 05:44:22,836 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4e5ea91f-f637-4472-8d67-c7090d97dfc0
2023-06-24 05:44:22,884 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34557
2023-06-24 05:44:22,885 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34557
2023-06-24 05:44:22,885 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42033
2023-06-24 05:44:22,885 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,885 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,885 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:22,885 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:22,885 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-v5faid18
2023-06-24 05:44:22,885 - distributed.worker - INFO - Starting Worker plugin PreImport-7fcfe64d-73a4-4f81-b801-a1804870f97d
2023-06-24 05:44:22,886 - distributed.worker - INFO - Starting Worker plugin RMMSetup-765bab23-b79d-4326-abbb-59923e2ac1b9
2023-06-24 05:44:22,893 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35427
2023-06-24 05:44:22,894 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35427
2023-06-24 05:44:22,894 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42135
2023-06-24 05:44:22,894 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,894 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,894 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:22,894 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:22,894 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t57sw3eb
2023-06-24 05:44:22,895 - distributed.worker - INFO - Starting Worker plugin PreImport-718c5d34-c422-4203-b806-fe9a29117d5f
2023-06-24 05:44:22,895 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3a17d07b-a091-4dfb-b25d-8f8bb2ede269
2023-06-24 05:44:22,901 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44783
2023-06-24 05:44:22,902 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44783
2023-06-24 05:44:22,902 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41683
2023-06-24 05:44:22,902 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,902 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,902 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:22,902 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:22,902 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qwzgbuir
2023-06-24 05:44:22,903 - distributed.worker - INFO - Starting Worker plugin PreImport-54c30f6f-ec4a-458d-b69e-0ffd88c33970
2023-06-24 05:44:22,903 - distributed.worker - INFO - Starting Worker plugin RMMSetup-846395e0-c305-4294-9e4b-534006d98988
2023-06-24 05:44:22,928 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,938 - distributed.worker - INFO - Starting Worker plugin PreImport-3bcc07f6-76ab-401a-ac00-e694bc20959f
2023-06-24 05:44:22,939 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,968 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39885', status: init, memory: 0, processing: 0>
2023-06-24 05:44:22,970 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39885
2023-06-24 05:44:22,970 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43862
2023-06-24 05:44:22,970 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,971 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,971 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34719', status: init, memory: 0, processing: 0>
2023-06-24 05:44:22,972 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34719
2023-06-24 05:44:22,972 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43866
2023-06-24 05:44:22,972 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:22,972 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:22,974 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:22,974 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:22,981 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0ace268e-35ef-4bbc-b8cd-10f985dad177
2023-06-24 05:44:22,982 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,008 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35481', status: init, memory: 0, processing: 0>
2023-06-24 05:44:23,009 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35481
2023-06-24 05:44:23,009 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43876
2023-06-24 05:44:23,010 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:23,010 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,012 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:23,042 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,045 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,076 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42277', status: init, memory: 0, processing: 0>
2023-06-24 05:44:23,076 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6f4322f2-245a-448f-8c15-371b341d5c92
2023-06-24 05:44:23,077 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,077 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42277
2023-06-24 05:44:23,077 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43886
2023-06-24 05:44:23,078 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:23,078 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,078 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42501', status: init, memory: 0, processing: 0>
2023-06-24 05:44:23,079 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42501
2023-06-24 05:44:23,079 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43894
2023-06-24 05:44:23,080 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:23,080 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,081 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:23,083 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ecfcce71-1056-407d-b879-c181140be333
2023-06-24 05:44:23,083 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:23,084 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,084 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ceecce7a-a3ee-4a35-9349-68e2654ffe64
2023-06-24 05:44:23,085 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,105 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34557', status: init, memory: 0, processing: 0>
2023-06-24 05:44:23,105 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34557
2023-06-24 05:44:23,105 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43904
2023-06-24 05:44:23,106 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:23,106 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,108 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:23,116 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44783', status: init, memory: 0, processing: 0>
2023-06-24 05:44:23,116 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44783
2023-06-24 05:44:23,117 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43932
2023-06-24 05:44:23,117 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:23,117 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,117 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35427', status: init, memory: 0, processing: 0>
2023-06-24 05:44:23,118 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35427
2023-06-24 05:44:23,118 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43918
2023-06-24 05:44:23,118 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:23,119 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:23,119 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:23,121 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:23,198 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:23,198 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:23,198 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:23,198 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:23,198 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:23,199 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:23,199 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:23,199 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:23,211 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-06-24 05:44:23,211 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-06-24 05:44:23,211 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-06-24 05:44:23,212 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-06-24 05:44:23,212 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-06-24 05:44:23,212 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-06-24 05:44:23,212 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-06-24 05:44:23,212 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-06-24 05:44:23,219 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:44:23,221 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:44:23,224 - distributed.scheduler - INFO - Remove client Client-27d5553f-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:23,224 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48958; closing.
2023-06-24 05:44:23,224 - distributed.scheduler - INFO - Remove client Client-27d5553f-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:23,224 - distributed.scheduler - INFO - Close client connection: Client-27d5553f-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:23,226 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36909'. Reason: nanny-close
2023-06-24 05:44:23,227 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:23,228 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46413'. Reason: nanny-close
2023-06-24 05:44:23,229 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:23,229 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36591'. Reason: nanny-close
2023-06-24 05:44:23,229 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42501. Reason: nanny-close
2023-06-24 05:44:23,230 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:23,230 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45553'. Reason: nanny-close
2023-06-24 05:44:23,230 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35427. Reason: nanny-close
2023-06-24 05:44:23,230 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:23,231 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34557. Reason: nanny-close
2023-06-24 05:44:23,231 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46525'. Reason: nanny-close
2023-06-24 05:44:23,231 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:23,231 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44783. Reason: nanny-close
2023-06-24 05:44:23,232 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35971'. Reason: nanny-close
2023-06-24 05:44:23,232 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43894; closing.
2023-06-24 05:44:23,232 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:23,232 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:23,232 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42501', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:23,232 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42501
2023-06-24 05:44:23,232 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43135'. Reason: nanny-close
2023-06-24 05:44:23,232 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39885. Reason: nanny-close
2023-06-24 05:44:23,232 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:23,233 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:23,233 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:23,233 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45673'. Reason: nanny-close
2023-06-24 05:44:23,233 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42277. Reason: nanny-close
2023-06-24 05:44:23,233 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:23,233 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:23,233 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34719. Reason: nanny-close
2023-06-24 05:44:23,234 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:23,234 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:23,234 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42501
2023-06-24 05:44:23,234 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:23,235 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43918; closing.
2023-06-24 05:44:23,235 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42501
2023-06-24 05:44:23,235 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35481. Reason: nanny-close
2023-06-24 05:44:23,235 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43904; closing.
2023-06-24 05:44:23,235 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:23,235 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42501
2023-06-24 05:44:23,235 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:23,236 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:23,236 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35427', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:23,236 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42501
2023-06-24 05:44:23,236 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35427
2023-06-24 05:44:23,236 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:23,237 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:23,237 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34557', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:23,237 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34557
2023-06-24 05:44:23,237 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:23,237 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:23,238 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43932; closing.
2023-06-24 05:44:23,238 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:23,238 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44783', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:23,238 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44783
2023-06-24 05:44:23,239 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43862; closing.
2023-06-24 05:44:23,239 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:23,239 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43866; closing.
2023-06-24 05:44:23,240 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39885', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:23,240 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39885
2023-06-24 05:44:23,241 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34719', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:23,241 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:34719
2023-06-24 05:44:23,241 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43886; closing.
2023-06-24 05:44:23,242 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43876; closing.
2023-06-24 05:44:23,242 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42277', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:23,243 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42277
2023-06-24 05:44:23,243 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35481', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:23,243 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35481
2023-06-24 05:44:23,243 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:44:23,244 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43876>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-24 05:44:24,694 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:44:24,694 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:44:24,695 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:44:24,696 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:44:24,696 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-06-24 05:44:26,683 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:26,687 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:44:26,690 - distributed.scheduler - INFO - State start
2023-06-24 05:44:26,709 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:26,710 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:44:26,710 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:44:26,949 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40901'
2023-06-24 05:44:26,966 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36031'
2023-06-24 05:44:26,976 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41019'
2023-06-24 05:44:26,978 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38633'
2023-06-24 05:44:26,986 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42761'
2023-06-24 05:44:26,994 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44201'
2023-06-24 05:44:27,004 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35999'
2023-06-24 05:44:27,012 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45027'
2023-06-24 05:44:28,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:28,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:28,644 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:28,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:28,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:28,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:28,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:28,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:28,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:28,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:28,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:28,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:28,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:28,740 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:28,741 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:28,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:28,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:28,742 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:28,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:28,745 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:28,752 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:28,764 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:28,787 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:28,795 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:28,967 - distributed.scheduler - INFO - Receive client connection: Client-2d45fb4b-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:28,979 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44066
2023-06-24 05:44:30,507 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44317
2023-06-24 05:44:30,507 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44317
2023-06-24 05:44:30,507 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39301
2023-06-24 05:44:30,507 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:30,507 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:30,507 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:30,507 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:30,507 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_tb1p_9h
2023-06-24 05:44:30,508 - distributed.worker - INFO - Starting Worker plugin PreImport-25f75463-1fe5-4f6b-8c30-f946bbb33198
2023-06-24 05:44:30,508 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b282b2f0-cd57-41ef-b135-d20a135b8d94
2023-06-24 05:44:30,865 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce61b6c4-600f-43da-a2d7-d44d631ddcf2
2023-06-24 05:44:30,866 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:30,905 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44317', status: init, memory: 0, processing: 0>
2023-06-24 05:44:30,906 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44317
2023-06-24 05:44:30,906 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33458
2023-06-24 05:44:30,907 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:30,907 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:30,909 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:31,961 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40273
2023-06-24 05:44:31,961 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40273
2023-06-24 05:44:31,961 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42549
2023-06-24 05:44:31,961 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45121
2023-06-24 05:44:31,961 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42549
2023-06-24 05:44:31,962 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:31,962 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37553
2023-06-24 05:44:31,962 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:31,962 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:31,962 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:31,962 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:31,962 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:31,962 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:31,962 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-j5r53t2z
2023-06-24 05:44:31,962 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:31,962 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-uz18xaz1
2023-06-24 05:44:31,962 - distributed.worker - INFO - Starting Worker plugin PreImport-b685fdd6-2f22-4149-8bfd-aca96514a8d3
2023-06-24 05:44:31,962 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44797
2023-06-24 05:44:31,962 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e1a57fae-d82d-4592-82cd-3374e764e101
2023-06-24 05:44:31,962 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e7a7b138-a8b4-4a6a-8fe2-dba008bfbb29
2023-06-24 05:44:31,962 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44797
2023-06-24 05:44:31,962 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37789
2023-06-24 05:44:31,962 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6d89a86e-03cd-4426-86c4-8a9fc201a382
2023-06-24 05:44:31,962 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41891
2023-06-24 05:44:31,962 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37789
2023-06-24 05:44:31,962 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:31,963 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:31,963 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38945
2023-06-24 05:44:31,963 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:31,963 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:31,963 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:31,963 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:31,963 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pcoup4mi
2023-06-24 05:44:31,963 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:31,963 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:31,963 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t2hy16zl
2023-06-24 05:44:31,963 - distributed.worker - INFO - Starting Worker plugin PreImport-9ea72a7a-09f4-4e8f-9c0e-531802b6f4db
2023-06-24 05:44:31,963 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2122ce20-4cb2-4f8a-a3ba-b148f3965aa4
2023-06-24 05:44:31,963 - distributed.worker - INFO - Starting Worker plugin PreImport-7c95a4fd-2e6f-4756-820f-6af55d2f9542
2023-06-24 05:44:31,963 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f54e6536-ff3a-4788-8567-8a9378da32c7
2023-06-24 05:44:31,964 - distributed.worker - INFO - Starting Worker plugin RMMSetup-def1f033-707e-4cd2-a105-6785053210f7
2023-06-24 05:44:31,965 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39729
2023-06-24 05:44:31,966 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39729
2023-06-24 05:44:31,966 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40225
2023-06-24 05:44:31,966 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:31,966 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:31,966 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:31,966 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:31,966 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-70673iz0
2023-06-24 05:44:31,966 - distributed.worker - INFO - Starting Worker plugin PreImport-bd697c63-a231-4032-9627-629750572799
2023-06-24 05:44:31,966 - distributed.worker - INFO - Starting Worker plugin RMMSetup-77943f2c-6ec1-40e9-9cb2-9b908fb079b3
2023-06-24 05:44:31,966 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41673
2023-06-24 05:44:31,967 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41673
2023-06-24 05:44:31,967 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37301
2023-06-24 05:44:31,967 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:31,967 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33605
2023-06-24 05:44:31,967 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:31,967 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:31,967 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33605
2023-06-24 05:44:31,967 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:31,967 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35335
2023-06-24 05:44:31,967 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ap8_i1h3
2023-06-24 05:44:31,967 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:31,967 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:31,967 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:31,967 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:44:31,967 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nm2xejqo
2023-06-24 05:44:31,967 - distributed.worker - INFO - Starting Worker plugin PreImport-8826bf36-2d83-44ba-8495-35dfb7002444
2023-06-24 05:44:31,967 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ab409d7f-3f14-414e-9dc1-18704480c6a3
2023-06-24 05:44:31,968 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ad13da7d-a4c5-455d-9946-0f94c925f598
2023-06-24 05:44:31,970 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dece8acf-df33-4576-b228-42c82785c9c1
2023-06-24 05:44:31,974 - distributed.worker - INFO - Starting Worker plugin PreImport-1b3e15e0-19ae-44e3-ab28-9175c4aca90f
2023-06-24 05:44:31,974 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cc0784cb-8ebb-41ef-bfe8-28c1967ae4ce
2023-06-24 05:44:32,117 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ca3a7fc5-62c9-41ef-893f-8f4d56e19e8d
2023-06-24 05:44:32,117 - distributed.worker - INFO - Starting Worker plugin PreImport-97032f54-a1a8-4248-aedf-556e2c7d1699
2023-06-24 05:44:32,118 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,118 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,126 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-caee221f-ddcc-4ddd-934a-9410225b12a9
2023-06-24 05:44:32,126 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e516f81f-a593-4398-874d-750a33e87916
2023-06-24 05:44:32,126 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,126 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,138 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,143 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,150 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,150 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40273', status: init, memory: 0, processing: 0>
2023-06-24 05:44:32,151 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40273
2023-06-24 05:44:32,151 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33476
2023-06-24 05:44:32,152 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:32,152 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,152 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42549', status: init, memory: 0, processing: 0>
2023-06-24 05:44:32,152 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42549
2023-06-24 05:44:32,153 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33478
2023-06-24 05:44:32,153 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:32,153 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,154 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:32,154 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37789', status: init, memory: 0, processing: 0>
2023-06-24 05:44:32,155 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37789
2023-06-24 05:44:32,155 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33500
2023-06-24 05:44:32,155 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:32,155 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:32,156 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,158 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:32,169 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39729', status: init, memory: 0, processing: 0>
2023-06-24 05:44:32,170 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39729
2023-06-24 05:44:32,170 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33510
2023-06-24 05:44:32,171 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:32,171 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,174 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:32,176 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41673', status: init, memory: 0, processing: 0>
2023-06-24 05:44:32,176 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41673
2023-06-24 05:44:32,177 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33518
2023-06-24 05:44:32,177 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:32,177 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,180 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:32,186 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33605', status: init, memory: 0, processing: 0>
2023-06-24 05:44:32,187 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33605
2023-06-24 05:44:32,187 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33532
2023-06-24 05:44:32,188 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:32,188 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,191 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:32,192 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44797', status: init, memory: 0, processing: 0>
2023-06-24 05:44:32,192 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44797
2023-06-24 05:44:32,192 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33534
2023-06-24 05:44:32,193 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:32,193 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:32,196 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:32,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:32,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:32,214 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:32,215 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:32,215 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:32,215 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:32,215 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:32,215 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:44:32,222 - distributed.scheduler - INFO - Remove client Client-2d45fb4b-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:32,222 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44066; closing.
2023-06-24 05:44:32,222 - distributed.scheduler - INFO - Remove client Client-2d45fb4b-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:32,223 - distributed.scheduler - INFO - Close client connection: Client-2d45fb4b-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:32,224 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41019'. Reason: nanny-close
2023-06-24 05:44:32,224 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:32,225 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44201'. Reason: nanny-close
2023-06-24 05:44:32,225 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:32,226 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40901'. Reason: nanny-close
2023-06-24 05:44:32,226 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33605. Reason: nanny-close
2023-06-24 05:44:32,226 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:32,226 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36031'. Reason: nanny-close
2023-06-24 05:44:32,227 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39729. Reason: nanny-close
2023-06-24 05:44:32,227 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:32,227 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38633'. Reason: nanny-close
2023-06-24 05:44:32,227 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44317. Reason: nanny-close
2023-06-24 05:44:32,227 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:32,228 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37789. Reason: nanny-close
2023-06-24 05:44:32,228 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42761'. Reason: nanny-close
2023-06-24 05:44:32,228 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:32,228 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35999'. Reason: nanny-close
2023-06-24 05:44:32,228 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33532; closing.
2023-06-24 05:44:32,228 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44797. Reason: nanny-close
2023-06-24 05:44:32,229 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:32,229 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:32,229 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33605', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:32,229 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33605
2023-06-24 05:44:32,229 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45027'. Reason: nanny-close
2023-06-24 05:44:32,229 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:32,229 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41673. Reason: nanny-close
2023-06-24 05:44:32,229 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:32,229 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:32,229 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:32,229 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42549. Reason: nanny-close
2023-06-24 05:44:32,230 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:32,230 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:32,230 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40273. Reason: nanny-close
2023-06-24 05:44:32,230 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33510; closing.
2023-06-24 05:44:32,231 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33458; closing.
2023-06-24 05:44:32,231 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:32,231 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33605
2023-06-24 05:44:32,231 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33500; closing.
2023-06-24 05:44:32,231 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:32,231 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33605
2023-06-24 05:44:32,231 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:32,231 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33605
2023-06-24 05:44:32,231 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39729', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:32,232 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:39729
2023-06-24 05:44:32,232 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:32,232 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33605
2023-06-24 05:44:32,232 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:32,232 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44317', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:32,232 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44317
2023-06-24 05:44:32,232 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37789', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:32,232 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:37789
2023-06-24 05:44:32,232 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:32,232 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:32,233 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:32,233 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33534; closing.
2023-06-24 05:44:32,233 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:32,233 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33478; closing.
2023-06-24 05:44:32,234 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:32,234 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44797', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:32,234 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44797
2023-06-24 05:44:32,234 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42549', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:32,234 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42549
2023-06-24 05:44:32,235 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33518; closing.
2023-06-24 05:44:32,235 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33476; closing.
2023-06-24 05:44:32,235 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41673', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:32,235 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:41673
2023-06-24 05:44:32,236 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40273', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:32,236 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40273
2023-06-24 05:44:32,236 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:44:33,893 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:44:33,894 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:44:33,894 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:44:33,895 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:44:33,895 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-06-24 05:44:36,208 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:36,214 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:44:36,218 - distributed.scheduler - INFO - State start
2023-06-24 05:44:36,243 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:36,244 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:44:36,245 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:44:36,276 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40891'
2023-06-24 05:44:38,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:38,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:44:38,504 - distributed.scheduler - INFO - Receive client connection: Client-32cc9823-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:38,522 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33654
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:44:38,678 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:39,742 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36201
2023-06-24 05:44:39,742 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36201
2023-06-24 05:44:39,742 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-06-24 05:44:39,743 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:39,743 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:39,743 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:39,743 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-06-24 05:44:39,743 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rf3wz82j
2023-06-24 05:44:39,743 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4be82bef-8c7f-4882-bf9a-aec393973f66
2023-06-24 05:44:39,744 - distributed.worker - INFO - Starting Worker plugin RMMSetup-57352711-21ae-4ae1-b779-dfaf56bfdfd9
2023-06-24 05:44:39,744 - distributed.worker - INFO - Starting Worker plugin PreImport-ebe3cb85-efa3-4e02-be42-082e4afcc5f8
2023-06-24 05:44:39,744 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:39,798 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36201', status: init, memory: 0, processing: 0>
2023-06-24 05:44:39,800 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36201
2023-06-24 05:44:39,800 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33662
2023-06-24 05:44:39,801 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:39,801 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:39,804 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:39,869 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:44:39,873 - distributed.scheduler - INFO - Remove client Client-32cc9823-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:39,873 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33654; closing.
2023-06-24 05:44:39,874 - distributed.scheduler - INFO - Remove client Client-32cc9823-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:39,874 - distributed.scheduler - INFO - Close client connection: Client-32cc9823-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:39,875 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40891'. Reason: nanny-close
2023-06-24 05:44:39,876 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:39,878 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36201. Reason: nanny-close
2023-06-24 05:44:39,880 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:39,880 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33662; closing.
2023-06-24 05:44:39,881 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36201', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:39,881 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36201
2023-06-24 05:44:39,881 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:44:39,882 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:41,345 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:44:41,345 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:44:41,346 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:44:41,347 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:44:41,347 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-06-24 05:44:45,800 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:45,804 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:44:45,808 - distributed.scheduler - INFO - State start
2023-06-24 05:44:45,829 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:45,831 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:44:45,831 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:44:45,891 - distributed.scheduler - INFO - Receive client connection: Client-38986650-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:45,905 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58048
2023-06-24 05:44:46,014 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43125'
2023-06-24 05:44:47,839 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:44:47,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:44:48,497 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:44:49,530 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35799
2023-06-24 05:44:49,530 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35799
2023-06-24 05:44:49,530 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45237
2023-06-24 05:44:49,530 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:44:49,530 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:49,530 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:44:49,530 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-06-24 05:44:49,530 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6dbn__af
2023-06-24 05:44:49,531 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8524cc01-014c-43ef-8fd3-2b2adb33aa8b
2023-06-24 05:44:49,531 - distributed.worker - INFO - Starting Worker plugin RMMSetup-be7a3907-c45e-4b4e-b412-f9bd3238486c
2023-06-24 05:44:49,532 - distributed.worker - INFO - Starting Worker plugin PreImport-e41c67ce-a8d6-4d84-a1fe-8e6fface648d
2023-06-24 05:44:49,534 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:49,573 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35799', status: init, memory: 0, processing: 0>
2023-06-24 05:44:49,575 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35799
2023-06-24 05:44:49,575 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58070
2023-06-24 05:44:49,575 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:44:49,575 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:44:49,578 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:44:49,587 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:44:49,590 - distributed.scheduler - INFO - Remove client Client-38986650-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:49,590 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58048; closing.
2023-06-24 05:44:49,590 - distributed.scheduler - INFO - Remove client Client-38986650-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:49,591 - distributed.scheduler - INFO - Close client connection: Client-38986650-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:44:49,592 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43125'. Reason: nanny-close
2023-06-24 05:44:49,612 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:44:49,614 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35799. Reason: nanny-close
2023-06-24 05:44:49,617 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:44:49,617 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58070; closing.
2023-06-24 05:44:49,617 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35799', status: closing, memory: 0, processing: 0>
2023-06-24 05:44:49,617 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35799
2023-06-24 05:44:49,618 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:44:49,618 - distributed.nanny - INFO - Worker closed
2023-06-24 05:44:50,910 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:44:50,910 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:44:50,911 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:44:50,912 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:44:50,912 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-06-24 05:44:53,228 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:53,233 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:44:53,237 - distributed.scheduler - INFO - State start
2023-06-24 05:44:53,258 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:44:53,259 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:44:53,260 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:44:58,003 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:44:58,003 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:44:58,004 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:44:58,004 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:44:58,005 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-06-24 05:45:00,363 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:45:00,367 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:45:00,371 - distributed.scheduler - INFO - State start
2023-06-24 05:45:00,393 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:45:00,394 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-06-24 05:45:00,395 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:45:00,527 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33789'
2023-06-24 05:45:01,099 - distributed.scheduler - INFO - Receive client connection: Client-4128c1db-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:01,114 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34844
2023-06-24 05:45:02,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:02,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:02,257 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:03,151 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43753
2023-06-24 05:45:03,151 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43753
2023-06-24 05:45:03,151 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35323
2023-06-24 05:45:03,152 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-06-24 05:45:03,152 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:03,152 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:03,152 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-06-24 05:45:03,152 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lg7jtgv_
2023-06-24 05:45:03,152 - distributed.worker - INFO - Starting Worker plugin PreImport-8db6bda4-2bd5-4e08-aadb-eb266484f113
2023-06-24 05:45:03,152 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ea99b210-4b60-4925-8c9d-571e52d929fd
2023-06-24 05:45:03,152 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ab7d6899-4ddf-4800-83d3-5b2aa4390de1
2023-06-24 05:45:03,153 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:03,182 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43753', status: init, memory: 0, processing: 0>
2023-06-24 05:45:03,183 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43753
2023-06-24 05:45:03,183 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34864
2023-06-24 05:45:03,184 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-06-24 05:45:03,184 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:03,187 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-06-24 05:45:03,214 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:03,218 - distributed.scheduler - INFO - Remove client Client-4128c1db-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:03,218 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34844; closing.
2023-06-24 05:45:03,218 - distributed.scheduler - INFO - Remove client Client-4128c1db-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:03,219 - distributed.scheduler - INFO - Close client connection: Client-4128c1db-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:03,220 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33789'. Reason: nanny-close
2023-06-24 05:45:03,221 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:03,222 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43753. Reason: nanny-close
2023-06-24 05:45:03,224 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-06-24 05:45:03,224 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34864; closing.
2023-06-24 05:45:03,225 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43753', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:03,225 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43753
2023-06-24 05:45:03,225 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:45:03,225 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:04,287 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:45:04,288 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:45:04,289 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:45:04,290 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-06-24 05:45:04,291 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-06-24 05:45:06,486 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:45:06,491 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:45:06,495 - distributed.scheduler - INFO - State start
2023-06-24 05:45:06,516 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:45:06,517 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:45:06,518 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:45:06,776 - distributed.scheduler - INFO - Receive client connection: Client-44ebecc6-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:06,791 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34522
2023-06-24 05:45:06,875 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43747'
2023-06-24 05:45:06,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40871'
2023-06-24 05:45:06,901 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33077'
2023-06-24 05:45:06,911 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37513'
2023-06-24 05:45:06,913 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44263'
2023-06-24 05:45:06,922 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36877'
2023-06-24 05:45:06,932 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33099'
2023-06-24 05:45:06,940 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39127'
2023-06-24 05:45:08,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:08,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:08,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:08,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:08,667 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:08,672 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:08,672 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:08,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:08,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:08,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:08,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:08,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:08,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:08,695 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:08,704 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:08,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:08,709 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:08,726 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:08,727 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:08,729 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:08,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:08,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:08,752 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:08,801 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:12,191 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32933
2023-06-24 05:45:12,191 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32933
2023-06-24 05:45:12,191 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37393
2023-06-24 05:45:12,191 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,191 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,191 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:12,191 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:45:12,191 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3ntykbpi
2023-06-24 05:45:12,192 - distributed.worker - INFO - Starting Worker plugin PreImport-abd9a0c0-6159-4845-ac03-3c69b8d5e027
2023-06-24 05:45:12,192 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6db1ce33-6170-499c-8b10-599c31df0c8e
2023-06-24 05:45:12,200 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40741
2023-06-24 05:45:12,200 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40741
2023-06-24 05:45:12,200 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36047
2023-06-24 05:45:12,200 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,200 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,200 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:12,200 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:45:12,200 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mcuv27ju
2023-06-24 05:45:12,201 - distributed.worker - INFO - Starting Worker plugin PreImport-d4dcf29f-0c80-4db1-b6f2-21917a5fbbd9
2023-06-24 05:45:12,201 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d1ba23d2-20cd-4cce-80ef-7a269fc15ae5
2023-06-24 05:45:12,224 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43651
2023-06-24 05:45:12,224 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43651
2023-06-24 05:45:12,224 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44163
2023-06-24 05:45:12,225 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39409
2023-06-24 05:45:12,225 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,225 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44163
2023-06-24 05:45:12,225 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,225 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33053
2023-06-24 05:45:12,225 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:12,225 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,225 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:45:12,225 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,225 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_5y41v9e
2023-06-24 05:45:12,225 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:12,225 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:45:12,225 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gf_m2dp5
2023-06-24 05:45:12,225 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b0461d42-b17b-4735-9401-92258b1a98b3
2023-06-24 05:45:12,225 - distributed.worker - INFO - Starting Worker plugin RMMSetup-273d8975-93bb-4594-8674-1874768d8f6c
2023-06-24 05:45:12,226 - distributed.worker - INFO - Starting Worker plugin PreImport-0e0d2cf0-a556-4d42-8902-e915bb17e9f0
2023-06-24 05:45:12,226 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1fc36106-9944-4551-b7b3-702ecceaac46
2023-06-24 05:45:12,226 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2c97bd82-c1d8-4846-8fba-c9f36fda336e
2023-06-24 05:45:12,230 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35157
2023-06-24 05:45:12,231 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35157
2023-06-24 05:45:12,231 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34783
2023-06-24 05:45:12,231 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,231 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,231 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43943
2023-06-24 05:45:12,231 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:12,231 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43943
2023-06-24 05:45:12,231 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:45:12,231 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_u73r370
2023-06-24 05:45:12,231 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34131
2023-06-24 05:45:12,231 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,231 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,231 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:12,231 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:45:12,231 - distributed.worker - INFO - Starting Worker plugin PreImport-3adf0252-09bc-4a26-88a0-a2759dc9b345
2023-06-24 05:45:12,231 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33503
2023-06-24 05:45:12,231 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9jm284tt
2023-06-24 05:45:12,232 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33503
2023-06-24 05:45:12,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e159b4df-af46-4125-949b-2f13b8982fed
2023-06-24 05:45:12,232 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37477
2023-06-24 05:45:12,232 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,232 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,232 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:12,232 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:45:12,232 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-98ctcdnf
2023-06-24 05:45:12,232 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2cfd2197-e958-42a2-a2e3-f7f90c63ca87
2023-06-24 05:45:12,232 - distributed.worker - INFO - Starting Worker plugin PreImport-0e11ead1-95d7-445d-9013-974f94233833
2023-06-24 05:45:12,233 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cd898827-b574-493e-8a0a-dde7b39ff6a1
2023-06-24 05:45:12,233 - distributed.worker - INFO - Starting Worker plugin PreImport-741ed730-d20f-446f-aff8-4ecdd77bb93a
2023-06-24 05:45:12,233 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-57a36e1d-3a84-4e55-8d5d-3525dfc0b988
2023-06-24 05:45:12,233 - distributed.worker - INFO - Starting Worker plugin RMMSetup-11dcebe5-c3ae-4876-b0ea-31d2dc8808da
2023-06-24 05:45:12,233 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42321
2023-06-24 05:45:12,233 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42321
2023-06-24 05:45:12,233 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41425
2023-06-24 05:45:12,233 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,233 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,233 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:12,234 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-06-24 05:45:12,234 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kgbm56jj
2023-06-24 05:45:12,234 - distributed.worker - INFO - Starting Worker plugin PreImport-e78d83fb-244b-4ab2-aca7-3b0a451bb473
2023-06-24 05:45:12,234 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9e7a9990-6901-47c7-a916-7ffe57b462cd
2023-06-24 05:45:12,385 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-17d5fadc-db6a-430b-ad53-a980985f8669
2023-06-24 05:45:12,385 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,388 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c4131e28-ff43-45f4-8254-1752e8106533
2023-06-24 05:45:12,388 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,410 - distributed.worker - INFO - Starting Worker plugin PreImport-15041569-b6e7-425b-8e19-4649caf03b0b
2023-06-24 05:45:12,410 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,410 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,410 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d4d9bd66-83ab-422c-8247-0fa8fdb8d9a8
2023-06-24 05:45:12,410 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,410 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-18287e2d-2c9f-45c2-9cff-d6ef18d4d40a
2023-06-24 05:45:12,410 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,411 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,411 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,417 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32933', status: init, memory: 0, processing: 0>
2023-06-24 05:45:12,419 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32933
2023-06-24 05:45:12,419 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39488
2023-06-24 05:45:12,420 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,420 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,421 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40741', status: init, memory: 0, processing: 0>
2023-06-24 05:45:12,421 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40741
2023-06-24 05:45:12,421 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39480
2023-06-24 05:45:12,422 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,422 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,422 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:45:12,424 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:45:12,438 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43651', status: init, memory: 0, processing: 0>
2023-06-24 05:45:12,438 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43651
2023-06-24 05:45:12,438 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39496
2023-06-24 05:45:12,439 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,439 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,441 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:45:12,444 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35157', status: init, memory: 0, processing: 0>
2023-06-24 05:45:12,445 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35157
2023-06-24 05:45:12,445 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39500
2023-06-24 05:45:12,445 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,445 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,447 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:45:12,448 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43943', status: init, memory: 0, processing: 0>
2023-06-24 05:45:12,449 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43943
2023-06-24 05:45:12,449 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39522
2023-06-24 05:45:12,449 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,449 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,450 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33503', status: init, memory: 0, processing: 0>
2023-06-24 05:45:12,451 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33503
2023-06-24 05:45:12,451 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39524
2023-06-24 05:45:12,451 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,451 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44163', status: init, memory: 0, processing: 0>
2023-06-24 05:45:12,451 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,452 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44163
2023-06-24 05:45:12,452 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39510
2023-06-24 05:45:12,452 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:45:12,452 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,453 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,454 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:45:12,455 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:45:12,458 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42321', status: init, memory: 0, processing: 0>
2023-06-24 05:45:12,459 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42321
2023-06-24 05:45:12,459 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39540
2023-06-24 05:45:12,460 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:45:12,460 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:12,463 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:45:12,530 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:45:12,530 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:45:12,530 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:45:12,530 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:45:12,530 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:45:12,531 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:45:12,531 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:45:12,531 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-06-24 05:45:12,546 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:12,546 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:12,546 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:12,546 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:12,546 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:12,546 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:12,546 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:12,547 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:12,551 - distributed.scheduler - INFO - Remove client Client-44ebecc6-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:12,552 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34522; closing.
2023-06-24 05:45:12,552 - distributed.scheduler - INFO - Remove client Client-44ebecc6-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:12,552 - distributed.scheduler - INFO - Close client connection: Client-44ebecc6-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:12,553 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33077'. Reason: nanny-close
2023-06-24 05:45:12,554 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:12,555 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36877'. Reason: nanny-close
2023-06-24 05:45:12,555 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:12,556 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43747'. Reason: nanny-close
2023-06-24 05:45:12,556 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43943. Reason: nanny-close
2023-06-24 05:45:12,556 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:12,556 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40871'. Reason: nanny-close
2023-06-24 05:45:12,556 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42321. Reason: nanny-close
2023-06-24 05:45:12,556 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:12,557 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35157. Reason: nanny-close
2023-06-24 05:45:12,557 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37513'. Reason: nanny-close
2023-06-24 05:45:12,557 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:12,557 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32933. Reason: nanny-close
2023-06-24 05:45:12,557 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44263'. Reason: nanny-close
2023-06-24 05:45:12,558 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:12,558 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39522; closing.
2023-06-24 05:45:12,558 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:45:12,558 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33099'. Reason: nanny-close
2023-06-24 05:45:12,558 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33503. Reason: nanny-close
2023-06-24 05:45:12,558 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:12,558 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43943', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:12,558 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43943
2023-06-24 05:45:12,558 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:45:12,558 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39127'. Reason: nanny-close
2023-06-24 05:45:12,559 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:45:12,559 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44163. Reason: nanny-close
2023-06-24 05:45:12,559 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:12,559 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:45:12,559 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43651. Reason: nanny-close
2023-06-24 05:45:12,559 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:12,560 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:12,560 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:12,560 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40741. Reason: nanny-close
2023-06-24 05:45:12,560 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:12,560 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:45:12,561 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39500; closing.
2023-06-24 05:45:12,561 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43943
2023-06-24 05:45:12,561 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:45:12,561 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39540; closing.
2023-06-24 05:45:12,561 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43943
2023-06-24 05:45:12,561 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39488; closing.
2023-06-24 05:45:12,561 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:12,561 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:45:12,562 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43943
2023-06-24 05:45:12,562 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:45:12,562 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:12,562 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35157', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:12,562 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:35157
2023-06-24 05:45:12,563 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42321', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:12,563 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:42321
2023-06-24 05:45:12,563 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:12,563 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:12,563 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32933', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:12,564 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:32933
2023-06-24 05:45:12,565 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39524; closing.
2023-06-24 05:45:12,565 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39496; closing.
2023-06-24 05:45:12,565 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39510; closing.
2023-06-24 05:45:12,566 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39480; closing.
2023-06-24 05:45:12,566 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33503', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:12,566 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33503
2023-06-24 05:45:12,567 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43651', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:12,567 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:43651
2023-06-24 05:45:12,567 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44163', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:12,567 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:44163
2023-06-24 05:45:12,568 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40741', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:12,568 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:40741
2023-06-24 05:45:12,568 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:45:14,273 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:45:14,273 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:45:14,274 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:45:14,275 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:45:14,275 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-06-24 05:45:16,438 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:45:16,443 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:45:16,446 - distributed.scheduler - INFO - State start
2023-06-24 05:45:16,467 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:45:16,468 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:45:16,469 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:45:16,729 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38935'
2023-06-24 05:45:18,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:18,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:18,394 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:19,352 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36717
2023-06-24 05:45:19,352 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36717
2023-06-24 05:45:19,352 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36113
2023-06-24 05:45:19,352 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:19,352 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:19,352 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:19,352 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-06-24 05:45:19,353 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-w5x1uvyw
2023-06-24 05:45:19,353 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9083854f-2ed4-4a58-96b7-cc93dbc04e60
2023-06-24 05:45:19,353 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9c88d752-44d3-4f52-9371-246393ff403d
2023-06-24 05:45:19,473 - distributed.worker - INFO - Starting Worker plugin PreImport-b51d49b7-a4f3-4616-b59d-8d889057442e
2023-06-24 05:45:19,473 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:19,503 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36717', status: init, memory: 0, processing: 0>
2023-06-24 05:45:19,519 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36717
2023-06-24 05:45:19,519 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39634
2023-06-24 05:45:19,520 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-06-24 05:45:19,520 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:19,522 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-06-24 05:45:21,225 - distributed.scheduler - INFO - Receive client connection: Client-4ae117a2-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:21,226 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33606
2023-06-24 05:45:21,233 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-06-24 05:45:21,236 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:21,238 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-24 05:45:21,241 - distributed.scheduler - INFO - Remove client Client-4ae117a2-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:21,241 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33606; closing.
2023-06-24 05:45:21,241 - distributed.scheduler - INFO - Remove client Client-4ae117a2-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:21,241 - distributed.scheduler - INFO - Close client connection: Client-4ae117a2-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:21,242 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38935'. Reason: nanny-close
2023-06-24 05:45:21,243 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-06-24 05:45:21,244 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36717. Reason: nanny-close
2023-06-24 05:45:21,246 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39634; closing.
2023-06-24 05:45:21,246 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-06-24 05:45:21,246 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36717', status: closing, memory: 0, processing: 0>
2023-06-24 05:45:21,246 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:36717
2023-06-24 05:45:21,246 - distributed.scheduler - INFO - Lost all workers
2023-06-24 05:45:21,247 - distributed.nanny - INFO - Worker closed
2023-06-24 05:45:22,359 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:45:22,360 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:45:22,360 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:45:22,361 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:45:22,361 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-06-24 05:45:24,562 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:45:24,566 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-06-24 05:45:24,570 - distributed.scheduler - INFO - State start
2023-06-24 05:45:24,591 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-24 05:45:24,592 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-06-24 05:45:24,592 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-06-24 05:45:24,759 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33923'
2023-06-24 05:45:26,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:26,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:26,426 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-24 05:45:26,730 - distributed.scheduler - INFO - Receive client connection: Client-4faac01c-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:26,742 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33718
2023-06-24 05:45:27,608 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43061
2023-06-24 05:45:27,608 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43061
2023-06-24 05:45:27,608 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43249
2023-06-24 05:45:27,608 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-06-24 05:45:27,608 - distributed.worker - INFO - -------------------------------------------------
2023-06-24 05:45:27,608 - distributed.worker - INFO -               Threads:                          1
2023-06-24 05:45:27,609 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-06-24 05:45:27,609 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mlmzj77e
2023-06-24 05:45:27,609 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d7b8db1b-5c06-41d3-9813-cb0ed97d90f6
2023-06-24 05:45:27,609 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b8cd150f-ca48-4d7d-ad2c-71a6a8d5d5ae
std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1881, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 115, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 847, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 907, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 348, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-24 05:45:27,944 - distributed.worker - INFO - Starting Worker plugin PreImport-a6c3e7fe-43a5-441a-8ff9-79adbaa8d8e1
2023-06-24 05:45:27,944 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43061. Reason: worker-close
2023-06-24 05:45:27,944 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2023-06-24 05:45:27,948 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1478, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1881, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 115, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 847, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 907, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 348, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 930, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 549, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
2023-06-24 05:45:27,996 - distributed.nanny - ERROR - Failed to start process
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1478, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1881, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 115, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 847, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 907, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 348, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 866, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 930, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 549, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
2023-06-24 05:45:28,000 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33923'. Reason: nanny-instantiate-failed
2023-06-24 05:45:28,000 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-instantiate-failed
2023-06-24 05:45:28,430 - distributed.nanny - INFO - Worker process 52808 was killed by signal 15
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1478, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1881, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 115, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 847, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 907, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 348, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 368, in start_unsafe
    response = await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 866, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 930, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 549, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 441, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 433, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-06-24 05:45:36,756 - distributed.scheduler - INFO - Remove client Client-4faac01c-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:36,756 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33718; closing.
2023-06-24 05:45:36,757 - distributed.scheduler - INFO - Remove client Client-4faac01c-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:36,757 - distributed.scheduler - INFO - Close client connection: Client-4faac01c-1252-11ee-8233-d8c49764f6bb
2023-06-24 05:45:36,758 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-24 05:45:36,758 - distributed.scheduler - INFO - Scheduler closing...
2023-06-24 05:45:36,759 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-24 05:45:36,760 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-06-24 05:45:36,761 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:45:47,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:47,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:47,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:47,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:47,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:47,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:47,384 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:47,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:47,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:47,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:47,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:47,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:47,454 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:47,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:47,474 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:47,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:45:57,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:57,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:57,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:57,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:57,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:57,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:57,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:57,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:57,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:57,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:57,981 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:57,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:58,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:58,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:45:58,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:45:58,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:46:07,456 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:07,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:07,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:07,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:07,491 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:07,491 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:07,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:07,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:07,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:07,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:07,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:07,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:07,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:07,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:07,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:07,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:46:17,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:17,996 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:17,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:17,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:18,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:18,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:18,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:18,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:18,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:18,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:18,050 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:18,050 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:18,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:18,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:18,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:18,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:46:29,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:29,656 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:29,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:29,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:29,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:29,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:29,658 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:29,658 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:29,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:29,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:29,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:29,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:29,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:29,690 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:29,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:29,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:46:41,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:41,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:41,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:41,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:41,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:41,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:41,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:41,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:41,467 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:41,467 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:41,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:41,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:41,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:41,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:41,509 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:41,509 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:46:53,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:53,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:53,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:53,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:53,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:53,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:53,397 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:53,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:53,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:53,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:53,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:53,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:53,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:53,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:46:53,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:46:53,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/dashboard/core.py:20: UserWarning: 
Dask needs bokeh >= 2.4.2, < 3 for the dashboard.
You have bokeh==3.1.1.
Continuing without the dashboard.
  warnings.warn(
2023-06-24 05:47:05,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:47:05,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:47:05,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:47:05,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:47:05,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:47:05,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:47:05,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:47:05,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:47:05,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:47:05,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:47:05,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:47:05,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:47:05,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:47:05,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-24 05:47:05,881 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-24 05:47:05,881 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[ucx-cudf-3] 2023-06-24 05:51:08,770 - distributed.core - ERROR - std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-06-24 05:51:08,798 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f34ec0e0580>>, <Task finished name='Task-17' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-17' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:201> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 204, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1290, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 883, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-06-24 05:51:10,801 - distributed.nanny - ERROR - Worker process died unexpectedly
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 12 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
