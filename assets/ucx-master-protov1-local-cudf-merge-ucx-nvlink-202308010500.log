/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41669 instead
  warnings.warn(
2023-08-01 05:56:11,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:11,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:11,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:11,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:11,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:11,309 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:11,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:11,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:11,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:11,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:11,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:11,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:11,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:11,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:11,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:11,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:73229:0:73229] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  73229) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f49211faced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f49211faee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f49211fb0aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f49c4a7a420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f492127a6f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f49212a2a49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f49211b445f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f49211b7548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f4921204399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f49211b665d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f492127752a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f492132c17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x56324cdc3b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x56324cdb4112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56324cdad27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56324cdbec05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56324cdae81b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56324cdbeef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x56324cdcca16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x56324cedc9b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x56324cd6a817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x56324cdb5f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x56324cdb3d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56324cdbeef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56324cdae81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56324cdbeef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56324cdae81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56324cdbeef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56324cdae81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56324cdbeef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56324cdae81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56324cdad27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56324cdbec05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x56324cdb2fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56324cdad27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x56324cdcc935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x56324cdcd104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x56324ce93fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x56324cdb72bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56324cdb21bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56324cdbeef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x56324cdccc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x56324cdb21bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56324cdbeef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56324cdae81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56324cdad27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56324cdbec05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x56324cdae81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x56324cdbeef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x56324cdae568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56324cdad27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x56324cdbec05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x56324cdaf3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x56324cdad27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x56324cdacf07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56324cdaceb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56324ce5d8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x56324ce8badc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x56324ce87c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x56324ce7f7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x56324ce7f6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x56324ce7e8a2]
=================================
[dgx13:73239:0:73239] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  73239) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fe401df1ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fe401df1ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fe401df20aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe4a3642420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fe401e716f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fe401e99a49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fe401dab45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7fe401dae548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fe401dfb399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fe401dad65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fe401e6e52a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fe401f2317a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5616e3c1db08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5616e3c0e112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5616e3c0727a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5616e3c18c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5616e3c0881b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5616e3c2d70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fe4241f72fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5616e3c112bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5616e3bc4817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5616e3c0ff83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5616e3c0dd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5616e3c18ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5616e3c0881b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5616e3c18ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5616e3c0881b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5616e3c18ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5616e3c0881b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5616e3c18ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5616e3c0881b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5616e3c0727a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5616e3c18c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5616e3c0cfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5616e3c0727a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5616e3c26935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5616e3c27104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5616e3cedfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5616e3c112bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5616e3c0c1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5616e3c18ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5616e3c26c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5616e3c0c1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5616e3c18ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5616e3c0881b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5616e3c0727a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5616e3c18c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5616e3c0881b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5616e3c18ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5616e3c08568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5616e3c0727a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5616e3c18c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5616e3c093cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5616e3c0727a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5616e3c06f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5616e3c06eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5616e3cb78bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5616e3ce5adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5616e3ce1c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5616e3cd97ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5616e3cd96bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5616e3cd88a2]
=================================
2023-08-01 05:56:20,885 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:54679 -> ucx://127.0.0.1:59749
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f9e5424a300, tag: 0x51fcfccb220dc751, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:20,886 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:45103 -> ucx://127.0.0.1:59749
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd0e1b45300, tag: 0x3ec7272c2353570a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:20,888 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:45103 -> ucx://127.0.0.1:33595
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd0e1b45340, tag: 0xa4654a780bb7c1df, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:20,888 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34491 -> ucx://127.0.0.1:33595
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f0781ced340, tag: 0x68e3e686fdea7e2c, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:20,956 - distributed.nanny - WARNING - Restarting worker
2023-08-01 05:56:21,012 - distributed.nanny - WARNING - Restarting worker
Task exception was never retrieved
future: <Task finished name='Task-1064' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 135, in _listener_handler_coroutine
    endpoint = ucx_api.UCXEndpoint.create_from_conn_request(
  File "ucp/_libs/ucx_endpoint.pyx", line 315, in ucp._libs.ucx_api.UCXEndpoint.create_from_conn_request
  File "ucp/_libs/ucx_endpoint.pyx", line 231, in ucp._libs.ucx_api.UCXEndpoint.__init__
  File "ucp/_libs/utils.pyx", line 107, in ucp._libs.ucx_api.assert_ucs_status
ucp._libs.exceptions.UCXError: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-1065' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 135, in _listener_handler_coroutine
    endpoint = ucx_api.UCXEndpoint.create_from_conn_request(
  File "ucp/_libs/ucx_endpoint.pyx", line 315, in ucp._libs.ucx_api.UCXEndpoint.create_from_conn_request
  File "ucp/_libs/ucx_endpoint.pyx", line 231, in ucp._libs.ucx_api.UCXEndpoint.__init__
  File "ucp/_libs/utils.pyx", line 107, in ucp._libs.ucx_api.assert_ucs_status
ucp._libs.exceptions.UCXError: Connection reset by remote peer
[1690869381.212937] [dgx13:73221:0]       wireup_cm.c:1278 UCX  WARN  server ep 0x7fc1608b23c0 failed to connect CM lane on device lo, tl_bitmap 0x4 0x0, status Connection reset by remote peer
[1690869381.218498] [dgx13:73221:0]       wireup_cm.c:1278 UCX  WARN  server ep 0x7fc1608b2400 failed to connect CM lane on device lo, tl_bitmap 0x4 0x0, status Connection reset by remote peer
[dgx13:73221:0:73221] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  73221) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc160af0ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7fc160af0ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7fc160af10aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc20038b420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fc160b706f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fc160b98a49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fc17403c45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7fc17403f548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc160afa399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fc17403e65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fc160b6d52a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fc160c2217a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55bebecfab08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55bebeceb112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55bebece427a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55bebecf5c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55bebece581b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55bebecf5ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55bebed03a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55bebee139b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55bebeca1817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55bebececf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55bebecead36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55bebecf5ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55bebece581b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55bebecf5ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55bebece581b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55bebecf5ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55bebece581b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55bebecf5ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55bebece581b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55bebece427a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55bebecf5c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55bebece9fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55bebece427a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55bebed03935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55bebed04104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55bebedcafc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55bebecee2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55bebece91bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55bebecf5ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55bebed03c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55bebece91bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55bebecf5ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55bebece581b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55bebece427a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55bebecf5c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55bebece581b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55bebecf5ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55bebece5568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55bebece427a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55bebecf5c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55bebece63cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55bebece427a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55bebece3f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55bebece3eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55bebed948bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55bebedc2adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55bebedbec24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55bebedb67ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55bebedb66bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55bebedb58a2]
=================================
2023-08-01 05:56:21,474 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:58051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7f0781ced100, tag: 0x15b18bb30ff27f5a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7f0781ced100, tag: 0x15b18bb30ff27f5a, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-08-01 05:56:21,474 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:54679 -> ucx://127.0.0.1:58051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f9e5424a2c0, tag: 0x8a6409f031d583a6, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:21,474 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:58051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fd0e1b45100, tag: 0xa6d9468ad6096972, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fd0e1b45100, tag: 0xa6d9468ad6096972, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-01 05:56:21,474 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46665 -> ucx://127.0.0.1:58051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1801bb3200, tag: 0xf9702e9113b52fda, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:21,474 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34491 -> ucx://127.0.0.1:58051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f0781ced280, tag: 0x35ca62b84037dee4, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:21,474 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:45103 -> ucx://127.0.0.1:58051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd0e1b452c0, tag: 0xa6ed4cd8ad10231d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:21,474 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:58051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f9e5424a100, tag: 0x14f66452ffc9331d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f9e5424a100, tag: 0x14f66452ffc9331d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-01 05:56:21,475 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:58051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f1801bb3100, tag: 0xe837e8955d54acfc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f1801bb3100, tag: 0xe837e8955d54acfc, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-01 05:56:21,615 - distributed.nanny - WARNING - Restarting worker
[dgx13:73225:0:73225] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  73225) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f091f4c3ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f091f4c3ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f091f4c40aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f09ced39420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f091f5436f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f091f56ba49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f091f47d45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f091f480548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f091f4cd399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f091f47f65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f091f54052a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f091f5f517a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55b5e6febb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55b5e6fdc112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b5e6fd527a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55b5e6fe6c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b5e6fd681b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55b5e6ffb70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f094f8eb2fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55b5e6fdf2bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55b5e6f92817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55b5e6fddf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55b5e6fdbd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b5e6fe6ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b5e6fd681b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b5e6fe6ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b5e6fd681b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b5e6fe6ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b5e6fd681b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b5e6fe6ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b5e6fd681b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b5e6fd527a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55b5e6fe6c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55b5e6fdafa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b5e6fd527a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55b5e6ff4935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55b5e6ff5104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55b5e70bbfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55b5e6fdf2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55b5e6fda1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b5e6fe6ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55b5e6ff4c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55b5e6fda1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b5e6fe6ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b5e6fd681b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b5e6fd527a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55b5e6fe6c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55b5e6fd681b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55b5e6fe6ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55b5e6fd6568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b5e6fd527a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55b5e6fe6c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55b5e6fd73cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55b5e6fd527a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55b5e6fd4f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55b5e6fd4eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55b5e70858bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55b5e70b3adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55b5e70afc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55b5e70a77ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55b5e70a76bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55b5e70a68a2]
=================================
2023-08-01 05:56:22,371 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34491 -> ucx://127.0.0.1:56915
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f0781ced100, tag: 0x32063b3e21a67055, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:22,371 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46665 -> ucx://127.0.0.1:56915
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1801bb3200, tag: 0x4341f71aa054ee66, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:22,371 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:45103 -> ucx://127.0.0.1:56915
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd0e1b45100, tag: 0xe65a95a96c3f470, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:22,372 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56915
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f1801bb3100, tag: 0x69599afd24bfcfd5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f1801bb3100, tag: 0x69599afd24bfcfd5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-01 05:56:22,372 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56915
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f0781ced280, tag: 0x97e77c01ff44a183, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f0781ced280, tag: 0x97e77c01ff44a183, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-01 05:56:22,372 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56915
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd0e1b452c0, tag: 0x82659d00d4b3228f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd0e1b452c0, tag: 0x82659d00d4b3228f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-08-01 05:56:22,371 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:56915
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f9e5424a100, tag: 0x1671c00d8b2ab374, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f9e5424a100, tag: 0x1671c00d8b2ab374, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-08-01 05:56:22,448 - distributed.nanny - WARNING - Restarting worker
2023-08-01 05:56:22,549 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:22,549 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:22,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:22,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:23,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:23,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:73752:0:73752] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  73752) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f82cf2f1ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f82cf2f1ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f82cf2f20aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f837e9e8420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f82cf3716f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f82cf399a49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f82cf2ab45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f82cf2ae548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f82cf2fb399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f82cf2ad65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f82cf36e52a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f82cf42317a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x557e1cbbab08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x557e1cbab112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557e1cba427a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x557e1cbb5c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557e1cba581b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557e1cbb5ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x557e1cbc3a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x557e1ccd39b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x557e1cb61817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x557e1cbacf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x557e1cbaad36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557e1cbb5ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557e1cba581b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557e1cbb5ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557e1cba581b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557e1cbb5ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557e1cba581b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557e1cbb5ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557e1cba581b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557e1cba427a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x557e1cbb5c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x557e1cba9fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557e1cba427a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x557e1cbc3935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x557e1cbc4104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x557e1cc8afc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x557e1cbae2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x557e1cba91bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557e1cbb5ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x557e1cbc3c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x557e1cba91bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557e1cbb5ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557e1cba581b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557e1cba427a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x557e1cbb5c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x557e1cba581b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x557e1cbb5ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x557e1cba5568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557e1cba427a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x557e1cbb5c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x557e1cba63cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x557e1cba427a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x557e1cba3f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x557e1cba3eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x557e1cc548bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x557e1cc82adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x557e1cc7ec24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x557e1cc767ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x557e1cc766bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x557e1cc758a2]
=================================
[dgx13:73755:0:73755] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  73755) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f5e4411fced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f5e4411fee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f5e441200aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f5ee37ed420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f5e4419f6f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f5e441c7a49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f5e440d945f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f5e440dc548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f5e44129399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f5e440db65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f5e4419c52a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f5e4425117a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55a77d039b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55a77d02a112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a77d02327a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a77d034c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a77d02481b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a77d034ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55a77d042a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55a77d1529b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55a77cfe0817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55a77d02bf83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55a77d029d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a77d034ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a77d02481b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a77d034ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a77d02481b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a77d034ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a77d02481b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a77d034ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a77d02481b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a77d02327a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a77d034c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55a77d028fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a77d02327a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55a77d042935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55a77d043104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55a77d109fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55a77d02d2bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55a77d0281bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a77d034ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55a77d042c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55a77d0281bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a77d034ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a77d02481b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a77d02327a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a77d034c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55a77d02481b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55a77d034ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55a77d024568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a77d02327a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55a77d034c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55a77d0253cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55a77d02327a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55a77d022f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55a77d022eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55a77d0d38bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55a77d101adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55a77d0fdc24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55a77d0f57ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55a77d0f56bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55a77d0f48a2]
=================================
2023-08-01 05:56:24,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:24,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:24,171 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-01 05:56:24,171 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-01 05:56:24,211 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 2)
Function:  <dask.layers.CallableLazyImport object at 0x7f98f8
args:      ([                key   payload
306823    202872806  57595204
306837    807583227  83707562
287281    810228802  12972184
279655    203566825  82054809
308986    854228915  62398502
...             ...       ...
99992499  810583170  66374968
99992508  866094477  53639545
99992510  207251339  50365345
99992511  600341196  21677289
99992404  310924515  80190288

[12503879 rows x 2 columns],                 key   payload
18658     963573657  89099239
18667     931889763  58541675
18672     963260844  45553535
120993    316516704  67141660
121003    960757605  68561580
...             ...       ...
99995392  946677514  40263142
99995400  921441481   6363084
99995409  937344322  77393466
99995415  954990547  26346670
99995416  963223324  57293349

[12499576 rows x 2 columns],                  key   payload
31973      432110429  15451182
31975     1055454091  89838610
31976     1024071644  15265133
11466     1044248299  84330162
31977     1058087456  85968777
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-01 05:56:24,244 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46665 -> ucx://127.0.0.1:56899
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7f1801bb3200, tag: 0x7c77abb8a420e383, nbytes: 99976608, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:24,275 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-054f65580a5efedc40c26858beb83d02', 0)
Function:  <dask.layers.CallableLazyImport object at 0x7f0226
args:      ([               key   payload
shuffle                     
0            95189  73668133
0           236934  68743553
0          1091053  98939135
0           239432  20672733
0          1078182    425075
...            ...       ...
0        799807002  45917459
0        799808102  24461658
0        799981439  15730973
0        799863055  84135383
0        799906812  26016308

[12505522 rows x 2 columns],                key   payload
shuffle                     
1            20123  71104057
1            31929  71152421
1           155164  50890630
1            19147  59620002
1           121312  26561539
...            ...       ...
1        799939826  34152057
1        799945953  50619648
1        799961180  36116335
1        799907854   3903210
1        799976462  24627057

[12497568 rows x 2 columns],                key   payload
shuffle                     
2           640051  31788162
2           606398  55459807
2           347955  79065485
2           548919  96354464
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-01 05:56:24,277 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34491 -> ucx://127.0.0.1:56899
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f0781ced280, tag: 0x76055466c4db1783, nbytes: 100015592, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:24,283 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-054f65580a5efedc40c26858beb83d02', 1)
Function:  <dask.layers.CallableLazyImport object at 0x7fcb98
args:      ([               key   payload
shuffle                     
0           212285  86251944
0            36288  64399552
0          1129388  92757807
0          1123241  19328370
0           385887  59437470
...            ...       ...
0        799907148  35539445
0        799831680  82695169
0        799867465  82546138
0        799770652  93279016
0        799782932  92918484

[12497508 rows x 2 columns],                key   payload
shuffle                     
1            69676  86217119
1            10465   2620369
1            23760  33324939
1            24811  26887056
1           125127  86590369
...            ...       ...
1        799951558  92742124
1        799980454  70039859
1        799940803  28815290
1        799915029    787592
1        799970911  27799790

[12503907 rows x 2 columns],                key   payload
shuffle                     
2           633553  84783673
2           579279  39780332
2           434007   3998240
2           619564  50853169
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-01 05:56:24,321 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34491 -> ucx://127.0.0.1:44051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f0781ced100, tag: 0x57ea28c2cc338255, nbytes: 99997352, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:24,340 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 4)
Function:  <dask.layers.CallableLazyImport object at 0x7f98f8
args:      ([                key   payload
306819    848734835  67755028
306822    844496765  37694700
306836    803377505  99717346
287266    814189304  85029734
279664    810255701  22315008
...             ...       ...
99992493  840936299  72796432
99992495  801090280   7422061
99992498  819017188   1058487
99992500  814787900  68527646
99992402  869342954  90215609

[12500589 rows x 2 columns],                 key   payload
18660     946511650  76336640
18666     921035989  69611191
18671     521174524  38798352
18675     905716499  71106662
18679     931029412  24894980
...             ...       ...
99995485  956133494  56553160
99995402  952668244  43881719
99995404  937805937  30989508
99995413  908183862  88487519
99995418  902158431  46235100

[12501715 rows x 2 columns],                  key   payload
31974      437015869  84893560
31978      330012373  70152722
31979      730158638  88254522
11458      733821200   9901127
31989      437131415   7370839
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-01 05:56:24,342 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:54679 -> ucx://127.0.0.1:56899
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f9e5424a2c0, tag: 0x81adcc329e01d3aa, nbytes: 100001664, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:24,407 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46665 -> ucx://127.0.0.1:44051
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1801bb3300, tag: 0xca96a32e81468006, nbytes: 99980632, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-6759' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-08-01 05:56:24,416 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:45103 -> ucx://127.0.0.1:56899
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 289, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-08-01 05:56:24,465 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-01 05:56:24,466 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-01 05:56:24,502 - distributed.nanny - WARNING - Restarting worker
2023-08-01 05:56:24,547 - distributed.nanny - WARNING - Restarting worker
[dgx13:73760:0:73760] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  73760) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f91712f1ced]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2aee4) [0x7f91712f1ee4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b0aa) [0x7f91712f20aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f92149f9420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f91713716f4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f9171399a49]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f91712ab45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23548) [0x7f91712ae548]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f91712fb399]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f91712ad65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f917136e52a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f917142317a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x560e3eab4b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x560e3eaa5112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x560e3ea9e27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x560e3eaafc05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x560e3ea9f81b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x560e3eac470e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f91955a62fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x560e3eaa82bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x560e3ea5b817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x560e3eaa6f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x560e3eaa4d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x560e3eaafef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x560e3ea9f81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x560e3eaafef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x560e3ea9f81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x560e3eaafef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x560e3ea9f81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x560e3eaafef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x560e3ea9f81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x560e3ea9e27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x560e3eaafc05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x560e3eaa3fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x560e3ea9e27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x560e3eabd935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x560e3eabe104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x560e3eb84fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x560e3eaa82bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x560e3eaa31bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x560e3eaafef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x560e3eabdc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x560e3eaa31bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x560e3eaafef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x560e3ea9f81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x560e3ea9e27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x560e3eaafc05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x560e3ea9f81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x560e3eaafef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x560e3ea9f568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x560e3ea9e27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x560e3eaafc05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x560e3eaa03cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x560e3ea9e27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x560e3ea9df07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x560e3ea9deb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x560e3eb4e8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x560e3eb7cadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x560e3eb78c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x560e3eb707ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x560e3eb706bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x560e3eb6f8a2]
=================================
2023-08-01 05:56:24,900 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  <dask.layers.CallableLazyImport object at 0x7fcb98
args:      ([                key   payload
306824    805494958     66893
306830    865772000  14096643
306841    866320720   1035290
306842    851078402  88429607
287265    709495995   7805669
...             ...       ...
99992504  409702886  71239787
99992386  860212489  70162302
99992389  806358933  65867236
99992409  507209833  29795883
99992414  800846165  61150211

[12497796 rows x 2 columns],                 key   payload
18670     938445100  72528511
120992    940328529  97851655
120994    947499611  30649088
121000    948564744  42278874
121005    910965129  71210274
...             ...       ...
99995471  965786063  70541346
99995484  962561653   5597102
99995403  964263230  90761609
99995412  960056361  85907219
99995414  937573577  26398366

[12497151 rows x 2 columns],                  key   payload
31968      531064474  31971482
31990      429532533  12297064
31993     1063602944  56330063
11481      435934946  26499763
31997     1033018957   8781169
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-01 05:56:24,924 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:54679 -> ucx://127.0.0.1:45315
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f9e5424a340, tag: 0x2674503972ad4dcd, nbytes: 100050144, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:24,924 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:45103 -> ucx://127.0.0.1:45315
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd0e1b452c0, tag: 0x6906b5d9329f838b, nbytes: 99991336, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:24,934 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-054f65580a5efedc40c26858beb83d02', 3)
Function:  <dask.layers.CallableLazyImport object at 0x7f12c1
args:      ([               key   payload
shuffle                     
0           212934  83984221
0           173437  41245833
0          1048872  46541297
0           155952  93819673
0          1080510   3193472
...            ...       ...
0        799805664  41584337
0        799782116   8900574
0        799824603  86890132
0        799853677  41614381
0        799745077  96808796

[12497076 rows x 2 columns],                key   payload
shuffle                     
1           120555  63853784
1            96796  69184603
1            17425  75587283
1            88109  17605495
1             6996  16081619
...            ...       ...
1        799926437  11774517
1        799953096  81438348
1        799866450  73417126
1        799981661  59953131
1        799993669  72569608

[12501362 rows x 2 columns],                key   payload
shuffle                     
2           628829  94472122
2           363301  78337775
2           428905   9476436
2           632833  67656435
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-08-01 05:56:24,936 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-01 05:56:24,936 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-08-01 05:56:24,936 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46665 -> ucx://127.0.0.1:45315
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f1801bb3300, tag: 0xcd3da9665ae14027, nbytes: 99985208, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:24,939 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34491 -> ucx://127.0.0.1:45315
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f0781ced100, tag: 0x9f801c891f441fad, nbytes: 100020640, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:24,940 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:34491
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 359, in read
    await self.ep.recv(header)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #089] ep: 0x7fd0e1b45140, tag: 0x6375835f4a6af837, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #089] ep: 0x7fd0e1b45140, tag: 0x6375835f4a6af837, nbytes: 16, type: <class 'numpy.ndarray'>>: Message truncated")
2023-08-01 05:56:24,940 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:34491 -> ucx://127.0.0.1:45103
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #090] ep: 0x7f0781ced200, tag: 0x6375835f4a6af837, nbytes: 100020640, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-08-01 05:56:24,972 - distributed.nanny - WARNING - Restarting worker
2023-08-01 05:56:26,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:26,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:26,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:26,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-08-01 05:56:26,542 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-08-01 05:56:26,542 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
