============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.2, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-10-17 05:44:04,967 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:04,972 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40509 instead
  warnings.warn(
2023-10-17 05:44:04,977 - distributed.scheduler - INFO - State start
2023-10-17 05:44:05,002 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:05,003 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-17 05:44:05,004 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40509/status
2023-10-17 05:44:05,004 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:44:05,263 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41779'
2023-10-17 05:44:05,282 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40957'
2023-10-17 05:44:05,285 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36153'
2023-10-17 05:44:05,296 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42689'
2023-10-17 05:44:07,039 - distributed.scheduler - INFO - Receive client connection: Client-2d6ff6a8-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:07,059 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49494
2023-10-17 05:44:07,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:07,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:07,413 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:07,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:07,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:07,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:07,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:07,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:07,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:07,467 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:07,467 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:07,467 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-10-17 05:44:07,659 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41831
2023-10-17 05:44:07,659 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41831
2023-10-17 05:44:07,660 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42779
2023-10-17 05:44:07,660 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-17 05:44:07,660 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:07,660 - distributed.worker - INFO -               Threads:                          4
2023-10-17 05:44:07,660 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-17 05:44:07,660 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-xtlc88ld
2023-10-17 05:44:07,660 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-074e3bc1-0ade-4d23-9cb6-dd858aa769f6
2023-10-17 05:44:07,660 - distributed.worker - INFO - Starting Worker plugin RMMSetup-79e75f83-7501-4ddf-8f78-123ebccab47e
2023-10-17 05:44:07,661 - distributed.worker - INFO - Starting Worker plugin PreImport-581f425b-17ac-46f5-a90d-7fa1587343c3
2023-10-17 05:44:07,661 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:07,909 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41831', status: init, memory: 0, processing: 0>
2023-10-17 05:44:07,910 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41831
2023-10-17 05:44:07,910 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49510
2023-10-17 05:44:07,911 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:07,912 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-17 05:44:07,912 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:07,914 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-17 05:44:08,982 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46771
2023-10-17 05:44:08,982 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46771
2023-10-17 05:44:08,982 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40609
2023-10-17 05:44:08,983 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-17 05:44:08,983 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:08,983 - distributed.worker - INFO -               Threads:                          4
2023-10-17 05:44:08,983 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-17 05:44:08,983 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-a1fnzih7
2023-10-17 05:44:08,983 - distributed.worker - INFO - Starting Worker plugin PreImport-11e5665e-5752-468b-aa6d-9adbdc2ce7a5
2023-10-17 05:44:08,984 - distributed.worker - INFO - Starting Worker plugin RMMSetup-11271b81-df57-4efc-a429-bf4447b797fd
2023-10-17 05:44:08,984 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4e5618dd-6dc8-4e03-b7de-7dd491f31d8a
2023-10-17 05:44:08,984 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:09,035 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46771', status: init, memory: 0, processing: 0>
2023-10-17 05:44:09,036 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46771
2023-10-17 05:44:09,036 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49534
2023-10-17 05:44:09,039 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:09,040 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-17 05:44:09,040 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:09,044 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-17 05:44:09,298 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37001
2023-10-17 05:44:09,299 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37001
2023-10-17 05:44:09,299 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46511
2023-10-17 05:44:09,299 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-17 05:44:09,299 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:09,299 - distributed.worker - INFO -               Threads:                          4
2023-10-17 05:44:09,299 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-17 05:44:09,300 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-zpeugiqv
2023-10-17 05:44:09,300 - distributed.worker - INFO - Starting Worker plugin PreImport-67e768c4-1350-4f50-91a1-090fc4537072
2023-10-17 05:44:09,300 - distributed.worker - INFO - Starting Worker plugin RMMSetup-07a493bc-53c0-4d97-9cd9-fa73f8383860
2023-10-17 05:44:09,301 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-69f9383f-7042-47cf-8fd7-6aed9c7aa526
2023-10-17 05:44:09,301 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:09,304 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36895
2023-10-17 05:44:09,305 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36895
2023-10-17 05:44:09,305 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44097
2023-10-17 05:44:09,305 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-17 05:44:09,305 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:09,305 - distributed.worker - INFO -               Threads:                          4
2023-10-17 05:44:09,305 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-10-17 05:44:09,305 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-lj5g4a8u
2023-10-17 05:44:09,306 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-101f3eeb-e2bb-4304-b423-f060a2e52b5c
2023-10-17 05:44:09,306 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2db8f11b-e841-4867-b8b7-34548127f731
2023-10-17 05:44:09,306 - distributed.worker - INFO - Starting Worker plugin PreImport-95bf8e4c-0d62-42bd-b0b7-3256a7d05456
2023-10-17 05:44:09,306 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:09,333 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36895', status: init, memory: 0, processing: 0>
2023-10-17 05:44:09,334 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36895
2023-10-17 05:44:09,334 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49548
2023-10-17 05:44:09,335 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:09,336 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-17 05:44:09,336 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:09,338 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-17 05:44:09,338 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37001', status: init, memory: 0, processing: 0>
2023-10-17 05:44:09,339 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37001
2023-10-17 05:44:09,340 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49544
2023-10-17 05:44:09,341 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:09,342 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-17 05:44:09,342 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:09,345 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-17 05:44:09,426 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-17 05:44:09,426 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-17 05:44:09,427 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-17 05:44:09,451 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-10-17 05:44:09,456 - distributed.scheduler - INFO - Remove client Client-2d6ff6a8-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:09,456 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49494; closing.
2023-10-17 05:44:09,457 - distributed.scheduler - INFO - Remove client Client-2d6ff6a8-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:09,457 - distributed.scheduler - INFO - Close client connection: Client-2d6ff6a8-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:09,458 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41779'. Reason: nanny-close
2023-10-17 05:44:09,458 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:09,459 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40957'. Reason: nanny-close
2023-10-17 05:44:09,460 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:09,460 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36153'. Reason: nanny-close
2023-10-17 05:44:09,460 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46771. Reason: nanny-close
2023-10-17 05:44:09,460 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:09,461 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36895. Reason: nanny-close
2023-10-17 05:44:09,461 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42689'. Reason: nanny-close
2023-10-17 05:44:09,461 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:09,461 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37001. Reason: nanny-close
2023-10-17 05:44:09,462 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41831. Reason: nanny-close
2023-10-17 05:44:09,463 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49548; closing.
2023-10-17 05:44:09,463 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-17 05:44:09,463 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-17 05:44:09,463 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36895', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521449.463481')
2023-10-17 05:44:09,464 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-17 05:44:09,464 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:09,465 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49534; closing.
2023-10-17 05:44:09,465 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-17 05:44:09,465 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:09,465 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49544; closing.
2023-10-17 05:44:09,466 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46771', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521449.466212')
2023-10-17 05:44:09,466 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:09,467 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:09,467 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37001', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521449.4672935')
2023-10-17 05:44:09,467 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49510; closing.
2023-10-17 05:44:09,468 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41831', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521449.4682434')
2023-10-17 05:44:09,468 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:44:10,876 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:44:10,877 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:44:10,877 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:44:10,878 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-17 05:44:10,879 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-10-17 05:44:13,297 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:13,302 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38507 instead
  warnings.warn(
2023-10-17 05:44:13,308 - distributed.scheduler - INFO - State start
2023-10-17 05:44:13,335 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:13,336 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:44:13,337 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38507/status
2023-10-17 05:44:13,338 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:44:13,551 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35419'
2023-10-17 05:44:13,567 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42309'
2023-10-17 05:44:13,582 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46839'
2023-10-17 05:44:13,605 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39269'
2023-10-17 05:44:13,609 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34071'
2023-10-17 05:44:13,621 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38995'
2023-10-17 05:44:13,631 - distributed.scheduler - INFO - Receive client connection: Client-3291a937-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:13,642 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33183'
2023-10-17 05:44:13,647 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52882
2023-10-17 05:44:13,656 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39881'
2023-10-17 05:44:15,768 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:15,768 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:15,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:15,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:15,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:15,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:15,776 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:15,779 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:15,780 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:15,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:15,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:15,893 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:15,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:15,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:15,947 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:15,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:15,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:16,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:16,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:16,007 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:16,008 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:16,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:16,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:16,100 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:20,641 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46649
2023-10-17 05:44:20,642 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46649
2023-10-17 05:44:20,642 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44027
2023-10-17 05:44:20,642 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:20,642 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:20,642 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:20,642 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:20,642 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mduxv8tw
2023-10-17 05:44:20,643 - distributed.worker - INFO - Starting Worker plugin PreImport-0cb2bdda-be3b-4007-9bab-c754b1580a22
2023-10-17 05:44:20,643 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e802595-f3e8-40d7-a647-d00de84e748a
2023-10-17 05:44:20,643 - distributed.worker - INFO - Starting Worker plugin RMMSetup-df2d0b11-2716-4096-b91b-b1ed5c208843
2023-10-17 05:44:20,650 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35203
2023-10-17 05:44:20,651 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35203
2023-10-17 05:44:20,651 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44473
2023-10-17 05:44:20,651 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:20,651 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:20,651 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:20,652 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:20,652 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w923mo14
2023-10-17 05:44:20,652 - distributed.worker - INFO - Starting Worker plugin RMMSetup-909b450e-59a1-4d6c-9ecc-31b65d73ef9e
2023-10-17 05:44:21,080 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a6a4091e-961c-46d3-bf27-439a91706ce5
2023-10-17 05:44:21,080 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,080 - distributed.worker - INFO - Starting Worker plugin PreImport-f7cc174a-dc39-4265-b3fc-c9768b1e02fe
2023-10-17 05:44:21,081 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,146 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46649', status: init, memory: 0, processing: 0>
2023-10-17 05:44:21,149 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46649
2023-10-17 05:44:21,149 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55206
2023-10-17 05:44:21,150 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:21,151 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:21,151 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,153 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:21,161 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35203', status: init, memory: 0, processing: 0>
2023-10-17 05:44:21,163 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35203
2023-10-17 05:44:21,163 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55220
2023-10-17 05:44:21,164 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:21,166 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:21,166 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,169 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:21,497 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46551
2023-10-17 05:44:21,498 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46551
2023-10-17 05:44:21,498 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39379
2023-10-17 05:44:21,498 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:21,498 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,498 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:21,498 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:21,498 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6h0zi4sf
2023-10-17 05:44:21,499 - distributed.worker - INFO - Starting Worker plugin RMMSetup-50dff1f2-f38c-4b45-a928-0a5a52638fae
2023-10-17 05:44:21,500 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37923
2023-10-17 05:44:21,501 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37923
2023-10-17 05:44:21,501 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35139
2023-10-17 05:44:21,501 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:21,501 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,502 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:21,502 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:21,502 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fx26f78k
2023-10-17 05:44:21,502 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6841f2a9-4c48-4291-b286-89c0b94b1114
2023-10-17 05:44:21,543 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36159
2023-10-17 05:44:21,543 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43737
2023-10-17 05:44:21,544 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36159
2023-10-17 05:44:21,544 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43737
2023-10-17 05:44:21,544 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41223
2023-10-17 05:44:21,544 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36039
2023-10-17 05:44:21,544 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:21,544 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:21,544 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,544 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,544 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:21,544 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:21,544 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:21,544 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:21,544 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qqj79aiv
2023-10-17 05:44:21,544 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w4mwvsay
2023-10-17 05:44:21,545 - distributed.worker - INFO - Starting Worker plugin RMMSetup-70e2ca97-0c75-430c-9190-2191ce8bd3fa
2023-10-17 05:44:21,545 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c2ad6080-2332-45ba-ba4a-c8df03786996
2023-10-17 05:44:21,556 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34891
2023-10-17 05:44:21,557 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34891
2023-10-17 05:44:21,557 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35235
2023-10-17 05:44:21,557 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:21,557 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,557 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:21,557 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:21,557 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-425scc44
2023-10-17 05:44:21,558 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fd8a8fb1-667c-4928-abf7-b81a0331308e
2023-10-17 05:44:21,558 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fb3428e0-637e-4b26-8709-349758273f35
2023-10-17 05:44:21,694 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35881
2023-10-17 05:44:21,695 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35881
2023-10-17 05:44:21,696 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37809
2023-10-17 05:44:21,696 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:21,696 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:21,696 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:21,696 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:21,696 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pqmy5xp2
2023-10-17 05:44:21,697 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ef9ec333-aa72-4ad9-8e9b-8a92e5b26f62
2023-10-17 05:44:22,045 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3475cc46-d6fc-4d09-88c4-f6ecbff91e08
2023-10-17 05:44:22,046 - distributed.worker - INFO - Starting Worker plugin PreImport-7c1211da-cdf5-4901-a12e-180aefe939d3
2023-10-17 05:44:22,046 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,055 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cc7985b9-c346-417a-afa1-c30f8622fc02
2023-10-17 05:44:22,057 - distributed.worker - INFO - Starting Worker plugin PreImport-5ac5e463-2b7b-417f-a48c-bd5b2a59d8de
2023-10-17 05:44:22,057 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,062 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-93e957de-332e-4b65-8822-f516752cc0cd
2023-10-17 05:44:22,064 - distributed.worker - INFO - Starting Worker plugin PreImport-20b74936-b471-41e9-afd8-69097493cd70
2023-10-17 05:44:22,064 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,070 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a2b3588c-0832-427f-b292-bd0c07b354e3
2023-10-17 05:44:22,074 - distributed.worker - INFO - Starting Worker plugin PreImport-0528a918-ad6c-4685-bebb-3fe8b8eda9a2
2023-10-17 05:44:22,076 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,079 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b5d7a9c1-7bcf-462d-a1ca-fcd1e4acf085
2023-10-17 05:44:22,079 - distributed.worker - INFO - Starting Worker plugin PreImport-d311c0e4-a612-46ca-8f7f-862e37606e5b
2023-10-17 05:44:22,079 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,081 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37923', status: init, memory: 0, processing: 0>
2023-10-17 05:44:22,082 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37923
2023-10-17 05:44:22,082 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55236
2023-10-17 05:44:22,083 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:22,084 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:22,084 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,086 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:22,097 - distributed.worker - INFO - Starting Worker plugin PreImport-b0946584-654a-4ead-a77b-9762f9ced845
2023-10-17 05:44:22,098 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,105 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43737', status: init, memory: 0, processing: 0>
2023-10-17 05:44:22,106 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43737
2023-10-17 05:44:22,107 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55248
2023-10-17 05:44:22,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:22,115 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:22,116 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,120 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:22,125 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46551', status: init, memory: 0, processing: 0>
2023-10-17 05:44:22,127 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46551
2023-10-17 05:44:22,127 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55264
2023-10-17 05:44:22,129 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35881', status: init, memory: 0, processing: 0>
2023-10-17 05:44:22,130 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35881
2023-10-17 05:44:22,130 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55292
2023-10-17 05:44:22,131 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:22,132 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36159', status: init, memory: 0, processing: 0>
2023-10-17 05:44:22,132 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:22,133 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36159
2023-10-17 05:44:22,133 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55280
2023-10-17 05:44:22,133 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:22,133 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,134 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:22,134 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,135 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34891', status: init, memory: 0, processing: 0>
2023-10-17 05:44:22,136 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:22,136 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:22,136 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34891
2023-10-17 05:44:22,137 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55302
2023-10-17 05:44:22,138 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:22,138 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,138 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:22,139 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:22,139 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:22,139 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:22,141 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:22,143 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:22,166 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:22,167 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:22,167 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:22,167 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:22,167 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:22,168 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:22,168 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:22,169 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:22,176 - distributed.scheduler - INFO - Remove client Client-3291a937-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:22,177 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52882; closing.
2023-10-17 05:44:22,177 - distributed.scheduler - INFO - Remove client Client-3291a937-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:22,178 - distributed.scheduler - INFO - Close client connection: Client-3291a937-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:22,179 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35419'. Reason: nanny-close
2023-10-17 05:44:22,179 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42309'. Reason: nanny-close
2023-10-17 05:44:22,179 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:22,180 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46839'. Reason: nanny-close
2023-10-17 05:44:22,180 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39269'. Reason: nanny-close
2023-10-17 05:44:22,181 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:22,181 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43737. Reason: nanny-close
2023-10-17 05:44:22,181 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34071'. Reason: nanny-close
2023-10-17 05:44:22,181 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38995'. Reason: nanny-close
2023-10-17 05:44:22,181 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:22,182 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46649. Reason: nanny-close
2023-10-17 05:44:22,182 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33183'. Reason: nanny-close
2023-10-17 05:44:22,182 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39881'. Reason: nanny-close
2023-10-17 05:44:22,182 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:22,183 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35203. Reason: nanny-close
2023-10-17 05:44:22,183 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37923. Reason: nanny-close
2023-10-17 05:44:22,184 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:22,184 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:22,184 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55206; closing.
2023-10-17 05:44:22,184 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:22,184 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:22,185 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46649', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521462.1850977')
2023-10-17 05:44:22,185 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:22,185 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:22,185 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:22,185 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35881. Reason: nanny-close
2023-10-17 05:44:22,185 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:22,186 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:22,186 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34891. Reason: nanny-close
2023-10-17 05:44:22,186 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:22,186 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46551. Reason: nanny-close
2023-10-17 05:44:22,186 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55248; closing.
2023-10-17 05:44:22,187 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:22,187 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36159. Reason: nanny-close
2023-10-17 05:44:22,187 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:22,187 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:22,188 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:22,189 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43737', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521462.189065')
2023-10-17 05:44:22,189 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:22,189 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55220; closing.
2023-10-17 05:44:22,190 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:22,190 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:22,191 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:22,192 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35203', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521462.1923702')
2023-10-17 05:44:22,192 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:22,193 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55236; closing.
2023-10-17 05:44:22,195 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:22,195 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:55220>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:55220>: Stream is closed
2023-10-17 05:44:22,199 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:55248>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-17 05:44:22,200 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37923', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521462.2001302')
2023-10-17 05:44:22,201 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55292; closing.
2023-10-17 05:44:22,201 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55302; closing.
2023-10-17 05:44:22,202 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35881', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521462.202822')
2023-10-17 05:44:22,203 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34891', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521462.2037826')
2023-10-17 05:44:22,204 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55264; closing.
2023-10-17 05:44:22,205 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55280; closing.
2023-10-17 05:44:22,206 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46551', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521462.2059262')
2023-10-17 05:44:22,206 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36159', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521462.2067113')
2023-10-17 05:44:22,207 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:44:24,249 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:44:24,249 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:44:24,250 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:44:24,251 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:44:24,252 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-10-17 05:44:26,802 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:26,808 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43591 instead
  warnings.warn(
2023-10-17 05:44:26,813 - distributed.scheduler - INFO - State start
2023-10-17 05:44:26,841 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:26,843 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:44:26,844 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43591/status
2023-10-17 05:44:26,844 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:44:27,070 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41651'
2023-10-17 05:44:27,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45839'
2023-10-17 05:44:27,111 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34889'
2023-10-17 05:44:27,115 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41183'
2023-10-17 05:44:27,129 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45881'
2023-10-17 05:44:27,140 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43971'
2023-10-17 05:44:27,154 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36939'
2023-10-17 05:44:27,168 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40295'
2023-10-17 05:44:27,355 - distributed.scheduler - INFO - Receive client connection: Client-3a9adfc6-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:27,372 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55430
2023-10-17 05:44:29,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:29,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:29,240 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:29,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:29,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:29,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:29,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:29,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:29,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:29,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:29,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:29,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:29,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:29,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:29,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:29,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:29,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:29,253 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:29,253 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:29,257 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:29,258 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:29,258 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:29,258 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:29,259 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:33,330 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42707
2023-10-17 05:44:33,330 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42707
2023-10-17 05:44:33,330 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37853
2023-10-17 05:44:33,330 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,331 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,331 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:33,331 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:33,331 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0ymj1k7v
2023-10-17 05:44:33,331 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dfd5982d-a77c-44d3-8eab-b1f1bb52e5c3
2023-10-17 05:44:33,332 - distributed.worker - INFO - Starting Worker plugin RMMSetup-56019208-667e-4781-9fa4-dcddbe33ced5
2023-10-17 05:44:33,350 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35157
2023-10-17 05:44:33,351 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35157
2023-10-17 05:44:33,351 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45529
2023-10-17 05:44:33,351 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,350 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46547
2023-10-17 05:44:33,351 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,351 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46547
2023-10-17 05:44:33,351 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38483
2023-10-17 05:44:33,351 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:33,351 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,351 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,351 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:33,351 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-55c0zt6y
2023-10-17 05:44:33,351 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:33,351 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:33,352 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2tf6xqz2
2023-10-17 05:44:33,352 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e78a9906-7834-4b87-aee2-aaea4aa3e3a4
2023-10-17 05:44:33,352 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f17f9673-81b4-4b7e-89f3-0136348d66df
2023-10-17 05:44:33,363 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40033
2023-10-17 05:44:33,364 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40033
2023-10-17 05:44:33,364 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35077
2023-10-17 05:44:33,364 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,364 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,364 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:33,364 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:33,364 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-de99o2rb
2023-10-17 05:44:33,364 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44629
2023-10-17 05:44:33,364 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44629
2023-10-17 05:44:33,365 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43179
2023-10-17 05:44:33,365 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,365 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,365 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-14e3b284-8b95-4f16-814d-a9a58797a6f2
2023-10-17 05:44:33,365 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:33,365 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:33,365 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3x2st8ez
2023-10-17 05:44:33,365 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d20285ed-6778-46f4-8c1c-e080a5a89a40
2023-10-17 05:44:33,366 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aec47cfd-5064-46ce-aaa5-3c7b17be8601
2023-10-17 05:44:33,366 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0c72006-ef25-4684-b5e9-5f883d64c96a
2023-10-17 05:44:33,372 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37995
2023-10-17 05:44:33,372 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37995
2023-10-17 05:44:33,372 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37369
2023-10-17 05:44:33,372 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,372 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,373 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:33,373 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:33,373 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rwflwsz4
2023-10-17 05:44:33,373 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0e4b918b-00f6-4b39-afa6-b441010695aa
2023-10-17 05:44:33,412 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42737
2023-10-17 05:44:33,413 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42737
2023-10-17 05:44:33,413 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33485
2023-10-17 05:44:33,413 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,413 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44299
2023-10-17 05:44:33,413 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,413 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44299
2023-10-17 05:44:33,413 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35161
2023-10-17 05:44:33,413 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:33,413 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,414 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,414 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:33,414 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zu4ocs5r
2023-10-17 05:44:33,414 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:33,414 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:33,414 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ps0_lgmg
2023-10-17 05:44:33,414 - distributed.worker - INFO - Starting Worker plugin RMMSetup-95b519aa-ece0-4e8b-93c4-8c3911e6135a
2023-10-17 05:44:33,414 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cdbcebbe-4930-4e5d-b92c-cc634dec0412
2023-10-17 05:44:33,446 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-13e724a6-4fbc-4fa6-ae9b-3c2fe2cd03b3
2023-10-17 05:44:33,446 - distributed.worker - INFO - Starting Worker plugin PreImport-44048cef-9fe4-4600-b2f2-57e9ab0b543c
2023-10-17 05:44:33,446 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,447 - distributed.worker - INFO - Starting Worker plugin PreImport-25de4c03-c8f5-4b3d-a948-1990a31256a8
2023-10-17 05:44:33,448 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,448 - distributed.worker - INFO - Starting Worker plugin PreImport-fe9a1b95-7578-41e7-ac3f-f2bdcfbebc7d
2023-10-17 05:44:33,449 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,448 - distributed.worker - INFO - Starting Worker plugin PreImport-9d19d9c2-bc42-4859-8999-d3d22e811d7b
2023-10-17 05:44:33,449 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,450 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fa804310-f336-49fc-8ef1-b702ada8c433
2023-10-17 05:44:33,450 - distributed.worker - INFO - Starting Worker plugin PreImport-24f68749-7b7b-44cd-a137-e1d8db46fe45
2023-10-17 05:44:33,450 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,450 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e34c4d80-8109-49d0-9101-f71bfc4d1261
2023-10-17 05:44:33,450 - distributed.worker - INFO - Starting Worker plugin PreImport-eb115f58-2ab7-4f8d-950e-c06c21df3b21
2023-10-17 05:44:33,450 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,451 - distributed.worker - INFO - Starting Worker plugin PreImport-06cbac22-38b5-43ae-818a-408f0af03160
2023-10-17 05:44:33,451 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-14892fea-6e79-49b4-b41e-b014128132d4
2023-10-17 05:44:33,452 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,452 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-552cf455-8ffb-4a8a-ad76-45c86a11dd65
2023-10-17 05:44:33,453 - distributed.worker - INFO - Starting Worker plugin PreImport-3eba87cf-bac8-4379-b30b-9511f04d517b
2023-10-17 05:44:33,453 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,482 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46547', status: init, memory: 0, processing: 0>
2023-10-17 05:44:33,485 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46547
2023-10-17 05:44:33,486 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49498
2023-10-17 05:44:33,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:33,487 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35157', status: init, memory: 0, processing: 0>
2023-10-17 05:44:33,487 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,488 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,488 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35157
2023-10-17 05:44:33,489 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49524
2023-10-17 05:44:33,490 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:33,490 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:33,490 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44629', status: init, memory: 0, processing: 0>
2023-10-17 05:44:33,490 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,491 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,491 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44629
2023-10-17 05:44:33,491 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49502
2023-10-17 05:44:33,492 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:33,492 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:33,493 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,493 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,494 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37995', status: init, memory: 0, processing: 0>
2023-10-17 05:44:33,495 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:33,495 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37995
2023-10-17 05:44:33,495 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49522
2023-10-17 05:44:33,496 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:33,496 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44299', status: init, memory: 0, processing: 0>
2023-10-17 05:44:33,497 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,497 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,497 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44299
2023-10-17 05:44:33,497 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49560
2023-10-17 05:44:33,499 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42737', status: init, memory: 0, processing: 0>
2023-10-17 05:44:33,499 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:33,499 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:33,500 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42737
2023-10-17 05:44:33,500 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49552
2023-10-17 05:44:33,501 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,501 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,501 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40033', status: init, memory: 0, processing: 0>
2023-10-17 05:44:33,502 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:33,502 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40033
2023-10-17 05:44:33,502 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49540
2023-10-17 05:44:33,503 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,503 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,503 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42707', status: init, memory: 0, processing: 0>
2023-10-17 05:44:33,504 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:33,504 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:33,504 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42707
2023-10-17 05:44:33,505 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49510
2023-10-17 05:44:33,505 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,505 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,506 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:33,506 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:33,508 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:33,508 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:33,509 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:33,511 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:33,535 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:33,535 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:33,536 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:33,536 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:33,536 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:33,536 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:33,536 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:33,536 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:33,544 - distributed.scheduler - INFO - Remove client Client-3a9adfc6-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:33,544 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55430; closing.
2023-10-17 05:44:33,544 - distributed.scheduler - INFO - Remove client Client-3a9adfc6-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:33,546 - distributed.scheduler - INFO - Close client connection: Client-3a9adfc6-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:33,546 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41651'. Reason: nanny-close
2023-10-17 05:44:33,546 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45839'. Reason: nanny-close
2023-10-17 05:44:33,547 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34889'. Reason: nanny-close
2023-10-17 05:44:33,547 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:33,548 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41183'. Reason: nanny-close
2023-10-17 05:44:33,548 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:33,548 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46547. Reason: nanny-close
2023-10-17 05:44:33,548 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45881'. Reason: nanny-close
2023-10-17 05:44:33,548 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43971'. Reason: nanny-close
2023-10-17 05:44:33,549 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36939'. Reason: nanny-close
2023-10-17 05:44:33,549 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:33,549 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37995. Reason: nanny-close
2023-10-17 05:44:33,549 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40295'. Reason: nanny-close
2023-10-17 05:44:33,549 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:33,550 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35157. Reason: nanny-close
2023-10-17 05:44:33,550 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44629. Reason: nanny-close
2023-10-17 05:44:33,550 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:33,551 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:33,551 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49498; closing.
2023-10-17 05:44:33,552 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:33,552 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46547', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521473.552014')
2023-10-17 05:44:33,552 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:33,552 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:33,552 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:33,553 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49522; closing.
2023-10-17 05:44:33,553 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:33,554 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:33,554 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49524; closing.
2023-10-17 05:44:33,555 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37995', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521473.5551033')
2023-10-17 05:44:33,555 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:33,556 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:33,556 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42737. Reason: nanny-close
2023-10-17 05:44:33,557 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44299. Reason: nanny-close
2023-10-17 05:44:33,557 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35157', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521473.5572083')
2023-10-17 05:44:33,557 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:33,558 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:33,558 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49502; closing.
2023-10-17 05:44:33,558 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42707. Reason: nanny-close
2023-10-17 05:44:33,559 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40033. Reason: nanny-close
2023-10-17 05:44:33,560 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:33,561 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:33,561 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:33,558 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:49524>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:49524>: Stream is closed
2023-10-17 05:44:33,561 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:33,561 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:49522>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-17 05:44:33,562 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:33,562 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44629', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521473.5627673')
2023-10-17 05:44:33,563 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:33,563 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:33,563 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:33,568 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49552; closing.
2023-10-17 05:44:33,569 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42737', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521473.569113')
2023-10-17 05:44:33,569 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49560; closing.
2023-10-17 05:44:33,569 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49510; closing.
2023-10-17 05:44:33,569 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49540; closing.
2023-10-17 05:44:33,570 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44299', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521473.5706034')
2023-10-17 05:44:33,571 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42707', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521473.5709949')
2023-10-17 05:44:33,571 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40033', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521473.5713367')
2023-10-17 05:44:33,571 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:44:33,571 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:49552>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-17 05:44:35,566 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:44:35,567 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:44:35,567 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:44:35,569 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:44:35,569 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-10-17 05:44:38,392 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:38,398 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36153 instead
  warnings.warn(
2023-10-17 05:44:38,404 - distributed.scheduler - INFO - State start
2023-10-17 05:44:38,433 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:38,435 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:44:38,436 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36153/status
2023-10-17 05:44:38,436 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:44:38,669 - distributed.scheduler - INFO - Receive client connection: Client-4174df25-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:38,689 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49668
2023-10-17 05:44:39,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41951'
2023-10-17 05:44:39,023 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33353'
2023-10-17 05:44:39,032 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42649'
2023-10-17 05:44:39,048 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43483'
2023-10-17 05:44:39,051 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42147'
2023-10-17 05:44:39,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45067'
2023-10-17 05:44:39,068 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39095'
2023-10-17 05:44:39,078 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41941'
2023-10-17 05:44:40,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:40,996 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:41,002 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:41,043 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:41,043 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:41,045 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:41,045 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:41,052 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:41,052 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:41,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:41,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:41,110 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:41,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:41,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:41,118 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:41,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:41,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:41,127 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:41,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:41,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:41,168 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:41,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:41,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:41,273 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:44,439 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39967
2023-10-17 05:44:44,440 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39967
2023-10-17 05:44:44,440 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45207
2023-10-17 05:44:44,440 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,440 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,440 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:44,440 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:44,440 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-il5o72y2
2023-10-17 05:44:44,441 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d3fbc416-368c-4ecc-97d6-544b4843bb4e
2023-10-17 05:44:44,445 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40243
2023-10-17 05:44:44,446 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40243
2023-10-17 05:44:44,446 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42809
2023-10-17 05:44:44,446 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,446 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,446 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:44,446 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:44,447 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ify5fv_m
2023-10-17 05:44:44,447 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a36d7838-b948-43bc-81fd-359b2aed09ba
2023-10-17 05:44:44,447 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b1d54c10-c6d3-4172-8940-7157653fb67a
2023-10-17 05:44:44,539 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35427
2023-10-17 05:44:44,540 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35427
2023-10-17 05:44:44,540 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39017
2023-10-17 05:44:44,540 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,540 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,539 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46297
2023-10-17 05:44:44,540 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46297
2023-10-17 05:44:44,540 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:44,540 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45387
2023-10-17 05:44:44,540 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,540 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:44,540 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,540 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-udpte4zd
2023-10-17 05:44:44,540 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:44,541 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:44,541 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ud8mim96
2023-10-17 05:44:44,541 - distributed.worker - INFO - Starting Worker plugin PreImport-9f97cf8c-0597-4857-8fb6-07cfc9c199e6
2023-10-17 05:44:44,541 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-354cc3f6-4ec8-4030-be20-2d4c1b9756a9
2023-10-17 05:44:44,541 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7dc3a0cc-e8c5-4d0e-92e3-d60152a3c34d
2023-10-17 05:44:44,541 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3904c2cc-b1e4-4dea-830f-d3fee756f4f7
2023-10-17 05:44:44,572 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42409
2023-10-17 05:44:44,573 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42409
2023-10-17 05:44:44,573 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46379
2023-10-17 05:44:44,573 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,573 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,573 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:44,573 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:44,573 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u7_jx6_t
2023-10-17 05:44:44,574 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a32dd02f-b92e-47fd-b7e4-918a92b65f8d
2023-10-17 05:44:44,621 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46307
2023-10-17 05:44:44,622 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46307
2023-10-17 05:44:44,622 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34725
2023-10-17 05:44:44,622 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,623 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,623 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:44,623 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:44,623 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5j3vulif
2023-10-17 05:44:44,623 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cab739a2-6191-4ded-8c50-9f23a6a6093c
2023-10-17 05:44:44,624 - distributed.worker - INFO - Starting Worker plugin RMMSetup-28155f8f-5a6e-4626-b9f4-e0d30d1614d3
2023-10-17 05:44:44,662 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43041
2023-10-17 05:44:44,662 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43041
2023-10-17 05:44:44,663 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37217
2023-10-17 05:44:44,663 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,663 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,663 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:44,663 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:44,663 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2y0ndl8j
2023-10-17 05:44:44,664 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e8bda944-ae49-4545-8052-87001ba67453
2023-10-17 05:44:44,680 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44603
2023-10-17 05:44:44,681 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44603
2023-10-17 05:44:44,681 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37791
2023-10-17 05:44:44,681 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,681 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,681 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:44,681 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:44,681 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4rh49tab
2023-10-17 05:44:44,682 - distributed.worker - INFO - Starting Worker plugin RMMSetup-66c8d29f-a1eb-4251-ac6c-e71f053a9033
2023-10-17 05:44:44,785 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b9c0f5c4-de2a-42fe-aeec-ebe03d472c44
2023-10-17 05:44:44,785 - distributed.worker - INFO - Starting Worker plugin PreImport-9a8d1dd9-96d6-4765-9b4b-37384023927d
2023-10-17 05:44:44,785 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,788 - distributed.worker - INFO - Starting Worker plugin PreImport-ed73b1fe-7be5-480e-8c6a-d8aeb59025cf
2023-10-17 05:44:44,788 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,817 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39967', status: init, memory: 0, processing: 0>
2023-10-17 05:44:44,818 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39967
2023-10-17 05:44:44,818 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60812
2023-10-17 05:44:44,819 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40243', status: init, memory: 0, processing: 0>
2023-10-17 05:44:44,819 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:44,819 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40243
2023-10-17 05:44:44,819 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60822
2023-10-17 05:44:44,820 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,820 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,820 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:44,821 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,821 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,821 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:44,823 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:44,861 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,874 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-561fdf66-4140-4382-9dfc-043fdc6f6b23
2023-10-17 05:44:44,874 - distributed.worker - INFO - Starting Worker plugin PreImport-f90bdd36-ee7d-4f27-b3e4-b6a875d540d4
2023-10-17 05:44:44,875 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,877 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5d6d9384-ff13-48b4-b42c-5e601510a316
2023-10-17 05:44:44,878 - distributed.worker - INFO - Starting Worker plugin PreImport-0a73603c-66ec-47cd-b477-1ce8df197286
2023-10-17 05:44:44,879 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,891 - distributed.worker - INFO - Starting Worker plugin PreImport-a6fc61e3-4239-4419-8e90-dc4fe8d800f7
2023-10-17 05:44:44,891 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,892 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35427', status: init, memory: 0, processing: 0>
2023-10-17 05:44:44,893 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35427
2023-10-17 05:44:44,893 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60832
2023-10-17 05:44:44,894 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:44,894 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2dbc1063-fc93-4f17-8f61-36deec149623
2023-10-17 05:44:44,895 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,895 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,895 - distributed.worker - INFO - Starting Worker plugin PreImport-23f711b8-0e13-4bce-80ca-9b0a3a948522
2023-10-17 05:44:44,896 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,897 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:44,897 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ebd181ec-c2b3-4407-868f-790c7f68521c
2023-10-17 05:44:44,898 - distributed.worker - INFO - Starting Worker plugin PreImport-11291d2c-b69a-4bb9-ab9f-fdd8ecfb7b32
2023-10-17 05:44:44,899 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,904 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46297', status: init, memory: 0, processing: 0>
2023-10-17 05:44:44,904 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46297
2023-10-17 05:44:44,904 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60842
2023-10-17 05:44:44,905 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:44,906 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,906 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,908 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:44,926 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42409', status: init, memory: 0, processing: 0>
2023-10-17 05:44:44,927 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42409
2023-10-17 05:44:44,927 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60846
2023-10-17 05:44:44,928 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:44,930 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,930 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,931 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46307', status: init, memory: 0, processing: 0>
2023-10-17 05:44:44,932 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46307
2023-10-17 05:44:44,932 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60862
2023-10-17 05:44:44,932 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:44,934 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:44,934 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44603', status: init, memory: 0, processing: 0>
2023-10-17 05:44:44,935 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44603
2023-10-17 05:44:44,935 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60878
2023-10-17 05:44:44,935 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,935 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,935 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43041', status: init, memory: 0, processing: 0>
2023-10-17 05:44:44,936 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43041
2023-10-17 05:44:44,936 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60872
2023-10-17 05:44:44,936 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:44,937 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:44,937 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,937 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,938 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:44,939 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:44,939 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:44,939 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:44,941 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:44,971 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:44,971 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:44,971 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:44,972 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:44,972 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:44,972 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:44,972 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:44,972 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:44:44,985 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:44,985 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:44,985 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:44,985 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:44,985 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:44,985 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:44,985 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:44,985 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:44,993 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:44,996 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:44,999 - distributed.scheduler - INFO - Remove client Client-4174df25-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:44,999 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49668; closing.
2023-10-17 05:44:44,999 - distributed.scheduler - INFO - Remove client Client-4174df25-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:45,000 - distributed.scheduler - INFO - Close client connection: Client-4174df25-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:45,000 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41951'. Reason: nanny-close
2023-10-17 05:44:45,001 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:45,002 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33353'. Reason: nanny-close
2023-10-17 05:44:45,002 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:45,002 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42649'. Reason: nanny-close
2023-10-17 05:44:45,002 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46307. Reason: nanny-close
2023-10-17 05:44:45,003 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:45,003 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43483'. Reason: nanny-close
2023-10-17 05:44:45,003 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43041. Reason: nanny-close
2023-10-17 05:44:45,003 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:45,003 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39967. Reason: nanny-close
2023-10-17 05:44:45,004 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42147'. Reason: nanny-close
2023-10-17 05:44:45,004 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:45,004 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35427. Reason: nanny-close
2023-10-17 05:44:45,004 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45067'. Reason: nanny-close
2023-10-17 05:44:45,004 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:45,005 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39095'. Reason: nanny-close
2023-10-17 05:44:45,005 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:45,005 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42409. Reason: nanny-close
2023-10-17 05:44:45,005 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41941'. Reason: nanny-close
2023-10-17 05:44:45,005 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:45,005 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:45,005 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44603. Reason: nanny-close
2023-10-17 05:44:45,006 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:45,006 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60872; closing.
2023-10-17 05:44:45,006 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:45,006 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40243. Reason: nanny-close
2023-10-17 05:44:45,006 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60812; closing.
2023-10-17 05:44:45,006 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:45,007 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46297. Reason: nanny-close
2023-10-17 05:44:45,007 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43041', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521485.007211')
2023-10-17 05:44:45,007 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:45,008 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39967', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521485.0080283')
2023-10-17 05:44:45,008 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:45,008 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:45,008 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:45,008 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:45,008 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:45,008 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:45,008 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60862; closing.
2023-10-17 05:44:45,009 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:45,009 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:45,009 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60832; closing.
2023-10-17 05:44:45,010 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46307', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521485.010078')
2023-10-17 05:44:45,010 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:45,011 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:45,011 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35427', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521485.0113678')
2023-10-17 05:44:45,011 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:45,011 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60846; closing.
2023-10-17 05:44:45,012 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60878; closing.
2023-10-17 05:44:45,012 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:60862>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-17 05:44:45,014 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42409', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521485.0142467')
2023-10-17 05:44:45,014 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44603', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521485.014663')
2023-10-17 05:44:45,015 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60822; closing.
2023-10-17 05:44:45,015 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60842; closing.
2023-10-17 05:44:45,015 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40243', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521485.0155313')
2023-10-17 05:44:45,015 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46297', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521485.0159073')
2023-10-17 05:44:45,016 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:44:46,971 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:44:46,972 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:44:46,972 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:44:46,974 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:44:46,975 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-10-17 05:44:49,708 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:49,714 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32789 instead
  warnings.warn(
2023-10-17 05:44:49,719 - distributed.scheduler - INFO - State start
2023-10-17 05:44:49,745 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:44:49,746 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:44:49,747 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:32789/status
2023-10-17 05:44:49,747 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:44:49,931 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33741'
2023-10-17 05:44:49,946 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43085'
2023-10-17 05:44:49,970 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34117'
2023-10-17 05:44:49,973 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34973'
2023-10-17 05:44:49,985 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45499'
2023-10-17 05:44:49,998 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34205'
2023-10-17 05:44:50,012 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45017'
2023-10-17 05:44:50,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35237'
2023-10-17 05:44:52,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:52,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:52,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:52,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:52,185 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:52,185 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:52,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:52,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:52,200 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:52,259 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:52,259 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:52,259 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:52,259 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:52,266 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:52,268 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:52,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:52,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:52,302 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:52,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:52,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:44:52,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:52,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:44:52,388 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:52,388 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:44:56,017 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33433
2023-10-17 05:44:56,018 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33433
2023-10-17 05:44:56,018 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44387
2023-10-17 05:44:56,018 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,018 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,018 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:56,018 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:56,018 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-phn41isb
2023-10-17 05:44:56,019 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-feaa4d0c-b6e1-401f-9d28-026c6d29853b
2023-10-17 05:44:56,019 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5397a871-11f1-4f74-8848-602141e9ac75
2023-10-17 05:44:56,353 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34927
2023-10-17 05:44:56,354 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34927
2023-10-17 05:44:56,354 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39425
2023-10-17 05:44:56,354 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,354 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,354 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:56,354 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:56,354 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gc9i5r2j
2023-10-17 05:44:56,355 - distributed.worker - INFO - Starting Worker plugin RMMSetup-08b28c3d-380d-41bd-8498-5a535ba33188
2023-10-17 05:44:56,369 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37391
2023-10-17 05:44:56,370 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37391
2023-10-17 05:44:56,370 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44367
2023-10-17 05:44:56,370 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,370 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,370 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:56,370 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:56,370 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dzj2l001
2023-10-17 05:44:56,371 - distributed.worker - INFO - Starting Worker plugin RMMSetup-777fe9da-5c68-425a-a523-1823daaf09b9
2023-10-17 05:44:56,398 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42753
2023-10-17 05:44:56,398 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42753
2023-10-17 05:44:56,399 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44499
2023-10-17 05:44:56,399 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,399 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,399 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:56,399 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:56,399 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oyiptoha
2023-10-17 05:44:56,399 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3da23d2c-0812-4b41-930d-b5b7deb3ae08
2023-10-17 05:44:56,409 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46425
2023-10-17 05:44:56,410 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46425
2023-10-17 05:44:56,410 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46753
2023-10-17 05:44:56,410 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,410 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,411 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:56,411 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:56,411 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1cp55hdr
2023-10-17 05:44:56,411 - distributed.worker - INFO - Starting Worker plugin PreImport-278b0828-8cb4-4b61-b2e6-a8a7028841ad
2023-10-17 05:44:56,411 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2c796867-6561-4bbd-9eb2-c8aedc2d788f
2023-10-17 05:44:56,412 - distributed.worker - INFO - Starting Worker plugin RMMSetup-294c21a6-8029-40a2-a8e6-8c7e0f18a9b9
2023-10-17 05:44:56,434 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36137
2023-10-17 05:44:56,434 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36137
2023-10-17 05:44:56,434 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38671
2023-10-17 05:44:56,435 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,435 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,435 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:56,435 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:56,435 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zbgq2yzg
2023-10-17 05:44:56,435 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bf94121f-b9d3-4146-90c5-6d1fd30f3ce8
2023-10-17 05:44:56,444 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40565
2023-10-17 05:44:56,445 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40565
2023-10-17 05:44:56,445 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46341
2023-10-17 05:44:56,445 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,445 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,445 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:56,446 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:56,446 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4yy6hk8m
2023-10-17 05:44:56,446 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4cbf03fc-ddc4-4a62-a52a-758e59fbe62c
2023-10-17 05:44:56,448 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40249
2023-10-17 05:44:56,449 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40249
2023-10-17 05:44:56,449 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36619
2023-10-17 05:44:56,449 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,449 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,449 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:44:56,449 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:44:56,449 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b6v4zhy9
2023-10-17 05:44:56,450 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ed42ea93-5e57-4c91-afd4-62e7ad027556
2023-10-17 05:44:56,450 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b288d789-596e-428b-a67c-6724e9be94c9
2023-10-17 05:44:56,560 - distributed.worker - INFO - Starting Worker plugin PreImport-b3e03b2d-e932-4004-bea1-260ce6a3f740
2023-10-17 05:44:56,561 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,595 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33433', status: init, memory: 0, processing: 0>
2023-10-17 05:44:56,611 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33433
2023-10-17 05:44:56,612 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53324
2023-10-17 05:44:56,612 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:56,613 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,613 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,615 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:56,662 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a5bdfca3-2c66-429c-ac63-bedc5c283d53
2023-10-17 05:44:56,664 - distributed.worker - INFO - Starting Worker plugin PreImport-b99acfa0-9400-4c39-b298-160342e32071
2023-10-17 05:44:56,664 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,694 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c7c4a50c-12c9-449f-9676-c72bc4bfaf51
2023-10-17 05:44:56,695 - distributed.worker - INFO - Starting Worker plugin PreImport-75ae13c4-ba73-41ff-abfc-11837cf2a826
2023-10-17 05:44:56,695 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,716 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37391', status: init, memory: 0, processing: 0>
2023-10-17 05:44:56,717 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37391
2023-10-17 05:44:56,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53328
2023-10-17 05:44:56,719 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:56,721 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,721 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,723 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:56,724 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34927', status: init, memory: 0, processing: 0>
2023-10-17 05:44:56,725 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34927
2023-10-17 05:44:56,725 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53334
2023-10-17 05:44:56,726 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:56,726 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9a0f23f3-522d-4567-90a4-7a969ec81801
2023-10-17 05:44:56,727 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,727 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,727 - distributed.worker - INFO - Starting Worker plugin PreImport-257f0a2b-db72-4edf-9eb2-291e570e8063
2023-10-17 05:44:56,728 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,731 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:56,734 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,750 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d55d7a18-d6b4-4510-b700-1d78756147d2
2023-10-17 05:44:56,751 - distributed.worker - INFO - Starting Worker plugin PreImport-b8455e47-4d6c-48be-943a-41e30a474a34
2023-10-17 05:44:56,751 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,752 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8ac2f266-0b9e-406a-8b68-57664d5033ae
2023-10-17 05:44:56,752 - distributed.worker - INFO - Starting Worker plugin PreImport-4fc8fc69-b9ca-4d53-b7ef-2b234f76d08f
2023-10-17 05:44:56,752 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,754 - distributed.worker - INFO - Starting Worker plugin PreImport-4ecfcc51-eb6a-49b6-829c-994eccfd933b
2023-10-17 05:44:56,754 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,762 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46425', status: init, memory: 0, processing: 0>
2023-10-17 05:44:56,763 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46425
2023-10-17 05:44:56,763 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53364
2023-10-17 05:44:56,764 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:56,765 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,765 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,766 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:56,771 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42753', status: init, memory: 0, processing: 0>
2023-10-17 05:44:56,771 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42753
2023-10-17 05:44:56,772 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53348
2023-10-17 05:44:56,773 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:56,774 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,775 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,777 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:56,781 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40565', status: init, memory: 0, processing: 0>
2023-10-17 05:44:56,781 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40565
2023-10-17 05:44:56,782 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53382
2023-10-17 05:44:56,783 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:56,783 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,783 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,785 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:56,788 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36137', status: init, memory: 0, processing: 0>
2023-10-17 05:44:56,789 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36137
2023-10-17 05:44:56,789 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53378
2023-10-17 05:44:56,791 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:56,792 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,792 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,794 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40249', status: init, memory: 0, processing: 0>
2023-10-17 05:44:56,795 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40249
2023-10-17 05:44:56,795 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53398
2023-10-17 05:44:56,795 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:56,796 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:44:56,797 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:44:56,797 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:44:56,800 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:44:58,945 - distributed.scheduler - INFO - Receive client connection: Client-483489a1-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:58,946 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:53464
2023-10-17 05:44:58,961 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,962 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,962 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,962 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,962 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,962 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,962 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,962 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,976 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:58,976 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:58,976 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:58,976 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:58,976 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:58,976 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:58,977 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:58,977 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:44:58,985 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,987 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:44:58,990 - distributed.scheduler - INFO - Remove client Client-483489a1-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:58,990 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53464; closing.
2023-10-17 05:44:58,990 - distributed.scheduler - INFO - Remove client Client-483489a1-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:58,990 - distributed.scheduler - INFO - Close client connection: Client-483489a1-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:44:58,992 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33741'. Reason: nanny-close
2023-10-17 05:44:58,992 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:58,993 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43085'. Reason: nanny-close
2023-10-17 05:44:58,993 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:58,994 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34117'. Reason: nanny-close
2023-10-17 05:44:58,994 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40249. Reason: nanny-close
2023-10-17 05:44:58,994 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:58,994 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34973'. Reason: nanny-close
2023-10-17 05:44:58,994 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:58,994 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36137. Reason: nanny-close
2023-10-17 05:44:58,995 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34927. Reason: nanny-close
2023-10-17 05:44:58,995 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45499'. Reason: nanny-close
2023-10-17 05:44:58,995 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:58,995 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46425. Reason: nanny-close
2023-10-17 05:44:58,995 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34205'. Reason: nanny-close
2023-10-17 05:44:58,996 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:58,996 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45017'. Reason: nanny-close
2023-10-17 05:44:58,996 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37391. Reason: nanny-close
2023-10-17 05:44:58,996 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:58,996 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:58,997 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35237'. Reason: nanny-close
2023-10-17 05:44:58,997 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53398; closing.
2023-10-17 05:44:58,997 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:44:58,997 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42753. Reason: nanny-close
2023-10-17 05:44:58,997 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:58,997 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33433. Reason: nanny-close
2023-10-17 05:44:58,997 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40249', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521498.9976332')
2023-10-17 05:44:58,997 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:58,997 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:58,998 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40565. Reason: nanny-close
2023-10-17 05:44:58,998 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53334; closing.
2023-10-17 05:44:58,999 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53378; closing.
2023-10-17 05:44:58,999 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:58,999 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:58,999 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:58,999 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:58,999 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:59,000 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:59,000 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34927', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521499.0002122')
2023-10-17 05:44:59,000 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36137', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521499.000654')
2023-10-17 05:44:59,000 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:59,000 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:44:59,001 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53364; closing.
2023-10-17 05:44:59,001 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:59,002 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53328; closing.
2023-10-17 05:44:59,002 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:59,002 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:59,002 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46425', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521499.0024822')
2023-10-17 05:44:59,002 - distributed.nanny - INFO - Worker closed
2023-10-17 05:44:59,003 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37391', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521499.0034811')
2023-10-17 05:44:59,003 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53324; closing.
2023-10-17 05:44:59,004 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53348; closing.
2023-10-17 05:44:59,004 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:53382; closing.
2023-10-17 05:44:59,004 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33433', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521499.0046782')
2023-10-17 05:44:59,005 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42753', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521499.005048')
2023-10-17 05:44:59,005 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40565', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521499.0054317')
2023-10-17 05:44:59,005 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:45:00,559 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:45:00,560 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:45:00,560 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:45:00,561 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:45:00,562 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-10-17 05:45:02,561 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:02,565 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35499 instead
  warnings.warn(
2023-10-17 05:45:02,569 - distributed.scheduler - INFO - State start
2023-10-17 05:45:02,589 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:02,590 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:45:02,591 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35499/status
2023-10-17 05:45:02,591 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:45:02,715 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34093'
2023-10-17 05:45:02,728 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34471'
2023-10-17 05:45:02,740 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45817'
2023-10-17 05:45:02,750 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33679'
2023-10-17 05:45:02,752 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35235'
2023-10-17 05:45:02,760 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41655'
2023-10-17 05:45:02,768 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40943'
2023-10-17 05:45:02,776 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34067'
2023-10-17 05:45:04,372 - distributed.scheduler - INFO - Receive client connection: Client-5017be60-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:04,389 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56596
2023-10-17 05:45:04,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:04,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:04,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:04,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:04,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:04,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:04,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:04,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:04,839 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:04,839 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:04,839 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:04,842 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:04,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:04,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:04,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:04,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:04,856 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:04,856 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:04,858 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:04,858 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:04,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:04,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:04,861 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:04,864 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:07,880 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44289
2023-10-17 05:45:07,880 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44289
2023-10-17 05:45:07,880 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41817
2023-10-17 05:45:07,881 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:07,881 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:07,881 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:07,881 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:07,881 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9yztudgh
2023-10-17 05:45:07,882 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0d01cd2c-e528-48a0-a0b1-6660856f4745
2023-10-17 05:45:07,882 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32881
2023-10-17 05:45:07,883 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32881
2023-10-17 05:45:07,883 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38393
2023-10-17 05:45:07,883 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:07,883 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:07,883 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:07,883 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:07,883 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bpv2cjjv
2023-10-17 05:45:07,884 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6446bb5c-1118-4e42-9c86-beeed95a6b71
2023-10-17 05:45:07,937 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36939
2023-10-17 05:45:07,939 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36939
2023-10-17 05:45:07,939 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36091
2023-10-17 05:45:07,939 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:07,939 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:07,939 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:07,939 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:07,940 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-accir94a
2023-10-17 05:45:07,940 - distributed.worker - INFO - Starting Worker plugin PreImport-4f1cd5c3-aa7f-49a5-ad89-3ee9819103ac
2023-10-17 05:45:07,941 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3497206b-367a-428a-819d-b84f1842cb29
2023-10-17 05:45:07,941 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c2dfea0d-fe8b-42da-89fb-ced358db02c2
2023-10-17 05:45:07,941 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37731
2023-10-17 05:45:07,942 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37731
2023-10-17 05:45:07,942 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35969
2023-10-17 05:45:07,942 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:07,942 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:07,943 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:07,943 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:07,943 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kqaizgp2
2023-10-17 05:45:07,943 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a37591f7-0d24-4f10-895e-7e2f478536a0
2023-10-17 05:45:08,969 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-df9c5202-afcd-46aa-b2ec-92a2edf6039c
2023-10-17 05:45:08,969 - distributed.worker - INFO - Starting Worker plugin PreImport-9cafbd9c-c3c4-465f-ac72-b387fcf85775
2023-10-17 05:45:08,970 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:08,992 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38135
2023-10-17 05:45:08,993 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38135
2023-10-17 05:45:08,993 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40803
2023-10-17 05:45:08,993 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:08,994 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:08,994 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:08,994 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:08,994 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-olu6zseg
2023-10-17 05:45:08,994 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce171551-f9ee-478c-8689-a3bb6778a78e
2023-10-17 05:45:08,995 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c009f0d8-28be-42e4-8c32-1c02560ca78b
2023-10-17 05:45:09,136 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-46e4ac91-04d4-4b53-b831-107f455e36ed
2023-10-17 05:45:09,137 - distributed.worker - INFO - Starting Worker plugin PreImport-68013451-ba5f-4b75-a013-9abf4ae993d7
2023-10-17 05:45:09,137 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,146 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44289', status: init, memory: 0, processing: 0>
2023-10-17 05:45:09,148 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44289
2023-10-17 05:45:09,148 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56612
2023-10-17 05:45:09,149 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:09,151 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,151 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,153 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:09,155 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41013
2023-10-17 05:45:09,156 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41013
2023-10-17 05:45:09,156 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42615
2023-10-17 05:45:09,157 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,157 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,157 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:09,157 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:09,157 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3k2trn4_
2023-10-17 05:45:09,158 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b656b291-accc-4dbb-bec7-cb8500030fed
2023-10-17 05:45:09,171 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,172 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32881', status: init, memory: 0, processing: 0>
2023-10-17 05:45:09,173 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32881
2023-10-17 05:45:09,173 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56622
2023-10-17 05:45:09,174 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:09,175 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,175 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,176 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:09,208 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36939', status: init, memory: 0, processing: 0>
2023-10-17 05:45:09,209 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36939
2023-10-17 05:45:09,209 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56638
2023-10-17 05:45:09,210 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:09,211 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,211 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,212 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:09,256 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36059
2023-10-17 05:45:09,257 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36059
2023-10-17 05:45:09,257 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39075
2023-10-17 05:45:09,257 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,257 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,257 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:09,257 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:09,257 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3p467u1s
2023-10-17 05:45:09,258 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cb25ce28-a581-44e8-80d9-ffb2a79bff5f
2023-10-17 05:45:09,258 - distributed.worker - INFO - Starting Worker plugin RMMSetup-68cd655c-9222-44a8-8478-9dcfb8858c3c
2023-10-17 05:45:09,260 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42929
2023-10-17 05:45:09,261 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42929
2023-10-17 05:45:09,261 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41029
2023-10-17 05:45:09,261 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,261 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,261 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:09,262 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:09,262 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v9st9uzd
2023-10-17 05:45:09,262 - distributed.worker - INFO - Starting Worker plugin RMMSetup-edf45fd3-7dcb-43a1-9b2f-a5e8bce24681
2023-10-17 05:45:09,271 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8941e9a0-7375-457b-9c50-dfad291fd235
2023-10-17 05:45:09,271 - distributed.worker - INFO - Starting Worker plugin PreImport-6cbc8aba-df39-4c66-9638-c496a12252f3
2023-10-17 05:45:09,272 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,301 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37731', status: init, memory: 0, processing: 0>
2023-10-17 05:45:09,302 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37731
2023-10-17 05:45:09,302 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56642
2023-10-17 05:45:09,303 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:09,304 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,304 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,305 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:09,465 - distributed.worker - INFO - Starting Worker plugin PreImport-0d0e58f8-90f4-47f4-85c8-b827a27a2385
2023-10-17 05:45:09,465 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,493 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5824d912-c550-4a05-b442-318d0c7f1e3c
2023-10-17 05:45:09,494 - distributed.worker - INFO - Starting Worker plugin PreImport-617b2219-b12e-401a-8e44-5293d023af92
2023-10-17 05:45:09,494 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,502 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38135', status: init, memory: 0, processing: 0>
2023-10-17 05:45:09,503 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38135
2023-10-17 05:45:09,503 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56650
2023-10-17 05:45:09,504 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:09,505 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,506 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,507 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:09,532 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41013', status: init, memory: 0, processing: 0>
2023-10-17 05:45:09,533 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41013
2023-10-17 05:45:09,533 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56666
2023-10-17 05:45:09,534 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:09,535 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,535 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,537 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:09,576 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-700ca7a5-0a9e-4374-bf31-bec74d8bfb51
2023-10-17 05:45:09,577 - distributed.worker - INFO - Starting Worker plugin PreImport-67c26f18-5f66-4b53-b790-e188ba349e30
2023-10-17 05:45:09,577 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,598 - distributed.worker - INFO - Starting Worker plugin PreImport-d21935fe-925f-4a08-989d-bbff916d1cdf
2023-10-17 05:45:09,598 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,613 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42929', status: init, memory: 0, processing: 0>
2023-10-17 05:45:09,614 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42929
2023-10-17 05:45:09,614 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56680
2023-10-17 05:45:09,615 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:09,616 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,616 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,618 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:09,631 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36059', status: init, memory: 0, processing: 0>
2023-10-17 05:45:09,632 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36059
2023-10-17 05:45:09,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56696
2023-10-17 05:45:09,633 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:09,634 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:09,634 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:09,636 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:09,701 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:45:09,701 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:45:09,701 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:45:09,701 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:45:09,701 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:45:09,702 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:45:09,702 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:45:09,702 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-10-17 05:45:09,706 - distributed.scheduler - INFO - Remove client Client-5017be60-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:09,706 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56596; closing.
2023-10-17 05:45:09,706 - distributed.scheduler - INFO - Remove client Client-5017be60-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:09,707 - distributed.scheduler - INFO - Close client connection: Client-5017be60-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:09,718 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34093'. Reason: nanny-close
2023-10-17 05:45:09,718 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:09,719 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34471'. Reason: nanny-close
2023-10-17 05:45:09,720 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:09,720 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36059. Reason: nanny-close
2023-10-17 05:45:09,720 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45817'. Reason: nanny-close
2023-10-17 05:45:09,720 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:09,720 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42929. Reason: nanny-close
2023-10-17 05:45:09,721 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33679'. Reason: nanny-close
2023-10-17 05:45:09,721 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:09,721 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32881. Reason: nanny-close
2023-10-17 05:45:09,721 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35235'. Reason: nanny-close
2023-10-17 05:45:09,721 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:09,722 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36939. Reason: nanny-close
2023-10-17 05:45:09,722 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41655'. Reason: nanny-close
2023-10-17 05:45:09,722 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:09,722 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:09,722 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41013. Reason: nanny-close
2023-10-17 05:45:09,722 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56696; closing.
2023-10-17 05:45:09,722 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40943'. Reason: nanny-close
2023-10-17 05:45:09,722 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:09,723 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36059', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521509.723002')
2023-10-17 05:45:09,723 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:09,723 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44289. Reason: nanny-close
2023-10-17 05:45:09,723 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34067'. Reason: nanny-close
2023-10-17 05:45:09,723 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:09,723 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38135. Reason: nanny-close
2023-10-17 05:45:09,723 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:09,723 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:09,724 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56680; closing.
2023-10-17 05:45:09,724 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37731. Reason: nanny-close
2023-10-17 05:45:09,724 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:09,724 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56638; closing.
2023-10-17 05:45:09,724 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:09,725 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42929', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521509.7250473')
2023-10-17 05:45:09,725 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:09,725 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:09,725 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:09,725 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:09,726 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:09,726 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36939', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521509.7259302')
2023-10-17 05:45:09,726 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:09,726 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56622; closing.
2023-10-17 05:45:09,726 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32881', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521509.7268505')
2023-10-17 05:45:09,727 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56666; closing.
2023-10-17 05:45:09,727 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:09,727 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:09,727 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:09,727 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:09,727 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41013', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521509.7279253')
2023-10-17 05:45:09,728 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56612; closing.
2023-10-17 05:45:09,728 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56650; closing.
2023-10-17 05:45:09,728 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56642; closing.
2023-10-17 05:45:09,729 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44289', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521509.7289515')
2023-10-17 05:45:09,729 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38135', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521509.7293782')
2023-10-17 05:45:09,729 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37731', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521509.7298253')
2023-10-17 05:45:09,730 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:45:11,476 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:45:11,476 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:45:11,477 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:45:11,478 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:45:11,478 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-10-17 05:45:13,376 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:13,380 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36481 instead
  warnings.warn(
2023-10-17 05:45:13,383 - distributed.scheduler - INFO - State start
2023-10-17 05:45:13,405 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:13,406 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:45:13,407 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:36481/status
2023-10-17 05:45:13,407 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:45:13,802 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39881'
2023-10-17 05:45:14,280 - distributed.scheduler - INFO - Receive client connection: Client-569c9718-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:14,294 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42086
2023-10-17 05:45:15,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:15,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:16,290 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:17,553 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45839
2023-10-17 05:45:17,553 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45839
2023-10-17 05:45:17,553 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-10-17 05:45:17,553 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:17,553 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:17,554 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:17,554 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-17 05:45:17,554 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5fkghlct
2023-10-17 05:45:17,554 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b8ae8bc2-1e17-4dd9-aa4a-98cac25e24e6
2023-10-17 05:45:17,554 - distributed.worker - INFO - Starting Worker plugin PreImport-b5ac7701-9e97-45bc-ad0c-2e5893de24fe
2023-10-17 05:45:17,554 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5e293ad1-f693-4c59-aec5-8a77cb7ac119
2023-10-17 05:45:17,556 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:17,586 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45839', status: init, memory: 0, processing: 0>
2023-10-17 05:45:17,587 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45839
2023-10-17 05:45:17,587 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42118
2023-10-17 05:45:17,588 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:17,589 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:17,589 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:17,591 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:17,667 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:45:17,670 - distributed.scheduler - INFO - Remove client Client-569c9718-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:17,670 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42086; closing.
2023-10-17 05:45:17,670 - distributed.scheduler - INFO - Remove client Client-569c9718-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:17,671 - distributed.scheduler - INFO - Close client connection: Client-569c9718-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:17,671 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39881'. Reason: nanny-close
2023-10-17 05:45:17,672 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:17,673 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45839. Reason: nanny-close
2023-10-17 05:45:17,675 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42118; closing.
2023-10-17 05:45:17,676 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:17,676 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45839', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521517.6761863')
2023-10-17 05:45:17,676 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:45:17,678 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:18,888 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:45:18,888 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:45:18,889 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:45:18,890 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:45:18,890 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-10-17 05:45:23,208 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:23,213 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39917 instead
  warnings.warn(
2023-10-17 05:45:23,217 - distributed.scheduler - INFO - State start
2023-10-17 05:45:23,240 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:23,241 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:45:23,241 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39917/status
2023-10-17 05:45:23,242 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:45:23,381 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33751'
2023-10-17 05:45:24,341 - distributed.scheduler - INFO - Receive client connection: Client-5c52a5fc-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:24,354 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36212
2023-10-17 05:45:25,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:25,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:25,704 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:26,756 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38829
2023-10-17 05:45:26,757 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38829
2023-10-17 05:45:26,757 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32843
2023-10-17 05:45:26,757 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:26,757 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:26,757 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:26,757 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-17 05:45:26,757 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z2ixi6d1
2023-10-17 05:45:26,758 - distributed.worker - INFO - Starting Worker plugin RMMSetup-78205ea4-da09-4a75-9151-844bbf2bd5bd
2023-10-17 05:45:26,758 - distributed.worker - INFO - Starting Worker plugin PreImport-dd27ce67-fab5-49a3-822c-a6254e015420
2023-10-17 05:45:26,759 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5eea5983-e25f-44e4-a626-4c98d16b063e
2023-10-17 05:45:26,765 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:26,801 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38829', status: init, memory: 0, processing: 0>
2023-10-17 05:45:26,802 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38829
2023-10-17 05:45:26,802 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:36226
2023-10-17 05:45:26,804 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:26,805 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:26,805 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:26,808 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:26,810 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:45:26,813 - distributed.scheduler - INFO - Remove client Client-5c52a5fc-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:26,813 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36212; closing.
2023-10-17 05:45:26,813 - distributed.scheduler - INFO - Remove client Client-5c52a5fc-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:26,813 - distributed.scheduler - INFO - Close client connection: Client-5c52a5fc-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:26,814 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33751'. Reason: nanny-close
2023-10-17 05:45:26,823 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:26,824 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38829. Reason: nanny-close
2023-10-17 05:45:26,827 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:36226; closing.
2023-10-17 05:45:26,827 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:45:26,827 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38829', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521526.8273346')
2023-10-17 05:45:26,827 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:45:26,829 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:27,931 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:45:27,931 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:45:27,932 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:45:27,933 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:45:27,933 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-10-17 05:45:30,302 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:30,306 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-10-17 05:45:30,310 - distributed.scheduler - INFO - State start
2023-10-17 05:45:30,333 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:30,334 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:45:30,335 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-10-17 05:45:30,335 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:45:35,071 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:40592'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:40592>: Stream is closed
2023-10-17 05:45:35,443 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:45:35,443 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:45:35,444 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:45:35,445 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:45:35,445 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-10-17 05:45:37,821 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:37,825 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35793 instead
  warnings.warn(
2023-10-17 05:45:37,830 - distributed.scheduler - INFO - State start
2023-10-17 05:45:37,853 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:37,854 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-10-17 05:45:37,854 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35793/status
2023-10-17 05:45:37,854 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:45:37,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39233'
2023-10-17 05:45:38,034 - distributed.scheduler - INFO - Receive client connection: Client-64f7e388-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:38,047 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58982
2023-10-17 05:45:39,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:39,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:39,762 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:40,970 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34633
2023-10-17 05:45:40,971 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34633
2023-10-17 05:45:40,971 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36023
2023-10-17 05:45:40,971 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-10-17 05:45:40,971 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:40,971 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:40,972 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-17 05:45:40,972 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-kz_ddq2i
2023-10-17 05:45:40,972 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cd4e4002-51e0-49d0-b025-3aaa80d73b1f
2023-10-17 05:45:40,973 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c0b5e701-18ba-406b-9d24-368545056d6d
2023-10-17 05:45:40,973 - distributed.worker - INFO - Starting Worker plugin PreImport-15a42235-bf1f-46c5-9662-90e204a8b2fd
2023-10-17 05:45:40,973 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:41,008 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34633', status: init, memory: 0, processing: 0>
2023-10-17 05:45:41,009 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34633
2023-10-17 05:45:41,009 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59092
2023-10-17 05:45:41,010 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:41,011 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-10-17 05:45:41,011 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:41,014 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-10-17 05:45:41,016 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:45:41,019 - distributed.scheduler - INFO - Remove client Client-64f7e388-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:41,019 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58982; closing.
2023-10-17 05:45:41,019 - distributed.scheduler - INFO - Remove client Client-64f7e388-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:41,020 - distributed.scheduler - INFO - Close client connection: Client-64f7e388-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:41,020 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39233'. Reason: nanny-close
2023-10-17 05:45:41,021 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:45:41,022 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34633. Reason: nanny-close
2023-10-17 05:45:41,025 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-10-17 05:45:41,025 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59092; closing.
2023-10-17 05:45:41,025 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34633', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521541.0253365')
2023-10-17 05:45:41,025 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:45:41,026 - distributed.nanny - INFO - Worker closed
2023-10-17 05:45:42,338 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:45:42,338 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:45:42,339 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:45:42,340 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-10-17 05:45:42,340 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-10-17 05:45:44,717 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:44,722 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39119 instead
  warnings.warn(
2023-10-17 05:45:44,726 - distributed.scheduler - INFO - State start
2023-10-17 05:45:44,776 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:45:44,777 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:45:44,778 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39119/status
2023-10-17 05:45:44,778 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:45:44,934 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40301'
2023-10-17 05:45:44,951 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40021'
2023-10-17 05:45:44,959 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46437'
2023-10-17 05:45:44,974 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36131'
2023-10-17 05:45:44,976 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33607'
2023-10-17 05:45:44,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45297'
2023-10-17 05:45:44,995 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39467'
2023-10-17 05:45:45,004 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38411'
2023-10-17 05:45:45,221 - distributed.scheduler - INFO - Receive client connection: Client-691a5e86-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:45:45,231 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44130
2023-10-17 05:45:46,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:46,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:46,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:46,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:46,840 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:46,841 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:46,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:46,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:46,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:46,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:46,854 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:46,856 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:46,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:46,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:46,930 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:46,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:46,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:46,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:46,933 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:46,937 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:46,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:45:46,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:45:46,938 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:46,942 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:45:50,622 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37711
2023-10-17 05:45:50,623 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37711
2023-10-17 05:45:50,623 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39783
2023-10-17 05:45:50,623 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,623 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,623 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:50,623 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:50,623 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6vdonbj6
2023-10-17 05:45:50,624 - distributed.worker - INFO - Starting Worker plugin RMMSetup-47884a37-ba20-4c42-8fa5-0eae595266b5
2023-10-17 05:45:50,644 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46711
2023-10-17 05:45:50,644 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46711
2023-10-17 05:45:50,644 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40505
2023-10-17 05:45:50,644 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,645 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,645 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:50,645 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:50,645 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ch04k8w5
2023-10-17 05:45:50,645 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f4d561da-aa26-4074-9f43-3d4d3a77fa41
2023-10-17 05:45:50,657 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45275
2023-10-17 05:45:50,657 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45275
2023-10-17 05:45:50,658 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36155
2023-10-17 05:45:50,658 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,658 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,658 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:50,658 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:50,658 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v8qcrvor
2023-10-17 05:45:50,658 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d16bf271-4150-46d3-bac2-7c802e410280
2023-10-17 05:45:50,659 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7af820d1-9207-4ff4-8abb-07cfbbe78451
2023-10-17 05:45:50,659 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37929
2023-10-17 05:45:50,660 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37929
2023-10-17 05:45:50,660 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38811
2023-10-17 05:45:50,660 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,660 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,660 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:50,660 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:50,660 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vqqdb4zk
2023-10-17 05:45:50,661 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d97e20ec-b688-4390-b525-b844023ad079
2023-10-17 05:45:50,665 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34541
2023-10-17 05:45:50,665 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34541
2023-10-17 05:45:50,665 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39863
2023-10-17 05:45:50,666 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,666 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,666 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:50,666 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:50,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-goccllqt
2023-10-17 05:45:50,665 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35341
2023-10-17 05:45:50,666 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35341
2023-10-17 05:45:50,666 - distributed.worker - INFO - Starting Worker plugin PreImport-6d8fb6c1-aec5-4341-b274-b8c984b87612
2023-10-17 05:45:50,666 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43985
2023-10-17 05:45:50,666 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,667 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,667 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0d40852f-0d80-4cb4-ba1d-a2c6a67f3619
2023-10-17 05:45:50,667 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5a5e89bd-9a5c-499c-bcd5-31bcffc9f8ae
2023-10-17 05:45:50,667 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:50,667 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:50,667 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fljghtgf
2023-10-17 05:45:50,667 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2024b72c-2ef3-41ef-882a-13f7f6fd21b6
2023-10-17 05:45:50,666 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35271
2023-10-17 05:45:50,668 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35271
2023-10-17 05:45:50,669 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40621
2023-10-17 05:45:50,669 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,669 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,669 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:50,669 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:50,669 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zj_dvskm
2023-10-17 05:45:50,669 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40541
2023-10-17 05:45:50,670 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40541
2023-10-17 05:45:50,670 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38257
2023-10-17 05:45:50,670 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,670 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,670 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8b7b5e37-f302-4687-83e1-bd0e49258ba1
2023-10-17 05:45:50,670 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:45:50,670 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-10-17 05:45:50,670 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wp_r07g3
2023-10-17 05:45:50,671 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ba6dde8d-812a-4638-8fc8-b59bf0b34772
2023-10-17 05:45:50,671 - distributed.worker - INFO - Starting Worker plugin RMMSetup-71c80909-e627-417e-8569-f6ed83032069
2023-10-17 05:45:50,801 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e7349124-a902-49d4-b496-859ef874f58f
2023-10-17 05:45:50,801 - distributed.worker - INFO - Starting Worker plugin PreImport-22f89596-db19-4842-ae44-9223a7f6b4ba
2023-10-17 05:45:50,801 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,823 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5cbde69f-c6b8-41ce-a593-ff496bc43481
2023-10-17 05:45:50,823 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2d78c405-da00-48d6-af9f-263f7cbecb92
2023-10-17 05:45:50,823 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fae4fd29-a849-4f31-b099-07307e60a41d
2023-10-17 05:45:50,823 - distributed.worker - INFO - Starting Worker plugin PreImport-51fcdf3a-dd74-4d0f-9b0b-2f525cccbd77
2023-10-17 05:45:50,823 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,823 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b17643a4-23da-4570-8def-2122101244ed
2023-10-17 05:45:50,824 - distributed.worker - INFO - Starting Worker plugin PreImport-3205bbdc-759c-416e-9c40-0128eb6b06c9
2023-10-17 05:45:50,824 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,824 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,826 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37929', status: init, memory: 0, processing: 0>
2023-10-17 05:45:50,827 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37929
2023-10-17 05:45:50,827 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43274
2023-10-17 05:45:50,827 - distributed.worker - INFO - Starting Worker plugin PreImport-3aae780b-92e7-40ef-9088-75bfa39e3148
2023-10-17 05:45:50,827 - distributed.worker - INFO - Starting Worker plugin PreImport-c102b9dc-2836-4958-90f2-35205f221afb
2023-10-17 05:45:50,828 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,828 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,828 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:50,829 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,829 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,830 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:50,831 - distributed.worker - INFO - Starting Worker plugin PreImport-48bbcb71-c131-4d99-b017-0fd6c3821a4e
2023-10-17 05:45:50,832 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,848 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34541', status: init, memory: 0, processing: 0>
2023-10-17 05:45:50,849 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34541
2023-10-17 05:45:50,849 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43278
2023-10-17 05:45:50,850 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:50,851 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,851 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,852 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40541', status: init, memory: 0, processing: 0>
2023-10-17 05:45:50,852 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40541
2023-10-17 05:45:50,852 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:50,852 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43294
2023-10-17 05:45:50,853 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:50,854 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,854 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,856 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:50,860 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35271', status: init, memory: 0, processing: 0>
2023-10-17 05:45:50,860 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35271
2023-10-17 05:45:50,860 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43308
2023-10-17 05:45:50,861 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:50,862 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,862 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,862 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35341', status: init, memory: 0, processing: 0>
2023-10-17 05:45:50,863 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35341
2023-10-17 05:45:50,863 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43334
2023-10-17 05:45:50,864 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:50,865 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:50,866 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,866 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,866 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37711', status: init, memory: 0, processing: 0>
2023-10-17 05:45:50,867 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37711
2023-10-17 05:45:50,867 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43320
2023-10-17 05:45:50,867 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46711', status: init, memory: 0, processing: 0>
2023-10-17 05:45:50,868 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46711
2023-10-17 05:45:50,868 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43312
2023-10-17 05:45:50,868 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:50,869 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:50,870 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:45:50,870 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,870 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,871 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:45:50,871 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:45:50,873 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:45:50,873 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
2023-10-17 05:45:51,027 - distributed.worker - INFO - Starting Worker plugin PreImport-2d084268-358b-4ee4-8852-6713e476813d
2023-10-17 05:45:51,028 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45275. Reason: failure-to-start-<class 'MemoryError'>
2023-10-17 05:45:51,028 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2023-10-17 05:45:51,033 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1476, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 953, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 630, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
2023-10-17 05:45:51,038 - distributed.nanny - ERROR - Failed to start process
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1476, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 953, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 630, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
2023-10-17 05:45:51,040 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40301'. Reason: nanny-instantiate-failed
2023-10-17 05:45:51,041 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-instantiate-failed
2023-10-17 05:45:51,448 - distributed.nanny - INFO - Worker process 55054 was killed by signal 15
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1476, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 362, in start_unsafe
    response = await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 953, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 630, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-10-17 05:45:51,452 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=55078 parent=54889 started daemon>
2023-10-17 05:45:51,452 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=55075 parent=54889 started daemon>
2023-10-17 05:45:51,452 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=55072 parent=54889 started daemon>
2023-10-17 05:45:51,449 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:44044'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44044>: Stream is closed
2023-10-17 05:45:51,453 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=55069 parent=54889 started daemon>
2023-10-17 05:45:51,453 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=55065 parent=54889 started daemon>
2023-10-17 05:45:51,453 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=55061 parent=54889 started daemon>
2023-10-17 05:45:51,453 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=55057 parent=54889 started daemon>
2023-10-17 05:45:51,499 - distributed.core - INFO - Connection to tcp://127.0.0.1:43294 has been closed.
2023-10-17 05:45:51,499 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40541', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521551.499876')
2023-10-17 05:45:51,501 - distributed.core - INFO - Connection to tcp://127.0.0.1:43278 has been closed.
2023-10-17 05:45:51,501 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34541', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521551.5011642')
2023-10-17 05:45:51,502 - distributed.core - INFO - Connection to tcp://127.0.0.1:43274 has been closed.
2023-10-17 05:45:51,502 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37929', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521551.502326')
2023-10-17 05:45:51,502 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43278>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-10-17 05:45:51,503 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43274>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43274>: Stream is closed
2023-10-17 05:45:51,504 - distributed.core - INFO - Connection to tcp://127.0.0.1:43320 has been closed.
2023-10-17 05:45:51,504 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37711', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521551.5045085')
2023-10-17 05:45:51,506 - distributed.core - INFO - Connection to tcp://127.0.0.1:43334 has been closed.
2023-10-17 05:45:51,507 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35341', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521551.5069945')
2023-10-17 05:45:51,507 - distributed.core - INFO - Connection to tcp://127.0.0.1:43312 has been closed.
2023-10-17 05:45:51,507 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46711', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521551.5074778')
2023-10-17 05:45:51,508 - distributed.core - INFO - Connection to tcp://127.0.0.1:43308 has been closed.
2023-10-17 05:45:51,508 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35271', status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521551.5082037')
2023-10-17 05:45:51,508 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:45:52,266 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 55078 exit status was already read will report exitcode 255
2023-10-17 05:46:01,318 - distributed.scheduler - INFO - Remove client Client-691a5e86-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:01,319 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44130; closing.
2023-10-17 05:46:01,319 - distributed.scheduler - INFO - Remove client Client-691a5e86-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:01,320 - distributed.scheduler - INFO - Close client connection: Client-691a5e86-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:01,321 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:46:01,321 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:46:01,321 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:46:01,322 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:46:01,323 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-10-17 05:46:03,759 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:46:03,763 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45035 instead
  warnings.warn(
2023-10-17 05:46:03,767 - distributed.scheduler - INFO - State start
2023-10-17 05:46:03,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-6vdonbj6', purging
2023-10-17 05:46:03,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-fljghtgf', purging
2023-10-17 05:46:03,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-goccllqt', purging
2023-10-17 05:46:03,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-vqqdb4zk', purging
2023-10-17 05:46:03,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-zj_dvskm', purging
2023-10-17 05:46:03,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ch04k8w5', purging
2023-10-17 05:46:03,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-wp_r07g3', purging
2023-10-17 05:46:03,792 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:46:03,793 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:46:03,794 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45035/status
2023-10-17 05:46:03,794 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:46:03,849 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38511'
2023-10-17 05:46:04,998 - distributed.scheduler - INFO - Receive client connection: Client-74815c66-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:05,011 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37002
2023-10-17 05:46:05,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:46:05,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:46:05,558 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:46:06,691 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44055
2023-10-17 05:46:06,692 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44055
2023-10-17 05:46:06,692 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40613
2023-10-17 05:46:06,692 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:46:06,692 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:46:06,692 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:46:06,692 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-17 05:46:06,692 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uzdaymz0
2023-10-17 05:46:06,693 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5c7eb8ff-bb9d-4f95-8e14-7a772b7c21af
2023-10-17 05:46:06,801 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e04974fa-40ef-4c7e-9624-f7d646344b91
2023-10-17 05:46:06,801 - distributed.worker - INFO - Starting Worker plugin PreImport-82014375-257a-47b0-9e55-26b47b931525
2023-10-17 05:46:06,802 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:46:06,839 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44055', status: init, memory: 0, processing: 0>
2023-10-17 05:46:06,840 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44055
2023-10-17 05:46:06,840 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37014
2023-10-17 05:46:06,841 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-10-17 05:46:06,842 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-10-17 05:46:06,842 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:46:06,844 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-10-17 05:46:06,882 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-10-17 05:46:06,886 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:46:06,888 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-10-17 05:46:06,890 - distributed.scheduler - INFO - Remove client Client-74815c66-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:06,891 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37002; closing.
2023-10-17 05:46:06,891 - distributed.scheduler - INFO - Remove client Client-74815c66-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:06,891 - distributed.scheduler - INFO - Close client connection: Client-74815c66-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:06,892 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38511'. Reason: nanny-close
2023-10-17 05:46:06,892 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-10-17 05:46:06,894 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44055. Reason: nanny-close
2023-10-17 05:46:06,896 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37014; closing.
2023-10-17 05:46:06,896 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-10-17 05:46:06,896 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44055', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1697521566.896662')
2023-10-17 05:46:06,896 - distributed.scheduler - INFO - Lost all workers
2023-10-17 05:46:06,898 - distributed.nanny - INFO - Worker closed
2023-10-17 05:46:08,109 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:46:08,110 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:46:08,110 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:46:08,111 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:46:08,112 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-10-17 05:46:10,376 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:46:10,381 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43085 instead
  warnings.warn(
2023-10-17 05:46:10,385 - distributed.scheduler - INFO - State start
2023-10-17 05:46:10,407 - distributed.scheduler - INFO - -----------------------------------------------
2023-10-17 05:46:10,408 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-10-17 05:46:10,409 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43085/status
2023-10-17 05:46:10,409 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-10-17 05:46:10,476 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41721'
2023-10-17 05:46:12,139 - distributed.scheduler - INFO - Receive client connection: Client-786a65ca-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:12,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-10-17 05:46:12,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-10-17 05:46:12,152 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34558
2023-10-17 05:46:12,155 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-10-17 05:46:13,095 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36523
2023-10-17 05:46:13,095 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36523
2023-10-17 05:46:13,095 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43181
2023-10-17 05:46:13,095 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-10-17 05:46:13,095 - distributed.worker - INFO - -------------------------------------------------
2023-10-17 05:46:13,096 - distributed.worker - INFO -               Threads:                          1
2023-10-17 05:46:13,096 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-10-17 05:46:13,096 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mytk1q3k
2023-10-17 05:46:13,096 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4cbec665-c03e-48d2-b0f6-6ab724d67c65
std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded
2023-10-17 05:46:13,381 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fe0c5967-6884-40cd-87f4-76b61783642b
2023-10-17 05:46:13,382 - distributed.worker - INFO - Starting Worker plugin PreImport-2a5386b7-2584-442e-b421-35be6fb28ffb
2023-10-17 05:46:13,382 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36523. Reason: failure-to-start-<class 'MemoryError'>
2023-10-17 05:46:13,382 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2023-10-17 05:46:13,385 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1476, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 953, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 630, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
2023-10-17 05:46:13,414 - distributed.nanny - ERROR - Failed to start process
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1476, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 953, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 630, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
2023-10-17 05:46:13,417 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41721'. Reason: nanny-instantiate-failed
2023-10-17 05:46:13,417 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-instantiate-failed
2023-10-17 05:46:13,850 - distributed.nanny - INFO - Worker process 55512 was killed by signal 15
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1476, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1876, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/utils.py", line 121, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:201: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 362, in start_unsafe
    response = await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 448, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 748, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 889, in _wait_until_connected
    raise msg["exception"]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 953, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 630, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-10-17 05:46:13,852 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:34548'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:34548>: Stream is closed
2023-10-17 05:46:22,248 - distributed.scheduler - INFO - Remove client Client-786a65ca-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:22,249 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34558; closing.
2023-10-17 05:46:22,249 - distributed.scheduler - INFO - Remove client Client-786a65ca-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:22,250 - distributed.scheduler - INFO - Close client connection: Client-786a65ca-6cb0-11ee-8bdc-d8c49764f6bb
2023-10-17 05:46:22,250 - distributed._signals - INFO - Received signal SIGINT (2)
2023-10-17 05:46:22,251 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-10-17 05:46:22,251 - distributed.scheduler - INFO - Scheduler closing all comms
2023-10-17 05:46:22,252 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-10-17 05:46:22,253 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43039 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44529 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35821 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37903 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions 2023-10-17 05:48:21,897 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-f01fb5de-bbf0-4603-ab22-12170e078747
Function:  _run_coroutine_on_worker
args:      (91838555705749578045039498074305039585, <function shuffle_task at 0x7ff7725aadc0>, ('explicit-comms-shuffle-f8c0a0df09478b6fa12c2e4100f3fdb2', {0: {('from_pandas-bfb6550680bff94cc6e078984cc59cdb', 1)}, 1: set(), 2: set(), 3: {('from_pandas-bfb6550680bff94cc6e078984cc59cdb', 0)}}, {0: {0}, 1: {1}, 2: set(), 3: set()}, ['key'], 2, False, 1, 2))
kwargs:    {}
Exception: "CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 24 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
