============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.3, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-12-10 06:34:16,787 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:16,791 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-12-10 06:34:16,794 - distributed.scheduler - INFO - State start
2023-12-10 06:34:16,951 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:16,952 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-12-10 06:34:16,953 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-12-10 06:34:16,953 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:34:17,065 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36549'
2023-12-10 06:34:17,088 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42433'
2023-12-10 06:34:17,090 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34979'
2023-12-10 06:34:17,098 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44821'
2023-12-10 06:34:17,342 - distributed.scheduler - INFO - Receive client connection: Client-234018d2-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:17,356 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47482
2023-12-10 06:34:18,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:18,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:18,763 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:18,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:18,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:18,769 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:18,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:18,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:18,811 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:18,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:18,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:18,823 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-12-10 06:34:18,840 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46619
2023-12-10 06:34:18,840 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46619
2023-12-10 06:34:18,840 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42651
2023-12-10 06:34:18,840 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-10 06:34:18,840 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:18,840 - distributed.worker - INFO -               Threads:                          4
2023-12-10 06:34:18,840 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-12-10 06:34:18,840 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-xemdj9df
2023-12-10 06:34:18,840 - distributed.worker - INFO - Starting Worker plugin PreImport-5466ae85-a1e8-4b0f-b8b1-a87cd15f92d5
2023-12-10 06:34:18,841 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f65203fd-59c1-44dd-ae83-5c0dc4d05906
2023-12-10 06:34:18,841 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9ef4f6de-e8dc-4716-8a0c-6fd7dfd9f5f6
2023-12-10 06:34:18,841 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:19,336 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46619', status: init, memory: 0, processing: 0>
2023-12-10 06:34:19,338 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46619
2023-12-10 06:34:19,338 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47504
2023-12-10 06:34:19,339 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:19,340 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-12-10 06:34:19,340 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:19,341 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-12-10 06:34:20,107 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38925
2023-12-10 06:34:20,108 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44745
2023-12-10 06:34:20,108 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38925
2023-12-10 06:34:20,108 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44745
2023-12-10 06:34:20,108 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33939
2023-12-10 06:34:20,108 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43597
2023-12-10 06:34:20,108 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-10 06:34:20,108 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-10 06:34:20,108 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:20,108 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:20,108 - distributed.worker - INFO -               Threads:                          4
2023-12-10 06:34:20,108 - distributed.worker - INFO -               Threads:                          4
2023-12-10 06:34:20,109 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-12-10 06:34:20,109 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-12-10 06:34:20,109 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-60_w91pm
2023-12-10 06:34:20,109 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-zfh9ogug
2023-12-10 06:34:20,109 - distributed.worker - INFO - Starting Worker plugin PreImport-d0642aa2-39a1-45ff-a2fb-1eeb6156a601
2023-12-10 06:34:20,109 - distributed.worker - INFO - Starting Worker plugin PreImport-067329f4-a4c4-44fa-8b74-d21419b59bd1
2023-12-10 06:34:20,109 - distributed.worker - INFO - Starting Worker plugin RMMSetup-20d69cc9-529b-494b-aab7-cee065b13dd4
2023-12-10 06:34:20,109 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f9f909ac-9ed9-4bba-9196-5c7a268a92a2
2023-12-10 06:34:20,110 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1796fbd9-6aef-4518-9428-0ecd7d6a089a
2023-12-10 06:34:20,110 - distributed.worker - INFO - Starting Worker plugin RMMSetup-45c1ce56-326e-451f-b17c-151ff244880f
2023-12-10 06:34:20,110 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:20,110 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:20,143 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44745', status: init, memory: 0, processing: 0>
2023-12-10 06:34:20,143 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44745
2023-12-10 06:34:20,143 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35766
2023-12-10 06:34:20,144 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:20,145 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38925', status: init, memory: 0, processing: 0>
2023-12-10 06:34:20,145 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-12-10 06:34:20,145 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38925
2023-12-10 06:34:20,145 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:20,145 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35778
2023-12-10 06:34:20,146 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:20,147 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-12-10 06:34:20,147 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:20,148 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-12-10 06:34:20,149 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-12-10 06:34:20,270 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36879
2023-12-10 06:34:20,271 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36879
2023-12-10 06:34:20,271 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36855
2023-12-10 06:34:20,271 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-10 06:34:20,271 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:20,271 - distributed.worker - INFO -               Threads:                          4
2023-12-10 06:34:20,272 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-12-10 06:34:20,272 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-3xu4c9sv
2023-12-10 06:34:20,272 - distributed.worker - INFO - Starting Worker plugin PreImport-9c5bfb5d-0784-431b-9693-4676b1d9da71
2023-12-10 06:34:20,272 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7b9c9e91-b1b8-42cd-b6a7-5f108b9cee5b
2023-12-10 06:34:20,273 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-032c30cb-84ff-4912-9b31-336ff3ca180d
2023-12-10 06:34:20,273 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:20,311 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36879', status: init, memory: 0, processing: 0>
2023-12-10 06:34:20,312 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36879
2023-12-10 06:34:20,312 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35792
2023-12-10 06:34:20,313 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:20,315 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-12-10 06:34:20,315 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:20,317 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-12-10 06:34:20,349 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-12-10 06:34:20,349 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-12-10 06:34:20,350 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-12-10 06:34:20,374 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-12-10 06:34:20,378 - distributed.scheduler - INFO - Remove client Client-234018d2-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:20,378 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47482; closing.
2023-12-10 06:34:20,379 - distributed.scheduler - INFO - Remove client Client-234018d2-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:20,379 - distributed.scheduler - INFO - Close client connection: Client-234018d2-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:20,380 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36549'. Reason: nanny-close
2023-12-10 06:34:20,381 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:20,381 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42433'. Reason: nanny-close
2023-12-10 06:34:20,382 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:20,382 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38925. Reason: nanny-close
2023-12-10 06:34:20,383 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36879. Reason: nanny-close
2023-12-10 06:34:20,384 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-12-10 06:34:20,385 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35778; closing.
2023-12-10 06:34:20,385 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38925', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190060.3853002')
2023-12-10 06:34:20,385 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-12-10 06:34:20,386 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35792; closing.
2023-12-10 06:34:20,386 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:20,386 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36879', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190060.3868492')
2023-12-10 06:34:20,387 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34979'. Reason: nanny-close
2023-12-10 06:34:20,388 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:20,388 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:20,388 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44821'. Reason: nanny-close
2023-12-10 06:34:20,388 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:20,389 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44745. Reason: nanny-close
2023-12-10 06:34:20,389 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46619. Reason: nanny-close
2023-12-10 06:34:20,390 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35766; closing.
2023-12-10 06:34:20,390 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-12-10 06:34:20,391 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-12-10 06:34:20,391 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44745', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190060.3911629')
2023-12-10 06:34:20,391 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47504; closing.
2023-12-10 06:34:20,392 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46619', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190060.3920038')
2023-12-10 06:34:20,392 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:34:20,392 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:20,392 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:20,392 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9359 remote=tcp://127.0.0.1:47504>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-12-10 06:34:21,647 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:34:21,647 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:34:21,648 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:34:21,649 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-12-10 06:34:21,649 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-12-10 06:34:23,696 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:23,700 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37981 instead
  warnings.warn(
2023-12-10 06:34:23,703 - distributed.scheduler - INFO - State start
2023-12-10 06:34:23,724 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:23,725 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:34:23,726 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37981/status
2023-12-10 06:34:23,726 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:34:23,854 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36993'
2023-12-10 06:34:23,867 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40527'
2023-12-10 06:34:23,881 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43731'
2023-12-10 06:34:23,891 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40691'
2023-12-10 06:34:23,893 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42157'
2023-12-10 06:34:23,902 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37931'
2023-12-10 06:34:23,910 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37333'
2023-12-10 06:34:23,920 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46309'
2023-12-10 06:34:25,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:25,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:25,723 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:25,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:25,745 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:25,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:25,745 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:25,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:25,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:25,749 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:25,749 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:25,750 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:25,750 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:25,752 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:25,754 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:25,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:25,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:25,770 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:25,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:25,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:25,775 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:25,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:25,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:25,831 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:27,161 - distributed.scheduler - INFO - Receive client connection: Client-27669fbf-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:27,174 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37542
2023-12-10 06:34:28,134 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32951
2023-12-10 06:34:28,135 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32951
2023-12-10 06:34:28,135 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44469
2023-12-10 06:34:28,135 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,135 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,135 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:28,136 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:28,136 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vusdg3n4
2023-12-10 06:34:28,136 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ed9eaf13-5d22-49b9-b5aa-fa226e358957
2023-12-10 06:34:28,136 - distributed.worker - INFO - Starting Worker plugin PreImport-1a910c0d-6e24-4e4d-a784-dd9893ab4455
2023-12-10 06:34:28,137 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9b18ffdf-0d34-4647-a817-89525035730e
2023-12-10 06:34:28,225 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35431
2023-12-10 06:34:28,226 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35431
2023-12-10 06:34:28,226 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39473
2023-12-10 06:34:28,226 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,226 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,226 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:28,226 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:28,226 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n51i2thr
2023-12-10 06:34:28,227 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3fa6168a-fc6b-4dab-872e-71e16a4fb37a
2023-12-10 06:34:28,227 - distributed.worker - INFO - Starting Worker plugin PreImport-33aca644-0adf-437f-8497-99bbe86a568c
2023-12-10 06:34:28,227 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ca2d0884-d66e-49ed-9a53-4738ece37dae
2023-12-10 06:34:28,227 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35397
2023-12-10 06:34:28,228 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35397
2023-12-10 06:34:28,227 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44701
2023-12-10 06:34:28,228 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33677
2023-12-10 06:34:28,228 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44701
2023-12-10 06:34:28,228 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,228 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42801
2023-12-10 06:34:28,228 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,228 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,228 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,228 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:28,228 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:28,228 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:28,228 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q2i5mlu4
2023-12-10 06:34:28,228 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:28,229 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f__fd4nv
2023-12-10 06:34:28,229 - distributed.worker - INFO - Starting Worker plugin PreImport-e079b881-a188-48f5-a902-f80da2444750
2023-12-10 06:34:28,229 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7dacf8ee-87d0-4a5a-9948-95e7766fd23c
2023-12-10 06:34:28,229 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d936ff6e-44a8-431c-b029-46d89a198e4d
2023-12-10 06:34:28,229 - distributed.worker - INFO - Starting Worker plugin PreImport-091c775c-bf9b-4ff1-8faf-f23f86c18891
2023-12-10 06:34:28,229 - distributed.worker - INFO - Starting Worker plugin RMMSetup-911b67b2-e9c1-4838-a7ee-6c4877edd259
2023-12-10 06:34:28,229 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ce65dd77-bafb-4bd8-aa8c-f93c4d01383c
2023-12-10 06:34:28,264 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,296 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32951', status: init, memory: 0, processing: 0>
2023-12-10 06:34:28,298 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32951
2023-12-10 06:34:28,298 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37562
2023-12-10 06:34:28,298 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:28,299 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,299 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,301 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:28,309 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33737
2023-12-10 06:34:28,310 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33737
2023-12-10 06:34:28,310 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40925
2023-12-10 06:34:28,310 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,310 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,310 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:28,311 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:28,311 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yaezwzn7
2023-12-10 06:34:28,311 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1131c1a3-d56a-407b-94d2-b13bf70cf31a
2023-12-10 06:34:28,311 - distributed.worker - INFO - Starting Worker plugin PreImport-41caf1c3-cd95-451d-9f57-1da5b4fd0a6d
2023-12-10 06:34:28,312 - distributed.worker - INFO - Starting Worker plugin RMMSetup-193d0c68-21f4-40c3-a53b-8f502d3245e3
2023-12-10 06:34:28,312 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35489
2023-12-10 06:34:28,313 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35489
2023-12-10 06:34:28,313 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44617
2023-12-10 06:34:28,313 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,313 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,313 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:28,314 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:28,314 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9veqfkfu
2023-12-10 06:34:28,313 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33115
2023-12-10 06:34:28,314 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33115
2023-12-10 06:34:28,314 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34683
2023-12-10 06:34:28,314 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,314 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,314 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b41cc0d4-5547-4055-92e6-fcd7b497bbc7
2023-12-10 06:34:28,314 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:28,314 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:28,314 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-63r3y8l8
2023-12-10 06:34:28,315 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9f62d718-4fd8-4812-9f93-32641bd0eb4c
2023-12-10 06:34:28,314 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33057
2023-12-10 06:34:28,315 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33057
2023-12-10 06:34:28,315 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38195
2023-12-10 06:34:28,316 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,315 - distributed.worker - INFO - Starting Worker plugin PreImport-dcd6ab0e-d8b5-4e76-8724-78fed0382852
2023-12-10 06:34:28,316 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,316 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a571cdd3-66c2-4567-b9f3-92e93e69c569
2023-12-10 06:34:28,316 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:28,316 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:28,316 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pu6sv65f
2023-12-10 06:34:28,316 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-aa649039-73fb-43e3-9235-8f0bf51fffae
2023-12-10 06:34:28,317 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cafd9075-acc1-4697-84dc-00e50380e893
2023-12-10 06:34:28,320 - distributed.worker - INFO - Starting Worker plugin PreImport-1104bb75-3c09-4664-8f86-a2a8b8ce0cda
2023-12-10 06:34:28,320 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8f4e1014-5cbd-4d56-b16e-3ad3b20a33e8
2023-12-10 06:34:28,398 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,407 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,416 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,426 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,434 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35397', status: init, memory: 0, processing: 0>
2023-12-10 06:34:28,435 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35397
2023-12-10 06:34:28,435 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37572
2023-12-10 06:34:28,436 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:28,437 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,437 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,438 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:28,464 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44701', status: init, memory: 0, processing: 0>
2023-12-10 06:34:28,465 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44701
2023-12-10 06:34:28,465 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37580
2023-12-10 06:34:28,466 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33737', status: init, memory: 0, processing: 0>
2023-12-10 06:34:28,466 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:28,466 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33737
2023-12-10 06:34:28,466 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37594
2023-12-10 06:34:28,467 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,467 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,467 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35431', status: init, memory: 0, processing: 0>
2023-12-10 06:34:28,467 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:28,468 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35431
2023-12-10 06:34:28,468 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37566
2023-12-10 06:34:28,468 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,468 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,468 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:28,469 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:28,470 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:28,470 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,471 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,473 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:28,488 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,488 - distributed.worker - INFO - Starting Worker plugin PreImport-65883bee-99fc-4e76-aa1e-3afdc977cf8c
2023-12-10 06:34:28,489 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,489 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,524 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33057', status: init, memory: 0, processing: 0>
2023-12-10 06:34:28,525 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33057
2023-12-10 06:34:28,525 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37600
2023-12-10 06:34:28,526 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35489', status: init, memory: 0, processing: 0>
2023-12-10 06:34:28,526 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35489
2023-12-10 06:34:28,526 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37608
2023-12-10 06:34:28,526 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:28,527 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33115', status: init, memory: 0, processing: 0>
2023-12-10 06:34:28,528 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,528 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33115
2023-12-10 06:34:28,528 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,528 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37620
2023-12-10 06:34:28,528 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:28,529 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,529 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,529 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:28,530 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:28,530 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:28,530 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:28,532 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:28,533 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:28,545 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:28,545 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:28,545 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:28,546 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:28,546 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:28,546 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:28,546 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:28,546 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:28,550 - distributed.scheduler - INFO - Remove client Client-27669fbf-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:28,550 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37542; closing.
2023-12-10 06:34:28,551 - distributed.scheduler - INFO - Remove client Client-27669fbf-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:28,551 - distributed.scheduler - INFO - Close client connection: Client-27669fbf-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:28,552 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36993'. Reason: nanny-close
2023-12-10 06:34:28,552 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40527'. Reason: nanny-close
2023-12-10 06:34:28,552 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43731'. Reason: nanny-close
2023-12-10 06:34:28,553 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:28,553 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40691'. Reason: nanny-close
2023-12-10 06:34:28,554 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:28,554 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32951. Reason: nanny-close
2023-12-10 06:34:28,554 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42157'. Reason: nanny-close
2023-12-10 06:34:28,554 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37931'. Reason: nanny-close
2023-12-10 06:34:28,554 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35397. Reason: nanny-close
2023-12-10 06:34:28,554 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:28,555 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37333'. Reason: nanny-close
2023-12-10 06:34:28,555 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:28,555 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35431. Reason: nanny-close
2023-12-10 06:34:28,556 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46309'. Reason: nanny-close
2023-12-10 06:34:28,556 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:28,556 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37562; closing.
2023-12-10 06:34:28,556 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:28,556 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44701. Reason: nanny-close
2023-12-10 06:34:28,556 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32951', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190068.5565288')
2023-12-10 06:34:28,556 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:28,557 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33737. Reason: nanny-close
2023-12-10 06:34:28,557 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:28,558 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:28,558 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37572; closing.
2023-12-10 06:34:28,558 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:28,558 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:28,559 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35397', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190068.559264')
2023-12-10 06:34:28,559 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:28,559 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37566; closing.
2023-12-10 06:34:28,559 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:28,560 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35431', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190068.5602412')
2023-12-10 06:34:28,560 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:28,560 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37580; closing.
2023-12-10 06:34:28,561 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:28,561 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44701', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190068.5611787')
2023-12-10 06:34:28,561 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37594; closing.
2023-12-10 06:34:28,561 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33737', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190068.5619175')
2023-12-10 06:34:28,564 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:28,565 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33115. Reason: nanny-close
2023-12-10 06:34:28,565 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:28,566 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35489. Reason: nanny-close
2023-12-10 06:34:28,567 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:28,568 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37620; closing.
2023-12-10 06:34:28,568 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33115', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190068.5684586')
2023-12-10 06:34:28,568 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:28,569 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37608; closing.
2023-12-10 06:34:28,569 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35489', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190068.5695808')
2023-12-10 06:34:28,569 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:28,570 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:28,576 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:28,577 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33057. Reason: nanny-close
2023-12-10 06:34:28,579 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37600; closing.
2023-12-10 06:34:28,579 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:28,579 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33057', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190068.5798306')
2023-12-10 06:34:28,580 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:34:28,581 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:30,019 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:34:30,019 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:34:30,020 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:34:30,021 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:34:30,021 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-12-10 06:34:32,130 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:32,134 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-12-10 06:34:32,137 - distributed.scheduler - INFO - State start
2023-12-10 06:34:32,159 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:32,160 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:34:32,160 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-12-10 06:34:32,161 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:34:32,362 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35779'
2023-12-10 06:34:32,376 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44263'
2023-12-10 06:34:32,394 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35973'
2023-12-10 06:34:32,396 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36025'
2023-12-10 06:34:32,404 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35171'
2023-12-10 06:34:32,413 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38877'
2023-12-10 06:34:32,422 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44303'
2023-12-10 06:34:32,434 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35269'
2023-12-10 06:34:32,667 - distributed.scheduler - INFO - Receive client connection: Client-2c66d41c-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:32,690 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54974
2023-12-10 06:34:34,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:34,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:34,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:34,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:34,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:34,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:34,255 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:34,255 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:34,258 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:34,258 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:34,258 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:34,259 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:34,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:34,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:34,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:34,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:34,294 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:34,295 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:34,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:34,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:34,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:34,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:34,329 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:34,330 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:37,617 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44779
2023-12-10 06:34:37,618 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44779
2023-12-10 06:34:37,618 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33297
2023-12-10 06:34:37,618 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,618 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39541
2023-12-10 06:34:37,618 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,618 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39541
2023-12-10 06:34:37,619 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32995
2023-12-10 06:34:37,618 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:37,619 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,619 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,619 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:37,619 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-16hv3flp
2023-12-10 06:34:37,619 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:37,619 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:37,619 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t21rcmkh
2023-12-10 06:34:37,619 - distributed.worker - INFO - Starting Worker plugin PreImport-c92e46cd-552e-4b54-885c-57d456d068ee
2023-12-10 06:34:37,619 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-23ef8907-61b1-47db-b84b-10528efd1267
2023-12-10 06:34:37,619 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5342aaaa-c8e3-4ad8-86e0-19e64c40fc3f
2023-12-10 06:34:37,619 - distributed.worker - INFO - Starting Worker plugin RMMSetup-21b5015e-13e9-4394-a910-3c9a58f02da1
2023-12-10 06:34:37,619 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46817
2023-12-10 06:34:37,620 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46817
2023-12-10 06:34:37,620 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43417
2023-12-10 06:34:37,620 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,620 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,620 - distributed.worker - INFO - Starting Worker plugin PreImport-49822467-39ae-4814-97aa-261b5d347c85
2023-12-10 06:34:37,620 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:37,620 - distributed.worker - INFO - Starting Worker plugin RMMSetup-52250ed8-704b-4d99-9917-b41e60a4f64a
2023-12-10 06:34:37,620 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:37,620 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j6_vkqru
2023-12-10 06:34:37,620 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f0861265-5ee2-48be-a275-480c1dce4cc2
2023-12-10 06:34:37,621 - distributed.worker - INFO - Starting Worker plugin PreImport-9346d26b-1fdc-49ec-a640-43205ae01434
2023-12-10 06:34:37,621 - distributed.worker - INFO - Starting Worker plugin RMMSetup-feb57f5a-5c6f-48eb-b006-6ff0cf37afbf
2023-12-10 06:34:37,624 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40119
2023-12-10 06:34:37,625 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40119
2023-12-10 06:34:37,625 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42097
2023-12-10 06:34:37,625 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,625 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,625 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:37,626 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:37,626 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dz45aech
2023-12-10 06:34:37,626 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bb157821-4777-4d18-b3e7-ab8d4713225a
2023-12-10 06:34:37,626 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f434c39c-a496-4968-ad83-ce90e5370130
2023-12-10 06:34:37,630 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46755
2023-12-10 06:34:37,631 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46755
2023-12-10 06:34:37,631 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34035
2023-12-10 06:34:37,631 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,631 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,631 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:37,631 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:37,631 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xy6na4xs
2023-12-10 06:34:37,631 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43541
2023-12-10 06:34:37,632 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43541
2023-12-10 06:34:37,632 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-82e99215-d209-4b25-965f-332befb1087f
2023-12-10 06:34:37,632 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43753
2023-12-10 06:34:37,632 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,632 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,632 - distributed.worker - INFO - Starting Worker plugin PreImport-e6dffb29-12fd-4c44-bfd0-8c886dde9244
2023-12-10 06:34:37,632 - distributed.worker - INFO - Starting Worker plugin RMMSetup-795bad1d-e683-4553-a24f-48e4e0534bdc
2023-12-10 06:34:37,632 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:37,632 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:37,632 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-eibyv6ry
2023-12-10 06:34:37,633 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-69a89401-ecde-4bfc-893c-3005a6a73bda
2023-12-10 06:34:37,632 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34453
2023-12-10 06:34:37,633 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34453
2023-12-10 06:34:37,633 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36881
2023-12-10 06:34:37,633 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,633 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,633 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:37,633 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:37,633 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mfvl23kx
2023-12-10 06:34:37,634 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-531e1fd8-4f46-4896-99d2-9e7ace8c1cd0
2023-12-10 06:34:37,634 - distributed.worker - INFO - Starting Worker plugin PreImport-70215249-e7b9-4a58-b6a7-517299c402aa
2023-12-10 06:34:37,634 - distributed.worker - INFO - Starting Worker plugin RMMSetup-072bfad9-754d-45bc-afd9-5b6c0770b790
2023-12-10 06:34:37,634 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42771
2023-12-10 06:34:37,635 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42771
2023-12-10 06:34:37,635 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39145
2023-12-10 06:34:37,635 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,635 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,635 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:37,635 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:37,635 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1vqx13uf
2023-12-10 06:34:37,635 - distributed.worker - INFO - Starting Worker plugin PreImport-a32d0ca6-ea23-422f-8de9-65716ad1200c
2023-12-10 06:34:37,636 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eebbd607-16fa-4d52-9ed4-1ae524ffe45a
2023-12-10 06:34:37,636 - distributed.worker - INFO - Starting Worker plugin PreImport-a8e3bb3d-bf86-4870-b592-d92129408d41
2023-12-10 06:34:37,636 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f41e10e3-cfde-4d7f-9ece-7eec0bf2297a
2023-12-10 06:34:37,637 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d657fb30-1543-43ca-ad9c-4b93f81ecc2e
2023-12-10 06:34:37,653 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,653 - distributed.worker - INFO - Starting Worker plugin PreImport-3c9dcce5-25d8-44cf-be93-2d6fcffc3109
2023-12-10 06:34:37,653 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,675 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,678 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,679 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,680 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,681 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,684 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40119', status: init, memory: 0, processing: 0>
2023-12-10 06:34:37,686 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40119
2023-12-10 06:34:37,686 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55006
2023-12-10 06:34:37,687 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44779', status: init, memory: 0, processing: 0>
2023-12-10 06:34:37,687 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:37,687 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44779
2023-12-10 06:34:37,687 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54996
2023-12-10 06:34:37,688 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,688 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,688 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:37,689 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,689 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,690 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:37,690 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,691 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:37,702 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46817', status: init, memory: 0, processing: 0>
2023-12-10 06:34:37,703 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46817
2023-12-10 06:34:37,703 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55010
2023-12-10 06:34:37,704 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:37,705 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,705 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,706 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46755', status: init, memory: 0, processing: 0>
2023-12-10 06:34:37,707 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:37,707 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46755
2023-12-10 06:34:37,707 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55038
2023-12-10 06:34:37,707 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43541', status: init, memory: 0, processing: 0>
2023-12-10 06:34:37,708 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:37,708 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43541
2023-12-10 06:34:37,708 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55008
2023-12-10 06:34:37,708 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,708 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:37,710 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:37,711 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,711 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,711 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42771', status: init, memory: 0, processing: 0>
2023-12-10 06:34:37,712 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42771
2023-12-10 06:34:37,712 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55044
2023-12-10 06:34:37,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:37,713 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:37,714 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,714 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,717 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39541', status: init, memory: 0, processing: 0>
2023-12-10 06:34:37,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:37,717 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39541
2023-12-10 06:34:37,717 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55022
2023-12-10 06:34:37,719 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:37,720 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,720 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,722 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:37,725 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34453', status: init, memory: 0, processing: 0>
2023-12-10 06:34:37,725 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34453
2023-12-10 06:34:37,725 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55058
2023-12-10 06:34:37,726 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:37,727 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:37,727 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:37,730 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:37,808 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:37,808 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:37,808 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:37,808 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:37,809 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:37,809 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:37,809 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:37,809 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:37,814 - distributed.scheduler - INFO - Remove client Client-2c66d41c-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:37,814 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54974; closing.
2023-12-10 06:34:37,814 - distributed.scheduler - INFO - Remove client Client-2c66d41c-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:37,815 - distributed.scheduler - INFO - Close client connection: Client-2c66d41c-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:37,816 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35779'. Reason: nanny-close
2023-12-10 06:34:37,816 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:37,817 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44263'. Reason: nanny-close
2023-12-10 06:34:37,817 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:37,818 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43541. Reason: nanny-close
2023-12-10 06:34:37,818 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35973'. Reason: nanny-close
2023-12-10 06:34:37,818 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:37,818 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34453. Reason: nanny-close
2023-12-10 06:34:37,818 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36025'. Reason: nanny-close
2023-12-10 06:34:37,819 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:37,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40119. Reason: nanny-close
2023-12-10 06:34:37,819 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35171'. Reason: nanny-close
2023-12-10 06:34:37,819 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:37,819 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46755. Reason: nanny-close
2023-12-10 06:34:37,820 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38877'. Reason: nanny-close
2023-12-10 06:34:37,820 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:37,820 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:37,820 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55008; closing.
2023-12-10 06:34:37,820 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42771. Reason: nanny-close
2023-12-10 06:34:37,821 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44303'. Reason: nanny-close
2023-12-10 06:34:37,821 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43541', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190077.8211026')
2023-12-10 06:34:37,821 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:37,821 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:37,821 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:37,821 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35269'. Reason: nanny-close
2023-12-10 06:34:37,821 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39541. Reason: nanny-close
2023-12-10 06:34:37,821 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:37,822 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:37,822 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44779. Reason: nanny-close
2023-12-10 06:34:37,822 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46817. Reason: nanny-close
2023-12-10 06:34:37,822 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:37,822 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:37,823 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55038; closing.
2023-12-10 06:34:37,823 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55006; closing.
2023-12-10 06:34:37,823 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:37,823 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55058; closing.
2023-12-10 06:34:37,823 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:37,823 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:37,824 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46755', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190077.8242419')
2023-12-10 06:34:37,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:37,824 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40119', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190077.824645')
2023-12-10 06:34:37,824 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:37,825 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34453', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190077.8250237')
2023-12-10 06:34:37,825 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:37,825 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:37,825 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55044; closing.
2023-12-10 06:34:37,825 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:37,826 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:37,826 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42771', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190077.8266864')
2023-12-10 06:34:37,827 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54996; closing.
2023-12-10 06:34:37,827 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55010; closing.
2023-12-10 06:34:37,827 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:37,827 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55022; closing.
2023-12-10 06:34:37,827 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44779', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190077.8278341')
2023-12-10 06:34:37,828 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46817', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190077.8282287')
2023-12-10 06:34:37,828 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39541', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190077.828707')
2023-12-10 06:34:37,828 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:34:39,284 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:34:39,284 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:34:39,285 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:34:39,286 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:34:39,287 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-12-10 06:34:41,517 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:41,521 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-12-10 06:34:41,524 - distributed.scheduler - INFO - State start
2023-12-10 06:34:41,544 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:41,545 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:34:41,546 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-12-10 06:34:41,546 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:34:41,624 - distributed.scheduler - INFO - Receive client connection: Client-32039f37-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:41,636 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42644
2023-12-10 06:34:41,707 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37241'
2023-12-10 06:34:41,728 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35867'
2023-12-10 06:34:41,742 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36917'
2023-12-10 06:34:41,758 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36639'
2023-12-10 06:34:41,760 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42855'
2023-12-10 06:34:41,769 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45437'
2023-12-10 06:34:41,772 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41597'
2023-12-10 06:34:41,788 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37189'
2023-12-10 06:34:43,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:43,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:43,582 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:43,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:43,594 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:43,598 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:43,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:43,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:43,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:43,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:43,628 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:43,629 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:43,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:43,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:43,682 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:43,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:43,712 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:43,713 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:43,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:43,716 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:43,718 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:43,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:43,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:43,944 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:45,521 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45563
2023-12-10 06:34:45,523 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45563
2023-12-10 06:34:45,524 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33127
2023-12-10 06:34:45,524 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:45,524 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:45,524 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:45,524 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:45,524 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zibh0oyr
2023-12-10 06:34:45,525 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-aaf0dce7-2c26-415b-8924-d6c0d2a2b586
2023-12-10 06:34:45,526 - distributed.worker - INFO - Starting Worker plugin PreImport-a03f822d-9b99-4d29-802e-a1b433b1dc80
2023-12-10 06:34:45,526 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6ed7c4aa-7eba-4829-91c5-59c351fdcaf3
2023-12-10 06:34:45,805 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:45,836 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45563', status: init, memory: 0, processing: 0>
2023-12-10 06:34:45,838 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45563
2023-12-10 06:34:45,838 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42754
2023-12-10 06:34:45,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:45,841 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:45,841 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:45,843 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:46,512 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46391
2023-12-10 06:34:46,512 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46391
2023-12-10 06:34:46,512 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35533
2023-12-10 06:34:46,513 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,513 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,511 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46819
2023-12-10 06:34:46,513 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:46,513 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46819
2023-12-10 06:34:46,513 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:46,511 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46649
2023-12-10 06:34:46,513 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0w6o76sw
2023-12-10 06:34:46,513 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46649
2023-12-10 06:34:46,513 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43703
2023-12-10 06:34:46,512 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38221
2023-12-10 06:34:46,513 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,513 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34051
2023-12-10 06:34:46,513 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,513 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38221
2023-12-10 06:34:46,513 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,513 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39799
2023-12-10 06:34:46,513 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,513 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,513 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,513 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8d1783fb-5aa6-4b7f-bfe7-cea63c1025bb
2023-12-10 06:34:46,513 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:46,513 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:46,513 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:46,513 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:46,514 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:46,514 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-asdq3la8
2023-12-10 06:34:46,514 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:46,514 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ge0f3wwc
2023-12-10 06:34:46,514 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bezouqy4
2023-12-10 06:34:46,514 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-58ffa4c4-ac74-4242-aa0e-3e59d348d077
2023-12-10 06:34:46,514 - distributed.worker - INFO - Starting Worker plugin PreImport-c44c5fca-e78a-464e-a4ab-e4ed263599f5
2023-12-10 06:34:46,514 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a4f05340-3798-4261-83a2-39bef6a12681
2023-12-10 06:34:46,515 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-13e2831e-6745-4f9c-9e18-3af796be88df
2023-12-10 06:34:46,515 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-60882bc4-39eb-42f1-959a-a3d6316e8982
2023-12-10 06:34:46,515 - distributed.worker - INFO - Starting Worker plugin PreImport-41c204da-58bf-47bf-a67c-dcac5798d7ed
2023-12-10 06:34:46,515 - distributed.worker - INFO - Starting Worker plugin PreImport-684f6cbe-0f00-46d7-9cca-9f058df245d7
2023-12-10 06:34:46,515 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7a82b078-b46e-4b4d-86e7-ec19800ee7de
2023-12-10 06:34:46,515 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dd1f22ef-9cc1-46f3-9bdc-1307a289732d
2023-12-10 06:34:46,516 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37389
2023-12-10 06:34:46,517 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37389
2023-12-10 06:34:46,517 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44095
2023-12-10 06:34:46,517 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,517 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,517 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:46,517 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:46,517 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-37a27q9j
2023-12-10 06:34:46,516 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35869
2023-12-10 06:34:46,518 - distributed.worker - INFO - Starting Worker plugin PreImport-fce6d60f-427d-4744-8ad8-6c4a9d76358e
2023-12-10 06:34:46,518 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35869
2023-12-10 06:34:46,518 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-de603660-d6ae-4ace-930a-2a11f0e3a8e1
2023-12-10 06:34:46,518 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37633
2023-12-10 06:34:46,518 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,518 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,518 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:46,519 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:46,519 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g8sy40xw
2023-12-10 06:34:46,519 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4913df0b-fc70-46a5-a754-c38a294919ef
2023-12-10 06:34:46,519 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45707
2023-12-10 06:34:46,520 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45707
2023-12-10 06:34:46,520 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43361
2023-12-10 06:34:46,520 - distributed.worker - INFO - Starting Worker plugin PreImport-dc09a252-5f16-4b63-a180-5253fee949a3
2023-12-10 06:34:46,520 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,520 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,520 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a9a0f033-a025-4328-959f-5fba9c2c39e0
2023-12-10 06:34:46,520 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:46,520 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:46,520 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-bg70c2g7
2023-12-10 06:34:46,520 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4270ba57-d463-4dfe-8956-371f0f4292d7
2023-12-10 06:34:46,521 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-44608534-9de5-4e46-bc09-83fb626eafc3
2023-12-10 06:34:46,521 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ef2d4fd5-2e1d-422d-85c9-fd14ef84f962
2023-12-10 06:34:46,792 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,792 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,793 - distributed.worker - INFO - Starting Worker plugin PreImport-fd439af6-9588-437b-b3ac-01b64505943b
2023-12-10 06:34:46,794 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,794 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-47692995-5644-4c1c-b88c-03425e6365c1
2023-12-10 06:34:46,795 - distributed.worker - INFO - Starting Worker plugin PreImport-d936c3dd-fcee-439c-996a-223cb20cb6c9
2023-12-10 06:34:46,795 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,796 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,796 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,797 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,822 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46391', status: init, memory: 0, processing: 0>
2023-12-10 06:34:46,823 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46391
2023-12-10 06:34:46,823 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42788
2023-12-10 06:34:46,824 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:46,825 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,825 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,827 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35869', status: init, memory: 0, processing: 0>
2023-12-10 06:34:46,827 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:46,827 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35869
2023-12-10 06:34:46,827 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42770
2023-12-10 06:34:46,828 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45707', status: init, memory: 0, processing: 0>
2023-12-10 06:34:46,828 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:46,829 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45707
2023-12-10 06:34:46,829 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42778
2023-12-10 06:34:46,829 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,830 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,830 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46819', status: init, memory: 0, processing: 0>
2023-12-10 06:34:46,830 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:46,831 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46819
2023-12-10 06:34:46,831 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42774
2023-12-10 06:34:46,831 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:46,831 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,831 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,832 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38221', status: init, memory: 0, processing: 0>
2023-12-10 06:34:46,832 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:46,833 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:46,833 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38221
2023-12-10 06:34:46,833 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42796
2023-12-10 06:34:46,834 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,834 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,834 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46649', status: init, memory: 0, processing: 0>
2023-12-10 06:34:46,834 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:46,834 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46649
2023-12-10 06:34:46,834 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42812
2023-12-10 06:34:46,834 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,835 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,836 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:46,836 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:46,836 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37389', status: init, memory: 0, processing: 0>
2023-12-10 06:34:46,836 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:46,836 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37389
2023-12-10 06:34:46,837 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:42820
2023-12-10 06:34:46,837 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,837 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,838 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:46,839 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:46,839 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:46,839 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:46,841 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:46,855 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:46,856 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:46,856 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:46,856 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:46,856 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:46,856 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:46,857 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:46,857 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:34:46,866 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:46,866 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:46,867 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:46,867 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:46,867 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:46,867 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:46,867 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:46,867 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:46,873 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:46,875 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:46,877 - distributed.scheduler - INFO - Remove client Client-32039f37-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:46,877 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42644; closing.
2023-12-10 06:34:46,877 - distributed.scheduler - INFO - Remove client Client-32039f37-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:46,878 - distributed.scheduler - INFO - Close client connection: Client-32039f37-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:46,879 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37241'. Reason: nanny-close
2023-12-10 06:34:46,879 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:46,880 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35867'. Reason: nanny-close
2023-12-10 06:34:46,880 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:46,880 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35869. Reason: nanny-close
2023-12-10 06:34:46,881 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36917'. Reason: nanny-close
2023-12-10 06:34:46,881 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:46,881 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45707. Reason: nanny-close
2023-12-10 06:34:46,881 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36639'. Reason: nanny-close
2023-12-10 06:34:46,881 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:46,882 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46649. Reason: nanny-close
2023-12-10 06:34:46,882 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42855'. Reason: nanny-close
2023-12-10 06:34:46,882 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:46,882 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37389. Reason: nanny-close
2023-12-10 06:34:46,882 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:46,882 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42770; closing.
2023-12-10 06:34:46,882 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45437'. Reason: nanny-close
2023-12-10 06:34:46,883 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35869', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190086.882985')
2023-12-10 06:34:46,883 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:46,883 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:46,883 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38221. Reason: nanny-close
2023-12-10 06:34:46,883 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41597'. Reason: nanny-close
2023-12-10 06:34:46,883 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:46,883 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46391. Reason: nanny-close
2023-12-10 06:34:46,884 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37189'. Reason: nanny-close
2023-12-10 06:34:46,884 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:46,884 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:46,884 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:46,884 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45563. Reason: nanny-close
2023-12-10 06:34:46,884 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:46,884 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42778; closing.
2023-12-10 06:34:46,885 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:46,885 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42812; closing.
2023-12-10 06:34:46,885 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:46,885 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45707', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190086.8856728')
2023-12-10 06:34:46,885 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46819. Reason: nanny-close
2023-12-10 06:34:46,885 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:46,886 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:46,886 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46649', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190086.8863585')
2023-12-10 06:34:46,886 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42820; closing.
2023-12-10 06:34:46,887 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:46,887 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:46,887 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:46,887 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:46,887 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37389', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190086.887742')
2023-12-10 06:34:46,887 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:46,888 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42796; closing.
2023-12-10 06:34:46,888 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42788; closing.
2023-12-10 06:34:46,888 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38221', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190086.8889136')
2023-12-10 06:34:46,889 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:46,889 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46391', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190086.88934')
2023-12-10 06:34:46,889 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:46,889 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42754; closing.
2023-12-10 06:34:46,890 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45563', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190086.8902533')
2023-12-10 06:34:46,890 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:42774; closing.
2023-12-10 06:34:46,891 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46819', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190086.8910787')
2023-12-10 06:34:46,891 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:34:48,497 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:34:48,497 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:34:48,497 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:34:48,499 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:34:48,499 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-12-10 06:34:50,685 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:50,689 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45355 instead
  warnings.warn(
2023-12-10 06:34:50,693 - distributed.scheduler - INFO - State start
2023-12-10 06:34:51,186 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:34:51,187 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:34:51,188 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45355/status
2023-12-10 06:34:51,188 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:34:51,337 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35887'
2023-12-10 06:34:51,349 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44787'
2023-12-10 06:34:51,366 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43009'
2023-12-10 06:34:51,368 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35503'
2023-12-10 06:34:51,376 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43255'
2023-12-10 06:34:51,385 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36339'
2023-12-10 06:34:51,394 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33311'
2023-12-10 06:34:51,405 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41717'
2023-12-10 06:34:53,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:53,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:53,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:53,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:53,210 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:53,211 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:53,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:53,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:53,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:53,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:53,240 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:53,242 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:53,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:53,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:53,261 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:53,263 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:53,263 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:53,267 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:53,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:53,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:53,279 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:53,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:34:53,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:34:53,306 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:34:55,767 - distributed.scheduler - INFO - Receive client connection: Client-376bf10f-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:55,780 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44868
2023-12-10 06:34:56,526 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45341
2023-12-10 06:34:56,527 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45341
2023-12-10 06:34:56,527 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39473
2023-12-10 06:34:56,528 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:56,528 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:56,528 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:56,528 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:56,528 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j2w0rd0g
2023-12-10 06:34:56,528 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-84b43399-5bed-4a0f-931f-506270e64b66
2023-12-10 06:34:56,528 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34757
2023-12-10 06:34:56,529 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34757
2023-12-10 06:34:56,529 - distributed.worker - INFO - Starting Worker plugin PreImport-2a06f2a7-c1ef-4674-8190-572458fa7830
2023-12-10 06:34:56,529 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41345
2023-12-10 06:34:56,529 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:56,529 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:56,529 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c96620dc-0b20-4569-a3be-e3511558027c
2023-12-10 06:34:56,529 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:56,529 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:56,529 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h0yp286t
2023-12-10 06:34:56,530 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2fa6e537-a5cd-40e5-8f1a-ffd857132aca
2023-12-10 06:34:56,531 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e7a2ec9d-8946-4b7a-88e6-2941825fe23c
2023-12-10 06:34:56,790 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46775
2023-12-10 06:34:56,790 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46775
2023-12-10 06:34:56,790 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41039
2023-12-10 06:34:56,790 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:56,791 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:56,791 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:56,791 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:56,791 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aac7y1pi
2023-12-10 06:34:56,791 - distributed.worker - INFO - Starting Worker plugin PreImport-bd899c7c-06d8-487d-8c62-01f7fef5b454
2023-12-10 06:34:56,791 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ac4e9216-94d0-4d01-9122-93a59cc94fef
2023-12-10 06:34:56,792 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a3f2f83f-aa4c-498e-9b69-4d9a2ea7579d
2023-12-10 06:34:56,794 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37133
2023-12-10 06:34:56,795 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37133
2023-12-10 06:34:56,795 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38279
2023-12-10 06:34:56,795 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:56,795 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:56,796 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:56,796 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:56,796 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8z89zg_u
2023-12-10 06:34:56,796 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-09931991-d943-45f2-b617-e58e71a4c004
2023-12-10 06:34:56,796 - distributed.worker - INFO - Starting Worker plugin PreImport-1f2bd756-3a90-4d07-8709-6f699f610d78
2023-12-10 06:34:56,796 - distributed.worker - INFO - Starting Worker plugin RMMSetup-55786f52-c1f8-4d37-81cb-40bc3520cd72
2023-12-10 06:34:56,798 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39493
2023-12-10 06:34:56,799 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39493
2023-12-10 06:34:56,799 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39269
2023-12-10 06:34:56,799 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:56,799 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:56,799 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:56,799 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:56,799 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0k3qdbdp
2023-12-10 06:34:56,800 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-404385e6-2408-4cb3-8699-40ebf7a30539
2023-12-10 06:34:56,800 - distributed.worker - INFO - Starting Worker plugin RMMSetup-696357f9-58ab-41fd-9565-6ed5551973ac
2023-12-10 06:34:56,801 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36949
2023-12-10 06:34:56,802 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36949
2023-12-10 06:34:56,802 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38345
2023-12-10 06:34:56,802 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:56,802 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:56,802 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:56,802 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:56,802 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yu2cqnir
2023-12-10 06:34:56,803 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8fd37344-23a7-4982-8c92-5081f3db50ea
2023-12-10 06:34:56,803 - distributed.worker - INFO - Starting Worker plugin PreImport-364d0a6d-85f3-47f2-949c-7a63d61d94c1
2023-12-10 06:34:56,804 - distributed.worker - INFO - Starting Worker plugin RMMSetup-11204d1d-d860-460c-a207-4df9adf6bbbf
2023-12-10 06:34:56,805 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44861
2023-12-10 06:34:56,805 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44861
2023-12-10 06:34:56,806 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40129
2023-12-10 06:34:56,806 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:56,806 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:56,806 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:56,806 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:56,806 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-37jk1tog
2023-12-10 06:34:56,806 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-889b58c1-bdad-4d8e-9567-c795502da218
2023-12-10 06:34:56,807 - distributed.worker - INFO - Starting Worker plugin PreImport-b5c2919a-64ef-4935-a426-bc07e502d6b7
2023-12-10 06:34:56,807 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ccdcdd6a-f462-42a0-a301-47400782fe5a
2023-12-10 06:34:56,805 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43947
2023-12-10 06:34:56,807 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43947
2023-12-10 06:34:56,807 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38543
2023-12-10 06:34:56,807 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:34:56,807 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:56,808 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:34:56,808 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:34:56,808 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n4zbatw9
2023-12-10 06:34:56,809 - distributed.worker - INFO - Starting Worker plugin PreImport-eb429e56-b2ee-4e9d-8bab-c95fe0339772
2023-12-10 06:34:56,809 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-05a03470-59f5-446b-8f48-db6aab773764
2023-12-10 06:34:56,810 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ee658b2b-764c-4b8e-a3f9-922deaf282b7
2023-12-10 06:34:56,821 - distributed.worker - INFO - Starting Worker plugin PreImport-515e2680-1fef-46f9-8e14-0fa2efa4a385
2023-12-10 06:34:56,822 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:56,825 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,008 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45341', status: init, memory: 0, processing: 0>
2023-12-10 06:34:57,009 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45341
2023-12-10 06:34:57,009 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44898
2023-12-10 06:34:57,010 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34757', status: init, memory: 0, processing: 0>
2023-12-10 06:34:57,010 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:57,011 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34757
2023-12-10 06:34:57,011 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44894
2023-12-10 06:34:57,011 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:57,011 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,012 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:57,013 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:57,014 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,014 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:57,016 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:57,709 - distributed.worker - INFO - Starting Worker plugin PreImport-7b795d3a-824e-44fd-8aba-9d6b1b512a89
2023-12-10 06:34:57,709 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,718 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,720 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,735 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39493', status: init, memory: 0, processing: 0>
2023-12-10 06:34:57,736 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39493
2023-12-10 06:34:57,736 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44900
2023-12-10 06:34:57,737 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:57,738 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:57,738 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,740 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:57,741 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,743 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37133', status: init, memory: 0, processing: 0>
2023-12-10 06:34:57,744 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37133
2023-12-10 06:34:57,744 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44914
2023-12-10 06:34:57,745 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:57,746 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:57,746 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,747 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:57,748 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,751 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46775', status: init, memory: 0, processing: 0>
2023-12-10 06:34:57,752 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46775
2023-12-10 06:34:57,752 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44916
2023-12-10 06:34:57,753 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:57,755 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:57,755 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,756 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,757 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:57,770 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44861', status: init, memory: 0, processing: 0>
2023-12-10 06:34:57,771 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44861
2023-12-10 06:34:57,771 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44928
2023-12-10 06:34:57,772 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:57,773 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:57,773 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,774 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:57,788 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43947', status: init, memory: 0, processing: 0>
2023-12-10 06:34:57,789 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43947
2023-12-10 06:34:57,789 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44946
2023-12-10 06:34:57,790 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36949', status: init, memory: 0, processing: 0>
2023-12-10 06:34:57,790 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:57,791 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36949
2023-12-10 06:34:57,791 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44940
2023-12-10 06:34:57,792 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:57,792 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,792 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:34:57,793 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:57,794 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:34:57,794 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:34:57,796 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:34:57,840 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,840 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,841 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,841 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,841 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,841 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,841 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,841 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,852 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:57,852 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:57,853 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:57,853 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:57,853 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:57,853 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:57,853 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:57,853 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:34:57,859 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,861 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:34:57,864 - distributed.scheduler - INFO - Remove client Client-376bf10f-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:57,864 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44868; closing.
2023-12-10 06:34:57,864 - distributed.scheduler - INFO - Remove client Client-376bf10f-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:57,864 - distributed.scheduler - INFO - Close client connection: Client-376bf10f-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:34:57,865 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35887'. Reason: nanny-close
2023-12-10 06:34:57,866 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:57,867 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44787'. Reason: nanny-close
2023-12-10 06:34:57,867 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:57,867 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34757. Reason: nanny-close
2023-12-10 06:34:57,867 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43009'. Reason: nanny-close
2023-12-10 06:34:57,867 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:57,868 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45341. Reason: nanny-close
2023-12-10 06:34:57,868 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35503'. Reason: nanny-close
2023-12-10 06:34:57,868 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:57,868 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39493. Reason: nanny-close
2023-12-10 06:34:57,869 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43255'. Reason: nanny-close
2023-12-10 06:34:57,869 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:57,869 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44861. Reason: nanny-close
2023-12-10 06:34:57,869 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36339'. Reason: nanny-close
2023-12-10 06:34:57,870 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:57,870 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44894; closing.
2023-12-10 06:34:57,870 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:57,870 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46775. Reason: nanny-close
2023-12-10 06:34:57,870 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33311'. Reason: nanny-close
2023-12-10 06:34:57,870 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34757', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190097.8702943')
2023-12-10 06:34:57,870 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:57,870 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:57,870 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:57,870 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36949. Reason: nanny-close
2023-12-10 06:34:57,870 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41717'. Reason: nanny-close
2023-12-10 06:34:57,871 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:34:57,871 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43947. Reason: nanny-close
2023-12-10 06:34:57,871 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:57,872 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44898; closing.
2023-12-10 06:34:57,872 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:57,872 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44900; closing.
2023-12-10 06:34:57,872 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:57,872 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37133. Reason: nanny-close
2023-12-10 06:34:57,872 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:57,872 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:57,872 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44928; closing.
2023-12-10 06:34:57,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:57,873 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45341', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190097.8730862')
2023-12-10 06:34:57,873 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39493', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190097.8734465')
2023-12-10 06:34:57,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:57,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:57,873 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:34:57,874 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44861', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190097.8739972')
2023-12-10 06:34:57,875 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44916; closing.
2023-12-10 06:34:57,875 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:57,875 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44940; closing.
2023-12-10 06:34:57,875 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44946; closing.
2023-12-10 06:34:57,875 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:57,875 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:57,875 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46775', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190097.8758829')
2023-12-10 06:34:57,875 - distributed.nanny - INFO - Worker closed
2023-12-10 06:34:57,876 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36949', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190097.8762603')
2023-12-10 06:34:57,876 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43947', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190097.8766341')
2023-12-10 06:34:57,877 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44914; closing.
2023-12-10 06:34:57,877 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37133', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190097.8773572')
2023-12-10 06:34:57,877 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:34:59,684 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:34:59,684 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:34:59,685 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:34:59,686 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:34:59,686 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-12-10 06:35:01,889 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:01,893 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41487 instead
  warnings.warn(
2023-12-10 06:35:01,897 - distributed.scheduler - INFO - State start
2023-12-10 06:35:01,919 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:01,920 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:35:01,921 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41487/status
2023-12-10 06:35:01,921 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:35:02,121 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43823'
2023-12-10 06:35:02,133 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46659'
2023-12-10 06:35:02,147 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33875'
2023-12-10 06:35:02,156 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44275'
2023-12-10 06:35:02,158 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46669'
2023-12-10 06:35:02,166 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40877'
2023-12-10 06:35:02,175 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36899'
2023-12-10 06:35:02,183 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36557'
2023-12-10 06:35:03,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:03,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:03,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:03,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:03,931 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:03,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:03,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:03,934 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:03,936 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:03,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:03,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:03,981 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:03,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:03,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:03,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:03,985 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:03,986 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:03,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:03,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:03,988 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:03,990 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:03,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:03,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:03,995 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:06,354 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46083
2023-12-10 06:35:06,355 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46083
2023-12-10 06:35:06,355 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37215
2023-12-10 06:35:06,355 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,355 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,355 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:06,355 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:06,355 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mm9w74x2
2023-12-10 06:35:06,356 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d04abf5d-627e-43f4-a228-bb54dd0e807b
2023-12-10 06:35:06,356 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3b7f026d-f7c4-40d3-82ef-a78364241537
2023-12-10 06:35:06,462 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34145
2023-12-10 06:35:06,462 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34145
2023-12-10 06:35:06,462 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39139
2023-12-10 06:35:06,462 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,463 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,463 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:06,463 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:06,463 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p_csodro
2023-12-10 06:35:06,463 - distributed.worker - INFO - Starting Worker plugin PreImport-e4ed4286-40b7-474c-b597-5820151c5e03
2023-12-10 06:35:06,463 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-575726dd-9592-4cef-a8e8-d150afecfbe3
2023-12-10 06:35:06,463 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42493
2023-12-10 06:35:06,463 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42493
2023-12-10 06:35:06,464 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37993
2023-12-10 06:35:06,464 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,464 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,464 - distributed.worker - INFO - Starting Worker plugin RMMSetup-52801ac5-b4f7-4605-9b67-0ef6d4b4cd36
2023-12-10 06:35:06,464 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:06,464 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:06,464 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xqnuoxhx
2023-12-10 06:35:06,464 - distributed.worker - INFO - Starting Worker plugin PreImport-8381c8c2-dc12-40ca-acfa-46d0d3669877
2023-12-10 06:35:06,465 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9781eca2-5991-4625-b82d-150252d76d8f
2023-12-10 06:35:06,465 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bebbc148-04c3-4275-ac17-143ed8419404
2023-12-10 06:35:06,475 - distributed.worker - INFO - Starting Worker plugin PreImport-2057b473-acbe-43e5-8ccd-366cf5674a2f
2023-12-10 06:35:06,475 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,505 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46083', status: init, memory: 0, processing: 0>
2023-12-10 06:35:06,522 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46083
2023-12-10 06:35:06,522 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49362
2023-12-10 06:35:06,523 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:06,524 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,524 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,525 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:06,563 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46065
2023-12-10 06:35:06,564 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46065
2023-12-10 06:35:06,564 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46483
2023-12-10 06:35:06,564 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,564 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,564 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:06,564 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:06,564 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yb39uwbg
2023-12-10 06:35:06,565 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-52b8e106-4315-45e2-81e2-dc4f72006530
2023-12-10 06:35:06,565 - distributed.worker - INFO - Starting Worker plugin PreImport-652e7753-ca76-4958-b574-44b4f84d17b3
2023-12-10 06:35:06,565 - distributed.worker - INFO - Starting Worker plugin RMMSetup-11f765d4-2965-4b02-80b8-88eb1d17b705
2023-12-10 06:35:06,566 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34583
2023-12-10 06:35:06,567 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34583
2023-12-10 06:35:06,566 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36353
2023-12-10 06:35:06,567 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36353
2023-12-10 06:35:06,567 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38239
2023-12-10 06:35:06,567 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,567 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45743
2023-12-10 06:35:06,567 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,567 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,567 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,567 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:06,568 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:06,568 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:06,568 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dvlakdsu
2023-12-10 06:35:06,568 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:06,568 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ry0by4ek
2023-12-10 06:35:06,568 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ee3f723d-1f24-4afc-940f-925f4434bf29
2023-12-10 06:35:06,568 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c650ba8d-6392-452b-9b6b-fb9d4de9978e
2023-12-10 06:35:06,572 - distributed.worker - INFO - Starting Worker plugin PreImport-bc0e415d-f26a-49cd-96ca-7b9cc2829358
2023-12-10 06:35:06,572 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab17a913-2390-4712-95af-ae80db8e827c
2023-12-10 06:35:06,572 - distributed.worker - INFO - Starting Worker plugin RMMSetup-96bd7f4b-e048-4c37-8731-b3aa664c74c3
2023-12-10 06:35:06,573 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39239
2023-12-10 06:35:06,574 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39239
2023-12-10 06:35:06,574 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39557
2023-12-10 06:35:06,574 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,574 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,574 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:06,574 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:06,574 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xjptltvs
2023-12-10 06:35:06,575 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-096b496f-afa5-42f2-8c7c-c9fb6298aab8
2023-12-10 06:35:06,575 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33491
2023-12-10 06:35:06,575 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33491
2023-12-10 06:35:06,576 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39703
2023-12-10 06:35:06,576 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,576 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,576 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:06,576 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:06,576 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jfpvutn1
2023-12-10 06:35:06,576 - distributed.scheduler - INFO - Receive client connection: Client-3e146415-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:06,577 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3223a582-4154-4f15-b2b6-2433ff003637
2023-12-10 06:35:06,577 - distributed.worker - INFO - Starting Worker plugin PreImport-02524c1b-2409-47e6-aa92-3480f5e22c4a
2023-12-10 06:35:06,577 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49376
2023-12-10 06:35:06,577 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7c0c3093-5261-40ff-add0-d008ae7e732f
2023-12-10 06:35:06,580 - distributed.worker - INFO - Starting Worker plugin PreImport-9d0cff8b-2610-4d9d-847a-c3dfb00d4d33
2023-12-10 06:35:06,580 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a2fb1d9a-1eba-42a5-9db3-48db6bb7fd17
2023-12-10 06:35:06,882 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,897 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,909 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42493', status: init, memory: 0, processing: 0>
2023-12-10 06:35:06,910 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42493
2023-12-10 06:35:06,910 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49396
2023-12-10 06:35:06,911 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:06,912 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,912 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,914 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:06,945 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34145', status: init, memory: 0, processing: 0>
2023-12-10 06:35:06,946 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34145
2023-12-10 06:35:06,946 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49404
2023-12-10 06:35:06,947 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:06,948 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:06,949 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:06,951 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:06,999 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,008 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,016 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,019 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,025 - distributed.worker - INFO - Starting Worker plugin PreImport-bff6f062-5d9c-4146-a9e7-0136dfd543bc
2023-12-10 06:35:07,026 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,028 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46065', status: init, memory: 0, processing: 0>
2023-12-10 06:35:07,029 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46065
2023-12-10 06:35:07,029 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49408
2023-12-10 06:35:07,030 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:07,031 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:07,031 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,032 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33491', status: init, memory: 0, processing: 0>
2023-12-10 06:35:07,033 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:07,033 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33491
2023-12-10 06:35:07,033 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49414
2023-12-10 06:35:07,034 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:07,035 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:07,035 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,037 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:07,056 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39239', status: init, memory: 0, processing: 0>
2023-12-10 06:35:07,056 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39239
2023-12-10 06:35:07,057 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49428
2023-12-10 06:35:07,057 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36353', status: init, memory: 0, processing: 0>
2023-12-10 06:35:07,058 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36353
2023-12-10 06:35:07,058 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49416
2023-12-10 06:35:07,058 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:07,059 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:07,059 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,059 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:07,061 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:07,061 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,062 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:07,063 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:07,064 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34583', status: init, memory: 0, processing: 0>
2023-12-10 06:35:07,064 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34583
2023-12-10 06:35:07,065 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49442
2023-12-10 06:35:07,066 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:07,067 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:07,067 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:07,069 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:07,098 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:07,099 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:07,099 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:07,099 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:07,099 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:07,099 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:07,099 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:07,099 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:07,103 - distributed.scheduler - INFO - Remove client Client-3e146415-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:07,104 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49376; closing.
2023-12-10 06:35:07,104 - distributed.scheduler - INFO - Remove client Client-3e146415-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:07,104 - distributed.scheduler - INFO - Close client connection: Client-3e146415-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:07,105 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43823'. Reason: nanny-close
2023-12-10 06:35:07,106 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:07,106 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46659'. Reason: nanny-close
2023-12-10 06:35:07,107 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:07,107 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34583. Reason: nanny-close
2023-12-10 06:35:07,108 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36353. Reason: nanny-close
2023-12-10 06:35:07,107 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33875'. Reason: nanny-close
2023-12-10 06:35:07,109 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49442; closing.
2023-12-10 06:35:07,109 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:07,110 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:07,110 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34583', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190107.1101038')
2023-12-10 06:35:07,110 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44275'. Reason: nanny-close
2023-12-10 06:35:07,110 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:07,110 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:07,110 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46083. Reason: nanny-close
2023-12-10 06:35:07,111 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46669'. Reason: nanny-close
2023-12-10 06:35:07,111 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:07,111 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46065. Reason: nanny-close
2023-12-10 06:35:07,111 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40877'. Reason: nanny-close
2023-12-10 06:35:07,111 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49416; closing.
2023-12-10 06:35:07,111 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:07,112 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:07,112 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36899'. Reason: nanny-close
2023-12-10 06:35:07,112 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:07,112 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36353', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190107.1125426')
2023-12-10 06:35:07,112 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:07,112 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34145. Reason: nanny-close
2023-12-10 06:35:07,112 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:07,112 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36557'. Reason: nanny-close
2023-12-10 06:35:07,113 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:07,113 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39239. Reason: nanny-close
2023-12-10 06:35:07,113 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42493. Reason: nanny-close
2023-12-10 06:35:07,113 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49362; closing.
2023-12-10 06:35:07,113 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:07,113 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33491. Reason: nanny-close
2023-12-10 06:35:07,113 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46083', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190107.1137562')
2023-12-10 06:35:07,114 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49408; closing.
2023-12-10 06:35:07,114 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46065', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190107.1145108')
2023-12-10 06:35:07,114 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:07,115 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:07,115 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:07,115 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49404; closing.
2023-12-10 06:35:07,115 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:07,115 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:07,115 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:07,116 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34145', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190107.1161287')
2023-12-10 06:35:07,116 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49396; closing.
2023-12-10 06:35:07,116 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49428; closing.
2023-12-10 06:35:07,116 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49414; closing.
2023-12-10 06:35:07,117 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:07,117 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:07,117 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:07,117 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42493', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190107.117325')
2023-12-10 06:35:07,117 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:07,117 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39239', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190107.1177313')
2023-12-10 06:35:07,118 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33491', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190107.1180806')
2023-12-10 06:35:07,118 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:35:08,723 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:35:08,723 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:35:08,723 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:35:08,725 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:35:08,725 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-12-10 06:35:10,934 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:10,938 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33819 instead
  warnings.warn(
2023-12-10 06:35:10,943 - distributed.scheduler - INFO - State start
2023-12-10 06:35:10,966 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:10,967 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:35:10,968 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33819/status
2023-12-10 06:35:10,968 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:35:11,003 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36935'
2023-12-10 06:35:11,139 - distributed.scheduler - INFO - Receive client connection: Client-437d3018-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:11,151 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34820
2023-12-10 06:35:12,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:12,440 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:12,911 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:13,781 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41265
2023-12-10 06:35:13,781 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41265
2023-12-10 06:35:13,781 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-12-10 06:35:13,781 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:13,781 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:13,781 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:13,782 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-10 06:35:13,782 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7396_xut
2023-12-10 06:35:13,782 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-82eafd5e-c6a5-4d71-aeb9-e21b768b23cf
2023-12-10 06:35:13,783 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2d6f2e72-4628-4c74-b533-79c2ccc44ebf
2023-12-10 06:35:13,783 - distributed.worker - INFO - Starting Worker plugin PreImport-106ec742-3a51-4bba-8e06-eb0d91782032
2023-12-10 06:35:13,784 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:13,816 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41265', status: init, memory: 0, processing: 0>
2023-12-10 06:35:13,817 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41265
2023-12-10 06:35:13,817 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34846
2023-12-10 06:35:13,818 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:13,819 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:13,819 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:13,821 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:13,900 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:13,903 - distributed.scheduler - INFO - Remove client Client-437d3018-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:13,903 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34820; closing.
2023-12-10 06:35:13,903 - distributed.scheduler - INFO - Remove client Client-437d3018-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:13,904 - distributed.scheduler - INFO - Close client connection: Client-437d3018-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:13,904 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36935'. Reason: nanny-close
2023-12-10 06:35:13,905 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:13,906 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41265. Reason: nanny-close
2023-12-10 06:35:13,908 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:13,908 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34846; closing.
2023-12-10 06:35:13,909 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41265', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190113.9091039')
2023-12-10 06:35:13,909 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:35:13,910 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:15,071 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:35:15,072 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:35:15,072 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:35:15,073 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:35:15,073 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-12-10 06:35:18,710 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:18,714 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37897 instead
  warnings.warn(
2023-12-10 06:35:18,718 - distributed.scheduler - INFO - State start
2023-12-10 06:35:18,739 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:18,740 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:35:18,740 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37897/status
2023-12-10 06:35:18,740 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:35:18,836 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35761'
2023-12-10 06:35:18,903 - distributed.scheduler - INFO - Receive client connection: Client-4844f8eb-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:18,914 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34942
2023-12-10 06:35:20,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:20,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:20,874 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:21,826 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38763
2023-12-10 06:35:21,827 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38763
2023-12-10 06:35:21,827 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34705
2023-12-10 06:35:21,827 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:21,827 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:21,827 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:21,827 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-10 06:35:21,827 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-loujahwm
2023-12-10 06:35:21,828 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2fddd7ba-bce5-463c-a207-b1b809ee8cfe
2023-12-10 06:35:21,828 - distributed.worker - INFO - Starting Worker plugin RMMSetup-084a9fd2-71c6-4f1d-8552-e51ca41ebd79
2023-12-10 06:35:21,828 - distributed.worker - INFO - Starting Worker plugin PreImport-26c4f011-a89a-42cb-b121-8f6523cca951
2023-12-10 06:35:21,829 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:21,856 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38763', status: init, memory: 0, processing: 0>
2023-12-10 06:35:21,857 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38763
2023-12-10 06:35:21,857 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58878
2023-12-10 06:35:21,857 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:21,858 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:21,858 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:21,860 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:21,865 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:21,867 - distributed.scheduler - INFO - Remove client Client-4844f8eb-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:21,868 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34942; closing.
2023-12-10 06:35:21,868 - distributed.scheduler - INFO - Remove client Client-4844f8eb-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:21,868 - distributed.scheduler - INFO - Close client connection: Client-4844f8eb-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:21,869 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35761'. Reason: nanny-close
2023-12-10 06:35:21,869 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:21,871 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38763. Reason: nanny-close
2023-12-10 06:35:21,872 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:21,872 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58878; closing.
2023-12-10 06:35:21,873 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38763', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190121.872975')
2023-12-10 06:35:21,873 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:35:21,874 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:22,885 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:35:22,885 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:35:22,886 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:35:22,887 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:35:22,887 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-12-10 06:35:24,966 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:24,970 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42619 instead
  warnings.warn(
2023-12-10 06:35:24,974 - distributed.scheduler - INFO - State start
2023-12-10 06:35:24,995 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:24,996 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:35:24,996 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:42619/status
2023-12-10 06:35:24,997 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:35:28,913 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:58894'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:58894>: Stream is closed
2023-12-10 06:35:29,258 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:35:29,258 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:35:29,259 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:35:29,260 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:35:29,260 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-12-10 06:35:31,319 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:31,324 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35783 instead
  warnings.warn(
2023-12-10 06:35:31,327 - distributed.scheduler - INFO - State start
2023-12-10 06:35:31,348 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:31,349 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-12-10 06:35:31,349 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35783/status
2023-12-10 06:35:31,350 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:35:31,466 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38733'
2023-12-10 06:35:32,058 - distributed.scheduler - INFO - Receive client connection: Client-4fafce63-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:32,068 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38448
2023-12-10 06:35:33,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:33,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:33,091 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:33,901 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39843
2023-12-10 06:35:33,902 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39843
2023-12-10 06:35:33,902 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33765
2023-12-10 06:35:33,902 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-12-10 06:35:33,902 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:33,902 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:33,902 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-10 06:35:33,902 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-x6yc9a_5
2023-12-10 06:35:33,903 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b1f2448c-065b-4e21-9287-31efadb68104
2023-12-10 06:35:33,903 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7ffa724f-de0a-4e98-9c55-e512a49096a5
2023-12-10 06:35:33,903 - distributed.worker - INFO - Starting Worker plugin PreImport-a23d7c70-96c3-41c6-b16e-f977e00a1f7d
2023-12-10 06:35:33,903 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:33,929 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39843', status: init, memory: 0, processing: 0>
2023-12-10 06:35:33,930 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39843
2023-12-10 06:35:33,930 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38474
2023-12-10 06:35:33,931 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:33,932 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-12-10 06:35:33,932 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:33,934 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-12-10 06:35:34,004 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:34,006 - distributed.scheduler - INFO - Remove client Client-4fafce63-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:34,006 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38448; closing.
2023-12-10 06:35:34,006 - distributed.scheduler - INFO - Remove client Client-4fafce63-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:34,007 - distributed.scheduler - INFO - Close client connection: Client-4fafce63-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:34,008 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38733'. Reason: nanny-close
2023-12-10 06:35:34,008 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:34,009 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39843. Reason: nanny-close
2023-12-10 06:35:34,011 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38474; closing.
2023-12-10 06:35:34,011 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-12-10 06:35:34,011 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39843', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190134.0117824')
2023-12-10 06:35:34,012 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:35:34,013 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:34,924 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:35:34,924 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:35:34,925 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:35:34,925 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-12-10 06:35:34,926 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-12-10 06:35:36,916 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:36,920 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35469 instead
  warnings.warn(
2023-12-10 06:35:36,924 - distributed.scheduler - INFO - State start
2023-12-10 06:35:36,946 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:36,947 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:35:36,947 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35469/status
2023-12-10 06:35:36,948 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:35:37,187 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37939'
2023-12-10 06:35:37,198 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42341'
2023-12-10 06:35:37,208 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42221'
2023-12-10 06:35:37,217 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44869'
2023-12-10 06:35:37,225 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37019'
2023-12-10 06:35:37,233 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32815'
2023-12-10 06:35:37,242 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35029'
2023-12-10 06:35:37,249 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38313'
2023-12-10 06:35:37,711 - distributed.scheduler - INFO - Receive client connection: Client-5303c47d-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:37,723 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46130
2023-12-10 06:35:39,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:39,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:39,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:39,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:39,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:39,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:39,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:39,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:39,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:39,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:39,060 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:39,060 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:39,062 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:39,062 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:39,063 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:39,090 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:39,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:39,094 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:39,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:39,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:39,109 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:39,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:39,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:39,150 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:41,820 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40855
2023-12-10 06:35:41,820 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40855
2023-12-10 06:35:41,821 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40043
2023-12-10 06:35:41,821 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:41,821 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:41,821 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:41,821 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:41,821 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ur4wkc1j
2023-12-10 06:35:41,822 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e1d1eee4-857e-49f6-ae1e-5d4fa04c56e3
2023-12-10 06:35:41,822 - distributed.worker - INFO - Starting Worker plugin RMMSetup-061e4676-54d1-4858-a547-6f85bbe147b0
2023-12-10 06:35:42,147 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37865
2023-12-10 06:35:42,147 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37865
2023-12-10 06:35:42,147 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44717
2023-12-10 06:35:42,147 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,148 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,148 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:42,148 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:42,148 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-316tlotg
2023-12-10 06:35:42,148 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3f6c7968-6cb9-4087-b72d-76afe95476ba
2023-12-10 06:35:42,148 - distributed.worker - INFO - Starting Worker plugin PreImport-b8ad813b-1357-4683-b7a6-c3515a5b9ede
2023-12-10 06:35:42,149 - distributed.worker - INFO - Starting Worker plugin RMMSetup-820dbf98-e384-4a0a-9c45-1b38df4dc098
2023-12-10 06:35:42,156 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36725
2023-12-10 06:35:42,157 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36725
2023-12-10 06:35:42,157 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33039
2023-12-10 06:35:42,157 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,157 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,157 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:42,157 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:42,158 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l_1c5o4q
2023-12-10 06:35:42,158 - distributed.worker - INFO - Starting Worker plugin PreImport-ea42b15a-24f8-457b-a949-4ecb517787bc
2023-12-10 06:35:42,158 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-110c453e-e81c-4a3f-9328-f22380db80fe
2023-12-10 06:35:42,158 - distributed.worker - INFO - Starting Worker plugin RMMSetup-775fcbfb-9b9f-4fac-83d5-efbf97a78aa7
2023-12-10 06:35:42,162 - distributed.worker - INFO - Starting Worker plugin PreImport-1f11dfd4-c73a-407d-b148-c8158daa30c3
2023-12-10 06:35:42,163 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,163 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37989
2023-12-10 06:35:42,164 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37989
2023-12-10 06:35:42,164 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33857
2023-12-10 06:35:42,164 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,164 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,164 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:42,164 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:42,164 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-srtx6r_a
2023-12-10 06:35:42,165 - distributed.worker - INFO - Starting Worker plugin PreImport-97494252-cc06-4cfe-aae5-627c35b5685c
2023-12-10 06:35:42,165 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a34cc257-04cb-41df-904f-429a977e834f
2023-12-10 06:35:42,165 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cec1b6d0-e04b-4cea-96d2-676bd2fe2fc8
2023-12-10 06:35:42,168 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39491
2023-12-10 06:35:42,170 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39491
2023-12-10 06:35:42,171 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42001
2023-12-10 06:35:42,171 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,171 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,169 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38107
2023-12-10 06:35:42,171 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38107
2023-12-10 06:35:42,171 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:42,171 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:42,171 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44847
2023-12-10 06:35:42,171 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-szpjvvwq
2023-12-10 06:35:42,171 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,171 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,170 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38395
2023-12-10 06:35:42,171 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38395
2023-12-10 06:35:42,171 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:42,171 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40195
2023-12-10 06:35:42,171 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,171 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:42,171 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,171 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0iccsf_5
2023-12-10 06:35:42,169 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39879
2023-12-10 06:35:42,172 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:42,172 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39879
2023-12-10 06:35:42,172 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:42,172 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dzwigxvb
2023-12-10 06:35:42,172 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39589
2023-12-10 06:35:42,172 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,172 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,172 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-16d74da0-23f7-437c-87ae-536efe0536ef
2023-12-10 06:35:42,172 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-36085e42-e6fd-4417-b4d2-5e2c0e63f023
2023-12-10 06:35:42,172 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:42,172 - distributed.worker - INFO - Starting Worker plugin PreImport-2821e2c8-31f9-4717-a608-a47e33eda6e8
2023-12-10 06:35:42,172 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-12-10 06:35:42,172 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-40dkdjr1
2023-12-10 06:35:42,172 - distributed.worker - INFO - Starting Worker plugin RMMSetup-31de8960-d0ef-43f5-bb8a-de7293aa1cd1
2023-12-10 06:35:42,173 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eae07809-086f-4378-92c9-a52a18369e59
2023-12-10 06:35:42,173 - distributed.worker - INFO - Starting Worker plugin PreImport-ed2bdabc-1d77-4266-a879-021e78ca2863
2023-12-10 06:35:42,173 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5d54650a-babe-41a1-830f-d4e008fa269a
2023-12-10 06:35:42,174 - distributed.worker - INFO - Starting Worker plugin PreImport-52a46cdb-497f-4221-a55d-05b7d92c6b05
2023-12-10 06:35:42,174 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2a0a95d7-2c69-43d3-8199-dc730eef6cfc
2023-12-10 06:35:42,174 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-23c7c5a7-dcf1-4b07-aee6-246f1c2fe46e
2023-12-10 06:35:42,175 - distributed.worker - INFO - Starting Worker plugin PreImport-fa61ec47-57f8-4855-bc36-45b77baaf0e7
2023-12-10 06:35:42,175 - distributed.worker - INFO - Starting Worker plugin RMMSetup-25832aed-0ccc-4df7-aada-fb676eb42324
2023-12-10 06:35:42,207 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40855', status: init, memory: 0, processing: 0>
2023-12-10 06:35:42,208 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40855
2023-12-10 06:35:42,208 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44012
2023-12-10 06:35:42,209 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:42,211 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,211 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,213 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:42,323 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,324 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,324 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,324 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,327 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,329 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,329 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,353 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37865', status: init, memory: 0, processing: 0>
2023-12-10 06:35:42,354 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37865
2023-12-10 06:35:42,354 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44058
2023-12-10 06:35:42,355 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36725', status: init, memory: 0, processing: 0>
2023-12-10 06:35:42,355 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:42,355 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36725
2023-12-10 06:35:42,355 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44028
2023-12-10 06:35:42,356 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,356 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,356 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:42,357 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,357 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,358 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:42,358 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38107', status: init, memory: 0, processing: 0>
2023-12-10 06:35:42,359 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38107
2023-12-10 06:35:42,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44042
2023-12-10 06:35:42,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:42,360 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39879', status: init, memory: 0, processing: 0>
2023-12-10 06:35:42,360 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:42,360 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39879
2023-12-10 06:35:42,360 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44078
2023-12-10 06:35:42,361 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,361 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,361 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:42,362 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,362 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,362 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37989', status: init, memory: 0, processing: 0>
2023-12-10 06:35:42,363 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:42,363 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37989
2023-12-10 06:35:42,363 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44068
2023-12-10 06:35:42,364 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:42,365 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:42,366 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,366 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,366 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39491', status: init, memory: 0, processing: 0>
2023-12-10 06:35:42,367 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39491
2023-12-10 06:35:42,367 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44092
2023-12-10 06:35:42,368 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38395', status: init, memory: 0, processing: 0>
2023-12-10 06:35:42,368 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:42,368 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38395
2023-12-10 06:35:42,368 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44098
2023-12-10 06:35:42,368 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:42,369 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,369 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,370 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:42,371 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:42,371 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:42,372 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:42,374 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:42,450 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:42,450 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:42,451 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:42,451 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:42,451 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:42,451 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:42,451 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:42,451 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-12-10 06:35:42,465 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:42,465 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:42,465 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:42,466 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:42,466 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:42,466 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:42,466 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:42,466 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:42,470 - distributed.scheduler - INFO - Remove client Client-5303c47d-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:42,470 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46130; closing.
2023-12-10 06:35:42,471 - distributed.scheduler - INFO - Remove client Client-5303c47d-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:42,471 - distributed.scheduler - INFO - Close client connection: Client-5303c47d-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:42,472 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37939'. Reason: nanny-close
2023-12-10 06:35:42,473 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:42,474 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42341'. Reason: nanny-close
2023-12-10 06:35:42,474 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:42,474 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37989. Reason: nanny-close
2023-12-10 06:35:42,474 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42221'. Reason: nanny-close
2023-12-10 06:35:42,475 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:42,475 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40855. Reason: nanny-close
2023-12-10 06:35:42,475 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44869'. Reason: nanny-close
2023-12-10 06:35:42,475 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:42,475 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37865. Reason: nanny-close
2023-12-10 06:35:42,476 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37019'. Reason: nanny-close
2023-12-10 06:35:42,476 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:42,476 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36725. Reason: nanny-close
2023-12-10 06:35:42,476 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:42,476 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44068; closing.
2023-12-10 06:35:42,476 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32815'. Reason: nanny-close
2023-12-10 06:35:42,477 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:42,477 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38395. Reason: nanny-close
2023-12-10 06:35:42,477 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37989', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190142.477154')
2023-12-10 06:35:42,477 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:42,477 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35029'. Reason: nanny-close
2023-12-10 06:35:42,477 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:42,477 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:42,477 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39491. Reason: nanny-close
2023-12-10 06:35:42,478 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38313'. Reason: nanny-close
2023-12-10 06:35:42,478 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44058; closing.
2023-12-10 06:35:42,478 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:42,478 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:42,478 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39879. Reason: nanny-close
2023-12-10 06:35:42,478 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:42,479 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38107. Reason: nanny-close
2023-12-10 06:35:42,479 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37865', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190142.4790215')
2023-12-10 06:35:42,479 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:42,479 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:42,479 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44012; closing.
2023-12-10 06:35:42,479 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:42,479 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:42,480 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:42,480 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:42,479 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44058>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44058>: Stream is closed
2023-12-10 06:35:42,481 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:42,481 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40855', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190142.4816608')
2023-12-10 06:35:42,481 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:42,481 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:42,482 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44028; closing.
2023-12-10 06:35:42,482 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:42,482 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36725', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190142.482611')
2023-12-10 06:35:42,482 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:42,483 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44098; closing.
2023-12-10 06:35:42,483 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38395', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190142.4837658')
2023-12-10 06:35:42,484 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44092; closing.
2023-12-10 06:35:42,484 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44078; closing.
2023-12-10 06:35:42,484 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39491', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190142.4848197')
2023-12-10 06:35:42,485 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39879', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190142.4852352')
2023-12-10 06:35:42,485 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44042; closing.
2023-12-10 06:35:42,486 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38107', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190142.486169')
2023-12-10 06:35:42,486 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:35:42,486 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:44042>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-12-10 06:35:44,040 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:35:44,041 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:35:44,041 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:35:44,042 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:35:44,043 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-12-10 06:35:46,136 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:46,140 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33661 instead
  warnings.warn(
2023-12-10 06:35:46,144 - distributed.scheduler - INFO - State start
2023-12-10 06:35:46,194 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:46,196 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:35:46,196 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33661/status
2023-12-10 06:35:46,197 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:35:46,276 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44947'
2023-12-10 06:35:47,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:47,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:47,981 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:48,154 - distributed.scheduler - INFO - Receive client connection: Client-58827e24-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:48,167 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44222
2023-12-10 06:35:49,090 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45035
2023-12-10 06:35:49,091 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45035
2023-12-10 06:35:49,091 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41707
2023-12-10 06:35:49,091 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:49,091 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:49,091 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:49,091 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-10 06:35:49,091 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vqft7_o6
2023-12-10 06:35:49,091 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-64809ac9-1232-453d-88c8-75297c8fa92b
2023-12-10 06:35:49,092 - distributed.worker - INFO - Starting Worker plugin PreImport-6c8e80fa-f599-40cc-a116-eb0a891b1894
2023-12-10 06:35:49,092 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b8641e15-baf1-4440-996f-bb7b9b88c454
2023-12-10 06:35:49,191 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:49,216 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45035', status: init, memory: 0, processing: 0>
2023-12-10 06:35:49,217 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45035
2023-12-10 06:35:49,217 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44248
2023-12-10 06:35:49,218 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:49,218 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:49,219 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:49,220 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:49,300 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:35:49,304 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:49,305 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:49,308 - distributed.scheduler - INFO - Remove client Client-58827e24-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:49,308 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44222; closing.
2023-12-10 06:35:49,309 - distributed.scheduler - INFO - Remove client Client-58827e24-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:49,309 - distributed.scheduler - INFO - Close client connection: Client-58827e24-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:49,310 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44947'. Reason: nanny-close
2023-12-10 06:35:49,310 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:49,311 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45035. Reason: nanny-close
2023-12-10 06:35:49,313 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44248; closing.
2023-12-10 06:35:49,313 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:49,313 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45035', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190149.3137107')
2023-12-10 06:35:49,314 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:35:49,315 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:50,677 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:35:50,678 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:35:50,679 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:35:50,680 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:35:50,680 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-12-10 06:35:53,174 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:53,178 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41507 instead
  warnings.warn(
2023-12-10 06:35:53,182 - distributed.scheduler - INFO - State start
2023-12-10 06:35:53,391 - distributed.scheduler - INFO - -----------------------------------------------
2023-12-10 06:35:53,392 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-12-10 06:35:53,393 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41507/status
2023-12-10 06:35:53,393 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-12-10 06:35:53,399 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37649'
2023-12-10 06:35:55,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-12-10 06:35:55,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-12-10 06:35:55,145 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-12-10 06:35:56,185 - distributed.scheduler - INFO - Receive client connection: Client-5c865e12-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:56,198 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48320
2023-12-10 06:35:56,464 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43553
2023-12-10 06:35:56,464 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43553
2023-12-10 06:35:56,465 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45793
2023-12-10 06:35:56,465 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-12-10 06:35:56,465 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:56,465 - distributed.worker - INFO -               Threads:                          1
2023-12-10 06:35:56,465 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-12-10 06:35:56,465 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gf3x6va1
2023-12-10 06:35:56,465 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-41484184-7de1-43d6-9282-3f667ac1145c
2023-12-10 06:35:56,466 - distributed.worker - INFO - Starting Worker plugin PreImport-148cea62-4803-4e2c-b49a-522da5ca25f9
2023-12-10 06:35:56,466 - distributed.worker - INFO - Starting Worker plugin RMMSetup-945a89f9-4b8d-4e69-8b86-77264f7b8289
2023-12-10 06:35:56,581 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:56,614 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43553', status: init, memory: 0, processing: 0>
2023-12-10 06:35:56,615 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43553
2023-12-10 06:35:56,615 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48350
2023-12-10 06:35:56,617 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-12-10 06:35:56,618 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-12-10 06:35:56,618 - distributed.worker - INFO - -------------------------------------------------
2023-12-10 06:35:56,621 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-12-10 06:35:56,715 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-12-10 06:35:56,720 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-12-10 06:35:56,724 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:56,725 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-12-10 06:35:56,728 - distributed.scheduler - INFO - Remove client Client-5c865e12-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:56,728 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48320; closing.
2023-12-10 06:35:56,728 - distributed.scheduler - INFO - Remove client Client-5c865e12-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:56,729 - distributed.scheduler - INFO - Close client connection: Client-5c865e12-9726-11ee-84d2-d8c49764f6bb
2023-12-10 06:35:56,730 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37649'. Reason: nanny-close
2023-12-10 06:35:56,730 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-12-10 06:35:56,732 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43553. Reason: nanny-close
2023-12-10 06:35:56,734 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48350; closing.
2023-12-10 06:35:56,734 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-12-10 06:35:56,734 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43553', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1702190156.7349067')
2023-12-10 06:35:56,735 - distributed.scheduler - INFO - Lost all workers
2023-12-10 06:35:56,736 - distributed.nanny - INFO - Worker closed
2023-12-10 06:35:58,097 - distributed._signals - INFO - Received signal SIGINT (2)
2023-12-10 06:35:58,097 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-12-10 06:35:58,098 - distributed.scheduler - INFO - Scheduler closing all comms
2023-12-10 06:35:58,098 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-12-10 06:35:58,099 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39565 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42649 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45235 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37257 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33163 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41623 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40645 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35751 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44305 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34425 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35179 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33947 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38973 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36647 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32813 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44429 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46441 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39241 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46063 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32891 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35899 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46699 instead
  warnings.warn(
2023-12-10 06:41:27,337 - distributed.nanny - WARNING - Worker process still alive after 3.1999971008300783 seconds, killing
2023-12-10 06:41:27,338 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33179 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33877 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45461 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43639 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32839 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44169 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38715 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33515 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33569 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37469 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36717 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40913 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44709 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41167 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42263 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45177 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38021 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36127 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33241 instead
  warnings.warn(
2023-12-10 06:47:32,835 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:32,840 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:32,843 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:32,849 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:44689'.
2023-12-10 06:47:32,849 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:32,849 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:34260 remote=tcp://127.0.0.1:46085>: Stream is closed
2023-12-10 06:47:32,852 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fba1c76eb80>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:32,852 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:34252 remote=tcp://127.0.0.1:46085>: Stream is closed
2023-12-10 06:47:32,853 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:34262 remote=tcp://127.0.0.1:46085>: Stream is closed
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:32,856 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:33735'.
2023-12-10 06:47:32,856 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f079ff09b80>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:32,857 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:42705'.
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:32,856 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fd4488b0b80>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:32,860 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:45893'.
2023-12-10 06:47:32,860 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1347, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:34268 remote=tcp://127.0.0.1:46085>: Stream is closed
2023-12-10 06:47:32,863 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f9e7d7d3b80>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-12-10 06:47:34,855 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-12-10 06:47:34,858 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-12-10 06:47:34,860 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-12-10 06:47:34,866 - distributed.nanny - ERROR - Worker process died unexpectedly
