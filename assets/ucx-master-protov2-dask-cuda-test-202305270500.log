============================= test session starts ==============================
platform linux -- Python 3.9.16, pytest-7.3.1, pluggy-1.0.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-05-27 06:07:59,607 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:07:59,611 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:07:59,613 - distributed.scheduler - INFO - State start
2023-05-27 06:07:59,632 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:07:59,632 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-05-27 06:07:59,633 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:07:59,732 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45801'
2023-05-27 06:07:59,733 - distributed.scheduler - INFO - Receive client connection: Client-d3f7cb79-fc54-11ed-a673-d8c49764f6bb
2023-05-27 06:07:59,742 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39640
2023-05-27 06:07:59,747 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43351'
2023-05-27 06:07:59,750 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35827'
2023-05-27 06:07:59,757 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36305'
2023-05-27 06:08:01,116 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_57oq4f_', purging
2023-05-27 06:08:01,116 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ynxfwmd2', purging
2023-05-27 06:08:01,116 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m9t26_cm', purging
2023-05-27 06:08:01,117 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c271yu2a', purging
2023-05-27 06:08:01,117 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:01,117 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:01,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:01,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:01,124 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:01,129 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:01,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:01,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:01,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:01,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:01,135 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:01,140 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-05-27 06:08:01,154 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46669
2023-05-27 06:08:01,154 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46669
2023-05-27 06:08:01,154 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41763
2023-05-27 06:08:01,154 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-05-27 06:08:01,154 - distributed.worker - INFO - -------------------------------------------------
2023-05-27 06:08:01,154 - distributed.worker - INFO -               Threads:                          4
2023-05-27 06:08:01,154 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-05-27 06:08:01,154 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5i68a4v1
2023-05-27 06:08:01,155 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a37d8e6b-58d8-405c-8fc3-58e2cf11db3a
2023-05-27 06:08:01,155 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9bbf2fc8-a8ee-4f78-968b-4c213503eba3
2023-05-27 06:08:01,155 - distributed.worker - INFO - Starting Worker plugin PreImport-20862bcb-6ad0-4907-a378-903413acf9e1
2023-05-27 06:08:01,155 - distributed.worker - INFO - -------------------------------------------------
2023-05-27 06:08:01,170 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46669', status: init, memory: 0, processing: 0>
2023-05-27 06:08:01,171 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46669
2023-05-27 06:08:01,171 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59564
2023-05-27 06:08:01,171 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-05-27 06:08:01,172 - distributed.worker - INFO - -------------------------------------------------
2023-05-27 06:08:01,173 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:01,859 - distributed.nanny - INFO - Worker process 26606 exited with status 127
2023-05-27 06:08:01,860 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:01,893 - distributed.nanny - INFO - Worker process 26603 exited with status 127
2023-05-27 06:08:01,894 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:01,914 - distributed.nanny - INFO - Worker process 26610 exited with status 127
2023-05-27 06:08:01,915 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:03,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wjxaixcj', purging
2023-05-27 06:08:03,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ywfqu4ea', purging
2023-05-27 06:08:03,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-avy3dljt', purging
2023-05-27 06:08:03,250 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:03,250 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:03,257 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:03,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:03,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:03,285 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:03,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:03,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:03,297 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:03,905 - distributed.nanny - INFO - Worker process 26645 exited with status 127
2023-05-27 06:08:03,906 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:04,006 - distributed.nanny - INFO - Worker process 26651 exited with status 127
2023-05-27 06:08:04,007 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:04,035 - distributed.nanny - INFO - Worker process 26648 exited with status 127
2023-05-27 06:08:04,036 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:05,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2jtd6gnz', purging
2023-05-27 06:08:05,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o340_kzl', purging
2023-05-27 06:08:05,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-akzrpn99', purging
2023-05-27 06:08:05,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:05,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:05,289 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:05,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:05,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:05,382 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:05,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:05,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:05,424 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:05,948 - distributed.nanny - INFO - Worker process 26673 exited with status 127
2023-05-27 06:08:05,948 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:06,069 - distributed.nanny - INFO - Worker process 26681 exited with status 127
2023-05-27 06:08:06,070 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:06,092 - distributed.nanny - INFO - Worker process 26678 exited with status 127
2023-05-27 06:08:06,093 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:07,317 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0pp765y3', purging
2023-05-27 06:08:07,318 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_ft906t', purging
2023-05-27 06:08:07,318 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ouhrdwnv', purging
2023-05-27 06:08:07,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:07,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:07,325 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:07,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:07,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:07,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:07,487 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:07,491 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:07,494 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:07,995 - distributed.nanny - INFO - Worker process 26703 exited with status 127
2023-05-27 06:08:07,996 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:08,116 - distributed.nanny - INFO - Worker process 26711 exited with status 127
2023-05-27 06:08:08,117 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:08,142 - distributed.nanny - INFO - Worker process 26708 exited with status 127
2023-05-27 06:08:08,143 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:09,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8f5n5_aw', purging
2023-05-27 06:08:09,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y0h8tuhs', purging
2023-05-27 06:08:09,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kfkpmbgq', purging
2023-05-27 06:08:09,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:09,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:09,391 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:09,524 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:09,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:09,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:09,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:09,531 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:09,531 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:09,778 - distributed.scheduler - INFO - Remove client Client-d3f7cb79-fc54-11ed-a673-d8c49764f6bb
2023-05-27 06:08:09,779 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39640; closing.
2023-05-27 06:08:09,779 - distributed.scheduler - INFO - Remove client Client-d3f7cb79-fc54-11ed-a673-d8c49764f6bb
2023-05-27 06:08:09,779 - distributed.scheduler - INFO - Close client connection: Client-d3f7cb79-fc54-11ed-a673-d8c49764f6bb
2023-05-27 06:08:09,821 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43351'. Reason: nanny-close
2023-05-27 06:08:09,821 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45801'. Reason: nanny-close
2023-05-27 06:08:09,822 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35827'. Reason: nanny-close
2023-05-27 06:08:09,822 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36305'. Reason: nanny-close
2023-05-27 06:08:09,822 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-05-27 06:08:09,823 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46669. Reason: nanny-close
2023-05-27 06:08:09,825 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59564; closing.
2023-05-27 06:08:09,825 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-05-27 06:08:09,825 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46669', status: closing, memory: 0, processing: 0>
2023-05-27 06:08:09,825 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:46669
2023-05-27 06:08:09,825 - distributed.scheduler - INFO - Lost all workers
2023-05-27 06:08:09,826 - distributed.nanny - INFO - Worker closed
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:10,070 - distributed.nanny - INFO - Worker process 26733 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:10,208 - distributed.nanny - INFO - Worker process 26741 exited with status 127
2023-05-27 06:08:10,228 - distributed.nanny - INFO - Worker process 26738 exited with status 127
2023-05-27 06:08:14,879 - distributed.scheduler - INFO - Receive client connection: Client-dde2ef39-fc54-11ed-a5fb-d8c49764f6bb
2023-05-27 06:08:14,879 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58024
2023-05-27 06:08:17,804 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33269', status: init, memory: 0, processing: 0>
2023-05-27 06:08:17,805 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33269
2023-05-27 06:08:17,805 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58070
2023-05-27 06:08:24,912 - distributed.scheduler - INFO - Remove client Client-dde2ef39-fc54-11ed-a5fb-d8c49764f6bb
2023-05-27 06:08:24,913 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58024; closing.
2023-05-27 06:08:24,913 - distributed.scheduler - INFO - Remove client Client-dde2ef39-fc54-11ed-a5fb-d8c49764f6bb
2023-05-27 06:08:24,913 - distributed.scheduler - INFO - Close client connection: Client-dde2ef39-fc54-11ed-a5fb-d8c49764f6bb
2023-05-27 06:08:24,918 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58070; closing.
2023-05-27 06:08:24,919 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33269', status: closing, memory: 0, processing: 0>
2023-05-27 06:08:24,919 - distributed.core - INFO - Removing comms to tcp://127.0.0.1:33269
2023-05-27 06:08:24,919 - distributed.scheduler - INFO - Lost all workers
2023-05-27 06:08:39,813 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:08:39,813 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:08:39,814 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:08:39,815 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-05-27 06:08:39,816 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-05-27 06:08:41,877 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:08:41,881 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:08:41,884 - distributed.scheduler - INFO - State start
2023-05-27 06:08:41,902 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:08:41,903 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:08:41,903 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:08:42,032 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36501'
2023-05-27 06:08:42,040 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39487'
2023-05-27 06:08:42,052 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45063'
2023-05-27 06:08:42,061 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34631'
2023-05-27 06:08:42,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38513'
2023-05-27 06:08:42,070 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41039'
2023-05-27 06:08:42,078 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38045'
2023-05-27 06:08:42,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35591'
2023-05-27 06:08:42,917 - distributed.scheduler - INFO - Receive client connection: Client-ed24974b-fc54-11ed-a673-d8c49764f6bb
2023-05-27 06:08:42,929 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54280
2023-05-27 06:08:43,453 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h9_z4_8y', purging
2023-05-27 06:08:43,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lpepbmtx', purging
2023-05-27 06:08:43,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6agnv9g1', purging
2023-05-27 06:08:43,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:43,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:43,478 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:43,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:43,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:43,557 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:43,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:43,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:43,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:43,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:43,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:43,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:43,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:43,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:43,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:43,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:43,635 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:43,635 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:43,757 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:43,757 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:43,758 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:43,759 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:43,759 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:43,762 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:44,205 - distributed.nanny - INFO - Worker process 26935 exited with status 127
2023-05-27 06:08:44,206 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:45,600 - distributed.nanny - INFO - Worker process 26946 exited with status 127
2023-05-27 06:08:45,601 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:45,638 - distributed.nanny - INFO - Worker process 26938 exited with status 127
2023-05-27 06:08:45,639 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:45,678 - distributed.nanny - INFO - Worker process 26950 exited with status 127
2023-05-27 06:08:45,679 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:45,704 - distributed.nanny - INFO - Worker process 26956 exited with status 127
2023-05-27 06:08:45,705 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:45,727 - distributed.nanny - INFO - Worker process 26959 exited with status 127
2023-05-27 06:08:45,728 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:45,730 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8nentniw', purging
2023-05-27 06:08:45,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6gklcekf', purging
2023-05-27 06:08:45,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-92ei4lb0', purging
2023-05-27 06:08:45,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dsfw75uq', purging
2023-05-27 06:08:45,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i5ek6ni0', purging
2023-05-27 06:08:45,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ytpzloo_', purging
2023-05-27 06:08:45,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:45,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:45,759 - distributed.nanny - INFO - Worker process 26953 exited with status 127
2023-05-27 06:08:45,759 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:45,783 - distributed.nanny - INFO - Worker process 26942 exited with status 127
2023-05-27 06:08:45,783 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:45,798 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:46,153 - distributed.nanny - INFO - Worker process 27004 exited with status 127
2023-05-27 06:08:46,154 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:47,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-stoz2plk', purging
2023-05-27 06:08:47,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mph30h__', purging
2023-05-27 06:08:47,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ts2gqok_', purging
2023-05-27 06:08:47,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:47,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:47,097 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:47,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:47,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:47,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:47,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:47,364 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:47,364 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:47,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:47,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:47,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:47,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:47,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:47,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:47,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:47,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:47,423 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:47,431 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:47,433 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:47,446 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:47,553 - distributed.nanny - INFO - Worker process 27021 exited with status 127
2023-05-27 06:08:47,554 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:47,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u44083s6', purging
2023-05-27 06:08:47,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:47,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:47,896 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:49,027 - distributed.nanny - INFO - Worker process 27029 exited with status 127
2023-05-27 06:08:49,029 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:49,063 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c6nrz2_4', purging
2023-05-27 06:08:49,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:49,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:49,230 - distributed.nanny - INFO - Worker process 27039 exited with status 127
2023-05-27 06:08:49,231 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:49,256 - distributed.nanny - INFO - Worker process 27026 exited with status 127
2023-05-27 06:08:49,257 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:49,274 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:49,324 - distributed.nanny - INFO - Worker process 27036 exited with status 127
2023-05-27 06:08:49,325 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:49,388 - distributed.nanny - INFO - Worker process 27042 exited with status 127
2023-05-27 06:08:49,389 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:49,413 - distributed.nanny - INFO - Worker process 27032 exited with status 127
2023-05-27 06:08:49,414 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:49,700 - distributed.nanny - INFO - Worker process 27050 exited with status 127
2023-05-27 06:08:49,701 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:49,861 - distributed.nanny - INFO - Worker process 27085 exited with status 127
2023-05-27 06:08:49,862 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:50,593 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s22beyip', purging
2023-05-27 06:08:50,593 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m9d8khtt', purging
2023-05-27 06:08:50,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tl2hdazo', purging
2023-05-27 06:08:50,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l3m3fkoq', purging
2023-05-27 06:08:50,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__goh8d_', purging
2023-05-27 06:08:50,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-47lffhrs', purging
2023-05-27 06:08:50,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tyao0n4a', purging
2023-05-27 06:08:50,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:50,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:50,620 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:50,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:50,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:50,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:50,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:50,886 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:50,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:50,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:50,920 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:50,950 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:51,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:51,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:51,039 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:51,039 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:51,213 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:51,220 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:51,248 - distributed.nanny - INFO - Worker process 27107 exited with status 127
2023-05-27 06:08:51,249 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:51,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p7ipmhi8', purging
2023-05-27 06:08:51,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:51,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:51,298 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:51,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:51,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:51,513 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:52,298 - distributed.nanny - INFO - Worker process 27114 exited with status 127
2023-05-27 06:08:52,299 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:52,711 - distributed.nanny - INFO - Worker process 27117 exited with status 127
2023-05-27 06:08:52,712 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:52,798 - distributed.nanny - INFO - Worker process 27124 exited with status 127
2023-05-27 06:08:52,799 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:52,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2rv1ktol', purging
2023-05-27 06:08:52,820 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_a7981pn', purging
2023-05-27 06:08:52,820 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hjzwmhjq', purging
2023-05-27 06:08:52,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:52,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:52,884 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:53,018 - distributed.nanny - INFO - Worker process 27127 exited with status 127
2023-05-27 06:08:53,019 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:53,044 - distributed.nanny - INFO - Worker process 27130 exited with status 127
2023-05-27 06:08:53,045 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:53,078 - distributed.nanny - INFO - Worker process 27142 exited with status 127
2023-05-27 06:08:53,078 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:53,113 - distributed.nanny - INFO - Worker process 27137 exited with status 127
2023-05-27 06:08:53,114 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:53,476 - distributed.nanny - INFO - Worker process 27175 exited with status 127
2023-05-27 06:08:53,477 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:53,774 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ehzvvaxe', purging
2023-05-27 06:08:53,775 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d5dy06le', purging
2023-05-27 06:08:53,775 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tk48w8_l', purging
2023-05-27 06:08:53,775 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0h97tzxt', purging
2023-05-27 06:08:53,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z0m6nj8b', purging
2023-05-27 06:08:53,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:53,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:53,799 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:54,194 - distributed.nanny - INFO - Worker process 27194 exited with status 127
2023-05-27 06:08:54,196 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:54,252 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-21bv5c9u', purging
2023-05-27 06:08:54,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:54,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:54,277 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:54,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:54,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:54,335 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:54,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:54,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:54,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:54,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:54,624 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:54,640 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:54,643 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:54,643 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:54,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:54,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:54,834 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:54,835 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:54,931 - distributed.nanny - INFO - Worker process 27205 exited with status 127
2023-05-27 06:08:54,932 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:55,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-atse2kw4', purging
2023-05-27 06:08:55,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:55,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:55,224 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:55,419 - distributed.scheduler - INFO - Receive client connection: Client-f610771b-fc54-11ed-a5fb-d8c49764f6bb
2023-05-27 06:08:55,420 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56418
2023-05-27 06:08:55,622 - distributed.nanny - INFO - Worker process 27202 exited with status 127
2023-05-27 06:08:55,623 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:55,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o4a91wvm', purging
2023-05-27 06:08:55,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:55,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:55,847 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:56,286 - distributed.nanny - INFO - Worker process 27216 exited with status 127
2023-05-27 06:08:56,287 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:56,372 - distributed.nanny - INFO - Worker process 27222 exited with status 127
2023-05-27 06:08:56,373 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:56,563 - distributed.nanny - INFO - Worker process 27225 exited with status 127
2023-05-27 06:08:56,564 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:56,590 - distributed.nanny - INFO - Worker process 27219 exited with status 127
2023-05-27 06:08:56,591 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:56,593 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m8fjri8m', purging
2023-05-27 06:08:56,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z1xp9xhp', purging
2023-05-27 06:08:56,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qupb0h0l', purging
2023-05-27 06:08:56,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dga1deor', purging
2023-05-27 06:08:56,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:56,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:56,654 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:56,793 - distributed.nanny - INFO - Worker process 27233 exited with status 127
2023-05-27 06:08:56,794 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:57,003 - distributed.nanny - INFO - Worker process 27247 exited with status 127
2023-05-27 06:08:57,004 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:57,169 - distributed.nanny - INFO - Worker process 27274 exited with status 127
2023-05-27 06:08:57,170 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:57,298 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ovowh8x', purging
2023-05-27 06:08:57,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pto62ur_', purging
2023-05-27 06:08:57,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1bswtppt', purging
2023-05-27 06:08:57,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:57,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:57,324 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:57,745 - distributed.nanny - INFO - Worker process 27290 exited with status 127
2023-05-27 06:08:57,746 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:57,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t8gtzq2f', purging
2023-05-27 06:08:57,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:57,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:57,980 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:58,032 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,061 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:58,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,247 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,285 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:58,285 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:08:58,428 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,479 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:58,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:58,808 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:58,854 - distributed.nanny - INFO - Worker process 27303 exited with status 127
2023-05-27 06:08:58,855 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:08:59,028 - distributed.scheduler - INFO - Remove client Client-ed24974b-fc54-11ed-a673-d8c49764f6bb
2023-05-27 06:08:59,028 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54280; closing.
2023-05-27 06:08:59,028 - distributed.scheduler - INFO - Remove client Client-ed24974b-fc54-11ed-a673-d8c49764f6bb
2023-05-27 06:08:59,029 - distributed.scheduler - INFO - Close client connection: Client-ed24974b-fc54-11ed-a673-d8c49764f6bb
2023-05-27 06:08:59,031 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36501'. Reason: nanny-close
2023-05-27 06:08:59,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39487'. Reason: nanny-close
2023-05-27 06:08:59,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45063'. Reason: nanny-close
2023-05-27 06:08:59,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34631'. Reason: nanny-close
2023-05-27 06:08:59,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38513'. Reason: nanny-close
2023-05-27 06:08:59,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41039'. Reason: nanny-close
2023-05-27 06:08:59,032 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38045'. Reason: nanny-close
2023-05-27 06:08:59,033 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35591'. Reason: nanny-close
2023-05-27 06:08:59,043 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:59,054 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:08:59,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7bxgwzpy', purging
2023-05-27 06:08:59,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:08:59,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:08:59,766 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:00,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:00,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:00,587 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:02,308 - distributed.nanny - INFO - Worker process 27308 exited with status 127
2023-05-27 06:09:02,680 - distributed.nanny - INFO - Worker process 27311 exited with status 127
2023-05-27 06:09:02,717 - distributed.nanny - INFO - Worker process 27315 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:03,679 - distributed.nanny - INFO - Worker process 27324 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:03,771 - distributed.nanny - INFO - Worker process 27333 exited with status 127
2023-05-27 06:09:03,825 - distributed.nanny - INFO - Worker process 27329 exited with status 127
2023-05-27 06:09:04,255 - distributed.nanny - INFO - Worker process 27346 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:04,518 - distributed.nanny - INFO - Worker process 27373 exited with status 127
2023-05-27 06:09:11,466 - distributed.scheduler - INFO - Remove client Client-f610771b-fc54-11ed-a5fb-d8c49764f6bb
2023-05-27 06:09:11,466 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:56418; closing.
2023-05-27 06:09:11,466 - distributed.scheduler - INFO - Remove client Client-f610771b-fc54-11ed-a5fb-d8c49764f6bb
2023-05-27 06:09:11,467 - distributed.scheduler - INFO - Close client connection: Client-f610771b-fc54-11ed-a5fb-d8c49764f6bb
2023-05-27 06:09:29,047 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:09:29,047 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:09:29,048 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:09:29,049 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:09:29,050 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-05-27 06:09:31,045 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:09:31,048 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:09:31,051 - distributed.scheduler - INFO - State start
2023-05-27 06:09:31,069 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:09:31,070 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:09:31,070 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:09:31,193 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40373'
2023-05-27 06:09:31,211 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40131'
2023-05-27 06:09:31,220 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41401'
2023-05-27 06:09:31,222 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40531'
2023-05-27 06:09:31,231 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44037'
2023-05-27 06:09:31,239 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42033'
2023-05-27 06:09:31,247 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36895'
2023-05-27 06:09:31,255 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34043'
2023-05-27 06:09:31,522 - distributed.scheduler - INFO - Receive client connection: Client-0a748d62-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:09:31,534 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59814
2023-05-27 06:09:32,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ao2m2hi9', purging
2023-05-27 06:09:32,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_1jtgd3i', purging
2023-05-27 06:09:32,652 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-75fmwkm3', purging
2023-05-27 06:09:32,652 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2k5mwz3g', purging
2023-05-27 06:09:32,652 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ok4f2jn', purging
2023-05-27 06:09:32,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-msntzc3x', purging
2023-05-27 06:09:32,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vbzct3gg', purging
2023-05-27 06:09:32,653 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dyc1ez6o', purging
2023-05-27 06:09:32,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:32,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:32,677 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:32,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:32,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:32,752 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:32,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:32,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:32,802 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:32,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:32,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:32,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:32,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:32,815 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:32,815 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:32,818 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:32,818 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:32,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:32,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:32,966 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:32,968 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:32,972 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:32,972 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:32,972 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:33,551 - distributed.nanny - INFO - Worker process 27576 exited with status 127
2023-05-27 06:09:33,552 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:34,805 - distributed.nanny - INFO - Worker process 27591 exited with status 127
2023-05-27 06:09:34,806 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:34,867 - distributed.nanny - INFO - Worker process 27583 exited with status 127
2023-05-27 06:09:34,868 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:34,924 - distributed.nanny - INFO - Worker process 27597 exited with status 127
2023-05-27 06:09:34,925 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:34,950 - distributed.nanny - INFO - Worker process 27600 exited with status 127
2023-05-27 06:09:34,950 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:35,000 - distributed.nanny - INFO - Worker process 27579 exited with status 127
2023-05-27 06:09:35,001 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:35,025 - distributed.nanny - INFO - Worker process 27587 exited with status 127
2023-05-27 06:09:35,025 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:35,050 - distributed.nanny - INFO - Worker process 27594 exited with status 127
2023-05-27 06:09:35,051 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:35,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r7nxim5e', purging
2023-05-27 06:09:35,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j1zwh3nr', purging
2023-05-27 06:09:35,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7ltii_3', purging
2023-05-27 06:09:35,092 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ahxe5acw', purging
2023-05-27 06:09:35,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2hl96xxs', purging
2023-05-27 06:09:35,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nyst4797', purging
2023-05-27 06:09:35,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-904y7jg9', purging
2023-05-27 06:09:35,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-67vmeigx', purging
2023-05-27 06:09:35,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:35,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:35,117 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:35,469 - distributed.nanny - INFO - Worker process 27643 exited with status 127
2023-05-27 06:09:35,470 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:36,392 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sdv6s53w', purging
2023-05-27 06:09:36,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:36,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:36,418 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:36,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:36,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:36,447 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:36,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:36,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:36,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:36,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:36,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:36,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:36,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:36,577 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:36,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:36,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:36,700 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:36,705 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:36,708 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:36,708 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:36,708 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:37,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:37,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:37,052 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:37,166 - distributed.nanny - INFO - Worker process 27659 exited with status 127
2023-05-27 06:09:37,167 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:38,073 - distributed.nanny - INFO - Worker process 27664 exited with status 127
2023-05-27 06:09:38,074 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:38,517 - distributed.nanny - INFO - Worker process 27670 exited with status 127
2023-05-27 06:09:38,518 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:38,522 - distributed.scheduler - INFO - Receive client connection: Client-0fc22830-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:09:38,523 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59830
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:38,581 - distributed.nanny - INFO - Worker process 27676 exited with status 127
2023-05-27 06:09:38,582 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:38,647 - distributed.nanny - INFO - Worker process 27673 exited with status 127
2023-05-27 06:09:38,648 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:38,673 - distributed.nanny - INFO - Worker process 27682 exited with status 127
2023-05-27 06:09:38,674 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:38,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3j9gmgs7', purging
2023-05-27 06:09:38,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c6grwz2r', purging
2023-05-27 06:09:38,689 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s2j_rvgx', purging
2023-05-27 06:09:38,689 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6exliyt_', purging
2023-05-27 06:09:38,690 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ni12u2di', purging
2023-05-27 06:09:38,690 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fyamdz2z', purging
2023-05-27 06:09:38,690 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mxo4bpcw', purging
2023-05-27 06:09:38,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:38,691 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:38,699 - distributed.nanny - INFO - Worker process 27679 exited with status 127
2023-05-27 06:09:38,699 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:38,716 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:38,866 - distributed.nanny - INFO - Worker process 27692 exited with status 127
2023-05-27 06:09:38,867 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:39,203 - distributed.nanny - INFO - Worker process 27731 exited with status 127
2023-05-27 06:09:39,204 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:39,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ualshpvi', purging
2023-05-27 06:09:39,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j46h283v', purging
2023-05-27 06:09:39,777 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:39,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:39,802 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:40,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yr0t6pzo', purging
2023-05-27 06:09:40,233 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:40,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:40,234 - distributed.nanny - INFO - Worker process 27746 exited with status 127
2023-05-27 06:09:40,235 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:40,242 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:40,242 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:40,259 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:40,268 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:40,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:40,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:40,347 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:40,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:40,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:40,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:40,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:40,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:40,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:40,548 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:40,557 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:40,742 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:40,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:40,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:40,927 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:41,714 - distributed.nanny - INFO - Worker process 27759 exited with status 127
2023-05-27 06:09:41,715 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:41,749 - distributed.nanny - INFO - Worker process 27753 exited with status 127
2023-05-27 06:09:41,750 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:41,874 - distributed.scheduler - INFO - Receive client connection: Client-11c1a421-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:09:41,876 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52404
2023-05-27 06:09:41,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vs6ikllm', purging
2023-05-27 06:09:41,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xn91kl2k', purging
2023-05-27 06:09:41,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:41,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:41,950 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:42,268 - distributed.nanny - INFO - Worker process 27762 exited with status 127
2023-05-27 06:09:42,269 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:42,413 - distributed.nanny - INFO - Worker process 27770 exited with status 127
2023-05-27 06:09:42,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:42,502 - distributed.nanny - INFO - Worker process 27765 exited with status 127
2023-05-27 06:09:42,503 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:42,558 - distributed.nanny - INFO - Worker process 27778 exited with status 127
2023-05-27 06:09:42,559 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:43,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-82nlzor5', purging
2023-05-27 06:09:43,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5bjncvvg', purging
2023-05-27 06:09:43,441 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dmej8r9g', purging
2023-05-27 06:09:43,441 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0l9m4cx4', purging
2023-05-27 06:09:43,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:43,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:43,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:43,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:43,815 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:43,817 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:43,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:43,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:44,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1qx4dbv0', purging
2023-05-27 06:09:44,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:44,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:44,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:44,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:44,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:44,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:44,425 - distributed.nanny - INFO - Worker process 27783 exited with status 127
2023-05-27 06:09:44,426 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:44,482 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:44,527 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:44,533 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:44,538 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:46,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l6r_6ugq', purging
2023-05-27 06:09:46,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:46,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:46,542 - distributed.nanny - INFO - Worker process 27800 exited with status 127
2023-05-27 06:09:46,543 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:46,620 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:47,193 - distributed.nanny - INFO - Worker process 27840 exited with status 127
2023-05-27 06:09:47,194 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:47,227 - distributed.nanny - INFO - Worker process 27837 exited with status 127
2023-05-27 06:09:47,228 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:47,358 - distributed.nanny - INFO - Worker process 27850 exited with status 127
2023-05-27 06:09:47,359 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:47,409 - distributed.nanny - INFO - Worker process 27860 exited with status 127
2023-05-27 06:09:47,410 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:47,446 - distributed.nanny - INFO - Worker process 27863 exited with status 127
2023-05-27 06:09:47,447 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:47,529 - distributed.nanny - INFO - Worker process 27856 exited with status 127
2023-05-27 06:09:47,530 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:09:47,588 - distributed.scheduler - INFO - Remove client Client-0a748d62-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:09:47,588 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59814; closing.
2023-05-27 06:09:47,589 - distributed.scheduler - INFO - Remove client Client-0a748d62-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:09:47,589 - distributed.scheduler - INFO - Close client connection: Client-0a748d62-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:09:47,590 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41401'. Reason: nanny-close
2023-05-27 06:09:47,590 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40531'. Reason: nanny-close
2023-05-27 06:09:47,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36895'. Reason: nanny-close
2023-05-27 06:09:47,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40373'. Reason: nanny-close
2023-05-27 06:09:47,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40131'. Reason: nanny-close
2023-05-27 06:09:47,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44037'. Reason: nanny-close
2023-05-27 06:09:47,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42033'. Reason: nanny-close
2023-05-27 06:09:47,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34043'. Reason: nanny-close
2023-05-27 06:09:48,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gxvpjqza', purging
2023-05-27 06:09:48,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_vo2xya9', purging
2023-05-27 06:09:48,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s45scplu', purging
2023-05-27 06:09:48,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-njxkmnha', purging
2023-05-27 06:09:48,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ia2pzky', purging
2023-05-27 06:09:48,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0sfpph5q', purging
2023-05-27 06:09:48,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:48,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:48,623 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:48,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:48,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:48,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:48,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:49,001 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:49,001 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:49,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:49,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:49,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:49,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:49,161 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:09:49,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:09:49,640 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:49,642 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:49,655 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:49,675 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:49,676 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:09:49,686 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:52,307 - distributed.nanny - INFO - Worker process 27883 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:09:54,351 - distributed.nanny - INFO - Worker process 27909 exited with status 127
2023-05-27 06:09:54,418 - distributed.nanny - INFO - Worker process 27933 exited with status 127
2023-05-27 06:09:54,462 - distributed.nanny - INFO - Worker process 27927 exited with status 127
2023-05-27 06:09:54,496 - distributed.nanny - INFO - Worker process 27936 exited with status 127
2023-05-27 06:09:54,532 - distributed.nanny - INFO - Worker process 27923 exited with status 127
2023-05-27 06:09:54,540 - distributed.scheduler - INFO - Remove client Client-0fc22830-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:09:54,541 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59830; closing.
2023-05-27 06:09:54,541 - distributed.scheduler - INFO - Remove client Client-0fc22830-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:09:54,541 - distributed.scheduler - INFO - Close client connection: Client-0fc22830-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:09:54,564 - distributed.nanny - INFO - Worker process 27930 exited with status 127
2023-05-27 06:09:54,612 - distributed.nanny - INFO - Worker process 27920 exited with status 127
2023-05-27 06:09:57,955 - distributed.scheduler - INFO - Remove client Client-11c1a421-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:09:57,955 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52404; closing.
2023-05-27 06:09:57,956 - distributed.scheduler - INFO - Remove client Client-11c1a421-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:09:57,956 - distributed.scheduler - INFO - Close client connection: Client-11c1a421-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:10:17,622 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:10:17,622 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:10:17,623 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:10:17,626 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:10:17,627 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-05-27 06:10:19,740 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:10:19,743 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:10:19,746 - distributed.scheduler - INFO - State start
2023-05-27 06:10:19,764 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:10:19,765 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:10:19,766 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:10:19,907 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40451'
2023-05-27 06:10:19,925 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45087'
2023-05-27 06:10:19,927 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36197'
2023-05-27 06:10:19,933 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33569'
2023-05-27 06:10:19,941 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39957'
2023-05-27 06:10:19,948 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36833'
2023-05-27 06:10:19,956 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38707'
2023-05-27 06:10:19,964 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43257'
2023-05-27 06:10:20,148 - distributed.scheduler - INFO - Receive client connection: Client-27793f4c-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:10:20,159 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32784
2023-05-27 06:10:21,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qo3uvmgy', purging
2023-05-27 06:10:21,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1z1prlle', purging
2023-05-27 06:10:21,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-frp3p83u', purging
2023-05-27 06:10:21,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2bwvh9c_', purging
2023-05-27 06:10:21,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lpjadufc', purging
2023-05-27 06:10:21,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9j1fcy5', purging
2023-05-27 06:10:21,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mwr2ufgh', purging
2023-05-27 06:10:21,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ekqh_k_', purging
2023-05-27 06:10:21,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:21,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:21,424 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:21,463 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:21,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:21,488 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:21,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:21,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:21,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:21,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:21,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:21,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:21,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:21,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:21,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:21,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:21,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:21,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:21,687 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:21,688 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:21,701 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:21,701 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:21,704 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:21,712 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:22,135 - distributed.nanny - INFO - Worker process 28173 exited with status 127
2023-05-27 06:10:22,136 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:23,449 - distributed.nanny - INFO - Worker process 28160 exited with status 127
2023-05-27 06:10:23,450 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:23,577 - distributed.nanny - INFO - Worker process 28169 exited with status 127
2023-05-27 06:10:23,578 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:23,611 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nfy0uhu7', purging
2023-05-27 06:10:23,611 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w0llrtxy', purging
2023-05-27 06:10:23,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hk1rjnwy', purging
2023-05-27 06:10:23,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rfijg_n9', purging
2023-05-27 06:10:23,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:23,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:23,613 - distributed.nanny - INFO - Worker process 28181 exited with status 127
2023-05-27 06:10:23,614 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:23,649 - distributed.nanny - INFO - Worker process 28164 exited with status 127
2023-05-27 06:10:23,650 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:23,677 - distributed.nanny - INFO - Worker process 28178 exited with status 127
2023-05-27 06:10:23,678 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:23,701 - distributed.nanny - INFO - Worker process 28176 exited with status 127
2023-05-27 06:10:23,701 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:23,724 - distributed.nanny - INFO - Worker process 28157 exited with status 127
2023-05-27 06:10:23,725 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:23,735 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:24,098 - distributed.nanny - INFO - Worker process 28222 exited with status 127
2023-05-27 06:10:24,099 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:24,917 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fbgv1w4a', purging
2023-05-27 06:10:24,918 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eeefn4av', purging
2023-05-27 06:10:24,918 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_45nf42x', purging
2023-05-27 06:10:24,918 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sy3m67ow', purging
2023-05-27 06:10:24,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m85b474_', purging
2023-05-27 06:10:24,919 - distributed.scheduler - INFO - Receive client connection: Client-2b69db4d-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:10:24,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:24,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:24,919 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32802
2023-05-27 06:10:24,942 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:25,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:25,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:25,249 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:25,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:25,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:25,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:25,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:25,309 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:25,319 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:25,343 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:25,343 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:25,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:25,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:25,376 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:25,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:25,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:25,559 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:25,562 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:25,598 - distributed.nanny - INFO - Worker process 28239 exited with status 127
2023-05-27 06:10:25,599 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:25,664 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yqiq8y9q', purging
2023-05-27 06:10:25,665 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:25,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:25,870 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:26,389 - distributed.nanny - INFO - Worker process 28248 exited with status 127
2023-05-27 06:10:26,390 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:27,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i8kfhdoz', purging
2023-05-27 06:10:27,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xd5cobzc', purging
2023-05-27 06:10:27,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:27,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:27,128 - distributed.nanny - INFO - Worker process 28252 exited with status 127
2023-05-27 06:10:27,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:27,179 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:27,209 - distributed.nanny - INFO - Worker process 28255 exited with status 127
2023-05-27 06:10:27,210 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:27,338 - distributed.nanny - INFO - Worker process 28261 exited with status 127
2023-05-27 06:10:27,339 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:27,389 - distributed.nanny - INFO - Worker process 28258 exited with status 127
2023-05-27 06:10:27,390 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:27,436 - distributed.nanny - INFO - Worker process 28264 exited with status 127
2023-05-27 06:10:27,437 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:27,477 - distributed.nanny - INFO - Worker process 28273 exited with status 127
2023-05-27 06:10:27,478 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:27,784 - distributed.nanny - INFO - Worker process 28309 exited with status 127
2023-05-27 06:10:27,785 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:28,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r9xqwk32', purging
2023-05-27 06:10:28,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0mq9drs9', purging
2023-05-27 06:10:28,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-da2ab430', purging
2023-05-27 06:10:28,077 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r9qxvo2o', purging
2023-05-27 06:10:28,077 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uq64akvh', purging
2023-05-27 06:10:28,077 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ub3ucjx', purging
2023-05-27 06:10:28,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,104 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:28,373 - distributed.scheduler - INFO - Receive client connection: Client-2d78ecb9-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:10:28,375 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32880
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:28,524 - distributed.nanny - INFO - Worker process 28323 exited with status 127
2023-05-27 06:10:28,525 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:28,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kdcmpb70', purging
2023-05-27 06:10:28,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,890 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:28,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:28,911 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:28,964 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:29,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:29,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:29,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:29,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:29,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:29,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:29,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:29,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:29,272 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:29,298 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:29,300 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:29,303 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:29,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:29,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:29,656 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:30,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:30,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:30,841 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:33,100 - distributed.nanny - INFO - Worker process 28359 exited with status 127
2023-05-27 06:10:33,101 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,183 - distributed.nanny - INFO - Worker process 28341 exited with status 127
2023-05-27 06:10:33,184 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:33,218 - distributed.nanny - INFO - Worker process 28336 exited with status 127
2023-05-27 06:10:33,219 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,242 - distributed.nanny - INFO - Worker process 28354 exited with status 127
2023-05-27 06:10:33,243 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,281 - distributed.nanny - INFO - Worker process 28346 exited with status 127
2023-05-27 06:10:33,282 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,307 - distributed.nanny - INFO - Worker process 28350 exited with status 127
2023-05-27 06:10:33,308 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:33,576 - distributed.nanny - INFO - Worker process 28364 exited with status 127
2023-05-27 06:10:33,577 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:33,856 - distributed.nanny - INFO - Worker process 28379 exited with status 127
2023-05-27 06:10:33,857 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:10:34,783 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x3h9e9o2', purging
2023-05-27 06:10:34,783 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7avo7p25', purging
2023-05-27 06:10:34,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-91b1qa4r', purging
2023-05-27 06:10:34,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-srlq33c3', purging
2023-05-27 06:10:34,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wntexq5i', purging
2023-05-27 06:10:34,785 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_vjf0pmh', purging
2023-05-27 06:10:34,785 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l572zb6d', purging
2023-05-27 06:10:34,785 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mstobqq9', purging
2023-05-27 06:10:34,786 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,786 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:34,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:34,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:34,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:34,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:35,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:35,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:35,017 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:35,018 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:35,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:35,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:35,316 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,378 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,415 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,422 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,424 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,427 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,448 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:35,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:10:35,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:10:35,698 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:10:36,234 - distributed.scheduler - INFO - Remove client Client-27793f4c-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:10:36,234 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32784; closing.
2023-05-27 06:10:36,234 - distributed.scheduler - INFO - Remove client Client-27793f4c-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:10:36,235 - distributed.scheduler - INFO - Close client connection: Client-27793f4c-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:10:36,236 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40451'. Reason: nanny-close
2023-05-27 06:10:36,236 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45087'. Reason: nanny-close
2023-05-27 06:10:36,236 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36197'. Reason: nanny-close
2023-05-27 06:10:36,237 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33569'. Reason: nanny-close
2023-05-27 06:10:36,237 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39957'. Reason: nanny-close
2023-05-27 06:10:36,237 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36833'. Reason: nanny-close
2023-05-27 06:10:36,237 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38707'. Reason: nanny-close
2023-05-27 06:10:36,237 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43257'. Reason: nanny-close
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:40,418 - distributed.nanny - INFO - Worker process 28448 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:10:40,715 - distributed.nanny - INFO - Worker process 28432 exited with status 127
2023-05-27 06:10:40,750 - distributed.nanny - INFO - Worker process 28429 exited with status 127
2023-05-27 06:10:40,780 - distributed.nanny - INFO - Worker process 28442 exited with status 127
2023-05-27 06:10:40,981 - distributed.nanny - INFO - Worker process 28436 exited with status 127
2023-05-27 06:10:40,990 - distributed.scheduler - INFO - Remove client Client-2b69db4d-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:10:40,990 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32802; closing.
2023-05-27 06:10:40,990 - distributed.scheduler - INFO - Remove client Client-2b69db4d-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:10:40,991 - distributed.scheduler - INFO - Close client connection: Client-2b69db4d-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:10:41,005 - distributed.nanny - INFO - Worker process 28445 exited with status 127
2023-05-27 06:10:41,061 - distributed.nanny - INFO - Worker process 28454 exited with status 127
2023-05-27 06:10:41,124 - distributed.nanny - INFO - Worker process 28439 exited with status 127
2023-05-27 06:10:44,395 - distributed.scheduler - INFO - Remove client Client-2d78ecb9-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:10:44,396 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32880; closing.
2023-05-27 06:10:44,396 - distributed.scheduler - INFO - Remove client Client-2d78ecb9-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:10:44,396 - distributed.scheduler - INFO - Close client connection: Client-2d78ecb9-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:11:06,269 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:11:06,269 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:11:06,270 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:11:06,273 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:11:06,274 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-05-27 06:11:08,268 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:11:08,271 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:11:08,274 - distributed.scheduler - INFO - State start
2023-05-27 06:11:08,294 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:11:08,295 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:11:08,295 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:11:08,443 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43755'
2023-05-27 06:11:08,453 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33167'
2023-05-27 06:11:08,466 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36527'
2023-05-27 06:11:08,468 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42871'
2023-05-27 06:11:08,475 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40325'
2023-05-27 06:11:08,482 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45121'
2023-05-27 06:11:08,491 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33417'
2023-05-27 06:11:08,499 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44261'
2023-05-27 06:11:08,678 - distributed.scheduler - INFO - Receive client connection: Client-4465e7ad-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:11:08,690 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38410
2023-05-27 06:11:09,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eddumxmo', purging
2023-05-27 06:11:09,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xr44zh2l', purging
2023-05-27 06:11:09,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a85ni__u', purging
2023-05-27 06:11:09,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jam11091', purging
2023-05-27 06:11:09,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jrrdx8ak', purging
2023-05-27 06:11:09,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d5mb1zyj', purging
2023-05-27 06:11:09,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xoc9fznm', purging
2023-05-27 06:11:09,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tcgutstr', purging
2023-05-27 06:11:09,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:09,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:09,899 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:10,002 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:10,002 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:10,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:10,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:10,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:10,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:10,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:10,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:10,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:10,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:10,072 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:10,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:10,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:10,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:10,188 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:10,189 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:10,190 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:10,191 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:10,191 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:10,192 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:10,194 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:10,445 - distributed.nanny - INFO - Worker process 28678 exited with status 127
2023-05-27 06:11:10,446 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:11,550 - distributed.scheduler - INFO - Receive client connection: Client-47354067-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:11:11,551 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34112
2023-05-27 06:11:11,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ulby_m92', purging
2023-05-27 06:11:11,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:11,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:12,053 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:12,118 - distributed.nanny - INFO - Worker process 28702 exited with status 127
2023-05-27 06:11:12,119 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:12,196 - distributed.nanny - INFO - Worker process 28699 exited with status 127
2023-05-27 06:11:12,197 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:12,218 - distributed.nanny - INFO - Worker process 28696 exited with status 127
2023-05-27 06:11:12,219 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:12,242 - distributed.nanny - INFO - Worker process 28689 exited with status 127
2023-05-27 06:11:12,243 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:12,267 - distributed.nanny - INFO - Worker process 28685 exited with status 127
2023-05-27 06:11:12,267 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:12,294 - distributed.nanny - INFO - Worker process 28694 exited with status 127
2023-05-27 06:11:12,295 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:12,369 - distributed.nanny - INFO - Worker process 28681 exited with status 127
2023-05-27 06:11:12,370 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:12,684 - distributed.nanny - INFO - Worker process 28741 exited with status 127
2023-05-27 06:11:12,685 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:13,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qehb7sqs', purging
2023-05-27 06:11:13,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-589ixl2i', purging
2023-05-27 06:11:13,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9k3kd1dn', purging
2023-05-27 06:11:13,804 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ezfc2k2', purging
2023-05-27 06:11:13,804 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c2c29l7y', purging
2023-05-27 06:11:13,804 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0v41u2m1', purging
2023-05-27 06:11:13,804 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rbst4sd8', purging
2023-05-27 06:11:13,805 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d92yqpdd', purging
2023-05-27 06:11:13,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:13,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:13,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:13,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:13,828 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:13,830 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:13,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:13,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:13,912 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:13,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:13,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:13,952 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:13,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:13,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:13,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:13,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:14,077 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:14,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:14,257 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:14,265 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:14,265 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:14,368 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:14,368 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:14,409 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:14,747 - distributed.scheduler - INFO - Receive client connection: Client-491cfd2b-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:11:14,748 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34196
2023-05-27 06:11:14,945 - distributed.nanny - INFO - Worker process 28780 exited with status 127
2023-05-27 06:11:14,945 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:14,971 - distributed.nanny - INFO - Worker process 28768 exited with status 127
2023-05-27 06:11:14,972 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:16,199 - distributed.nanny - INFO - Worker process 28771 exited with status 127
2023-05-27 06:11:16,200 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:16,330 - distributed.nanny - INFO - Worker process 28774 exited with status 127
2023-05-27 06:11:16,331 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:16,495 - distributed.nanny - INFO - Worker process 28783 exited with status 127
2023-05-27 06:11:16,496 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:16,643 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7g193zxd', purging
2023-05-27 06:11:16,643 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f0bm_h0a', purging
2023-05-27 06:11:16,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-766_b11z', purging
2023-05-27 06:11:16,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y_8_ww2g', purging
2023-05-27 06:11:16,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-glezzltp', purging
2023-05-27 06:11:16,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:16,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:16,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:16,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:17,039 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:17,056 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:17,911 - distributed.nanny - INFO - Worker process 28777 exited with status 127
2023-05-27 06:11:17,912 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:17,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ymr22fex', purging
2023-05-27 06:11:17,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sj3gqxog', purging
2023-05-27 06:11:17,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e66tp_bh', purging
2023-05-27 06:11:17,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:17,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:17,961 - distributed.nanny - INFO - Worker process 28789 exited with status 127
2023-05-27 06:11:17,963 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:17,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:17,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:17,999 - distributed.nanny - INFO - Worker process 28793 exited with status 127
2023-05-27 06:11:18,000 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:18,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:18,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:18,096 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:18,123 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:18,192 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:19,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:19,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:19,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:19,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:19,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:19,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:20,067 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:20,090 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:20,097 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:22,629 - distributed.nanny - INFO - Worker process 28841 exited with status 127
2023-05-27 06:11:22,630 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:22,753 - distributed.nanny - INFO - Worker process 28838 exited with status 127
2023-05-27 06:11:22,754 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:23,437 - distributed.nanny - INFO - Worker process 28860 exited with status 127
2023-05-27 06:11:23,438 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:23,501 - distributed.nanny - INFO - Worker process 28856 exited with status 127
2023-05-27 06:11:23,501 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:11:23,671 - distributed.nanny - INFO - Worker process 28865 exited with status 127
2023-05-27 06:11:23,672 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:24,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zydcejas', purging
2023-05-27 06:11:24,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-es8q4ohx', purging
2023-05-27 06:11:24,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ggk6lb05', purging
2023-05-27 06:11:24,198 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bs_v5ci4', purging
2023-05-27 06:11:24,199 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nrko_uka', purging
2023-05-27 06:11:24,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:24,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:24,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:24,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:24,588 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:24,705 - distributed.scheduler - INFO - Remove client Client-4465e7ad-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:11:24,705 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38410; closing.
2023-05-27 06:11:24,706 - distributed.scheduler - INFO - Remove client Client-4465e7ad-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:11:24,706 - distributed.scheduler - INFO - Close client connection: Client-4465e7ad-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:11:24,707 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43755'. Reason: nanny-close
2023-05-27 06:11:24,708 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33167'. Reason: nanny-close
2023-05-27 06:11:24,708 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36527'. Reason: nanny-close
2023-05-27 06:11:24,708 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42871'. Reason: nanny-close
2023-05-27 06:11:24,708 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40325'. Reason: nanny-close
2023-05-27 06:11:24,709 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45121'. Reason: nanny-close
2023-05-27 06:11:24,709 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33417'. Reason: nanny-close
2023-05-27 06:11:24,709 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44261'. Reason: nanny-close
2023-05-27 06:11:24,802 - distributed.nanny - INFO - Worker process 28879 exited with status 127
2023-05-27 06:11:25,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h5x27z7_', purging
2023-05-27 06:11:25,099 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ii39kzm', purging
2023-05-27 06:11:25,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:25,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:25,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:25,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:25,306 - distributed.nanny - INFO - Worker process 28886 exited with status 127
2023-05-27 06:11:25,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:25,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:25,418 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:25,489 - distributed.nanny - INFO - Worker process 28882 exited with status 127
2023-05-27 06:11:25,509 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:25,526 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:25,557 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:11:27,601 - distributed.scheduler - INFO - Remove client Client-47354067-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:11:27,602 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34112; closing.
2023-05-27 06:11:27,602 - distributed.scheduler - INFO - Remove client Client-47354067-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:11:27,602 - distributed.scheduler - INFO - Close client connection: Client-47354067-fc55-11ed-a607-d8c49764f6bb
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:28,020 - distributed.nanny - INFO - Worker process 28926 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:28,052 - distributed.nanny - INFO - Worker process 28937 exited with status 127
2023-05-27 06:11:28,159 - distributed.nanny - INFO - Worker process 28929 exited with status 127
2023-05-27 06:11:28,190 - distributed.nanny - INFO - Worker process 28940 exited with status 127
2023-05-27 06:11:28,220 - distributed.nanny - INFO - Worker process 28943 exited with status 127
2023-05-27 06:11:30,846 - distributed.scheduler - INFO - Remove client Client-491cfd2b-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:11:30,846 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34196; closing.
2023-05-27 06:11:30,846 - distributed.scheduler - INFO - Remove client Client-491cfd2b-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:11:30,847 - distributed.scheduler - INFO - Close client connection: Client-491cfd2b-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:11:54,739 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:11:54,740 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:11:54,740 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:11:54,743 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:11:54,743 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-05-27 06:11:56,835 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:11:56,839 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:11:56,842 - distributed.scheduler - INFO - State start
2023-05-27 06:11:56,860 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:11:56,861 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:11:56,862 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:11:56,879 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46437'
2023-05-27 06:11:57,057 - distributed.scheduler - INFO - Receive client connection: Client-6156bbba-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:11:57,069 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55872
2023-05-27 06:11:57,886 - distributed.scheduler - INFO - Receive client connection: Client-62d3794a-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:11:57,886 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55880
2023-05-27 06:11:58,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s2h_u0h2', purging
2023-05-27 06:11:58,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gf2zbye2', purging
2023-05-27 06:11:58,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h4q7dfji', purging
2023-05-27 06:11:58,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hcvu5giq', purging
2023-05-27 06:11:58,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-06byjhsb', purging
2023-05-27 06:11:58,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z7n4dszg', purging
2023-05-27 06:11:58,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:11:58,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:11:58,493 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:11:58,875 - distributed.nanny - INFO - Worker process 29149 exited with status 127
2023-05-27 06:11:58,876 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:00,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-874zoffe', purging
2023-05-27 06:12:00,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:00,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:00,437 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:00,844 - distributed.nanny - INFO - Worker process 29160 exited with status 127
2023-05-27 06:12:00,845 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:01,350 - distributed.scheduler - INFO - Receive client connection: Client-64e4192e-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:12:01,350 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:59558
2023-05-27 06:12:02,551 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-36i58j5l', purging
2023-05-27 06:12:02,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:02,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:03,170 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:03,852 - distributed.nanny - INFO - Worker process 29170 exited with status 127
2023-05-27 06:12:03,853 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:05,526 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w0c5l3qd', purging
2023-05-27 06:12:05,527 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:05,527 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 9370 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45845 instead
  warnings.warn(
2023-05-27 06:12:06,058 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:12:07,142 - distributed.scheduler - INFO - Remove client Client-6156bbba-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:12:07,143 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55872; closing.
2023-05-27 06:12:07,143 - distributed.scheduler - INFO - Remove client Client-6156bbba-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:12:07,145 - distributed.scheduler - INFO - Close client connection: Client-6156bbba-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:12:07,145 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46437'. Reason: nanny-close
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:07,835 - distributed.nanny - INFO - Worker process 29180 exited with status 127
2023-05-27 06:12:11,491 - distributed.scheduler - INFO - Remove client Client-64e4192e-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:12:11,491 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:59558; closing.
2023-05-27 06:12:11,491 - distributed.scheduler - INFO - Remove client Client-64e4192e-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:12:11,492 - distributed.scheduler - INFO - Close client connection: Client-64e4192e-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:12:13,928 - distributed.scheduler - INFO - Remove client Client-62d3794a-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:12:13,929 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55880; closing.
2023-05-27 06:12:13,930 - distributed.scheduler - INFO - Remove client Client-62d3794a-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:12:13,931 - distributed.scheduler - INFO - Close client connection: Client-62d3794a-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:12:37,177 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:12:37,178 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:12:37,179 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:12:37,181 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:12:37,182 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-05-27 06:12:40,739 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:12:40,742 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:12:40,745 - distributed.scheduler - INFO - State start
2023-05-27 06:12:40,763 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:12:40,764 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:12:40,764 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:12:40,792 - distributed.scheduler - INFO - Receive client connection: Client-7b8a4f07-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:12:40,803 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32940
2023-05-27 06:12:40,880 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43121'
2023-05-27 06:12:42,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ngoacd2', purging
2023-05-27 06:12:42,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:42,218 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:42,471 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:42,827 - distributed.nanny - INFO - Worker process 29439 exited with status 127
2023-05-27 06:12:42,828 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:43,373 - distributed.scheduler - INFO - Receive client connection: Client-7df0720d-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:12:43,374 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32962
2023-05-27 06:12:44,164 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-acxalt12', purging
2023-05-27 06:12:44,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:44,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:44,342 - distributed.scheduler - INFO - Receive client connection: Client-7e844fd4-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:12:44,343 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:32982
2023-05-27 06:12:44,435 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:44,899 - distributed.nanny - INFO - Worker process 29449 exited with status 127
2023-05-27 06:12:44,900 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:46,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4of996ae', purging
2023-05-27 06:12:46,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:46,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:46,581 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:47,187 - distributed.nanny - INFO - Worker process 29459 exited with status 127
2023-05-27 06:12:47,188 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:48,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-smkx5vny', purging
2023-05-27 06:12:48,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:48,588 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:48,853 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:49,441 - distributed.nanny - INFO - Worker process 29469 exited with status 127
2023-05-27 06:12:49,442 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:12:50,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2jkv6tj', purging
2023-05-27 06:12:50,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:12:50,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:12:50,832 - distributed.scheduler - INFO - Remove client Client-7b8a4f07-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:12:50,832 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32940; closing.
2023-05-27 06:12:50,833 - distributed.scheduler - INFO - Remove client Client-7b8a4f07-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:12:50,833 - distributed.scheduler - INFO - Close client connection: Client-7b8a4f07-fc55-11ed-a673-d8c49764f6bb
2023-05-27 06:12:50,834 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43121'. Reason: nanny-close
2023-05-27 06:12:51,082 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:12:51,695 - distributed.nanny - INFO - Worker process 29479 exited with status 127
2023-05-27 06:12:53,469 - distributed.scheduler - INFO - Remove client Client-7df0720d-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:12:53,469 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32962; closing.
2023-05-27 06:12:53,469 - distributed.scheduler - INFO - Remove client Client-7df0720d-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:12:53,470 - distributed.scheduler - INFO - Close client connection: Client-7df0720d-fc55-11ed-a5fb-d8c49764f6bb
2023-05-27 06:12:54,379 - distributed.scheduler - INFO - Remove client Client-7e844fd4-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:12:54,379 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:32982; closing.
2023-05-27 06:12:54,380 - distributed.scheduler - INFO - Remove client Client-7e844fd4-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:12:54,380 - distributed.scheduler - INFO - Close client connection: Client-7e844fd4-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:13:20,866 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:13:20,867 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:13:20,867 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:13:20,868 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:13:20,869 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-05-27 06:13:22,831 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:13:22,835 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:13:22,837 - distributed.scheduler - INFO - State start
2023-05-27 06:13:22,857 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:13:22,858 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:13:22,859 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:13:26,322 - distributed.scheduler - INFO - Receive client connection: Client-9789ce1a-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:13:26,336 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39202
2023-05-27 06:13:36,403 - distributed.scheduler - INFO - Remove client Client-9789ce1a-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:13:36,404 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39202; closing.
2023-05-27 06:13:36,405 - distributed.scheduler - INFO - Remove client Client-9789ce1a-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:13:36,405 - distributed.scheduler - INFO - Close client connection: Client-9789ce1a-fc55-11ed-a607-d8c49764f6bb
2023-05-27 06:25:38,480 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:25:38,480 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:25:38,482 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:25:38,483 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:25:38,484 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-05-27 06:25:40,407 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:25:40,411 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:25:40,414 - distributed.scheduler - INFO - State start
2023-05-27 06:25:40,432 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:25:40,433 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-05-27 06:25:40,434 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:25:40,549 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33755'
2023-05-27 06:25:40,605 - distributed.scheduler - INFO - Receive client connection: Client-4c3dde3b-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:25:40,617 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58562
2023-05-27 06:25:41,944 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tvh7p8zn', purging
2023-05-27 06:25:41,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:25:41,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:25:41,950 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:25:42,488 - distributed.nanny - INFO - Worker process 33313 exited with status 127
2023-05-27 06:25:42,489 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:25:43,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o0gl0s8x', purging
2023-05-27 06:25:43,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:25:43,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:25:43,883 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:25:44,237 - distributed.nanny - INFO - Worker process 33324 exited with status 127
2023-05-27 06:25:44,238 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:25:45,661 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hkj31ygr', purging
2023-05-27 06:25:45,662 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:25:45,662 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:25:45,669 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:25:46,153 - distributed.nanny - INFO - Worker process 33334 exited with status 127
2023-05-27 06:25:46,154 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:25:47,539 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3hfxnd0r', purging
2023-05-27 06:25:47,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:25:47,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:25:47,546 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:25:48,044 - distributed.nanny - INFO - Worker process 33344 exited with status 127
2023-05-27 06:25:48,045 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:25:49,444 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-doch5t1w', purging
2023-05-27 06:25:49,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:25:49,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:25:49,451 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:25:49,804 - distributed.nanny - INFO - Worker process 33354 exited with status 127
2023-05-27 06:25:49,804 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:25:50,673 - distributed.scheduler - INFO - Remove client Client-4c3dde3b-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:25:50,674 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58562; closing.
2023-05-27 06:25:50,674 - distributed.scheduler - INFO - Remove client Client-4c3dde3b-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:25:50,675 - distributed.scheduler - INFO - Close client connection: Client-4c3dde3b-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:25:50,675 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33755'. Reason: nanny-close
2023-05-27 06:25:51,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7p1nzim5', purging
2023-05-27 06:25:51,195 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:25:51,195 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:25:51,202 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:25:51,533 - distributed.nanny - INFO - Worker process 33364 exited with status 127
2023-05-27 06:26:20,707 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:26:20,707 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:26:20,708 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:26:20,709 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-05-27 06:26:20,709 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-05-27 06:26:22,753 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:26:22,757 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:26:22,760 - distributed.scheduler - INFO - State start
2023-05-27 06:26:22,871 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:26:22,872 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:26:22,872 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:26:23,055 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44173'
2023-05-27 06:26:23,076 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43023'
2023-05-27 06:26:23,078 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36917'
2023-05-27 06:26:23,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39821'
2023-05-27 06:26:23,093 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33759'
2023-05-27 06:26:23,101 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36123'
2023-05-27 06:26:23,109 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44461'
2023-05-27 06:26:23,117 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38513'
2023-05-27 06:26:23,260 - distributed.scheduler - INFO - Receive client connection: Client-65690d5d-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:26:23,275 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45136
2023-05-27 06:26:24,587 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tgfekm_6', purging
2023-05-27 06:26:24,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:24,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:24,610 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:24,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:24,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:24,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:24,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:24,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:24,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:24,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:24,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:24,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:24,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:24,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:24,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:24,822 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:24,822 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:24,890 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:24,891 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:24,898 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:24,899 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:24,902 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:24,902 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:24,902 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:25,183 - distributed.nanny - INFO - Worker process 33552 exited with status 127
2023-05-27 06:26:25,185 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:26,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8m11b8ay', purging
2023-05-27 06:26:26,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:26,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:26,871 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:27,020 - distributed.nanny - INFO - Worker process 33557 exited with status 127
2023-05-27 06:26:27,021 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:27,046 - distributed.nanny - INFO - Worker process 33562 exited with status 127
2023-05-27 06:26:27,047 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:27,118 - distributed.nanny - INFO - Worker process 33541 exited with status 127
2023-05-27 06:26:27,119 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:27,141 - distributed.nanny - INFO - Worker process 33565 exited with status 127
2023-05-27 06:26:27,142 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:27,165 - distributed.nanny - INFO - Worker process 33548 exited with status 127
2023-05-27 06:26:27,166 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:27,191 - distributed.nanny - INFO - Worker process 33560 exited with status 127
2023-05-27 06:26:27,192 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:27,238 - distributed.nanny - INFO - Worker process 33544 exited with status 127
2023-05-27 06:26:27,239 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:27,823 - distributed.nanny - INFO - Worker process 33604 exited with status 127
2023-05-27 06:26:27,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:28,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmhyen7b', purging
2023-05-27 06:26:28,613 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uqf_v9na', purging
2023-05-27 06:26:28,613 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cgqx6yeh', purging
2023-05-27 06:26:28,614 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gk4lbiyf', purging
2023-05-27 06:26:28,614 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g53rfqki', purging
2023-05-27 06:26:28,614 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmr3alom', purging
2023-05-27 06:26:28,615 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tcgsx8kg', purging
2023-05-27 06:26:28,615 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ngazgbj', purging
2023-05-27 06:26:28,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:28,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:28,638 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:28,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:28,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:28,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:28,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:28,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:28,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:28,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:28,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:28,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:28,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:28,887 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:28,891 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:28,892 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:28,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:28,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:28,916 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:28,927 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:28,939 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:29,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:29,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:29,588 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:30,484 - distributed.nanny - INFO - Worker process 33631 exited with status 127
2023-05-27 06:26:30,485 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:31,040 - distributed.nanny - INFO - Worker process 33641 exited with status 127
2023-05-27 06:26:31,041 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:31,067 - distributed.nanny - INFO - Worker process 33634 exited with status 127
2023-05-27 06:26:31,068 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:31,104 - distributed.nanny - INFO - Worker process 33638 exited with status 127
2023-05-27 06:26:31,105 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:31,327 - distributed.nanny - INFO - Worker process 33647 exited with status 127
2023-05-27 06:26:31,328 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:31,353 - distributed.nanny - INFO - Worker process 33650 exited with status 127
2023-05-27 06:26:31,354 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:31,387 - distributed.nanny - INFO - Worker process 33644 exited with status 127
2023-05-27 06:26:31,388 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:31,712 - distributed.nanny - INFO - Worker process 33661 exited with status 127
2023-05-27 06:26:31,713 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:32,136 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vg13a1lk', purging
2023-05-27 06:26:32,136 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qyn_3z53', purging
2023-05-27 06:26:32,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1jfsvbhc', purging
2023-05-27 06:26:32,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nxdsl6r0', purging
2023-05-27 06:26:32,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p0m84p8b', purging
2023-05-27 06:26:32,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bh58linn', purging
2023-05-27 06:26:32,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i6b3hpl4', purging
2023-05-27 06:26:32,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u1yecbql', purging
2023-05-27 06:26:32,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:32,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:32,164 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:32,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-omgntbrk', purging
2023-05-27 06:26:32,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:32,561 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:32,576 - distributed.nanny - INFO - Worker process 33706 exited with status 127
2023-05-27 06:26:32,577 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:32,591 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:32,694 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:32,694 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:32,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:32,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:32,836 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:32,836 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:32,996 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9wvcpo0y', purging
2023-05-27 06:26:32,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:32,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:33,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:33,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:33,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:33,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:33,171 - distributed.nanny - INFO - Worker process 33720 exited with status 127
2023-05-27 06:26:33,172 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:33,379 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:33,383 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:33,387 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:33,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:33,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:33,438 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:33,984 - distributed.nanny - INFO - Worker process 33717 exited with status 127
2023-05-27 06:26:33,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:34,013 - distributed.nanny - INFO - Worker process 33723 exited with status 127
2023-05-27 06:26:34,014 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:34,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-15_4k8ks', purging
2023-05-27 06:26:34,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hzjmkpvy', purging
2023-05-27 06:26:34,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:34,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:34,421 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:34,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:34,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:35,020 - distributed.nanny - INFO - Worker process 33727 exited with status 127
2023-05-27 06:26:35,022 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:35,049 - distributed.nanny - INFO - Worker process 33733 exited with status 127
2023-05-27 06:26:35,050 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:35,065 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:35,091 - distributed.nanny - INFO - Worker process 33730 exited with status 127
2023-05-27 06:26:35,092 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:35,122 - distributed.nanny - INFO - Worker process 33739 exited with status 127
2023-05-27 06:26:35,122 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:35,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-inull8lf', purging
2023-05-27 06:26:35,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z5fzq83g', purging
2023-05-27 06:26:35,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xtgebijm', purging
2023-05-27 06:26:35,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vo0p8wry', purging
2023-05-27 06:26:35,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:35,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:35,592 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:35,592 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:35,649 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:35,654 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:35,754 - distributed.nanny - INFO - Worker process 33754 exited with status 127
2023-05-27 06:26:35,755 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:36,249 - distributed.nanny - INFO - Worker process 33775 exited with status 127
2023-05-27 06:26:36,250 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:36,433 - distributed.nanny - INFO - Worker process 33797 exited with status 127
2023-05-27 06:26:36,434 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:36,460 - distributed.nanny - INFO - Worker process 33800 exited with status 127
2023-05-27 06:26:36,461 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:36,634 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-787jn7v6', purging
2023-05-27 06:26:36,634 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fxxiah7z', purging
2023-05-27 06:26:36,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6gxfay3i', purging
2023-05-27 06:26:36,635 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zhcyw_lc', purging
2023-05-27 06:26:36,635 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:36,635 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:36,660 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:36,695 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:36,695 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:36,706 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:36,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:36,721 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:36,734 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:36,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:36,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:36,927 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:37,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:37,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:37,267 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:37,462 - distributed.nanny - INFO - Worker process 33815 exited with status 127
2023-05-27 06:26:37,463 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:37,836 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kv3a4v88', purging
2023-05-27 06:26:37,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:37,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:37,880 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:37,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v2e3mo37', purging
2023-05-27 06:26:37,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:37,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:38,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:38,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:38,066 - distributed.nanny - INFO - Worker process 33818 exited with status 127
2023-05-27 06:26:38,066 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:38,114 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:38,115 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:38,154 - distributed.nanny - INFO - Worker process 33826 exited with status 127
2023-05-27 06:26:38,155 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:38,373 - distributed.nanny - INFO - Worker process 33823 exited with status 127
2023-05-27 06:26:38,374 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:38,954 - distributed.nanny - INFO - Worker process 33844 exited with status 127
2023-05-27 06:26:38,954 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:26:38,986 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cmq04ziy', purging
2023-05-27 06:26:38,986 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-amm_jh4t', purging
2023-05-27 06:26:38,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6scgkzaf', purging
2023-05-27 06:26:38,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:38,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:39,334 - distributed.scheduler - INFO - Remove client Client-65690d5d-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:26:39,335 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45136; closing.
2023-05-27 06:26:39,335 - distributed.scheduler - INFO - Remove client Client-65690d5d-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:26:39,335 - distributed.scheduler - INFO - Close client connection: Client-65690d5d-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:26:39,337 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44173'. Reason: nanny-close
2023-05-27 06:26:39,337 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43023'. Reason: nanny-close
2023-05-27 06:26:39,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36917'. Reason: nanny-close
2023-05-27 06:26:39,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39821'. Reason: nanny-close
2023-05-27 06:26:39,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33759'. Reason: nanny-close
2023-05-27 06:26:39,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36123'. Reason: nanny-close
2023-05-27 06:26:39,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44461'. Reason: nanny-close
2023-05-27 06:26:39,338 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38513'. Reason: nanny-close
2023-05-27 06:26:39,369 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:39,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:39,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:39,586 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:39,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-an546mv_', purging
2023-05-27 06:26:39,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:39,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:39,760 - distributed.nanny - INFO - Worker process 33852 exited with status 127
2023-05-27 06:26:39,818 - distributed.nanny - INFO - Worker process 33858 exited with status 127
2023-05-27 06:26:39,848 - distributed.nanny - INFO - Worker process 33861 exited with status 127
2023-05-27 06:26:39,854 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:39,938 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ve2714h7', purging
2023-05-27 06:26:39,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0o0ba032', purging
2023-05-27 06:26:39,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:39,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:40,103 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:26:40,175 - distributed.nanny - INFO - Worker process 33889 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:40,501 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0i8mtp23', purging
2023-05-27 06:26:40,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y0tyv0ly', purging
2023-05-27 06:26:40,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:26:40,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:26:40,635 - distributed.nanny - INFO - Worker process 33904 exited with status 127
2023-05-27 06:26:40,655 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:40,743 - distributed.nanny - INFO - Worker process 33912 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:40,976 - distributed.nanny - INFO - Worker process 33915 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:26:41,115 - distributed.nanny - INFO - Worker process 33923 exited with status 127
2023-05-27 06:27:09,368 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:27:09,369 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:27:09,369 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:27:09,370 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:27:09,370 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-05-27 06:27:11,394 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:27:11,398 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:27:11,401 - distributed.scheduler - INFO - State start
2023-05-27 06:27:11,421 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:27:11,422 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:27:11,422 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:27:11,503 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44789'
2023-05-27 06:27:12,803 - distributed.scheduler - INFO - Receive client connection: Client-82676a52-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:27:12,816 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50670
2023-05-27 06:27:12,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q8m476w4', purging
2023-05-27 06:27:12,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_wi8lx3i', purging
2023-05-27 06:27:12,899 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-roimw1rx', purging
2023-05-27 06:27:12,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:27:12,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:27:12,921 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:27:13,595 - distributed.nanny - INFO - Worker process 34132 exited with status 127
2023-05-27 06:27:13,596 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:27:14,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mlmab46v', purging
2023-05-27 06:27:14,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:27:14,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:27:15,003 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:27:15,374 - distributed.nanny - INFO - Worker process 34143 exited with status 127
2023-05-27 06:27:15,375 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:27:16,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-edece2xw', purging
2023-05-27 06:27:16,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:27:16,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:27:16,791 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:27:17,157 - distributed.nanny - INFO - Worker process 34153 exited with status 127
2023-05-27 06:27:17,158 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:27:18,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gif9vzoq', purging
2023-05-27 06:27:18,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:27:18,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:27:18,567 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:27:18,950 - distributed.nanny - INFO - Worker process 34163 exited with status 127
2023-05-27 06:27:18,951 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:27:20,363 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xqfc7ldh', purging
2023-05-27 06:27:20,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:27:20,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:27:20,475 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:27:20,921 - distributed.nanny - INFO - Worker process 34173 exited with status 127
2023-05-27 06:27:20,922 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:27:22,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2amf9xzn', purging
2023-05-27 06:27:22,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:27:22,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:27:22,518 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-27 06:27:22,905 - distributed.scheduler - INFO - Remove client Client-82676a52-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:27:22,906 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50670; closing.
2023-05-27 06:27:22,906 - distributed.scheduler - INFO - Remove client Client-82676a52-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:27:22,906 - distributed.scheduler - INFO - Close client connection: Client-82676a52-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:27:22,907 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44789'. Reason: nanny-close
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:27:23,131 - distributed.nanny - INFO - Worker process 34183 exited with status 127
2023-05-27 06:27:52,939 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:27:52,940 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:27:52,941 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:27:52,942 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:27:52,942 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-05-27 06:27:55,100 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:27:55,104 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-27 06:27:55,107 - distributed.scheduler - INFO - State start
2023-05-27 06:27:55,125 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-27 06:27:55,126 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-27 06:27:55,127 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-27 06:27:55,239 - distributed.scheduler - INFO - Receive client connection: Client-9c734237-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:27:55,250 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50170
2023-05-27 06:27:55,287 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45699'
2023-05-27 06:27:56,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w1h9b0rz', purging
2023-05-27 06:27:56,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:27:56,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:27:56,754 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:27:57,172 - distributed.nanny - INFO - Worker process 34361 exited with status 127
2023-05-27 06:27:57,173 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:27:58,612 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yzp9_srs', purging
2023-05-27 06:27:58,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:27:58,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:27:58,640 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:27:59,191 - distributed.nanny - INFO - Worker process 34371 exited with status 127
2023-05-27 06:27:59,192 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:00,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2j931dza', purging
2023-05-27 06:28:00,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:00,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:00,655 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:01,177 - distributed.nanny - INFO - Worker process 34381 exited with status 127
2023-05-27 06:28:01,178 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:02,548 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pevpzpkc', purging
2023-05-27 06:28:02,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:02,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:02,570 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:02,932 - distributed.nanny - INFO - Worker process 34391 exited with status 127
2023-05-27 06:28:02,934 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:04,315 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iqdvw3e2', purging
2023-05-27 06:28:04,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:04,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:04,340 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:04,724 - distributed.nanny - INFO - Worker process 34401 exited with status 127
2023-05-27 06:28:04,725 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:05,272 - distributed.scheduler - INFO - Remove client Client-9c734237-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:28:05,272 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50170; closing.
2023-05-27 06:28:05,273 - distributed.scheduler - INFO - Remove client Client-9c734237-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:28:05,273 - distributed.scheduler - INFO - Close client connection: Client-9c734237-fc57-11ed-a673-d8c49764f6bb
2023-05-27 06:28:05,274 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45699'. Reason: nanny-close
2023-05-27 06:28:06,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gywbci8y', purging
2023-05-27 06:28:06,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:06,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:06,187 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:06,744 - distributed.nanny - INFO - Worker process 34411 exited with status 127
2023-05-27 06:28:35,306 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-27 06:28:35,306 - distributed.scheduler - INFO - Scheduler closing...
2023-05-27 06:28:35,307 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-27 06:28:35,307 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-27 06:28:35,308 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default 2023-05-27 06:28:44,140 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5rqj2mho', purging
2023-05-27 06:28:44,141 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:44,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:44,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:44,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:44,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:44,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:44,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:44,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:44,160 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:44,160 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:44,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:44,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:44,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:44,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:44,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:44,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:46,355 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:46,383 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:46,413 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:46,462 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:46,509 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:46,538 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:46,565 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:46,600 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:47,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a6warkns', purging
2023-05-27 06:28:47,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ekb5sj5', purging
2023-05-27 06:28:47,979 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ym6_aak', purging
2023-05-27 06:28:47,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1z2z1jz6', purging
2023-05-27 06:28:47,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fre98w9m', purging
2023-05-27 06:28:47,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uk74kap9', purging
2023-05-27 06:28:47,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aip4f45l', purging
2023-05-27 06:28:47,982 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tdu0kw8f', purging
2023-05-27 06:28:47,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:47,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:47,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:47,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:47,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:47,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:48,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:48,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:48,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:48,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:48,199 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:48,199 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:48,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:48,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:48,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:48,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:49,420 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:49,422 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:49,433 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:50,683 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:50,741 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:50,768 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:50,820 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:50,844 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:50,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rqg75mff', purging
2023-05-27 06:28:50,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-radu4jc1', purging
2023-05-27 06:28:50,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n5p_uyvm', purging
2023-05-27 06:28:50,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5nsiir85', purging
2023-05-27 06:28:50,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i0px59ek', purging
2023-05-27 06:28:50,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ifmjrnf6', purging
2023-05-27 06:28:50,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7m5n4f6j', purging
2023-05-27 06:28:50,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pke25ie3', purging
2023-05-27 06:28:50,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:50,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:50,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:50,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:51,042 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:51,042 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:51,777 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:51,907 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:52,011 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:52,300 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0co0affc', purging
2023-05-27 06:28:52,301 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-38sxhcnq', purging
2023-05-27 06:28:52,301 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6t5yz3jl', purging
2023-05-27 06:28:52,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:52,302 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:52,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:52,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:52,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:52,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:52,463 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:52,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:52,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:52,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:53,220 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:53,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-feil82yi', purging
2023-05-27 06:28:53,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:53,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:53,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:53,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:53,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:53,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:54,118 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:54,143 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:54,225 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:54,250 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:54,811 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-byi2ewec', purging
2023-05-27 06:28:54,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ffiyc14_', purging
2023-05-27 06:28:54,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w43zvmno', purging
2023-05-27 06:28:54,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wsl7rrgd', purging
2023-05-27 06:28:54,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:54,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:55,472 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:55,503 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:55,531 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:55,668 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:55,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ep45ku6', purging
2023-05-27 06:28:55,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jcbxis1p', purging
2023-05-27 06:28:55,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ga33_7a3', purging
2023-05-27 06:28:55,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yk7o1p9c', purging
2023-05-27 06:28:55,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:55,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:55,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:55,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:55,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:55,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:55,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:55,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:56,622 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:56,896 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:57,044 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cb8501a_', purging
2023-05-27 06:28:57,045 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_b0t7og', purging
2023-05-27 06:28:57,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:57,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:57,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:57,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:57,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:57,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:57,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:57,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:57,280 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:57,309 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:58,148 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yrj_4qjs', purging
2023-05-27 06:28:58,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-22z49ujy', purging
2023-05-27 06:28:58,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:58,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:58,376 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:58,403 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:58,431 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:58,441 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ce6zotes', purging
2023-05-27 06:28:58,441 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-st_muniz', purging
2023-05-27 06:28:58,442 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-po0kyntj', purging
2023-05-27 06:28:58,442 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:58,443 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:58,692 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:58,838 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sn6w177k', purging
2023-05-27 06:28:58,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:58,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:58,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:58,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:59,039 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:59,295 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:28:59,841 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:59,863 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:28:59,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8dnq97t', purging
2023-05-27 06:28:59,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w6yo85ny', purging
2023-05-27 06:28:59,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aljhq470', purging
2023-05-27 06:28:59,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sno06rc1', purging
2023-05-27 06:28:59,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:59,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:59,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:59,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:28:59,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:28:59,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:00,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:00,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:00,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:00,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:00,800 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:00,851 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:00,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6nvwlqw7', purging
2023-05-27 06:29:00,870 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ichyt4dw', purging
2023-05-27 06:29:00,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:00,871 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:01,076 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:01,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3761d965', purging
2023-05-27 06:29:01,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:01,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:01,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:01,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:01,614 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:01,704 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:02,178 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:02,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kfonpxjv', purging
2023-05-27 06:29:02,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ltr9vwa', purging
2023-05-27 06:29:02,404 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-720cob4c', purging
2023-05-27 06:29:02,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:02,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:02,456 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:02,456 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:02,610 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:02,639 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:02,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-duhsowbp', purging
2023-05-27 06:29:02,652 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f9u5fyug', purging
2023-05-27 06:29:02,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:02,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:03,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:03,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:03,278 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:03,278 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:03,385 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:03,436 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:03,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kwfp48ea', purging
2023-05-27 06:29:03,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-emx7v0i2', purging
2023-05-27 06:29:03,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:03,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:03,908 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:04,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2y7iqat9', purging
2023-05-27 06:29:04,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:04,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:04,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:04,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:04,287 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:04,314 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:04,821 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:04,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1bijk_d3', purging
2023-05-27 06:29:04,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mlb80dy3', purging
2023-05-27 06:29:04,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bbntouwe', purging
2023-05-27 06:29:04,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:04,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:05,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:05,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:05,465 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:05,492 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:05,547 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vba4erov', purging
2023-05-27 06:29:05,548 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-waish_pi', purging
2023-05-27 06:29:05,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:05,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:05,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tuj0_gbm', purging
2023-05-27 06:29:05,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:05,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:05,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:05,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:06,050 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:06,103 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:06,360 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ojea57hn', purging
2023-05-27 06:29:06,360 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:06,360 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:06,616 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:06,964 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:06,993 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:07,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:07,079 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mfy5jygz', purging
2023-05-27 06:29:07,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:07,080 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iu3rhu8q', purging
2023-05-27 06:29:07,080 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t3vhbjsn', purging
2023-05-27 06:29:07,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:07,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:07,272 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:07,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_hp4wdd', purging
2023-05-27 06:29:07,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:07,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:07,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:07,742 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:08,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:08,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:08,316 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:08,346 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:08,548 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o8gt_ktg', purging
2023-05-27 06:29:08,549 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8plgrzs4', purging
2023-05-27 06:29:08,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:08,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:08,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:08,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:08,711 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:08,735 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:08,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2b72icvq', purging
2023-05-27 06:29:08,879 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6sw7ri6d', purging
2023-05-27 06:29:08,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:08,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:09,246 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:09,603 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:09,634 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:09,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l4708smo', purging
2023-05-27 06:29:09,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mp5q_97s', purging
2023-05-27 06:29:09,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wpfkj7_z', purging
2023-05-27 06:29:09,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:09,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:09,960 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:09,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w4jl4vse', purging
2023-05-27 06:29:09,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:09,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:10,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:10,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:10,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:10,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:10,586 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:10,838 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t5a08tl9', purging
2023-05-27 06:29:10,839 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:10,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:11,065 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:11,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iyp22q00', purging
2023-05-27 06:29:11,151 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:11,151 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:11,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:11,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:11,430 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:11,457 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:11,549 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0eo1ua_t', purging
2023-05-27 06:29:11,550 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wohr09sz', purging
2023-05-27 06:29:11,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:11,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:11,817 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:12,184 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_tgt_y0a', purging
2023-05-27 06:29:12,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:12,185 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:12,316 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:12,613 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:12,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bhy68j3j', purging
2023-05-27 06:29:12,659 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-akztp9z_', purging
2023-05-27 06:29:12,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:12,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:12,906 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:12,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k7btphjp', purging
2023-05-27 06:29:12,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:12,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:12,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:12,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:13,202 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:13,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kukn1cfj', purging
2023-05-27 06:29:13,390 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:13,390 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:13,713 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:13,885 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g1zoffyb', purging
2023-05-27 06:29:13,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:13,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:14,075 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:14,105 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:14,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yljd53o2', purging
2023-05-27 06:29:14,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hyy5myvz', purging
2023-05-27 06:29:14,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:14,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:14,434 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:14,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r2rk6any', purging
2023-05-27 06:29:14,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:14,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:14,805 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:14,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w64fdbld', purging
2023-05-27 06:29:14,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:14,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:15,241 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:15,323 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pvs86dm_', purging
2023-05-27 06:29:15,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:15,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:15,550 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:15,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zk8x9hu7', purging
2023-05-27 06:29:15,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:15,709 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:15,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:15,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:15,918 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:16,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d3sie7q6', purging
2023-05-27 06:29:16,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:16,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:16,391 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:16,420 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bzc_md4n', purging
2023-05-27 06:29:16,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:16,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:16,749 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:16,781 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:16,826 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-czfqlv4c', purging
2023-05-27 06:29:16,826 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ja_v6bv', purging
2023-05-27 06:29:16,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:16,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:16,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:16,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:17,127 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:17,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zxe3a50i', purging
2023-05-27 06:29:17,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g9864l0n', purging
2023-05-27 06:29:17,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:17,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:17,575 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:17,971 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:17,971 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ze0moxl', purging
2023-05-27 06:29:17,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ghauj41e', purging
2023-05-27 06:29:17,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:17,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:17,997 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:18,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:18,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:18,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:18,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:18,522 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:18,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2r75bd4h', purging
2023-05-27 06:29:18,696 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:18,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:19,021 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:19,096 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mepfpoxw', purging
2023-05-27 06:29:19,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:19,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:19,421 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:19,448 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:19,483 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vbdkxf3h', purging
2023-05-27 06:29:19,483 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gizgrh8z', purging
2023-05-27 06:29:19,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:19,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:19,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:19,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:19,800 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:20,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4xogi_dg', purging
2023-05-27 06:29:20,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b171stdz', purging
2023-05-27 06:29:20,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:20,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:20,228 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:20,580 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:20,586 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vpg6y08f', purging
2023-05-27 06:29:20,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:20,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:20,784 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:21,005 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r50wpah_', purging
2023-05-27 06:29:21,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:21,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:21,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:21,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:21,150 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:21,312 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mqe3pqyg', purging
2023-05-27 06:29:21,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:21,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:21,622 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:21,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8cs5zftq', purging
2023-05-27 06:29:21,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:21,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:21,967 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:22,010 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:22,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ji3aynl0', purging
2023-05-27 06:29:22,126 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3ioy3uko', purging
2023-05-27 06:29:22,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:22,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:22,302 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:22,327 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l631w4zw', purging
2023-05-27 06:29:22,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:22,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:22,628 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:22,718 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s7v8zybr', purging
2023-05-27 06:29:22,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:22,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:22,992 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:23,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xhlkzjeh', purging
2023-05-27 06:29:23,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:23,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:23,411 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:23,614 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rv63jl4e', purging
2023-05-27 06:29:23,615 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:23,615 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:23,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:23,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:23,780 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:23,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-66f87w_e', purging
2023-05-27 06:29:23,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:23,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:24,130 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:24,245 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pwz65vxu', purging
2023-05-27 06:29:24,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:24,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:24,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:24,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:24,739 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:24,774 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:25,009 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-razgh8cr', purging
2023-05-27 06:29:25,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cpu9c0og', purging
2023-05-27 06:29:25,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:25,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:25,294 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:25,342 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:25,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oibuh2c4', purging
2023-05-27 06:29:25,409 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j_cg40i7', purging
2023-05-27 06:29:25,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:25,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:25,676 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:25,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f7l_8uhn', purging
2023-05-27 06:29:25,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:25,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:25,934 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:26,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pu37qwzl', purging
2023-05-27 06:29:26,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:26,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:26,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fho8zdv_', purging
2023-05-27 06:29:26,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:26,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:26,481 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:26,806 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:26,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ocve0gb', purging
2023-05-27 06:29:26,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:26,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:26,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:26,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:27,163 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:27,213 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:27,318 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2y9t6jxw', purging
2023-05-27 06:29:27,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wc8z9km_', purging
2023-05-27 06:29:27,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:27,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:27,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:27,668 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:27,982 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:28,013 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:28,141 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ws9vy17n', purging
2023-05-27 06:29:28,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uunxhd4n', purging
2023-05-27 06:29:28,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:28,454 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:28,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gnv11daq', purging
2023-05-27 06:29:28,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:28,668 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:28,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hg_80v5t', purging
2023-05-27 06:29:28,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:28,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:28,894 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:29,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:29,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:29,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:29,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:30,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:30,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:30,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:30,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:31,607 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:32,811 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:33,186 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:33,210 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:33,242 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5cky3i9o', purging
2023-05-27 06:29:33,242 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0r_3z0ds', purging
2023-05-27 06:29:33,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-93v698id', purging
2023-05-27 06:29:33,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zubup2kb', purging
2023-05-27 06:29:33,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:33,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:33,285 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:33,309 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:33,335 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:33,378 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:34,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yoeb94lv', purging
2023-05-27 06:29:34,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lf6h_6ab', purging
2023-05-27 06:29:34,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-scu3olcl', purging
2023-05-27 06:29:34,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oul5sbbe', purging
2023-05-27 06:29:34,440 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,440 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:34,770 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,770 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:34,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:34,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:34,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:34,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:34,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:35,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:35,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:35,356 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:36,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wkz7888l', purging
2023-05-27 06:29:36,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:36,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:38,322 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:38,383 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:38,450 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:39,375 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:39,571 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:39,596 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:39,660 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:39,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qcc6ikpo', purging
2023-05-27 06:29:39,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8g19tea1', purging
2023-05-27 06:29:39,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h4h8dgzh', purging
2023-05-27 06:29:39,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dr0i7kqn', purging
2023-05-27 06:29:39,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-448qd2m6', purging
2023-05-27 06:29:39,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gg25caek', purging
2023-05-27 06:29:39,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-62108ula', purging
2023-05-27 06:29:39,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:39,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:39,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:39,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:39,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:39,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:40,102 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:41,037 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vhbikakm', purging
2023-05-27 06:29:41,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:41,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:41,264 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,264 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:41,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:41,698 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:41,737 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m65fibgx', purging
2023-05-27 06:29:41,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:41,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:42,004 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:42,195 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:43,312 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a2ssbec9', purging
2023-05-27 06:29:43,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4lk71c6c', purging
2023-05-27 06:29:43,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:43,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:43,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:43,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:43,786 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:43,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:45,120 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:45,161 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:45,190 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:45,227 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:46,456 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:46,615 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bnj6tshj', purging
2023-05-27 06:29:46,616 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lem2ya3w', purging
2023-05-27 06:29:46,616 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w_z4zeqv', purging
2023-05-27 06:29:46,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yxu5hot8', purging
2023-05-27 06:29:46,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lbgl6cv9', purging
2023-05-27 06:29:46,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:46,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:46,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:46,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:46,837 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:46,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:46,841 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:46,841 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4estiiwg', purging
2023-05-27 06:29:46,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:46,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:46,969 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:46,995 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:47,961 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:47,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ec65_wsr', purging
2023-05-27 06:29:47,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cng_i7gk', purging
2023-05-27 06:29:47,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-at5ft12s', purging
2023-05-27 06:29:47,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:47,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:48,252 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:48,366 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hx98h7ot', purging
2023-05-27 06:29:48,366 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1x54ent4', purging
2023-05-27 06:29:48,367 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-da5mwm9r', purging
2023-05-27 06:29:48,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:48,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:48,392 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:48,394 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:48,445 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:48,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:48,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:48,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:48,979 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:49,510 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:49,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fj443kgw', purging
2023-05-27 06:29:49,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l51b1l7y', purging
2023-05-27 06:29:49,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mka_2k8d', purging
2023-05-27 06:29:49,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-naxzc8b6', purging
2023-05-27 06:29:49,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:49,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:49,595 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:49,620 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:49,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:49,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:49,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:49,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:50,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:50,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:50,220 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:50,549 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:50,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sv6x1w86', purging
2023-05-27 06:29:50,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8w6k2x9c', purging
2023-05-27 06:29:50,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:50,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:51,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:51,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:51,107 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:51,137 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:51,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jkt6dezp', purging
2023-05-27 06:29:51,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tu8s50mo', purging
2023-05-27 06:29:51,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:51,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:51,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:51,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:51,714 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:51,747 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-08711mgn', purging
2023-05-27 06:29:51,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:51,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:52,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:52,077 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:52,308 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:52,365 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:52,398 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:52,649 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xt59uknt', purging
2023-05-27 06:29:52,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iowq8c0l', purging
2023-05-27 06:29:52,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5sqx4e4k', purging
2023-05-27 06:29:52,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:52,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:52,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:52,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:53,276 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2pnr5ab0', purging
2023-05-27 06:29:53,276 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-orcoqo65', purging
2023-05-27 06:29:53,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:53,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:53,295 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:53,324 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:53,709 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:53,738 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:53,885 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t611ndlk', purging
2023-05-27 06:29:53,885 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sorw83h8', purging
2023-05-27 06:29:53,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:53,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:53,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:53,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:53,966 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:53,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:54,502 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:54,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:54,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zw0ah9d6', purging
2023-05-27 06:29:54,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:54,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2wjl2dbc', purging
2023-05-27 06:29:54,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r0ogmwhc', purging
2023-05-27 06:29:54,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:54,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:54,926 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:54,952 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:54,991 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:55,301 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijdrlg2j', purging
2023-05-27 06:29:55,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:55,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:55,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:55,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:56,002 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:56,029 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:56,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2dtgtz5c', purging
2023-05-27 06:29:56,107 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gp913p9g', purging
2023-05-27 06:29:56,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:56,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:56,364 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:56,413 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:56,545 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1artgwo3', purging
2023-05-27 06:29:56,546 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8szba_gm', purging
2023-05-27 06:29:56,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:56,546 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:56,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:56,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:56,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:56,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:57,202 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:57,596 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-42lyye2c', purging
2023-05-27 06:29:57,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uu1ek_0b', purging
2023-05-27 06:29:57,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:57,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:57,616 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:57,653 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:57,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hf06ey1m', purging
2023-05-27 06:29:57,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yawk9c_q', purging
2023-05-27 06:29:57,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:57,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:57,683 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:57,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:57,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:58,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:58,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:58,735 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:58,789 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:58,810 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3mqu6hge', purging
2023-05-27 06:29:58,810 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-er4259i8', purging
2023-05-27 06:29:58,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:58,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:29:59,139 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:59,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ipx1_pw2', purging
2023-05-27 06:29:59,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zlq_t21_', purging
2023-05-27 06:29:59,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:59,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:59,165 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:29:59,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:59,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:29:59,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:29:59,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:00,012 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:00,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hl2uw25s', purging
2023-05-27 06:30:00,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:00,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:00,370 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:00,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5v6x03rz', purging
2023-05-27 06:30:00,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jo236mre', purging
2023-05-27 06:30:00,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:00,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:00,403 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:00,442 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:00,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:00,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:00,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o_qa5a_m', purging
2023-05-27 06:30:00,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:00,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:00,984 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:01,427 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:01,628 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tfyquebu', purging
2023-05-27 06:30:01,628 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6x_h_6d8', purging
2023-05-27 06:30:01,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:01,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:01,827 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:01,856 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:01,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z2v2qha2', purging
2023-05-27 06:30:01,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n04g7wff', purging
2023-05-27 06:30:01,966 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:01,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:02,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:02,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:02,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:02,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:02,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zm5c06w2', purging
2023-05-27 06:30:02,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:02,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:02,859 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:03,000 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:03,000 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:03,312 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:03,331 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:03,372 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:03,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ma731445', purging
2023-05-27 06:30:03,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7qoek7a', purging
2023-05-27 06:30:03,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0l9swc9t', purging
2023-05-27 06:30:03,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:03,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:03,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:03,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:03,699 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:04,161 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:04,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-blo_kj12', purging
2023-05-27 06:30:04,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8u0_c1zm', purging
2023-05-27 06:30:04,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:04,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:04,524 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:04,554 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:04,857 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0lrgbv66', purging
2023-05-27 06:30:04,857 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqktxfpx', purging
2023-05-27 06:30:04,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:04,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:04,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:04,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:05,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:05,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:05,167 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:05,312 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-icytrf3z', purging
2023-05-27 06:30:05,313 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2kkvp17_', purging
2023-05-27 06:30:05,314 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:05,314 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:05,502 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:05,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:05,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:06,067 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:06,094 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:06,120 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ar5gzyfk', purging
2023-05-27 06:30:06,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sd8mwxi1', purging
2023-05-27 06:30:06,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:06,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:06,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:06,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:06,446 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:06,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qqim6vby', purging
2023-05-27 06:30:06,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:06,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:06,885 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:07,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d6_5wvml', purging
2023-05-27 06:30:07,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:07,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:07,276 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:07,521 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:07,613 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kf9ouqvv', purging
2023-05-27 06:30:07,613 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2c0xb4az', purging
2023-05-27 06:30:07,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:07,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:07,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:07,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:07,866 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:08,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vxilspu7', purging
2023-05-27 06:30:08,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:08,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:08,267 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:08,472 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2juald1y', purging
2023-05-27 06:30:08,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:08,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:08,632 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:08,656 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:08,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pbl1nhm8', purging
2023-05-27 06:30:08,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yg9dtp5q', purging
2023-05-27 06:30:08,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:08,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:08,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:09,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j168eqmt', purging
2023-05-27 06:30:09,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:09,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:09,302 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:09,467 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aijjg3uv', purging
2023-05-27 06:30:09,468 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:09,468 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:09,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hka3wwo0', purging
2023-05-27 06:30:09,786 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:09,786 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:09,803 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:10,133 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:10,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-brii2d0u', purging
2023-05-27 06:30:10,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:10,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:10,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:10,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:10,466 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:10,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-saonoy4e', purging
2023-05-27 06:30:10,544 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rq5m09j0', purging
2023-05-27 06:30:10,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:10,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:10,558 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:10,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:10,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:11,286 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:11,316 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:11,404 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2nj_jzi6', purging
2023-05-27 06:30:11,404 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-prf9bbcy', purging
2023-05-27 06:30:11,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:11,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:11,668 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:11,668 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-civnty3d', purging
2023-05-27 06:30:11,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:11,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:11,718 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:12,091 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j9bider_', purging
2023-05-27 06:30:12,092 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:12,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:12,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:12,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:12,363 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:12,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h4pbr4ar', purging
2023-05-27 06:30:12,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:12,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:12,932 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:12,996 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hk_7tnz0', purging
2023-05-27 06:30:12,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:12,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:13,289 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ol4qn8z7', purging
2023-05-27 06:30:13,290 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2yj0c76d', purging
2023-05-27 06:30:13,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:13,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:13,315 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:13,337 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:13,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:13,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:13,705 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:14,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6e2fxslc', purging
2023-05-27 06:30:14,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:14,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:14,137 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:14,490 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:14,523 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:14,677 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mscnw5ro', purging
2023-05-27 06:30:14,677 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gpv3z27u', purging
2023-05-27 06:30:14,678 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z6rh3v09', purging
2023-05-27 06:30:14,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:14,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:14,799 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:15,017 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k3ek0ol8', purging
2023-05-27 06:30:15,018 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:15,018 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:15,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:15,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:15,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:15,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:15,641 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:15,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ccb4dfag', purging
2023-05-27 06:30:15,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:15,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:16,007 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:16,029 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:16,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-62mm5zk_', purging
2023-05-27 06:30:16,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-huuwp4rl', purging
2023-05-27 06:30:16,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:16,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:16,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:16,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:16,356 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:16,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wa1y715', purging
2023-05-27 06:30:16,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:16,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:16,876 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:17,220 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:17,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-366aynse', purging
2023-05-27 06:30:17,266 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q0zi_ub0', purging
2023-05-27 06:30:17,266 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f02ehgfx', purging
2023-05-27 06:30:17,266 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:17,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:17,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:17,597 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:17,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-78ndl7vi', purging
2023-05-27 06:30:17,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:17,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:17,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:17,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:17,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:17,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:18,445 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:18,452 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8jhfez5g', purging
2023-05-27 06:30:18,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:18,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:18,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:18,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:18,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:18,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:19,097 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:19,137 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:19,172 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-237629hp', purging
2023-05-27 06:30:19,173 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-as2cy6au', purging
2023-05-27 06:30:19,173 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:19,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:19,767 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:20,020 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-moos37cq', purging
2023-05-27 06:30:20,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:20,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:20,161 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:20,223 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:20,284 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:20,623 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vtiumn6b', purging
2023-05-27 06:30:20,624 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-owgo1pg8', purging
2023-05-27 06:30:20,624 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xvv_d4cn', purging
2023-05-27 06:30:20,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:20,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:20,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:20,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:20,776 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:21,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vs9i2622', purging
2023-05-27 06:30:21,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:21,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:21,553 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:21,701 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1y8eg0u', purging
2023-05-27 06:30:21,702 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:21,702 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:21,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:21,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:21,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:21,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:21,950 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:21,975 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:22,328 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:22,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ncgg4ta', purging
2023-05-27 06:30:22,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f7snbuze', purging
2023-05-27 06:30:22,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-904y3wp_', purging
2023-05-27 06:30:22,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:22,430 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:22,893 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:23,110 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:23,139 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:23,174 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-761zu2sf', purging
2023-05-27 06:30:23,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q42f5v7p', purging
2023-05-27 06:30:23,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pudwmeie', purging
2023-05-27 06:30:23,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:23,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:23,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:23,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:23,499 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:23,580 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j7q56ulj', purging
2023-05-27 06:30:23,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:23,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:23,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:23,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:24,293 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:24,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6w82m_4y', purging
2023-05-27 06:30:24,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:24,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:24,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:24,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:24,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:24,738 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:24,893 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:25,002 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:25,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z49akn5v', purging
2023-05-27 06:30:25,132 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a8em2eys', purging
2023-05-27 06:30:25,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:25,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:25,661 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:25,837 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:25,890 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9gg7kszw', purging
2023-05-27 06:30:25,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-je8sfadl', purging
2023-05-27 06:30:25,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:25,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:26,137 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:26,167 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:26,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n79vv00a', purging
2023-05-27 06:30:26,478 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8uy9tpbi', purging
2023-05-27 06:30:26,479 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9842an_0', purging
2023-05-27 06:30:26,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:26,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:26,602 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:26,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:26,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:27,009 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:27,236 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lex4r7mx', purging
2023-05-27 06:30:27,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:27,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:27,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:27,459 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:27,636 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:27,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hl5n6ckd', purging
2023-05-27 06:30:27,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:27,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:27,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:27,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:27,894 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:28,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vh5i_1ns', purging
2023-05-27 06:30:28,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:28,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:28,647 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:28,648 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2s4npcg3', purging
2023-05-27 06:30:28,649 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:28,649 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:28,715 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:29,081 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:29,112 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:29,141 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6u0cufv', purging
2023-05-27 06:30:29,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cm6qs1yh', purging
2023-05-27 06:30:29,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0kyulf1i', purging
2023-05-27 06:30:29,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:29,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:29,414 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:29,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3skgcm8a', purging
2023-05-27 06:30:29,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:29,512 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:29,671 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:30,168 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:30,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j2297xqy', purging
2023-05-27 06:30:30,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0n5ik8le', purging
2023-05-27 06:30:30,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:30,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:30,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:30,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:30,383 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:30,716 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wc8czcfs', purging
2023-05-27 06:30:30,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:30,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:30,738 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:30,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:31,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:31,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:31,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:31,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:31,403 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:31,435 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:31,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9immhba', purging
2023-05-27 06:30:31,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a358pbp6', purging
2023-05-27 06:30:31,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:31,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:31,912 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:31,912 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:32,021 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:32,045 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:32,602 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:32,636 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:32,960 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:32,998 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:33,070 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q42iwb3i', purging
2023-05-27 06:30:33,071 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g_krai33', purging
2023-05-27 06:30:33,071 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n3w9i8hk', purging
2023-05-27 06:30:33,071 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p8uw1gt6', purging
2023-05-27 06:30:33,071 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zxiv3a0s', purging
2023-05-27 06:30:33,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8qeq6f3j', purging
2023-05-27 06:30:33,072 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:33,072 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:33,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:33,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:33,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:33,690 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:33,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:33,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:33,767 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:33,803 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:34,255 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r9gu0m93', purging
2023-05-27 06:30:34,256 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rl5_a59f', purging
2023-05-27 06:30:34,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:34,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:34,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:34,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:34,416 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:34,466 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:34,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2hgp232f', purging
2023-05-27 06:30:34,601 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_tmkm8tm', purging
2023-05-27 06:30:34,602 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:34,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:34,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:34,664 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:35,227 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:35,387 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j0m0t9sc', purging
2023-05-27 06:30:35,388 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xn7c9bvm', purging
2023-05-27 06:30:35,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:35,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:35,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:35,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:35,422 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:35,804 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:35,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uuffkboe', purging
2023-05-27 06:30:35,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:35,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:36,013 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vvw9bnos', purging
2023-05-27 06:30:36,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:36,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 06:30:36,797 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sl18yt8w', purging
2023-05-27 06:30:36,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:36,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:36,829 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:36,862 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:36,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0oqvwo4b', purging
2023-05-27 06:30:36,953 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:36,953 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:37,214 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:37,239 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:37,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nbvc2ubm', purging
2023-05-27 06:30:37,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lm18u1w3', purging
2023-05-27 06:30:37,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:37,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:37,545 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:37,817 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:37,971 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:38,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8raxpsla', purging
2023-05-27 06:30:38,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-isewcl6m', purging
2023-05-27 06:30:38,433 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8mmmakp0', purging
2023-05-27 06:30:38,434 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:38,434 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:38,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:38,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:38,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:38,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:38,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:38,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:39,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:39,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:39,392 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4g5h9g7p', purging
2023-05-27 06:30:39,392 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3hjm3gho', purging
2023-05-27 06:30:39,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:39,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:39,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:39,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:39,514 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:40,116 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:40,142 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:40,419 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:40,537 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:40,576 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:41,036 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-plxba6ad', purging
2023-05-27 06:30:41,037 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u5bruq09', purging
2023-05-27 06:30:41,037 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-87yoe4_u', purging
2023-05-27 06:30:41,037 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ayhbw27z', purging
2023-05-27 06:30:41,037 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bs6jtww7', purging
2023-05-27 06:30:41,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:41,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:41,441 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:41,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kt3scjok', purging
2023-05-27 06:30:41,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:41,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:41,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:41,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:41,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:41,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:42,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:42,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:42,155 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:42,155 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:42,563 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:42,592 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:43,007 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tbg44i2p', purging
2023-05-27 06:30:43,008 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uipewwzw', purging
2023-05-27 06:30:43,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:43,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:43,370 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:43,399 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:43,424 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:43,827 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:44,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mb75wwe9', purging
2023-05-27 06:30:44,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2tgy1alm', purging
2023-05-27 06:30:44,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05vc74fx', purging
2023-05-27 06:30:44,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-edkjzxiu', purging
2023-05-27 06:30:44,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:44,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:44,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:44,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:44,705 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:44,854 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:44,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ohvbvtn_', purging
2023-05-27 06:30:44,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5sh88m1d', purging
2023-05-27 06:30:44,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:44,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:44,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:44,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:44,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:44,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:45,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:45,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:45,727 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:45,999 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:46,193 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:46,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-omjokk6o', purging
2023-05-27 06:30:46,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3z43cedw', purging
2023-05-27 06:30:46,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f8ohdfhe', purging
2023-05-27 06:30:46,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:46,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:46,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yi8uipbr', purging
2023-05-27 06:30:46,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:46,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:46,395 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:46,879 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:47,016 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:47,255 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-isuqi0t1', purging
2023-05-27 06:30:47,255 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tj6kifnt', purging
2023-05-27 06:30:47,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:47,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:47,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:47,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:47,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:47,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:47,853 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:47,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-40ffm4ym', purging
2023-05-27 06:30:47,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:47,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:48,179 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:48,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qczie15z', purging
2023-05-27 06:30:48,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:48,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:48,509 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:48,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yfldl5j_', purging
2023-05-27 06:30:48,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:48,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:49,051 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:49,367 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vgqgmdnk', purging
2023-05-27 06:30:49,368 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e62jhj1q', purging
2023-05-27 06:30:49,368 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:49,368 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:49,389 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:49,424 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:49,641 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zvdmb3_d', purging
2023-05-27 06:30:49,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:49,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:49,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:50,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-530olfv3', purging
2023-05-27 06:30:50,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:50,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:50,129 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:50,464 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:50,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2itbz4hd', purging
2023-05-27 06:30:50,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vwwjbtof', purging
2023-05-27 06:30:50,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:50,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:50,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:50,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:50,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:50,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:51,170 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:51,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z9ikrtth', purging
2023-05-27 06:30:51,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:51,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:51,597 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:51,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:52,005 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-23akvqli', purging
2023-05-27 06:30:52,006 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kusk9edv', purging
2023-05-27 06:30:52,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:52,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:52,026 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:52,050 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:52,588 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:52,613 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:52,755 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:52,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ssj27n5', purging
2023-05-27 06:30:52,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x_kv798t', purging
2023-05-27 06:30:52,762 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3d8kri29', purging
2023-05-27 06:30:52,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:52,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:53,199 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:53,615 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cbj0hz1v', purging
2023-05-27 06:30:53,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:53,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:53,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:53,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:54,125 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:54,125 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:54,141 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:54,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:54,279 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:54,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zdffi7nm', purging
2023-05-27 06:30:54,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uf63ntaw', purging
2023-05-27 06:30:54,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:54,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:54,331 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:54,735 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:54,735 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:55,049 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:55,078 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:55,408 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:55,628 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:55,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ym2s7_23', purging
2023-05-27 06:30:55,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hjcbr908', purging
2023-05-27 06:30:55,865 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nl0zlecj', purging
2023-05-27 06:30:55,865 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hg483qux', purging
2023-05-27 06:30:55,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:55,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:55,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:55,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:56,501 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:56,545 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:56,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lr7qcmu5', purging
2023-05-27 06:30:56,627 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lcv2wo0j', purging
2023-05-27 06:30:56,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:56,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:56,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:56,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:57,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:57,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:57,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:57,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:57,489 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:57,519 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:58,034 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:58,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-riqkv3xv', purging
2023-05-27 06:30:58,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gq5riwwx', purging
2023-05-27 06:30:58,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-868cf1ie', purging
2023-05-27 06:30:58,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:58,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:58,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:58,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:58,242 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:58,888 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:58,912 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:30:59,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-912r3hjo', purging
2023-05-27 06:30:59,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2261fwaa', purging
2023-05-27 06:30:59,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p7lhlqfv', purging
2023-05-27 06:30:59,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:59,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:59,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:59,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:59,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:59,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:59,662 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:30:59,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t8iihiyd', purging
2023-05-27 06:30:59,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:30:59,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:30:59,932 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:00,217 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:00,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v4iht5kv', purging
2023-05-27 06:31:00,466 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_th_6ygp', purging
2023-05-27 06:31:00,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:00,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:00,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:00,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:00,792 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:01,238 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t7wdfwim', purging
2023-05-27 06:31:01,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:01,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:01,381 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:01,422 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:01,494 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jxmi1aal', purging
2023-05-27 06:31:01,495 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xwh4f8rv', purging
2023-05-27 06:31:01,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:01,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:01,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:01,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:01,925 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:02,246 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:02,420 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h_ceoh6o', purging
2023-05-27 06:31:02,421 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xq2_curp', purging
2023-05-27 06:31:02,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:02,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:02,579 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:02,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-97asmc9_', purging
2023-05-27 06:31:02,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:02,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:03,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:03,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:03,227 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:03,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x7vm6bb1', purging
2023-05-27 06:31:03,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:03,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:03,869 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:03,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:04,049 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:04,065 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:04,116 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j3jzh8k0', purging
2023-05-27 06:31:04,117 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-26mczdwn', purging
2023-05-27 06:31:04,117 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:04,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:04,394 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:04,731 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:04,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8c8cwtji', purging
2023-05-27 06:31:04,800 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cre3a5gj', purging
2023-05-27 06:31:04,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:04,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:05,001 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:05,581 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:05,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s4o_nljh', purging
2023-05-27 06:31:05,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5da0_kor', purging
2023-05-27 06:31:05,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:05,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:05,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:05,694 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:06,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:06,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:06,288 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:06,362 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wqo2gnei', purging
2023-05-27 06:31:06,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:06,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:06,542 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:06,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zxvb_zps', purging
2023-05-27 06:31:06,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:06,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:06,878 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:07,182 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b6iqmukw', purging
2023-05-27 06:31:07,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:07,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:07,219 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:07,485 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:07,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mrcmdnre', purging
2023-05-27 06:31:07,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u39ktepl', purging
2023-05-27 06:31:07,889 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:07,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:07,997 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:08,138 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-19grvr7m', purging
2023-05-27 06:31:08,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:08,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:08,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:08,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:08,624 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:08,810 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-de9aw2zj', purging
2023-05-27 06:31:08,810 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:08,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:08,940 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:09,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p11mzyw3', purging
2023-05-27 06:31:09,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:09,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:09,255 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:09,594 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:09,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-noz7qu7m', purging
2023-05-27 06:31:09,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zh9w_ngt', purging
2023-05-27 06:31:09,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:09,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:09,931 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:10,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ys7dkke', purging
2023-05-27 06:31:10,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:10,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:10,458 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:10,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_ttlm00', purging
2023-05-27 06:31:10,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:10,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:10,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:10,841 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:11,036 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:11,109 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0edfzxo2', purging
2023-05-27 06:31:11,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:11,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:11,317 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:11,498 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eog4g3s3', purging
2023-05-27 06:31:11,498 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:11,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:11,627 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:11,934 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:12,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-un51a3ql', purging
2023-05-27 06:31:12,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s75of_bh', purging
2023-05-27 06:31:12,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:12,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:12,080 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:12,511 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:12,618 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2tnfepkt', purging
2023-05-27 06:31:12,619 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rc7l31oq', purging
2023-05-27 06:31:12,619 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:12,619 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:12,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:12,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:13,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:13,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:13,432 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:13,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x55hlcsc', purging
2023-05-27 06:31:13,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:13,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:13,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:13,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:13,743 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:14,089 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-umgyl59l', purging
2023-05-27 06:31:14,090 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kkpu0kcz', purging
2023-05-27 06:31:14,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:14,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:14,235 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:14,619 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:14,636 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:14,777 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:15,006 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cw1lejjk', purging
2023-05-27 06:31:15,006 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f8a638w5', purging
2023-05-27 06:31:15,007 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nih4qley', purging
2023-05-27 06:31:15,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:15,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:15,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:15,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:15,716 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:15,793 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d90qjxxd', purging
2023-05-27 06:31:15,794 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:15,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:15,861 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:16,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:16,204 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-js25o5jo', purging
2023-05-27 06:31:16,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:16,205 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:16,205 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:16,257 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:16,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qb45ewjd', purging
2023-05-27 06:31:16,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:16,374 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:17,080 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:17,106 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:17,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufeb_z89', purging
2023-05-27 06:31:17,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pavervx7', purging
2023-05-27 06:31:17,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:17,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:17,391 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:17,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wcm7jwu9', purging
2023-05-27 06:31:17,468 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:17,468 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:17,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:17,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:18,020 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:18,317 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:18,459 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:18,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uxn09qin', purging
2023-05-27 06:31:18,644 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mnv3w_n7', purging
2023-05-27 06:31:18,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2cwclmbh', purging
2023-05-27 06:31:18,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:18,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:18,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:18,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:18,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:18,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:19,493 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:19,511 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:19,546 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-557dcji5', purging
2023-05-27 06:31:19,547 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c3_t_qy_', purging
2023-05-27 06:31:19,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:19,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:19,830 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:19,836 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-he41aczx', purging
2023-05-27 06:31:19,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:19,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:20,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:20,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:20,606 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:20,738 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:20,790 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:21,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-drfq1rn9', purging
2023-05-27 06:31:21,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j9fz5a_v', purging
2023-05-27 06:31:21,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r6o1vqa6', purging
2023-05-27 06:31:21,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:21,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:21,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:21,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:21,433 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:21,433 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:21,698 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:21,939 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:22,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d8cusr0o', purging
2023-05-27 06:31:22,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fbq_0u5b', purging
2023-05-27 06:31:22,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:22,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:22,244 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:22,360 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9erkmzl8', purging
2023-05-27 06:31:22,361 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:22,361 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:22,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:22,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:22,696 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:23,220 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:23,253 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:23,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u6gec9jk', purging
2023-05-27 06:31:23,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wkxe3otd', purging
2023-05-27 06:31:23,335 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-duil4mzk', purging
2023-05-27 06:31:23,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:23,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:23,517 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:23,517 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:23,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:23,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:23,945 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:24,122 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:24,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1yjxglcp', purging
2023-05-27 06:31:24,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-djnmq6rh', purging
2023-05-27 06:31:24,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:24,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:24,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:24,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:24,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2auzyl2i', purging
2023-05-27 06:31:24,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:24,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:24,822 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:25,132 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:25,461 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:25,506 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:25,511 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a56xmeqn', purging
2023-05-27 06:31:25,511 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6z_xihzb', purging
2023-05-27 06:31:25,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5itjobzc', purging
2023-05-27 06:31:25,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:25,512 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:25,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:25,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:26,125 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:26,265 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:26,411 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-23_d27yy', purging
2023-05-27 06:31:26,411 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qbv4p2np', purging
2023-05-27 06:31:26,412 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:26,412 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:26,697 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:26,697 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:27,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:27,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:27,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:27,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:27,252 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:27,735 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:27,766 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ox2296d', purging
2023-05-27 06:31:27,767 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3y_2gc5v', purging
2023-05-27 06:31:27,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:27,768 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:27,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:27,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:27,929 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:27,959 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:28,479 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:28,567 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:28,824 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ob4cgs97', purging
2023-05-27 06:31:28,825 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cgksc13p', purging
2023-05-27 06:31:28,825 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ah0gzcyi', purging
2023-05-27 06:31:28,826 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y6jyasmq', purging
2023-05-27 06:31:28,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:28,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:29,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:29,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:29,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:29,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:29,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:29,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:29,684 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:29,852 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:30,095 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8sx40giz', purging
2023-05-27 06:31:30,096 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3w37a38l', purging
2023-05-27 06:31:30,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:30,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:30,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:30,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:30,757 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:30,781 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:30,962 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:30,986 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:31,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u0k0aoly', purging
2023-05-27 06:31:31,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-16826gy1', purging
2023-05-27 06:31:31,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k3x4cy1j', purging
2023-05-27 06:31:31,193 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jrbul6no', purging
2023-05-27 06:31:31,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:31,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:31,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:31,438 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:31,921 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:32,071 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:32,304 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8vpo13sa', purging
2023-05-27 06:31:32,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pnuiqbl1', purging
2023-05-27 06:31:32,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:32,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:32,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:32,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:32,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:32,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:32,549 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:32,549 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:33,350 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:33,384 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:33,490 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4_ox46_w', purging
2023-05-27 06:31:33,490 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-646yl53l', purging
2023-05-27 06:31:33,491 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:33,491 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:33,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:33,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:33,742 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:33,767 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:34,373 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:34,400 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:34,887 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-28u86nrs', purging
2023-05-27 06:31:34,887 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v8zny8j0', purging
2023-05-27 06:31:34,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-91mftdqx', purging
2023-05-27 06:31:34,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lck7eyp6', purging
2023-05-27 06:31:34,889 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:34,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:34,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:34,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:35,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:35,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:35,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:35,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:35,515 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:35,907 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7fn06zcm', purging
2023-05-27 06:31:35,907 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:35,907 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:35,941 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3utkj_vk', purging
2023-05-27 06:31:35,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:35,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:35,956 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:36,374 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:36,375 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:36,988 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:37,023 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:37,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-86iiss94', purging
2023-05-27 06:31:37,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gua3ieif', purging
2023-05-27 06:31:37,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ot9ekaxa', purging
2023-05-27 06:31:37,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kjccaz8d', purging
2023-05-27 06:31:37,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:37,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:37,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1wbvyu7a', purging
2023-05-27 06:31:37,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:37,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:37,576 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:38,013 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:38,018 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i1l0skoo', purging
2023-05-27 06:31:38,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:38,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:38,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:38,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:38,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:38,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:38,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:38,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:38,684 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:38,718 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:39,148 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7jbk7oyw', purging
2023-05-27 06:31:39,148 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n2j9fte0', purging
2023-05-27 06:31:39,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:39,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:39,470 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:39,607 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:39,630 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zsohzktt', purging
2023-05-27 06:31:39,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d85k1h3d', purging
2023-05-27 06:31:39,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:39,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:40,124 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:40,277 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:40,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-08lqa9tt', purging
2023-05-27 06:31:40,302 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-01jw9li9', purging
2023-05-27 06:31:40,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:40,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:40,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:40,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:40,952 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:40,996 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:41,077 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ig8zsdb', purging
2023-05-27 06:31:41,077 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-70fd6z9_', purging
2023-05-27 06:31:41,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:41,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:41,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:41,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:41,654 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:41,718 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xpp1dzur', purging
2023-05-27 06:31:41,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:41,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:41,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:41,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:41,985 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:42,557 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1sy21quw', purging
2023-05-27 06:31:42,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:42,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:42,586 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kmfmyr9t', purging
2023-05-27 06:31:42,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:42,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:42,606 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:42,691 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:43,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lbrfq71k', purging
2023-05-27 06:31:43,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:43,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:43,291 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:43,316 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:43,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-23ta9o11', purging
2023-05-27 06:31:43,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ut3ax605', purging
2023-05-27 06:31:43,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:43,577 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:43,705 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:44,074 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:44,214 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0r9l803m', purging
2023-05-27 06:31:44,214 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z66vd43h', purging
2023-05-27 06:31:44,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:44,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:44,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:44,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:44,853 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:44,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6tkyuhdz', purging
2023-05-27 06:31:44,949 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:44,949 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:44,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:44,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:45,004 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:45,312 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ko9xb4og', purging
2023-05-27 06:31:45,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:45,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:45,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:45,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:45,824 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:45,838 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:46,149 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:46,292 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:46,371 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-68txior5', purging
2023-05-27 06:31:46,371 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufvd9sox', purging
2023-05-27 06:31:46,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-30_cxuwt', purging
2023-05-27 06:31:46,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xn57wt00', purging
2023-05-27 06:31:46,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:46,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:46,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:46,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:47,201 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:47,352 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:47,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kic8f341', purging
2023-05-27 06:31:47,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rqsgwf77', purging
2023-05-27 06:31:47,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:47,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:47,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:47,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:47,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:47,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:47,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:47,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:48,056 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:48,313 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:48,654 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:48,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-em8fhpqe', purging
2023-05-27 06:31:48,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qanp5_2k', purging
2023-05-27 06:31:48,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kg2st5b_', purging
2023-05-27 06:31:48,732 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c3z6wqvd', purging
2023-05-27 06:31:48,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:48,756 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:48,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:48,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:49,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:49,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:49,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:49,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:50,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:50,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:50,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:50,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:52,712 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:52,751 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:52,949 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:53,000 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:53,023 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:53,059 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:54,378 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v1t4o387', purging
2023-05-27 06:31:54,378 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iwf04qi1', purging
2023-05-27 06:31:54,379 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j0o5oq1i', purging
2023-05-27 06:31:54,379 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3khtfwx3', purging
2023-05-27 06:31:54,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ulee6jf7', purging
2023-05-27 06:31:54,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jj20b8v1', purging
2023-05-27 06:31:54,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:54,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:54,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:54,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:54,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:54,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:54,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:54,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:54,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:54,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:54,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:54,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:31:57,765 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:57,820 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:57,853 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:57,898 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:57,923 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:57,977 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:31:59,467 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s_dam61s', purging
2023-05-27 06:31:59,467 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fpev4b__', purging
2023-05-27 06:31:59,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iyn92q74', purging
2023-05-27 06:31:59,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q5y5me66', purging
2023-05-27 06:31:59,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x31iuhrt', purging
2023-05-27 06:31:59,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z0p98vin', purging
2023-05-27 06:31:59,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:59,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:59,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:59,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:59,522 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:59,522 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:59,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:59,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:59,568 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:59,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:31:59,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:31:59,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:02,081 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:02,152 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:02,259 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:03,389 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:03,425 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:03,453 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:03,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7juzvttg', purging
2023-05-27 06:32:03,684 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1w6pkqr', purging
2023-05-27 06:32:03,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cg273fmy', purging
2023-05-27 06:32:03,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y5ojwenc', purging
2023-05-27 06:32:03,685 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0mt158gy', purging
2023-05-27 06:32:03,686 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gx9mh2kz', purging
2023-05-27 06:32:03,686 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:03,686 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:03,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:03,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:03,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:03,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:05,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:05,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:05,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:05,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:05,411 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:05,477 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:05,551 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:07,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wrt5w_m', purging
2023-05-27 06:32:07,062 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uuntkhvk', purging
2023-05-27 06:32:07,062 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5z5qovhu', purging
2023-05-27 06:32:07,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:07,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:07,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:07,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:07,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:07,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:07,753 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:07,797 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:07,858 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:09,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zw6ouslj', purging
2023-05-27 06:32:09,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0qv6s3cc', purging
2023-05-27 06:32:09,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-luaeqm1b', purging
2023-05-27 06:32:09,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:09,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:09,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:09,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:09,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:09,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:09,883 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:09,900 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:10,282 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:11,141 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:11,359 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:11,361 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:11,526 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d2l9nom8', purging
2023-05-27 06:32:11,526 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1oxq4y14', purging
2023-05-27 06:32:11,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgi7ljb4', purging
2023-05-27 06:32:11,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_p5zizl9', purging
2023-05-27 06:32:11,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-etgx782l', purging
2023-05-27 06:32:11,528 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-142vpnsm', purging
2023-05-27 06:32:11,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:11,528 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:11,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:11,529 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:11,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:11,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:12,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:12,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:12,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:12,996 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:12,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:12,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:14,449 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:14,931 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:15,570 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:15,663 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:15,919 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:15,951 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:16,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ucw0ktl', purging
2023-05-27 06:32:16,105 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-85ngtyur', purging
2023-05-27 06:32:16,105 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dzapntin', purging
2023-05-27 06:32:16,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yz3q339v', purging
2023-05-27 06:32:16,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vd3ibk1p', purging
2023-05-27 06:32:16,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uum13nsb', purging
2023-05-27 06:32:16,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:16,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:16,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:16,561 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:17,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:17,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:17,295 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:17,295 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:17,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:17,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:17,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:17,546 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:19,696 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:19,958 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:20,393 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:20,467 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:20,496 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:20,564 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:21,326 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2ytzd00', purging
2023-05-27 06:32:21,327 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ckvq_d4g', purging
2023-05-27 06:32:21,327 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hr199qc3', purging
2023-05-27 06:32:21,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yjl4ni6b', purging
2023-05-27 06:32:21,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f3_9c82f', purging
2023-05-27 06:32:21,328 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xw5ayt0l', purging
2023-05-27 06:32:21,329 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:21,329 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:21,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:21,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:22,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:22,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:22,139 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:22,139 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:22,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:22,151 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:22,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:22,248 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:24,107 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:24,151 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:24,721 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:24,755 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:25,571 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:25,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wfiz093p', purging
2023-05-27 06:32:25,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dvkatoyq', purging
2023-05-27 06:32:25,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ynbs2w6v', purging
2023-05-27 06:32:25,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1j2rqm7m', purging
2023-05-27 06:32:25,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yf84l9ce', purging
2023-05-27 06:32:25,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-apj1dcqq', purging
2023-05-27 06:32:25,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:25,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:25,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:25,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:25,999 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:26,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:26,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:26,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:26,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:27,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:27,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:27,543 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p1y9_mix', purging
2023-05-27 06:32:27,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:27,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 06:32:27,790 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:28,813 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:28,857 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:29,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lv765_sw', purging
2023-05-27 06:32:29,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5dtrzttm', purging
2023-05-27 06:32:29,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nuuugfvx', purging
2023-05-27 06:32:29,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:29,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:29,658 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:30,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5hfgzppv', purging
2023-05-27 06:32:30,404 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-knikgyzd', purging
2023-05-27 06:32:30,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:30,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:30,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:30,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:30,457 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:31,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:31,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:31,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:31,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:32,172 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:32,719 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:32,770 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:33,383 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:33,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0lue0x47', purging
2023-05-27 06:32:33,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-enwpylh8', purging
2023-05-27 06:32:33,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ho16_lsa', purging
2023-05-27 06:32:33,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hxe_affi', purging
2023-05-27 06:32:33,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:33,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:34,295 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:34,354 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6bckrbf_', purging
2023-05-27 06:32:34,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:34,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:34,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:34,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:34,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:34,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:35,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:35,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:36,870 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:37,058 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:37,207 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:37,522 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:38,557 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v9gj2vu0', purging
2023-05-27 06:32:38,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wi0cop5j', purging
2023-05-27 06:32:38,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mct51qe0', purging
2023-05-27 06:32:38,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_gm32cpg', purging
2023-05-27 06:32:38,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-97zfym11', purging
2023-05-27 06:32:38,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:38,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:38,601 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:38,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:38,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:38,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:38,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:39,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:39,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:40,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:40,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:41,414 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:41,454 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:41,502 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:42,499 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:42,834 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:43,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ci62b67', purging
2023-05-27 06:32:43,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vx5c85xn', purging
2023-05-27 06:32:43,049 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ydjj3g1n', purging
2023-05-27 06:32:43,049 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufqm3l8b', purging
2023-05-27 06:32:43,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9d9ot5rw', purging
2023-05-27 06:32:43,050 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:43,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:43,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:43,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:43,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:43,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:44,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:44,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:44,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:44,546 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:45,257 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:45,294 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:45,325 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:45,857 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:46,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ap2dy07', purging
2023-05-27 06:32:46,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ga0xblq', purging
2023-05-27 06:32:46,785 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ccj9j0wm', purging
2023-05-27 06:32:46,785 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6k6akjgp', purging
2023-05-27 06:32:46,786 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:46,786 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:46,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:46,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:46,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:46,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:47,240 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:47,416 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wmjlri3u', purging
2023-05-27 06:32:47,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:47,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:48,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:48,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:49,101 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:49,124 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:49,205 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:50,022 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:50,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-37km5g3p', purging
2023-05-27 06:32:50,659 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xzknbwhg', purging
2023-05-27 06:32:50,659 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7037nehd', purging
2023-05-27 06:32:50,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_2hgblrl', purging
2023-05-27 06:32:50,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:50,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:50,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:50,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:50,841 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:50,841 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:51,531 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:51,659 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j_ehwok7', purging
2023-05-27 06:32:51,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:51,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:53,093 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:53,093 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:53,294 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:53,345 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:53,447 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:54,083 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:54,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ozldqxqz', purging
2023-05-27 06:32:54,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-853bk4u8', purging
2023-05-27 06:32:54,925 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4wukfjb2', purging
2023-05-27 06:32:54,926 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_2ch08re', purging
2023-05-27 06:32:54,926 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:54,926 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:55,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:55,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:55,039 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:55,039 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:55,375 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:55,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jh63k8n4', purging
2023-05-27 06:32:55,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:55,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:56,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:56,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:57,411 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:57,753 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:57,783 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:59,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pcjy3m1x', purging
2023-05-27 06:32:59,053 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a9mj1psx', purging
2023-05-27 06:32:59,054 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tspzx9f5', purging
2023-05-27 06:32:59,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:59,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:32:59,430 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_b82xtci', purging
2023-05-27 06:32:59,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:59,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:59,436 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:32:59,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:32:59,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:32:59,589 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:01,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-czt7lw8v', purging
2023-05-27 06:33:01,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:01,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:01,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_old0a_', purging
2023-05-27 06:33:01,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:01,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:01,474 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:01,894 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:03,129 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1on4jvst', purging
2023-05-27 06:33:03,130 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-17kg_xmg', purging
2023-05-27 06:33:03,130 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:03,130 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:03,156 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:03,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:03,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:03,791 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:03,880 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:04,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-991alge7', purging
2023-05-27 06:33:04,834 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lthytcob', purging
2023-05-27 06:33:04,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:04,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:05,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:05,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:05,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:05,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:05,591 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:05,759 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:07,126 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rg0lw1x1', purging
2023-05-27 06:33:07,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wbc5hvx0', purging
2023-05-27 06:33:07,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:07,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:07,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:07,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:07,566 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:07,709 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:08,089 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:09,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jsjbaujh', purging
2023-05-27 06:33:09,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-068klsu8', purging
2023-05-27 06:33:09,060 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jc2v07_6', purging
2023-05-27 06:33:09,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:09,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:09,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:09,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:09,797 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:09,797 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:09,920 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:09,943 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:11,467 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qv10r0_4', purging
2023-05-27 06:33:11,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zohn5emr', purging
2023-05-27 06:33:11,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m212mgq9', purging
2023-05-27 06:33:11,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:11,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:11,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:11,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:11,796 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:11,910 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 06:33:13,264 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qaqjpd70', purging
2023-05-27 06:33:13,264 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_dwqk6f', purging
2023-05-27 06:33:13,265 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:13,265 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:13,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:13,419 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:14,183 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:14,496 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:15,675 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:15,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gr2b_y09', purging
2023-05-27 06:33:15,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p7t137t8', purging
2023-05-27 06:33:15,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kfnban44', purging
2023-05-27 06:33:15,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:15,709 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:15,813 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:16,157 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5na8oez', purging
2023-05-27 06:33:16,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:16,158 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:17,309 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:17,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:17,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:17,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:17,943 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:19,046 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:19,453 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9maaiidp', purging
2023-05-27 06:33:19,454 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qh9axeiz', purging
2023-05-27 06:33:19,454 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:19,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:19,867 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:19,922 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:20,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ub9e8bc4', purging
2023-05-27 06:33:20,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_wamewge', purging
2023-05-27 06:33:20,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:20,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:21,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:21,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:21,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:21,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:21,622 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:23,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2b4_5gdk', purging
2023-05-27 06:33:23,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:23,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:23,450 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:23,858 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:23,940 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:24,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-arxlc9v8', purging
2023-05-27 06:33:24,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5rih00z6', purging
2023-05-27 06:33:24,983 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lcse6210', purging
2023-05-27 06:33:24,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:24,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:25,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:25,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:25,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:25,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:25,643 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:27,033 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:27,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3gqrit0n', purging
2023-05-27 06:33:27,283 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58lc_1y7', purging
2023-05-27 06:33:27,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:27,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:27,908 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:27,910 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:28,593 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ldrpdfw_', purging
2023-05-27 06:33:28,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m1_jxfxt', purging
2023-05-27 06:33:28,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:28,594 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:29,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wd5rm0ed', purging
2023-05-27 06:33:29,535 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:29,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:29,553 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:29,592 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:29,592 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:31,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s_eyfkw1', purging
2023-05-27 06:33:31,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:31,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:31,154 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:31,581 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:31,714 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:32,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oyhou1sy', purging
2023-05-27 06:33:32,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8vi4g_nx', purging
2023-05-27 06:33:32,727 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:32,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:33,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:33,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:33,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-73t08xfi', purging
2023-05-27 06:33:33,353 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:33,353 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:33,480 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:35,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:35,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:35,432 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:35,618 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:35,720 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:37,045 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p3b6q771', purging
2023-05-27 06:33:37,045 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ksifp7cm', purging
2023-05-27 06:33:37,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dk90dfkj', purging
2023-05-27 06:33:37,046 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2wf_qs1', purging
2023-05-27 06:33:37,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:37,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:37,067 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:37,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:37,173 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:37,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:37,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:38,677 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:38,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:39,603 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:39,634 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:39,759 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:41,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g91lh7cy', purging
2023-05-27 06:33:41,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2a8yiyjb', purging
2023-05-27 06:33:41,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mc7ue39k', purging
2023-05-27 06:33:41,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:41,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:41,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:41,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:41,316 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:41,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6uxf_ogj', purging
2023-05-27 06:33:41,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:41,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:43,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:43,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:43,584 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:43,698 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:43,762 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:45,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vb4eb86f', purging
2023-05-27 06:33:45,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xx8sye8k', purging
2023-05-27 06:33:45,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6frm1tc3', purging
2023-05-27 06:33:45,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:45,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:45,390 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:45,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:45,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ffz6egnr', purging
2023-05-27 06:33:45,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:45,404 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:45,404 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:47,010 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:47,010 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:47,562 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:47,649 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:48,663 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:49,135 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fsm51jj2', purging
2023-05-27 06:33:49,136 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0n9mdwzg', purging
2023-05-27 06:33:49,136 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vz6osdgc', purging
2023-05-27 06:33:49,137 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:49,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:49,250 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:49,250 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:49,354 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:50,322 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2h580y0_', purging
2023-05-27 06:33:50,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:50,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:50,678 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:50,778 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:50,918 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j7995bje', purging
2023-05-27 06:33:50,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p_6z66qd', purging
2023-05-27 06:33:50,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:50,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:52,329 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:52,329 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:52,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:52,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:52,682 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:53,321 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:54,230 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lkt_494l', purging
2023-05-27 06:33:54,230 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tn0hr2lp', purging
2023-05-27 06:33:54,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:54,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:54,875 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:54,949 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:55,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b__gzc8i', purging
2023-05-27 06:33:55,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hmpn_7u6', purging
2023-05-27 06:33:55,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:55,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:56,376 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:56,444 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-14cgwwp1', purging
2023-05-27 06:33:56,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:56,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:56,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:56,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:56,848 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:58,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y15_brqb', purging
2023-05-27 06:33:58,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:58,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:33:58,366 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sb_2ompg', purging
2023-05-27 06:33:58,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:58,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:33:58,392 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:58,527 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:33:59,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ga82f2v9', purging
2023-05-27 06:33:59,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:33:59,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:00,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:00,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:00,316 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:00,422 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:01,893 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:02,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-70z0zlmy', purging
2023-05-27 06:34:02,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cd53xg24', purging
2023-05-27 06:34:02,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1l8iouxi', purging
2023-05-27 06:34:02,022 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iq2bs2t_', purging
2023-05-27 06:34:02,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:02,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:02,045 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:02,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:02,086 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:03,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:03,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:03,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:03,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:04,021 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:04,129 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:05,464 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:05,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ajj0wp5y', purging
2023-05-27 06:34:05,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-me1p6m1c', purging
2023-05-27 06:34:05,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psommv2g', purging
2023-05-27 06:34:05,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j18rcyha', purging
2023-05-27 06:34:05,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:05,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:05,570 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:05,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:05,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:07,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:07,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:07,169 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:07,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:07,682 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:07,903 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:09,141 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fgnu14up', purging
2023-05-27 06:34:09,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iz4r9qxd', purging
2023-05-27 06:34:09,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:09,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:09,479 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:09,501 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b1t0hzw9', purging
2023-05-27 06:34:09,501 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cq9uy01o', purging
2023-05-27 06:34:09,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:09,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:09,545 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:11,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:11,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:11,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8i0ei6jw', purging
2023-05-27 06:34:11,151 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:11,151 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:11,170 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:11,400 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:12,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j6q05ppw', purging
2023-05-27 06:34:12,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:12,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:13,014 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ig_io7t', purging
2023-05-27 06:34:13,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:13,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:13,042 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:13,150 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:14,673 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:14,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y3bl419k', purging
2023-05-27 06:34:14,699 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6l8p9eo4', purging
2023-05-27 06:34:14,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:14,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:14,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:14,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:14,955 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:16,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m0kbdz3o', purging
2023-05-27 06:34:16,226 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:16,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:16,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:16,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:16,723 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:16,779 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:18,360 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:18,370 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3smh38cg', purging
2023-05-27 06:34:18,370 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d7se8lpq', purging
2023-05-27 06:34:18,371 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-atim93bl', purging
2023-05-27 06:34:18,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:18,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:18,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-02xpxuan', purging
2023-05-27 06:34:18,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:18,438 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:18,511 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:20,000 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:20,000 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:20,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:20,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:20,271 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:20,513 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:21,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-prv8fqg0', purging
2023-05-27 06:34:21,899 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ewsjiwzb', purging
2023-05-27 06:34:21,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:21,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:22,042 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:22,042 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:22,099 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:22,552 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:23,682 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ydbtrj_i', purging
2023-05-27 06:34:23,683 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q_h8a4aa', purging
2023-05-27 06:34:23,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:23,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:23,895 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:24,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g7z7bk5d', purging
2023-05-27 06:34:24,206 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gbiregp5', purging
2023-05-27 06:34:24,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:24,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:24,214 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:25,443 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2xh_9ufk', purging
2023-05-27 06:34:25,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:25,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:25,487 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:25,856 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:25,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-20l35ceb', purging
2023-05-27 06:34:25,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:25,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:27,085 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m5_4y5ur', purging
2023-05-27 06:34:27,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:27,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-27 06:34:27,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:27,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:27,929 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:29,300 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:29,336 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:29,463 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mvq37cwx', purging
2023-05-27 06:34:29,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f67bxiei', purging
2023-05-27 06:34:29,464 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gpi1gel0', purging
2023-05-27 06:34:29,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:29,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:30,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:30,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:30,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:30,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:31,064 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:32,518 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:32,632 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wiir5_a', purging
2023-05-27 06:34:32,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9llqqd_o', purging
2023-05-27 06:34:32,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-whbvr9fs', purging
2023-05-27 06:34:32,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:32,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:32,773 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:34,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:34,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:34,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:34,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:34,371 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:35,276 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:35,643 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:35,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__nn7jlk', purging
2023-05-27 06:34:35,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dec57lts', purging
2023-05-27 06:34:35,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lnhkjz7k', purging
2023-05-27 06:34:35,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:35,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:36,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:36,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:37,120 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:37,120 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:37,486 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:38,800 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:38,948 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:39,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9j3ll_cb', purging
2023-05-27 06:34:39,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zfn94830', purging
2023-05-27 06:34:39,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qgugg3gu', purging
2023-05-27 06:34:39,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:39,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:40,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:40,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:40,516 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:40,539 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k9ao9rdv', purging
2023-05-27 06:34:40,540 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:40,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:41,846 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:42,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-riy7oes3', purging
2023-05-27 06:34:42,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:42,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:42,474 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:43,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ey8_2uj7', purging
2023-05-27 06:34:43,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:43,465 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:43,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a8odt1ic', purging
2023-05-27 06:34:43,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:43,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:44,096 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:45,103 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:45,654 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:45,765 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wqvdzroz', purging
2023-05-27 06:34:45,765 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1112nyz3', purging
2023-05-27 06:34:45,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:45,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:46,727 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:46,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:47,192 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:47,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y1lasipy', purging
2023-05-27 06:34:47,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:47,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:48,262 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:48,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-em0rcrx8', purging
2023-05-27 06:34:48,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:48,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:49,336 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:49,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aqza6qzf', purging
2023-05-27 06:34:49,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:49,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:50,521 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:50,968 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a520wh3d', purging
2023-05-27 06:34:50,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:50,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:51,258 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:52,137 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7357bc0a', purging
2023-05-27 06:34:52,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:52,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:52,569 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:52,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vzz99xjd', purging
2023-05-27 06:34:52,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:52,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:53,995 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:54,204 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2jrvyq5a', purging
2023-05-27 06:34:54,205 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:54,205 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:54,541 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:55,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-djikfafn', purging
2023-05-27 06:34:55,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:55,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:56,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:56,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:56,161 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:57,688 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:57,794 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fmw4g3_u', purging
2023-05-27 06:34:57,795 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h1f07l74', purging
2023-05-27 06:34:57,795 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hjdf0fb8', purging
2023-05-27 06:34:57,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:57,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:57,839 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:34:59,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:59,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:34:59,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:34:59,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:34:59,592 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:01,129 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:01,192 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:01,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_ahhm19k', purging
2023-05-27 06:35:01,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i6r3p8a0', purging
2023-05-27 06:35:01,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ov_uwjm9', purging
2023-05-27 06:35:01,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:01,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:02,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:02,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:02,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:02,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:02,925 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:04,481 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:04,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xy18k6hz', purging
2023-05-27 06:35:04,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-836fs2am', purging
2023-05-27 06:35:04,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-as38olul', purging
2023-05-27 06:35:04,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:04,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:04,732 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:06,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:06,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:06,252 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:06,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t7nit0gy', purging
2023-05-27 06:35:06,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:06,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:07,410 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:07,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uu1eb44n', purging
2023-05-27 06:35:07,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:07,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:08,062 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:08,916 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rlf53hf7', purging
2023-05-27 06:35:08,916 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:08,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:09,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:09,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:09,641 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:10,537 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:11,301 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yvg7okq4', purging
2023-05-27 06:35:11,301 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s9krkzmu', purging
2023-05-27 06:35:11,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:11,302 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:11,390 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:12,064 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v9p2f103', purging
2023-05-27 06:35:12,065 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:12,065 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:13,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ppebv1d9', purging
2023-05-27 06:35:13,039 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:13,039 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:13,178 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:13,705 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:14,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-egpnctc7', purging
2023-05-27 06:35:14,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:14,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:14,984 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:15,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h1xkw3jk', purging
2023-05-27 06:35:15,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:15,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:16,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gcm1pa1m', purging
2023-05-27 06:35:16,518 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:16,518 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:16,696 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:17,283 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:18,142 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:18,324 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-36o5f4sf', purging
2023-05-27 06:35:18,324 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tic2wrl4', purging
2023-05-27 06:35:18,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:18,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:18,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:18,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:19,594 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:19,722 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xh7ob3eq', purging
2023-05-27 06:35:19,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:19,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:20,436 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:21,125 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:21,273 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1r3mu133', purging
2023-05-27 06:35:21,273 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9bmmk66f', purging
2023-05-27 06:35:21,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:21,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:22,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:22,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:22,654 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:22,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mxxkqlh1', purging
2023-05-27 06:35:22,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:22,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:23,471 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:24,115 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:24,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vrh691t3', purging
2023-05-27 06:35:24,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-91ptfi99', purging
2023-05-27 06:35:24,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:24,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:25,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:25,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:25,655 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:25,689 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p36kt_dg', purging
2023-05-27 06:35:25,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:25,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:26,635 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:27,209 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bjdr_akg', purging
2023-05-27 06:35:27,210 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sjz72hal', purging
2023-05-27 06:35:27,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:27,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:27,330 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:28,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:28,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:28,628 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:28,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e7dtwy25', purging
2023-05-27 06:35:28,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:28,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:29,292 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:30,199 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j39wlc1i', purging
2023-05-27 06:35:30,199 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fe04p809', purging
2023-05-27 06:35:30,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:30,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:30,380 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:30,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:30,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:31,876 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:31,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vinq4njk', purging
2023-05-27 06:35:31,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:31,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:32,287 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:33,457 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sczmb5fn', purging
2023-05-27 06:35:33,457 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h07qkh53', purging
2023-05-27 06:35:33,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:33,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:33,471 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:33,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:33,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:34,448 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:35,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ah3sh0vn', purging
2023-05-27 06:35:35,026 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:35,026 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:35,330 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:36,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eyj1tgkr', purging
2023-05-27 06:35:36,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:36,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:36,536 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:36,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-89u3c2vm', purging
2023-05-27 06:35:36,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:36,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:37,641 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:38,055 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nur8rsv3', purging
2023-05-27 06:35:38,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:38,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:38,300 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:39,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-esy6kcgy', purging
2023-05-27 06:35:39,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:39,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:39,487 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:39,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fx581ekv', purging
2023-05-27 06:35:39,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:39,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:40,737 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:41,080 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-43dysbld', purging
2023-05-27 06:35:41,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:41,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:41,343 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:42,254 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qjgtbg_a', purging
2023-05-27 06:35:42,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:42,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:42,504 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:42,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qlub7hmk', purging
2023-05-27 06:35:42,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:42,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:43,531 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:44,075 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cqvbzog', purging
2023-05-27 06:35:44,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:44,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:44,344 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:45,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8fyl0zwu', purging
2023-05-27 06:35:45,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tf8t5jjw', purging
2023-05-27 06:35:45,125 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:45,125 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:45,266 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:46,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:46,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:46,566 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:46,840 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1dh27hdg', purging
2023-05-27 06:35:46,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:46,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:47,591 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:48,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q4ejdv0q', purging
2023-05-27 06:35:48,128 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l9gnkuch', purging
2023-05-27 06:35:48,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:48,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:48,192 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:49,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:49,205 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:49,519 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:49,806 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7d075v0n', purging
2023-05-27 06:35:49,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:49,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:50,384 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:51,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nw_a_01f', purging
2023-05-27 06:35:51,021 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l8n5hq7p', purging
2023-05-27 06:35:51,022 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:51,022 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:51,159 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:51,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:51,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:52,699 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:52,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zuzyj9ee', purging
2023-05-27 06:35:52,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:52,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:53,408 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:54,155 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5pdxeen3', purging
2023-05-27 06:35:54,155 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:54,156 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:54,224 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:55,012 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j1pb6uov', purging
2023-05-27 06:35:55,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:55,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:55,217 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:55,757 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xtnp5vr5', purging
2023-05-27 06:35:55,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:55,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:56,660 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:56,822 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4vzyd6ue', purging
2023-05-27 06:35:56,823 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:56,823 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:35:57,229 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:58,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hhzk2ifo', purging
2023-05-27 06:35:58,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:58,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:58,335 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:58,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-prlsk7xt', purging
2023-05-27 06:35:58,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:58,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:59,452 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:35:59,887 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:35:59,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5f3r7mvj', purging
2023-05-27 06:35:59,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-403ub42t', purging
2023-05-27 06:35:59,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:35:59,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:01,050 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:01,050 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:01,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:01,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:01,734 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:02,593 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:02,868 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:03,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qlptutqu', purging
2023-05-27 06:36:03,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v86feyd8', purging
2023-05-27 06:36:03,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5llzet2p', purging
2023-05-27 06:36:03,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:03,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:04,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:04,233 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:04,329 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:04,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eq0ca1gr', purging
2023-05-27 06:36:04,392 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:04,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:05,723 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:05,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fc4nij5n', purging
2023-05-27 06:36:05,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:05,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:06,317 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:07,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zv3gfuhs', purging
2023-05-27 06:36:07,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tq74gb1k', purging
2023-05-27 06:36:07,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:07,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:07,340 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:07,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:07,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:08,086 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:08,887 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8lbyogzr', purging
2023-05-27 06:36:08,887 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bwx8ynvc', purging
2023-05-27 06:36:08,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:08,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:08,911 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:09,678 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:09,678 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:10,414 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:10,483 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-td3_03_v', purging
2023-05-27 06:36:10,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:10,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:11,513 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:11,926 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:11,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uhrhvewd', purging
2023-05-27 06:36:11,985 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5rv8ajf6', purging
2023-05-27 06:36:11,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:11,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:13,155 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bppz59em', purging
2023-05-27 06:36:13,155 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:13,155 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:13,193 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:13,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:13,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:14,398 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:14,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lz7xr11v', purging
2023-05-27 06:36:14,733 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zing0tf1', purging
2023-05-27 06:36:14,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:14,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:14,750 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:15,936 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:15,981 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vw33glwx', purging
2023-05-27 06:36:15,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:15,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:16,348 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:16,348 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:17,381 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:17,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rk9ump2w', purging
2023-05-27 06:36:17,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:17,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:17,713 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:18,840 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:19,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z0wdfvoi', purging
2023-05-27 06:36:19,039 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uq_fsusy', purging
2023-05-27 06:36:19,040 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:19,040 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:19,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:19,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:20,105 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:20,386 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bm2zn59r', purging
2023-05-27 06:36:20,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:20,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:20,671 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:21,711 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7id916nt', purging
2023-05-27 06:36:21,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:21,712 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:21,847 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:22,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v4frq2lg', purging
2023-05-27 06:36:22,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:22,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:23,055 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:23,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hdxjux8h', purging
2023-05-27 06:36:23,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:23,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:23,640 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:24,692 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqntsbhm', purging
2023-05-27 06:36:24,693 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:24,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:24,756 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:25,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5fui486z', purging
2023-05-27 06:36:25,188 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:25,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:25,753 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:26,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kwfl8zhg', purging
2023-05-27 06:36:26,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:26,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:26,577 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:27,298 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_cc2ldoe', purging
2023-05-27 06:36:27,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:27,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:27,966 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:28,149 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kuegf06y', purging
2023-05-27 06:36:28,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:28,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:28,616 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:29,497 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:29,619 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3gv8ccfs', purging
2023-05-27 06:36:29,619 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7z68assk', purging
2023-05-27 06:36:29,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:29,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:30,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:30,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:30,960 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:31,131 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q96et16t', purging
2023-05-27 06:36:31,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:31,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:31,577 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:32,412 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:32,593 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w3jsyw9h', purging
2023-05-27 06:36:32,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qoysupcw', purging
2023-05-27 06:36:32,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:32,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:33,169 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:33,169 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:33,895 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:34,080 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9mxe2dao', purging
2023-05-27 06:36:34,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:34,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:34,425 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:35,426 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:35,551 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0dyrpga', purging
2023-05-27 06:36:35,552 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_q_u0kc_', purging
2023-05-27 06:36:35,553 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:35,553 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:36,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:36,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:36,776 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:37,042 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-euja4kk5', purging
2023-05-27 06:36:37,043 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o93a3tl8', purging
2023-05-27 06:36:37,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:37,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:37,340 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:38,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kcthd8s9', purging
2023-05-27 06:36:38,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:38,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:38,554 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:38,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:38,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:39,732 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:40,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7honkirv', purging
2023-05-27 06:36:40,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:40,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:40,321 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:41,239 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_jcln4j9', purging
2023-05-27 06:36:41,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:41,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:41,514 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:41,928 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a3nv29ep', purging
2023-05-27 06:36:41,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:41,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:42,478 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:43,077 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:43,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ts_m5dms', purging
2023-05-27 06:36:43,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4jeg_yym', purging
2023-05-27 06:36:43,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:43,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:43,982 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:43,982 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:44,483 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:44,703 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y58kwotd', purging
2023-05-27 06:36:44,704 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:44,704 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:45,420 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:46,062 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pjtv78gy', purging
2023-05-27 06:36:46,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:46,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:46,209 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:46,937 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cw788_d8', purging
2023-05-27 06:36:46,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:46,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:47,356 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:47,848 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fvkp2mzp', purging
2023-05-27 06:36:47,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:47,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:48,288 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:48,903 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j_mryegc', purging
2023-05-27 06:36:48,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:48,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:49,197 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:49,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tae2xuuw', purging
2023-05-27 06:36:49,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:49,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:50,281 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:50,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7emlonq3', purging
2023-05-27 06:36:50,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:50,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:51,220 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:51,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hj6ie8c_', purging
2023-05-27 06:36:51,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:51,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:52,056 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:52,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dxb1mkcj', purging
2023-05-27 06:36:52,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:52,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:52,966 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:53,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x7y57w8g', purging
2023-05-27 06:36:53,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:53,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:54,413 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:54,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iq8el2zz', purging
2023-05-27 06:36:54,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:54,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:55,092 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:55,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:56,040 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ksbvn6v7', purging
2023-05-27 06:36:56,041 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mpk_nrfk', purging
2023-05-27 06:36:56,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:56,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:56,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:56,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:57,372 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:57,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lvuhy2gi', purging
2023-05-27 06:36:57,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:57,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:58,049 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:36:58,920 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:36:58,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ohsfdm6', purging
2023-05-27 06:36:58,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i6lvwhsh', purging
2023-05-27 06:36:58,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:58,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:36:59,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:36:59,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:00,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:00,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:00,582 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:00,985 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:01,837 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:02,030 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h1vg3loa', purging
2023-05-27 06:37:02,030 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1lzkwo30', purging
2023-05-27 06:37:02,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ug9db1v', purging
2023-05-27 06:37:02,031 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:02,031 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:02,570 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:02,654 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-30_bphij', purging
2023-05-27 06:37:02,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:02,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:03,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:03,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:04,116 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:04,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_434cci', purging
2023-05-27 06:37:04,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:04,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:04,685 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:05,199 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:05,659 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pi_ydjl3', purging
2023-05-27 06:37:05,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dozfyfu2', purging
2023-05-27 06:37:05,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:05,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:06,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:06,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:06,387 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:06,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qpa9u8bi', purging
2023-05-27 06:37:06,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:06,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:07,054 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:07,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qzn05q7o', purging
2023-05-27 06:37:07,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3gybl0n7', purging
2023-05-27 06:37:07,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:07,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:08,053 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:08,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:08,668 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:09,261 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:09,554 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:09,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_kpw5jh', purging
2023-05-27 06:37:09,660 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eg7hflgs', purging
2023-05-27 06:37:09,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:09,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:10,489 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:10,904 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d9k_6ugi', purging
2023-05-27 06:37:10,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:10,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:11,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:11,182 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:12,025 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:12,121 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i4fo49ra', purging
2023-05-27 06:37:12,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:12,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:12,426 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:13,206 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:13,665 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0i3n1fch', purging
2023-05-27 06:37:13,666 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uyewj7o_', purging
2023-05-27 06:37:13,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:13,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:13,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:13,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:14,667 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:14,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dfdugp38', purging
2023-05-27 06:37:14,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:14,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:15,055 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:15,834 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:16,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mdutwlgl', purging
2023-05-27 06:37:16,392 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-urvni2jo', purging
2023-05-27 06:37:16,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:16,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:16,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:16,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:17,390 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:17,451 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hq23dird', purging
2023-05-27 06:37:17,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:17,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:17,675 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:18,747 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:18,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rma1163h', purging
2023-05-27 06:37:18,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_bhxmydi', purging
2023-05-27 06:37:18,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:18,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:19,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:19,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:20,008 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:20,275 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:20,344 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xrit2i6z', purging
2023-05-27 06:37:20,344 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a07rmg1f', purging
2023-05-27 06:37:20,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:20,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:21,282 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:21,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8c3r_al3', purging
2023-05-27 06:37:21,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:21,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:21,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:21,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:22,871 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bkcdfoo2', purging
2023-05-27 06:37:22,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:22,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:22,899 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:23,249 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:23,698 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:24,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-spg0z6hq', purging
2023-05-27 06:37:24,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1kp06fzi', purging
2023-05-27 06:37:24,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:24,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:24,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:24,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:25,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:25,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:25,995 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:26,523 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:26,571 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:27,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yccg0ysj', purging
2023-05-27 06:37:27,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6pnxb4re', purging
2023-05-27 06:37:27,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w5umkja3', purging
2023-05-27 06:37:27,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:27,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:28,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:28,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:28,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:28,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:28,258 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:29,798 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:29,810 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k_ug3oc7', purging
2023-05-27 06:37:29,810 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7qb7as9q', purging
2023-05-27 06:37:29,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:29,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:29,871 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:30,819 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:31,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2foebsoz', purging
2023-05-27 06:37:31,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4u8n8dcv', purging
2023-05-27 06:37:31,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:31,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:31,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:31,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:32,182 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:32,212 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:32,378 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w4a93h0q', purging
2023-05-27 06:37:32,379 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nrthjtez', purging
2023-05-27 06:37:32,379 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:32,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:33,508 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:33,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b3o3p7gd', purging
2023-05-27 06:37:33,696 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:33,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:33,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:33,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:34,681 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:34,777 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:35,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cxm3ww0v', purging
2023-05-27 06:37:35,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nvpm1j1u', purging
2023-05-27 06:37:35,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:35,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:36,209 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:36,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3b2pw1ig', purging
2023-05-27 06:37:36,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:36,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:36,330 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:36,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:37,462 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:37,486 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:37,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n3zqaegg', purging
2023-05-27 06:37:37,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x9j4lmjy', purging
2023-05-27 06:37:37,696 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:37,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:38,862 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:38,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-37b2q0q7', purging
2023-05-27 06:37:38,960 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:38,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:39,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:39,099 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:40,405 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:40,416 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xpwli50n', purging
2023-05-27 06:37:40,416 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kna7871s', purging
2023-05-27 06:37:40,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:40,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:41,482 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:41,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-26rrlia_', purging
2023-05-27 06:37:41,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:41,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:42,822 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:43,056 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gapf18xm', purging
2023-05-27 06:37:43,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:43,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:43,598 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:44,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-djem607l', purging
2023-05-27 06:37:44,390 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:44,390 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:45,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:45,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:45,273 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:46,154 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:46,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-85m7etct', purging
2023-05-27 06:37:46,765 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xridio6k', purging
2023-05-27 06:37:46,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:46,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:47,407 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:47,758 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_qxe4752', purging
2023-05-27 06:37:47,759 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:47,759 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:48,437 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:48,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zoft0io2', purging
2023-05-27 06:37:48,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:48,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:50,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:50,015 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:50,117 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:50,985 - distributed.nanny - WARNING - Restarting worker
2023-05-27 06:37:51,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-64kfb039', purging
2023-05-27 06:37:51,595 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9hnjirbu', purging
2023-05-27 06:37:51,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:51,596 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-27 06:37:52,532 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-76to3iwy', purging
2023-05-27 06:37:52,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-27 06:37:52,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-27 06:37:52,550 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 825 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
