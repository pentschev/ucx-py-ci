============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.3, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-11-03 05:25:26,727 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:25:26,732 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43977 instead
  warnings.warn(
2023-11-03 05:25:26,735 - distributed.scheduler - INFO - State start
2023-11-03 05:25:26,835 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:25:26,836 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-11-03 05:25:26,837 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43977/status
2023-11-03 05:25:26,837 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-03 05:25:27,029 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33695'
2023-11-03 05:25:27,047 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41777'
2023-11-03 05:25:27,049 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42431'
2023-11-03 05:25:27,057 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35439'
2023-11-03 05:25:28,609 - distributed.scheduler - INFO - Receive client connection: Client-644228ad-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:25:28,620 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48374
2023-11-03 05:25:28,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:28,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:28,793 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-11-03 05:25:28,808 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44297
2023-11-03 05:25:28,808 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44297
2023-11-03 05:25:28,808 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45455
2023-11-03 05:25:28,808 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-03 05:25:28,808 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:28,809 - distributed.worker - INFO -               Threads:                          4
2023-11-03 05:25:28,809 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-03 05:25:28,809 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-hakow10v
2023-11-03 05:25:28,809 - distributed.worker - INFO - Starting Worker plugin RMMSetup-adc3caa4-ecc0-43e9-896c-845e6ffb8ac8
2023-11-03 05:25:28,809 - distributed.worker - INFO - Starting Worker plugin PreImport-f0386bda-694c-4687-a621-4aad6d0d19ba
2023-11-03 05:25:28,809 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2cdb1c33-5883-4e04-8bed-0ae4262bbf54
2023-11-03 05:25:28,810 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:28,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:28,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:28,829 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:28,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:28,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:28,838 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:28,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:28,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:28,859 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:29,160 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44297', status: init, memory: 0, processing: 0>
2023-11-03 05:25:29,161 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44297
2023-11-03 05:25:29,161 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48392
2023-11-03 05:25:29,162 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:29,162 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-03 05:25:29,163 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:29,164 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-03 05:25:30,367 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33529
2023-11-03 05:25:30,368 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33529
2023-11-03 05:25:30,369 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39139
2023-11-03 05:25:30,369 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-03 05:25:30,369 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:30,369 - distributed.worker - INFO -               Threads:                          4
2023-11-03 05:25:30,369 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-03 05:25:30,369 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-cu0cgj4e
2023-11-03 05:25:30,370 - distributed.worker - INFO - Starting Worker plugin PreImport-4127e9c5-fe4d-4adc-8a4b-423711612d04
2023-11-03 05:25:30,370 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ea36dad6-c409-44bc-8676-cf1a9972552c
2023-11-03 05:25:30,370 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ba2c81cd-e366-48fe-bf0d-77da4b29e4b4
2023-11-03 05:25:30,370 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:30,387 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32991
2023-11-03 05:25:30,388 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32991
2023-11-03 05:25:30,388 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45537
2023-11-03 05:25:30,388 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-03 05:25:30,388 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:30,388 - distributed.worker - INFO -               Threads:                          4
2023-11-03 05:25:30,388 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-03 05:25:30,388 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-betkl_ex
2023-11-03 05:25:30,387 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41345
2023-11-03 05:25:30,388 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41345
2023-11-03 05:25:30,388 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37113
2023-11-03 05:25:30,388 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-03 05:25:30,388 - distributed.worker - INFO - Starting Worker plugin RMMSetup-567f9386-913e-4182-b3c9-a27d80ba710f
2023-11-03 05:25:30,388 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:30,388 - distributed.worker - INFO - Starting Worker plugin PreImport-9b2e4104-ca18-4666-ba72-157f6fe4d028
2023-11-03 05:25:30,388 - distributed.worker - INFO -               Threads:                          4
2023-11-03 05:25:30,388 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-889db905-f23d-4bd4-9132-962f6ca08295
2023-11-03 05:25:30,388 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-03 05:25:30,389 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-wewm11_5
2023-11-03 05:25:30,389 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:30,389 - distributed.worker - INFO - Starting Worker plugin RMMSetup-53dd0dc7-5d14-41d9-a59d-f83eb771e1ba
2023-11-03 05:25:30,389 - distributed.worker - INFO - Starting Worker plugin PreImport-5e37f149-9d7e-44c0-b3c7-95d5c420159d
2023-11-03 05:25:30,389 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d004f874-9247-4179-a645-654b7bbbc8af
2023-11-03 05:25:30,390 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:30,400 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33529', status: init, memory: 0, processing: 0>
2023-11-03 05:25:30,401 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33529
2023-11-03 05:25:30,401 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50162
2023-11-03 05:25:30,402 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:30,402 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-03 05:25:30,402 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:30,404 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-03 05:25:30,410 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32991', status: init, memory: 0, processing: 0>
2023-11-03 05:25:30,411 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32991
2023-11-03 05:25:30,411 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50172
2023-11-03 05:25:30,411 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:30,412 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-03 05:25:30,412 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:30,414 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-03 05:25:30,422 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41345', status: init, memory: 0, processing: 0>
2023-11-03 05:25:30,422 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41345
2023-11-03 05:25:30,422 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50184
2023-11-03 05:25:30,423 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:30,424 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-03 05:25:30,424 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:30,426 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-03 05:25:30,461 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-03 05:25:30,461 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-03 05:25:30,461 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-03 05:25:30,461 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-03 05:25:30,466 - distributed.scheduler - INFO - Remove client Client-644228ad-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:25:30,466 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48374; closing.
2023-11-03 05:25:30,466 - distributed.scheduler - INFO - Remove client Client-644228ad-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:25:30,467 - distributed.scheduler - INFO - Close client connection: Client-644228ad-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:25:30,468 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33695'. Reason: nanny-close
2023-11-03 05:25:30,468 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:25:30,469 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41777'. Reason: nanny-close
2023-11-03 05:25:30,469 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:25:30,469 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41345. Reason: nanny-close
2023-11-03 05:25:30,470 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42431'. Reason: nanny-close
2023-11-03 05:25:30,470 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:25:30,470 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32991. Reason: nanny-close
2023-11-03 05:25:30,470 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35439'. Reason: nanny-close
2023-11-03 05:25:30,471 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:25:30,471 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33529. Reason: nanny-close
2023-11-03 05:25:30,471 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50184; closing.
2023-11-03 05:25:30,471 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-03 05:25:30,471 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44297. Reason: nanny-close
2023-11-03 05:25:30,471 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41345', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989130.4719117')
2023-11-03 05:25:30,472 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-03 05:25:30,473 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50172; closing.
2023-11-03 05:25:30,473 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:30,473 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50162; closing.
2023-11-03 05:25:30,473 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:30,473 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-03 05:25:30,473 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32991', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989130.4736888')
2023-11-03 05:25:30,473 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-03 05:25:30,474 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33529', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989130.4744217')
2023-11-03 05:25:30,474 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48392; closing.
2023-11-03 05:25:30,475 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:30,475 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44297', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989130.4753075')
2023-11-03 05:25:30,475 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:30,475 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:25:31,484 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-03 05:25:31,484 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-03 05:25:31,485 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:25:31,486 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-11-03 05:25:31,486 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-11-03 05:25:33,369 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:25:33,373 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45015 instead
  warnings.warn(
2023-11-03 05:25:33,377 - distributed.scheduler - INFO - State start
2023-11-03 05:25:33,398 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:25:33,398 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-03 05:25:33,399 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:25:33,400 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-03 05:25:33,938 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44421'
2023-11-03 05:25:33,951 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44505'
2023-11-03 05:25:33,966 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43147'
2023-11-03 05:25:33,968 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34183'
2023-11-03 05:25:33,977 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33753'
2023-11-03 05:25:33,986 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33185'
2023-11-03 05:25:33,994 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35451'
2023-11-03 05:25:34,003 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42517'
2023-11-03 05:25:35,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:35,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:35,717 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:35,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:35,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:35,762 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:35,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:35,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:35,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:35,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:35,796 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:35,800 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:35,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:35,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:35,850 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:35,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:35,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:35,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:35,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:35,862 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:35,862 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:36,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:36,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:36,115 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:37,859 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44757
2023-11-03 05:25:37,861 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44757
2023-11-03 05:25:37,861 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36635
2023-11-03 05:25:37,861 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:37,861 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:37,861 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:37,861 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:37,862 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2fh0u5m8
2023-11-03 05:25:37,863 - distributed.worker - INFO - Starting Worker plugin PreImport-db7ebb81-123f-4587-8ece-ae70171c535e
2023-11-03 05:25:37,863 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd24d4ba-56dc-4ba8-b16f-83f694b84ac7
2023-11-03 05:25:37,863 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0fbe7c44-f6d9-4ceb-9530-68881b6e2df5
2023-11-03 05:25:38,305 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:38,348 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:38,349 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:38,349 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:38,351 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:38,582 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41255
2023-11-03 05:25:38,584 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41255
2023-11-03 05:25:38,584 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38775
2023-11-03 05:25:38,584 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:38,585 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:38,585 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:38,585 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:38,585 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n4d81ofs
2023-11-03 05:25:38,586 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e6944702-32b7-4c95-aa7e-300812f816a2
2023-11-03 05:25:38,586 - distributed.worker - INFO - Starting Worker plugin PreImport-fbc7825a-98ca-45e8-94e5-3c38d9ca9983
2023-11-03 05:25:38,586 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aeabe5dc-673e-484d-aa48-4dc5c39df5fe
2023-11-03 05:25:38,587 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44757. Reason: scheduler-close
2023-11-03 05:25:38,589 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://127.0.0.1:53604 remote=tcp://127.0.0.1:9369>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://127.0.0.1:53604 remote=tcp://127.0.0.1:9369>: Stream is closed
2023-11-03 05:25:38,592 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://127.0.0.1:35451'. Reason: scheduler-close
2023-11-03 05:25:38,596 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:9369; closing.
2023-11-03 05:25:38,596 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:38,702 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,000 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37523
2023-11-03 05:25:39,001 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37523
2023-11-03 05:25:39,001 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41505
2023-11-03 05:25:39,001 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:39,001 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,001 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:39,001 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:39,001 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-biqt8ilj
2023-11-03 05:25:39,002 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6ce2cbbc-6cc0-4932-aac4-d7af3c9a3a5d
2023-11-03 05:25:39,002 - distributed.worker - INFO - Starting Worker plugin PreImport-1591a35b-0992-45f8-91a8-a6d4c0e14d6c
2023-11-03 05:25:39,003 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d5e96171-4450-4b0b-adc3-9156606224c9
2023-11-03 05:25:39,003 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41059
2023-11-03 05:25:39,005 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41059
2023-11-03 05:25:39,005 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46513
2023-11-03 05:25:39,005 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:39,005 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,005 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:39,005 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:39,005 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j_z_wuy1
2023-11-03 05:25:39,006 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e0af6ad3-3193-44df-9810-f7bc97efe883
2023-11-03 05:25:39,007 - distributed.worker - INFO - Starting Worker plugin PreImport-2147e8bf-38d5-40f6-95b5-4cf791e2cdcc
2023-11-03 05:25:39,007 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eafef011-b1d6-469b-9ef6-13f977ff8eb2
2023-11-03 05:25:39,052 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41673
2023-11-03 05:25:39,053 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41673
2023-11-03 05:25:39,053 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33405
2023-11-03 05:25:39,053 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:39,053 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,053 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:39,053 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:39,054 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uwhqnumw
2023-11-03 05:25:39,054 - distributed.worker - INFO - Starting Worker plugin PreImport-2616b947-7f56-4090-b639-2855418967fc
2023-11-03 05:25:39,054 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1cda8bde-91ec-4c4f-bf78-8cc335ce9196
2023-11-03 05:25:39,054 - distributed.worker - INFO - Starting Worker plugin RMMSetup-18e35607-1032-497e-8409-10a726e9fd1a
2023-11-03 05:25:39,054 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36249
2023-11-03 05:25:39,055 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36249
2023-11-03 05:25:39,055 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41451
2023-11-03 05:25:39,055 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:39,055 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,055 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:39,055 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:39,055 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ca_f3_mt
2023-11-03 05:25:39,056 - distributed.worker - INFO - Starting Worker plugin PreImport-3feec0de-95c8-4d2b-8b8e-a8dec8af7769
2023-11-03 05:25:39,056 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ed325992-af09-4e64-8017-b22c89696bb8
2023-11-03 05:25:39,058 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45441
2023-11-03 05:25:39,058 - distributed.worker - INFO - Starting Worker plugin RMMSetup-37f289ff-3edb-43c6-9cee-b4140c747b87
2023-11-03 05:25:39,058 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45441
2023-11-03 05:25:39,058 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38485
2023-11-03 05:25:39,059 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:39,059 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,059 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:39,059 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:39,059 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ptbw6mu6
2023-11-03 05:25:39,059 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c29fef82-761e-45eb-9875-dc38d0da269f
2023-11-03 05:25:39,059 - distributed.worker - INFO - Starting Worker plugin PreImport-b27a5116-0060-477c-afbe-0e33e10c0c7e
2023-11-03 05:25:39,059 - distributed.worker - INFO - Starting Worker plugin RMMSetup-acb9be71-d931-4819-af0f-307013e49308
2023-11-03 05:25:39,066 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41347
2023-11-03 05:25:39,068 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41347
2023-11-03 05:25:39,068 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37489
2023-11-03 05:25:39,068 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:39,068 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,068 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:39,068 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:39,068 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pklo8_3q
2023-11-03 05:25:39,069 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5edbaf7b-78d0-48f2-b7ce-85f7b2954c7a
2023-11-03 05:25:39,070 - distributed.worker - INFO - Starting Worker plugin PreImport-d5a31499-01cd-44ea-ac20-d9d5da56e1ff
2023-11-03 05:25:39,070 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2fe4aef9-5b86-44b2-9e48-fc351bf7ebd7
2023-11-03 05:25:39,148 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,164 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,172 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,174 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,185 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:39,185 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:40,598 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-11-03 05:25:41,089 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:41,090 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:41,090 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:41,092 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:41,132 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42517'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,132 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,134 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45441. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,137 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:41,139 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:41,207 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:41,208 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:41,208 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:41,209 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:41,231 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43147'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,231 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,232 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41673. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,234 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:41,236 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:41,379 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35451'. Reason: nanny-close-gracefully
2023-11-03 05:25:41,550 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:41,551 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:41,551 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:41,553 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:41,573 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:41,574 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:41,574 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:41,576 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:41,587 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44505'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,587 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,588 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37523. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,589 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33185'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,589 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,590 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41255. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,591 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:41,592 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:41,593 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:41,594 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:41,820 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:41,821 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:41,821 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:41,822 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:41,842 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34183'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,842 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,843 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41059. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:41,845 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:41,847 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 376, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:53522 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-11-03 05:25:41,878 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54149 parent=53966 started daemon>
2023-11-03 05:25:41,878 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54146 parent=53966 started daemon>
2023-11-03 05:25:41,878 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54142 parent=53966 started daemon>
2023-11-03 05:25:41,878 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54138 parent=53966 started daemon>
2023-11-03 05:25:41,879 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54134 parent=53966 started daemon>
2023-11-03 05:25:41,879 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54131 parent=53966 started daemon>
2023-11-03 05:25:41,954 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 54138 exit status was already read will report exitcode 255
2023-11-03 05:25:42,217 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 54131 exit status was already read will report exitcode 255
2023-11-03 05:25:42,336 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 54142 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-11-03 05:25:52,886 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:25:52,891 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36479 instead
  warnings.warn(
2023-11-03 05:25:52,895 - distributed.scheduler - INFO - State start
2023-11-03 05:25:52,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ca_f3_mt', purging
2023-11-03 05:25:52,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-pklo8_3q', purging
2023-11-03 05:25:53,185 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:25:53,187 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-03 05:25:53,187 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:25:53,189 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-03 05:25:53,958 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37667'
2023-11-03 05:25:53,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44877'
2023-11-03 05:25:53,986 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43179'
2023-11-03 05:25:53,995 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37623'
2023-11-03 05:25:54,008 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44343'
2023-11-03 05:25:54,016 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40211'
2023-11-03 05:25:54,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38487'
2023-11-03 05:25:54,034 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40671'
2023-11-03 05:25:55,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:55,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:55,858 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:55,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:55,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:55,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:55,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:55,903 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:55,903 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:55,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:55,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:55,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:55,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:55,936 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:55,936 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:55,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:55,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:55,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:55,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:55,948 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:55,950 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:55,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:25:55,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:25:55,961 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:25:58,582 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32949
2023-11-03 05:25:58,583 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32949
2023-11-03 05:25:58,583 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39857
2023-11-03 05:25:58,583 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,583 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,584 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:58,584 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:58,584 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z5lem689
2023-11-03 05:25:58,584 - distributed.worker - INFO - Starting Worker plugin PreImport-4e1b3eb6-e938-4a1d-9bcf-1a0fbf863db4
2023-11-03 05:25:58,585 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e1ad93a5-30f4-4cfe-b189-eecffc321838
2023-11-03 05:25:58,585 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c06ae1d6-8907-4235-b766-3869c5853b33
2023-11-03 05:25:58,591 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,650 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46283
2023-11-03 05:25:58,652 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46283
2023-11-03 05:25:58,652 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45595
2023-11-03 05:25:58,652 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,652 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,652 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:58,653 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:58,653 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mc_gw0bk
2023-11-03 05:25:58,654 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-da8b600d-c163-4c69-8623-6373ebfaf5fd
2023-11-03 05:25:58,654 - distributed.worker - INFO - Starting Worker plugin PreImport-8c8fe05d-90f7-4aa1-839d-0fec50183dc8
2023-11-03 05:25:58,654 - distributed.worker - INFO - Starting Worker plugin RMMSetup-423d2129-6c2b-4f2a-9d25-33b9ea5ac123
2023-11-03 05:25:58,653 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38619
2023-11-03 05:25:58,655 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38619
2023-11-03 05:25:58,654 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43399
2023-11-03 05:25:58,655 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46461
2023-11-03 05:25:58,655 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,655 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43399
2023-11-03 05:25:58,655 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,655 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40919
2023-11-03 05:25:58,655 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,655 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,655 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:58,655 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:58,656 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:58,656 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cvz93fyy
2023-11-03 05:25:58,656 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:58,656 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yre1k2k3
2023-11-03 05:25:58,656 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-13108364-26fd-4ae5-aabe-182546a47f09
2023-11-03 05:25:58,656 - distributed.worker - INFO - Starting Worker plugin PreImport-e9e084f4-e418-47ea-822a-a1c6e9c7badb
2023-11-03 05:25:58,656 - distributed.worker - INFO - Starting Worker plugin RMMSetup-92fbfd4f-add3-4d75-a6cb-d511aa9eda11
2023-11-03 05:25:58,657 - distributed.worker - INFO - Starting Worker plugin PreImport-297086ff-87ec-4767-b01b-995e5abf5eae
2023-11-03 05:25:58,657 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4c59b161-a234-45d2-9aa8-a4a13d907683
2023-11-03 05:25:58,658 - distributed.worker - INFO - Starting Worker plugin RMMSetup-58665cda-0853-4f15-bf00-55ce4bf35e53
2023-11-03 05:25:58,666 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,669 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,670 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,793 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34347
2023-11-03 05:25:58,794 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34347
2023-11-03 05:25:58,794 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43863
2023-11-03 05:25:58,794 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,794 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,794 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:58,794 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:58,794 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u2j1we98
2023-11-03 05:25:58,795 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2c7a67e0-cd64-43f1-98ac-21db42cca440
2023-11-03 05:25:58,795 - distributed.worker - INFO - Starting Worker plugin PreImport-3e70a508-d994-4efd-9325-8c47a4bb2263
2023-11-03 05:25:58,795 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4427ae15-ab60-422c-a9d3-9e61a611f1af
2023-11-03 05:25:58,795 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36421
2023-11-03 05:25:58,796 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36421
2023-11-03 05:25:58,796 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44799
2023-11-03 05:25:58,796 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,796 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,796 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:58,797 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:58,797 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-for5xwv8
2023-11-03 05:25:58,797 - distributed.worker - INFO - Starting Worker plugin PreImport-a5e97592-9c54-47f6-a8a6-9cd3c264d353
2023-11-03 05:25:58,797 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a7a9b82f-be5f-44fe-8ce0-abb548b7581a
2023-11-03 05:25:58,799 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42635
2023-11-03 05:25:58,800 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42635
2023-11-03 05:25:58,800 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44477
2023-11-03 05:25:58,800 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,800 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,800 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:58,800 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:58,800 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a55l0fbh
2023-11-03 05:25:58,801 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-04e4d6bf-9120-454b-a3a2-64858d16c654
2023-11-03 05:25:58,800 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45073
2023-11-03 05:25:58,801 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45073
2023-11-03 05:25:58,802 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45923
2023-11-03 05:25:58,802 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,802 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,802 - distributed.worker - INFO - Starting Worker plugin PreImport-28d695ab-4020-46ba-8f95-f511153f42e0
2023-11-03 05:25:58,802 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:25:58,802 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:25:58,802 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ys_32hky
2023-11-03 05:25:58,802 - distributed.worker - INFO - Starting Worker plugin RMMSetup-151a4c6f-d868-4688-a0fa-cacabf4a0831
2023-11-03 05:25:58,802 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-afd30cdd-5ba1-4a98-9016-fb98f9910142
2023-11-03 05:25:58,803 - distributed.worker - INFO - Starting Worker plugin PreImport-bbde8728-5681-45a2-93ba-394188b621d1
2023-11-03 05:25:58,804 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c801889f-ee3b-484f-8c56-0c90b5175955
2023-11-03 05:25:58,813 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,813 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c5979a48-9c1d-4b6f-b662-003798764e23
2023-11-03 05:25:58,816 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,817 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,817 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,959 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:58,960 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,960 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,962 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:58,963 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:58,965 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,965 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,965 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:58,967 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,967 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,967 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:58,967 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:58,968 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,968 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,969 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:58,969 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:58,970 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:58,970 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:58,971 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:58,972 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:58,983 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37667'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,984 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,986 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44877'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,986 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36421. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,986 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,987 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43179'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,987 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45073. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,988 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,989 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:58,989 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38619. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,989 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44343'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,989 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,990 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:58,991 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42635. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,991 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40211'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,991 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,992 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:58,993 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34347. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:58,993 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:58,993 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:58,994 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:58,996 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:58,996 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:58,996 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:58,998 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:59,006 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:59,007 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:59,007 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:59,010 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:59,043 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37623'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:59,044 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:59,045 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46283. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:59,049 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:59,052 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:59,200 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:59,201 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:59,201 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:59,202 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:59,205 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:25:59,206 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:25:59,206 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:25:59,207 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:25:59,247 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38487'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:59,247 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:59,248 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40671'. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:59,248 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32949. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:59,248 - distributed.nanny - INFO - Nanny asking worker to close. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:59,249 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43399. Reason: failure-to-start-<class 'distributed.comm.core.CommClosedError'>
2023-11-03 05:25:59,250 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:59,251 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:25:59,252 - distributed.nanny - INFO - Worker closed
2023-11-03 05:25:59,253 - distributed.nanny - INFO - Worker closed
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 376, in start_unsafe
    await comm.write({"status": "ok"})
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Nanny->Scheduler (registration) local=tcp://127.0.0.1:34276 remote=tcp://127.0.0.1:9369>: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 442, in worker
    loop.run_sync(run)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 527, in run_sync
    return future_cell[0].result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cli.py", line 434, in run
    await worker
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/cuda_worker.py", line 244, in _wait
    await asyncio.gather(*self.nannies)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 688, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Nanny failed to start.
2023-11-03 05:25:59,906 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54440 parent=54251 started daemon>
2023-11-03 05:25:59,906 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54437 parent=54251 started daemon>
2023-11-03 05:25:59,907 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54434 parent=54251 started daemon>
2023-11-03 05:25:59,907 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54431 parent=54251 started daemon>
2023-11-03 05:25:59,907 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54427 parent=54251 started daemon>
2023-11-03 05:25:59,907 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54423 parent=54251 started daemon>
2023-11-03 05:25:59,907 - distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=54419 parent=54251 started daemon>
2023-11-03 05:26:00,125 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 54423 exit status was already read will report exitcode 255
2023-11-03 05:26:00,183 - distributed.process - WARNING - [<AsyncProcess Dask Worker process (from Nanny)>] process 54427 exit status was already read will report exitcode 255
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-11-03 05:26:06,600 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:06,606 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-11-03 05:26:06,610 - distributed.scheduler - INFO - State start
2023-11-03 05:26:06,784 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:06,785 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-03 05:26:06,785 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-11-03 05:26:06,786 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-03 05:26:06,793 - distributed.scheduler - INFO - Receive client connection: Client-7d18b573-7a09-11ee-90fa-d8c49764f6bb
2023-11-03 05:26:06,805 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37522
2023-11-03 05:26:06,835 - distributed.scheduler - INFO - Receive client connection: Client-7be164f9-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:06,835 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37570
2023-11-03 05:26:06,849 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45899'
2023-11-03 05:26:06,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35289'
2023-11-03 05:26:06,875 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40173'
2023-11-03 05:26:06,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34621'
2023-11-03 05:26:06,895 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43671'
2023-11-03 05:26:06,903 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43307'
2023-11-03 05:26:06,912 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42773'
2023-11-03 05:26:06,922 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37249'
2023-11-03 05:26:08,697 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:08,697 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:08,701 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:08,718 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:08,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:08,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:08,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:08,723 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:08,723 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:08,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:08,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:08,758 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:08,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:08,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:08,766 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:08,766 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:08,768 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:08,770 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:08,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:08,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:08,777 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:08,777 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:08,779 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:08,781 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:11,320 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46621
2023-11-03 05:26:11,321 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46621
2023-11-03 05:26:11,321 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41177
2023-11-03 05:26:11,321 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:11,321 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,321 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:11,321 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:11,321 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zrf4jb2w
2023-11-03 05:26:11,322 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a7a0ec23-3a09-4527-98f3-8b01f6c953f9
2023-11-03 05:26:11,322 - distributed.worker - INFO - Starting Worker plugin PreImport-46e9ab1b-b523-4348-b014-23d26a70808b
2023-11-03 05:26:11,322 - distributed.worker - INFO - Starting Worker plugin RMMSetup-bab29439-e2c4-4593-a6f6-d74cfae4f389
2023-11-03 05:26:11,459 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,486 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46621', status: init, memory: 0, processing: 0>
2023-11-03 05:26:11,487 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46621
2023-11-03 05:26:11,488 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48788
2023-11-03 05:26:11,488 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:11,489 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:11,489 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,491 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:11,564 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:11,567 - distributed.scheduler - INFO - Remove client Client-7d18b573-7a09-11ee-90fa-d8c49764f6bb
2023-11-03 05:26:11,568 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37522; closing.
2023-11-03 05:26:11,568 - distributed.scheduler - INFO - Remove client Client-7d18b573-7a09-11ee-90fa-d8c49764f6bb
2023-11-03 05:26:11,568 - distributed.scheduler - INFO - Close client connection: Client-7d18b573-7a09-11ee-90fa-d8c49764f6bb
2023-11-03 05:26:11,773 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36619
2023-11-03 05:26:11,774 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36619
2023-11-03 05:26:11,774 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35745
2023-11-03 05:26:11,774 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:11,774 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,774 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:11,774 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:11,774 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tpqbxyh1
2023-11-03 05:26:11,775 - distributed.worker - INFO - Starting Worker plugin PreImport-360caf86-de1a-417b-b8aa-1572c114cbda
2023-11-03 05:26:11,775 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-94e20d64-7c70-4542-b51e-ae42ce5a271d
2023-11-03 05:26:11,775 - distributed.worker - INFO - Starting Worker plugin RMMSetup-58caf9d9-9780-47a3-8562-77635e4ef6e2
2023-11-03 05:26:11,775 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43239
2023-11-03 05:26:11,776 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43239
2023-11-03 05:26:11,776 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33337
2023-11-03 05:26:11,776 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:11,776 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,776 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:11,776 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:11,776 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rp4qac2p
2023-11-03 05:26:11,777 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2f295273-1213-42d5-8b4c-357ee9642f63
2023-11-03 05:26:11,779 - distributed.worker - INFO - Starting Worker plugin PreImport-eec18501-f342-40ba-9888-1889e67008a4
2023-11-03 05:26:11,779 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aa403d64-a038-4b6d-995f-b21ee2ac0d2e
2023-11-03 05:26:11,780 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37091
2023-11-03 05:26:11,781 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37091
2023-11-03 05:26:11,781 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40313
2023-11-03 05:26:11,781 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:11,781 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,781 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:11,781 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:11,781 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a8ci1zmc
2023-11-03 05:26:11,782 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a5d1fd20-a56f-46d9-b9fd-b0eee6f44a07
2023-11-03 05:26:11,783 - distributed.worker - INFO - Starting Worker plugin PreImport-5e1e9b31-f48c-4942-a637-3d0b937667da
2023-11-03 05:26:11,783 - distributed.worker - INFO - Starting Worker plugin RMMSetup-56114a8e-fb8b-4480-9ee2-87a70f8a43c4
2023-11-03 05:26:11,783 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35601
2023-11-03 05:26:11,784 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35601
2023-11-03 05:26:11,784 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39717
2023-11-03 05:26:11,784 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:11,784 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,784 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:11,784 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:11,784 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ylbja9fq
2023-11-03 05:26:11,785 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b4d52a0e-2427-4885-9a1c-434d292ce9f2
2023-11-03 05:26:11,785 - distributed.worker - INFO - Starting Worker plugin PreImport-28ec2f3d-893a-4a6e-beeb-e88d0f0ce882
2023-11-03 05:26:11,785 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8012133d-afcb-4045-9b38-d489d1252ad8
2023-11-03 05:26:11,787 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46567
2023-11-03 05:26:11,787 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40567
2023-11-03 05:26:11,788 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46567
2023-11-03 05:26:11,788 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40567
2023-11-03 05:26:11,788 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40971
2023-11-03 05:26:11,788 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35391
2023-11-03 05:26:11,788 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:11,788 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:11,788 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,788 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,788 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:11,788 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:11,788 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:11,788 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:11,788 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sltco7zj
2023-11-03 05:26:11,788 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q89c95tc
2023-11-03 05:26:11,789 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-55f54be5-d248-4327-9ef2-5143ffc7b4dc
2023-11-03 05:26:11,789 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-94354106-04a2-4186-b903-24a1d993addc
2023-11-03 05:26:11,789 - distributed.worker - INFO - Starting Worker plugin PreImport-6c45f349-1a4c-4f60-bf67-57d1424e3c1e
2023-11-03 05:26:11,789 - distributed.worker - INFO - Starting Worker plugin PreImport-5a48cd20-87b5-4c9a-8c34-b6b02315446f
2023-11-03 05:26:11,789 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b786e781-ed68-44a0-990a-077deda2a4d3
2023-11-03 05:26:11,789 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fb436bf5-2190-4112-b34a-94b66561a9e4
2023-11-03 05:26:11,789 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44835
2023-11-03 05:26:11,790 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44835
2023-11-03 05:26:11,790 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37433
2023-11-03 05:26:11,790 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:11,790 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:11,790 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:11,790 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:11,791 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1ng8yzro
2023-11-03 05:26:11,792 - distributed.worker - INFO - Starting Worker plugin PreImport-9773cfeb-048c-4837-a3f0-6ced93c696f0
2023-11-03 05:26:11,792 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-416bf415-edff-4a39-8a06-2ccccef70524
2023-11-03 05:26:11,792 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2f658645-95ea-4ba7-923f-d406f67083b1
2023-11-03 05:26:12,051 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,054 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,055 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,057 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,057 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,058 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,058 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,080 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40567', status: init, memory: 0, processing: 0>
2023-11-03 05:26:12,081 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40567
2023-11-03 05:26:12,081 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48790
2023-11-03 05:26:12,082 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:12,083 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:12,083 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,084 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46567', status: init, memory: 0, processing: 0>
2023-11-03 05:26:12,084 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46567
2023-11-03 05:26:12,084 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48802
2023-11-03 05:26:12,084 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:12,085 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35601', status: init, memory: 0, processing: 0>
2023-11-03 05:26:12,085 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:12,086 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:12,086 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35601
2023-11-03 05:26:12,086 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,086 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48800
2023-11-03 05:26:12,087 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:12,088 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:12,088 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:12,088 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,090 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:12,093 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36619', status: init, memory: 0, processing: 0>
2023-11-03 05:26:12,094 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36619
2023-11-03 05:26:12,094 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48822
2023-11-03 05:26:12,094 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37091', status: init, memory: 0, processing: 0>
2023-11-03 05:26:12,095 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37091
2023-11-03 05:26:12,095 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48816
2023-11-03 05:26:12,095 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:12,095 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43239', status: init, memory: 0, processing: 0>
2023-11-03 05:26:12,096 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43239
2023-11-03 05:26:12,096 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48812
2023-11-03 05:26:12,096 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:12,096 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,096 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:12,097 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44835', status: init, memory: 0, processing: 0>
2023-11-03 05:26:12,097 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44835
2023-11-03 05:26:12,097 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48820
2023-11-03 05:26:12,097 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:12,097 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,097 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:12,098 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:12,098 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:12,098 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,099 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:12,100 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:12,100 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:12,100 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:12,101 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:12,102 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:12,183 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:12,184 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:12,184 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:12,184 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:12,184 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:12,184 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:12,184 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:12,184 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:12,198 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:12,198 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:12,198 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:12,198 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:12,199 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:12,199 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:12,199 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:12,199 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:12,206 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:12,207 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:12,210 - distributed.scheduler - INFO - Remove client Client-7be164f9-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:12,210 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37570; closing.
2023-11-03 05:26:12,210 - distributed.scheduler - INFO - Remove client Client-7be164f9-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:12,211 - distributed.scheduler - INFO - Close client connection: Client-7be164f9-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:12,212 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45899'. Reason: nanny-close
2023-11-03 05:26:12,213 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:12,214 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35289'. Reason: nanny-close
2023-11-03 05:26:12,214 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:12,214 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43239. Reason: nanny-close
2023-11-03 05:26:12,215 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40173'. Reason: nanny-close
2023-11-03 05:26:12,216 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:12,216 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37091. Reason: nanny-close
2023-11-03 05:26:12,216 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34621'. Reason: nanny-close
2023-11-03 05:26:12,217 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46621. Reason: nanny-close
2023-11-03 05:26:12,217 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:12,217 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48812; closing.
2023-11-03 05:26:12,217 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:12,217 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43239', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989172.2177756')
2023-11-03 05:26:12,218 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43671'. Reason: nanny-close
2023-11-03 05:26:12,218 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40567. Reason: nanny-close
2023-11-03 05:26:12,218 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:12,218 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:12,218 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43307'. Reason: nanny-close
2023-11-03 05:26:12,219 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:12,219 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:12,219 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36619. Reason: nanny-close
2023-11-03 05:26:12,219 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:12,219 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42773'. Reason: nanny-close
2023-11-03 05:26:12,220 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48816; closing.
2023-11-03 05:26:12,220 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:12,220 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:12,221 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44835. Reason: nanny-close
2023-11-03 05:26:12,220 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37249'. Reason: nanny-close
2023-11-03 05:26:12,221 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37091', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989172.2211123')
2023-11-03 05:26:12,221 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:12,221 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:12,221 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46567. Reason: nanny-close
2023-11-03 05:26:12,221 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:12,221 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48788; closing.
2023-11-03 05:26:12,222 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46621', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989172.2220716')
2023-11-03 05:26:12,222 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35601. Reason: nanny-close
2023-11-03 05:26:12,222 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:12,222 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:12,223 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48790; closing.
2023-11-03 05:26:12,223 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:12,223 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:12,224 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:12,224 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40567', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989172.224257')
2023-11-03 05:26:12,224 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:12,224 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48822; closing.
2023-11-03 05:26:12,224 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:12,225 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48820; closing.
2023-11-03 05:26:12,225 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:12,225 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36619', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989172.2258875')
2023-11-03 05:26:12,226 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:12,226 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44835', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989172.2262638')
2023-11-03 05:26:12,226 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48802; closing.
2023-11-03 05:26:12,227 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46567', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989172.2274117')
2023-11-03 05:26:12,227 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48800; closing.
2023-11-03 05:26:12,228 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35601', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989172.2285314')
2023-11-03 05:26:12,228 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:26:12,228 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:48802>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-03 05:26:12,570 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42315', status: init, memory: 0, processing: 0>
2023-11-03 05:26:12,571 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42315
2023-11-03 05:26:12,571 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48834
2023-11-03 05:26:12,597 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48834; closing.
2023-11-03 05:26:12,597 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42315', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989172.5976925')
2023-11-03 05:26:12,597 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:26:13,880 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-03 05:26:13,880 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-03 05:26:13,881 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:26:13,882 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-03 05:26:13,882 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-11-03 05:26:15,943 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:15,947 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-11-03 05:26:15,951 - distributed.scheduler - INFO - State start
2023-11-03 05:26:15,974 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:15,975 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-03 05:26:15,975 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-11-03 05:26:15,976 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-03 05:26:16,344 - distributed.scheduler - INFO - Receive client connection: Client-82d57853-7a09-11ee-90fa-d8c49764f6bb
2023-11-03 05:26:16,356 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48918
2023-11-03 05:26:16,395 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46153'
2023-11-03 05:26:16,408 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40007'
2023-11-03 05:26:16,416 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36039'
2023-11-03 05:26:16,430 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33857'
2023-11-03 05:26:16,433 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38075'
2023-11-03 05:26:16,442 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33417'
2023-11-03 05:26:16,450 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46361'
2023-11-03 05:26:16,459 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37073'
2023-11-03 05:26:16,584 - distributed.scheduler - INFO - Receive client connection: Client-819f71f0-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:16,585 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48978
2023-11-03 05:26:18,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:18,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:18,458 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:18,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:18,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:18,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:18,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:18,477 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:18,480 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:18,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:18,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:18,486 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:18,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:18,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:18,496 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:18,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:18,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:18,509 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:18,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:18,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:18,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:18,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:18,515 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:18,517 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:21,082 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45277
2023-11-03 05:26:21,082 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45277
2023-11-03 05:26:21,082 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38125
2023-11-03 05:26:21,083 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,083 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,083 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:21,083 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:21,083 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-iis0j8z_
2023-11-03 05:26:21,083 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36991
2023-11-03 05:26:21,083 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36991
2023-11-03 05:26:21,083 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-203759ee-4208-459a-8f5d-561f32238be1
2023-11-03 05:26:21,083 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33591
2023-11-03 05:26:21,083 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,084 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,084 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:21,084 - distributed.worker - INFO - Starting Worker plugin PreImport-a20720c5-849d-4870-9824-e39bf59552f7
2023-11-03 05:26:21,084 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:21,084 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gz2ofp2b
2023-11-03 05:26:21,084 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cf1d0983-5fbf-4695-89cb-03ebdc9ed8c1
2023-11-03 05:26:21,084 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d595de0f-5a33-4377-8d99-d5c8a2892506
2023-11-03 05:26:21,085 - distributed.worker - INFO - Starting Worker plugin PreImport-c4551896-140b-4d1e-a9a1-36fb93e52361
2023-11-03 05:26:21,085 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9e657940-bdbd-4031-9660-0e30d71060fd
2023-11-03 05:26:21,260 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44165
2023-11-03 05:26:21,261 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44165
2023-11-03 05:26:21,261 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34809
2023-11-03 05:26:21,261 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,261 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,261 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:21,261 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:21,261 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k_k5fuuu
2023-11-03 05:26:21,262 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-48791185-fab9-4e54-b645-9d5301f47d0e
2023-11-03 05:26:21,263 - distributed.worker - INFO - Starting Worker plugin PreImport-874df665-a777-42bf-83b9-c930ba6576e9
2023-11-03 05:26:21,264 - distributed.worker - INFO - Starting Worker plugin RMMSetup-83e6fe45-ae64-46e4-bae4-9201a9351790
2023-11-03 05:26:21,264 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39609
2023-11-03 05:26:21,266 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39609
2023-11-03 05:26:21,266 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41433
2023-11-03 05:26:21,266 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,266 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,266 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:21,266 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:21,266 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nrpgzdh0
2023-11-03 05:26:21,268 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9da89dde-7c7f-4821-9b58-ea4e809f2e34
2023-11-03 05:26:21,268 - distributed.worker - INFO - Starting Worker plugin PreImport-ea1d8202-7e92-4b53-901b-7ef0e99f1ba8
2023-11-03 05:26:21,268 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b69cbc8a-0486-4010-b195-5b8d0eb157f6
2023-11-03 05:26:21,316 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37311
2023-11-03 05:26:21,317 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37311
2023-11-03 05:26:21,317 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34155
2023-11-03 05:26:21,317 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,317 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,317 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:21,317 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:21,317 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2b_8ws_l
2023-11-03 05:26:21,318 - distributed.worker - INFO - Starting Worker plugin PreImport-c93e69ea-d894-4e94-acf4-f1c2946abd89
2023-11-03 05:26:21,318 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0508b246-3a08-42a4-9852-b3e292b0e353
2023-11-03 05:26:21,318 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39841
2023-11-03 05:26:21,319 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39841
2023-11-03 05:26:21,319 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41063
2023-11-03 05:26:21,319 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,319 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,319 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:21,319 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:21,319 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e9s5ddg6
2023-11-03 05:26:21,319 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35507
2023-11-03 05:26:21,319 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35507
2023-11-03 05:26:21,319 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33625
2023-11-03 05:26:21,319 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,320 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,319 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40973
2023-11-03 05:26:21,320 - distributed.worker - INFO - Starting Worker plugin PreImport-8baf2858-0cce-4b5f-b073-04ce854e670a
2023-11-03 05:26:21,320 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40973
2023-11-03 05:26:21,320 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:21,320 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33359
2023-11-03 05:26:21,320 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:21,320 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6cecb818-f988-4f07-943e-2e1e15c675b8
2023-11-03 05:26:21,320 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,320 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-20l5zt6g
2023-11-03 05:26:21,320 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,320 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c2877cde-5ad6-442a-990b-755225ca491e
2023-11-03 05:26:21,320 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:21,320 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:21,320 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zargy7em
2023-11-03 05:26:21,320 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0601de1a-0ccc-40a9-bb4b-4e553cac181f
2023-11-03 05:26:21,321 - distributed.worker - INFO - Starting Worker plugin PreImport-67d8f3ef-7dea-42ab-a6d7-c522dcdb8445
2023-11-03 05:26:21,321 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-04b54adc-59a6-4e10-a1d4-9ca2c054440e
2023-11-03 05:26:21,321 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c58fa0ff-9b64-4451-aa99-84d85e1c9aab
2023-11-03 05:26:21,322 - distributed.worker - INFO - Starting Worker plugin PreImport-b9d3fb4c-56d3-4398-94d7-2399173785e2
2023-11-03 05:26:21,322 - distributed.worker - INFO - Starting Worker plugin RMMSetup-65d31d7a-be9e-4614-8c44-d578697cd108
2023-11-03 05:26:21,344 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,346 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,380 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36991', status: init, memory: 0, processing: 0>
2023-11-03 05:26:21,382 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36991
2023-11-03 05:26:21,383 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55772
2023-11-03 05:26:21,383 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:21,384 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,384 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,386 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:21,390 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,394 - distributed.scheduler - INFO - Remove client Client-82d57853-7a09-11ee-90fa-d8c49764f6bb
2023-11-03 05:26:21,394 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48918; closing.
2023-11-03 05:26:21,394 - distributed.scheduler - INFO - Remove client Client-82d57853-7a09-11ee-90fa-d8c49764f6bb
2023-11-03 05:26:21,395 - distributed.scheduler - INFO - Close client connection: Client-82d57853-7a09-11ee-90fa-d8c49764f6bb
2023-11-03 05:26:21,561 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45277', status: init, memory: 0, processing: 0>
2023-11-03 05:26:21,561 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45277
2023-11-03 05:26:21,561 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55758
2023-11-03 05:26:21,563 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:21,564 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,564 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,566 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:21,699 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,702 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,713 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,713 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d1ab4453-e194-4062-bf80-99a3a1e9e898
2023-11-03 05:26:21,713 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,724 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,725 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,731 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39609', status: init, memory: 0, processing: 0>
2023-11-03 05:26:21,732 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39609
2023-11-03 05:26:21,732 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55782
2023-11-03 05:26:21,733 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:21,734 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,734 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,735 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:21,741 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44165', status: init, memory: 0, processing: 0>
2023-11-03 05:26:21,741 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44165
2023-11-03 05:26:21,741 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55798
2023-11-03 05:26:21,742 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39841', status: init, memory: 0, processing: 0>
2023-11-03 05:26:21,743 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39841
2023-11-03 05:26:21,743 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55806
2023-11-03 05:26:21,743 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:21,744 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:21,744 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,744 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,745 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,745 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,746 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:21,747 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:21,749 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37311', status: init, memory: 0, processing: 0>
2023-11-03 05:26:21,750 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37311
2023-11-03 05:26:21,750 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55810
2023-11-03 05:26:21,751 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:21,752 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,752 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,754 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40973', status: init, memory: 0, processing: 0>
2023-11-03 05:26:21,754 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:21,755 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40973
2023-11-03 05:26:21,755 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55816
2023-11-03 05:26:21,755 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:21,756 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,756 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,758 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:21,759 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35507', status: init, memory: 0, processing: 0>
2023-11-03 05:26:21,760 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35507
2023-11-03 05:26:21,760 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55830
2023-11-03 05:26:21,761 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:21,762 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:21,762 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:21,764 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:21,776 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,776 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,777 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,777 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,777 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,777 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,777 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,778 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,787 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:21,787 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:21,787 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:21,787 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:21,788 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:21,788 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:21,788 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:21,788 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:26:21,793 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,795 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:21,797 - distributed.scheduler - INFO - Remove client Client-819f71f0-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:21,797 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48978; closing.
2023-11-03 05:26:21,798 - distributed.scheduler - INFO - Remove client Client-819f71f0-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:21,798 - distributed.scheduler - INFO - Close client connection: Client-819f71f0-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:21,799 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46153'. Reason: nanny-close
2023-11-03 05:26:21,799 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:21,800 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40007'. Reason: nanny-close
2023-11-03 05:26:21,801 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:21,801 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37311. Reason: nanny-close
2023-11-03 05:26:21,801 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36039'. Reason: nanny-close
2023-11-03 05:26:21,801 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:21,801 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35507. Reason: nanny-close
2023-11-03 05:26:21,802 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33857'. Reason: nanny-close
2023-11-03 05:26:21,802 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39841. Reason: nanny-close
2023-11-03 05:26:21,802 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:21,803 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38075'. Reason: nanny-close
2023-11-03 05:26:21,803 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:21,803 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36991. Reason: nanny-close
2023-11-03 05:26:21,803 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:21,803 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55810; closing.
2023-11-03 05:26:21,803 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33417'. Reason: nanny-close
2023-11-03 05:26:21,803 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:21,803 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37311', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989181.8039103')
2023-11-03 05:26:21,804 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:21,804 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44165. Reason: nanny-close
2023-11-03 05:26:21,804 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46361'. Reason: nanny-close
2023-11-03 05:26:21,804 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:21,804 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:21,804 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45277. Reason: nanny-close
2023-11-03 05:26:21,804 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37073'. Reason: nanny-close
2023-11-03 05:26:21,805 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:21,805 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40973. Reason: nanny-close
2023-11-03 05:26:21,805 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:21,805 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55830; closing.
2023-11-03 05:26:21,805 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55806; closing.
2023-11-03 05:26:21,805 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:21,806 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39609. Reason: nanny-close
2023-11-03 05:26:21,806 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35507', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989181.8061624')
2023-11-03 05:26:21,806 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:21,806 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:21,806 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39841', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989181.806588')
2023-11-03 05:26:21,806 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:21,807 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55772; closing.
2023-11-03 05:26:21,807 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:21,808 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:21,808 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36991', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989181.8081567')
2023-11-03 05:26:21,808 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:21,808 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55798; closing.
2023-11-03 05:26:21,808 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:21,808 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55758; closing.
2023-11-03 05:26:21,808 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:21,809 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:21,809 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44165', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989181.8095033')
2023-11-03 05:26:21,809 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45277', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989181.8098378')
2023-11-03 05:26:21,810 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:21,810 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55816; closing.
2023-11-03 05:26:21,810 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:21,810 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55782; closing.
2023-11-03 05:26:21,810 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40973', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989181.8106859')
2023-11-03 05:26:21,811 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39609', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989181.8111155')
2023-11-03 05:26:21,811 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:26:22,451 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33543', status: init, memory: 0, processing: 0>
2023-11-03 05:26:22,452 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33543
2023-11-03 05:26:22,452 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55838
2023-11-03 05:26:22,480 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55838; closing.
2023-11-03 05:26:22,481 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33543', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989182.4811196')
2023-11-03 05:26:22,481 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:26:23,468 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-03 05:26:23,468 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-03 05:26:23,469 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:26:23,470 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-03 05:26:23,471 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-11-03 05:26:25,647 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:25,651 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35815 instead
  warnings.warn(
2023-11-03 05:26:25,655 - distributed.scheduler - INFO - State start
2023-11-03 05:26:25,678 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:25,679 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-03 05:26:25,680 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:26:25,681 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-03 05:26:25,876 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38179'
2023-11-03 05:26:25,900 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35041'
2023-11-03 05:26:25,902 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36645'
2023-11-03 05:26:25,910 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41509'
2023-11-03 05:26:25,920 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43891'
2023-11-03 05:26:25,928 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38433'
2023-11-03 05:26:25,937 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44965'
2023-11-03 05:26:25,946 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40413'
2023-11-03 05:26:27,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:27,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:27,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:27,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:27,848 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:27,848 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:27,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:27,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:27,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:27,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:27,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:27,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:27,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:27,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:27,886 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:27,887 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:27,888 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:27,889 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:27,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:27,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:27,900 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:27,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:27,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:27,990 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:30,785 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40735
2023-11-03 05:26:30,786 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40735
2023-11-03 05:26:30,786 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43501
2023-11-03 05:26:30,786 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:30,786 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:30,786 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:30,787 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:30,787 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s_q3nzxa
2023-11-03 05:26:30,787 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-16377c9c-e6c7-4614-95b1-cb4251424794
2023-11-03 05:26:30,788 - distributed.worker - INFO - Starting Worker plugin PreImport-45cbc2f2-313b-408e-8900-c93edb709422
2023-11-03 05:26:30,788 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fc5b01a6-5ec3-4265-9429-a7c286f25abb
2023-11-03 05:26:30,927 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:30,957 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38309
2023-11-03 05:26:30,958 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38309
2023-11-03 05:26:30,958 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44613
2023-11-03 05:26:30,958 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:30,958 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:30,958 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:30,958 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:30,958 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_6nan8sg
2023-11-03 05:26:30,959 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-dd0531ac-2eee-4595-b5f2-46ff4ba21350
2023-11-03 05:26:30,959 - distributed.worker - INFO - Starting Worker plugin PreImport-8ab9b24c-0ad7-4ffc-8558-6f4d2a68ac24
2023-11-03 05:26:30,959 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab475954-5753-443f-80e7-f6983a53499e
2023-11-03 05:26:30,963 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42477
2023-11-03 05:26:30,964 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42477
2023-11-03 05:26:30,964 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35049
2023-11-03 05:26:30,964 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:30,964 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:30,964 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:30,964 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:30,964 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1742hzfz
2023-11-03 05:26:30,965 - distributed.worker - INFO - Starting Worker plugin PreImport-197b323f-b3a0-4e2d-85e6-31f48de1ab55
2023-11-03 05:26:30,965 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d7c31964-f056-48f5-a624-142e64d613f0
2023-11-03 05:26:30,965 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aad700da-a6ff-4f10-b3c0-d36a228d929e
2023-11-03 05:26:30,974 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:30,973 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46873
2023-11-03 05:26:30,975 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46873
2023-11-03 05:26:30,975 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32889
2023-11-03 05:26:30,975 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:30,975 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:30,975 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:30,975 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:30,975 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:30,975 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:30,975 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-famrdzrt
2023-11-03 05:26:30,976 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-95471fc8-bb4a-48a6-a343-3ffbda3218fd
2023-11-03 05:26:30,977 - distributed.worker - INFO - Starting Worker plugin PreImport-9773c54b-4d5b-4b3c-a546-586a0f117515
2023-11-03 05:26:30,977 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7fe6d186-7022-41bf-8c99-260424b88c1a
2023-11-03 05:26:30,977 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:31,143 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33635
2023-11-03 05:26:31,144 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33635
2023-11-03 05:26:31,144 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39637
2023-11-03 05:26:31,144 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,144 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,144 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:31,144 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:31,144 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y8w2ekwy
2023-11-03 05:26:31,145 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f2debabd-c6b5-4254-af38-7701be29fa58
2023-11-03 05:26:31,145 - distributed.worker - INFO - Starting Worker plugin PreImport-38386322-0fb1-44cb-8473-4377cf1f832d
2023-11-03 05:26:31,145 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4a687592-db77-4dbe-aa71-db9de4893e79
2023-11-03 05:26:31,146 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46043
2023-11-03 05:26:31,147 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46043
2023-11-03 05:26:31,147 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36871
2023-11-03 05:26:31,147 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,147 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,144 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36225
2023-11-03 05:26:31,147 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36225
2023-11-03 05:26:31,147 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:31,147 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:31,147 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6e0c7xs0
2023-11-03 05:26:31,147 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33299
2023-11-03 05:26:31,148 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,148 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,148 - distributed.worker - INFO - Starting Worker plugin PreImport-bdbc21ca-f9dd-4a38-9a66-6c2b2088bb50
2023-11-03 05:26:31,148 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ce601d1b-42f6-4799-b2d9-73c4c5613e8b
2023-11-03 05:26:31,148 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:31,148 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:31,148 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-anz1hb0v
2023-11-03 05:26:31,148 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45945
2023-11-03 05:26:31,149 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45945
2023-11-03 05:26:31,149 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45985
2023-11-03 05:26:31,149 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,149 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,149 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:31,149 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:26:31,149 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mlaijwi7
2023-11-03 05:26:31,150 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7afd1d20-f956-4f69-9a51-d63995f5ce1c
2023-11-03 05:26:31,150 - distributed.worker - INFO - Starting Worker plugin PreImport-5588d0d7-43d2-43a4-b464-b0e74a6c356d
2023-11-03 05:26:31,150 - distributed.worker - INFO - Starting Worker plugin RMMSetup-33d173fa-da19-42a8-82a5-f6dbf5d3b42d
2023-11-03 05:26:31,150 - distributed.worker - INFO - Starting Worker plugin RMMSetup-41ad2765-64ba-421e-a03c-8539660bed37
2023-11-03 05:26:31,163 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c09eac8d-2136-452a-8b97-3fcd78425f74
2023-11-03 05:26:31,164 - distributed.worker - INFO - Starting Worker plugin PreImport-0a854a63-126b-4b76-aa35-581484c0f6f5
2023-11-03 05:26:31,164 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8b8883f5-c833-443a-9f77-c4ee9ba5d882
2023-11-03 05:26:31,309 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,315 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,328 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,328 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,328 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,328 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,329 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,335 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:31,335 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,336 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,337 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:31,340 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:31,340 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,340 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,342 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:31,354 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:31,355 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,355 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,357 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:31,360 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:31,361 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,361 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,363 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:31,364 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:31,365 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,366 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,367 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:31,368 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,368 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:31,368 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,368 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:31,369 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:31,370 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:31,371 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:31,372 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:31,424 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:31,424 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:31,424 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:31,425 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:31,425 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:31,425 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:31,425 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:31,426 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:26:31,432 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38179'. Reason: nanny-close
2023-11-03 05:26:31,432 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:31,433 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35041'. Reason: nanny-close
2023-11-03 05:26:31,433 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:31,434 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46873. Reason: nanny-close
2023-11-03 05:26:31,434 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36645'. Reason: nanny-close
2023-11-03 05:26:31,434 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:31,434 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40735. Reason: nanny-close
2023-11-03 05:26:31,435 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41509'. Reason: nanny-close
2023-11-03 05:26:31,435 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38309. Reason: nanny-close
2023-11-03 05:26:31,435 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:31,435 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43891'. Reason: nanny-close
2023-11-03 05:26:31,436 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:31,436 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45945. Reason: nanny-close
2023-11-03 05:26:31,436 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38433'. Reason: nanny-close
2023-11-03 05:26:31,436 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:31,436 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:31,437 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42477. Reason: nanny-close
2023-11-03 05:26:31,437 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44965'. Reason: nanny-close
2023-11-03 05:26:31,437 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:31,437 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:31,437 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:31,437 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46043. Reason: nanny-close
2023-11-03 05:26:31,437 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40413'. Reason: nanny-close
2023-11-03 05:26:31,438 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:31,438 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33635. Reason: nanny-close
2023-11-03 05:26:31,438 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:31,438 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:31,438 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36225. Reason: nanny-close
2023-11-03 05:26:31,439 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:31,439 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:31,439 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:31,439 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:31,440 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:31,440 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:31,441 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:31,441 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:31,441 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:31,442 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:31,443 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-11-03 05:26:35,012 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:35,020 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34975 instead
  warnings.warn(
2023-11-03 05:26:35,027 - distributed.scheduler - INFO - State start
2023-11-03 05:26:35,063 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:35,064 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-03 05:26:35,064 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34975/status
2023-11-03 05:26:35,064 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-03 05:26:35,104 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41487'
2023-11-03 05:26:35,618 - distributed.scheduler - INFO - Receive client connection: Client-8cf1e4f0-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:35,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50980
2023-11-03 05:26:36,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:36,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:37,245 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:38,211 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39403
2023-11-03 05:26:38,212 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39403
2023-11-03 05:26:38,212 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-11-03 05:26:38,212 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:38,212 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:38,212 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:38,212 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-03 05:26:38,212 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aoswc9o0
2023-11-03 05:26:38,212 - distributed.worker - INFO - Starting Worker plugin PreImport-51d8b897-3bb2-433e-a10e-eb648bc8fc12
2023-11-03 05:26:38,213 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6ea92663-d8c8-4848-ae7a-7b11f95854a3
2023-11-03 05:26:38,213 - distributed.worker - INFO - Starting Worker plugin RMMSetup-727d86a3-89b3-4e5a-a6dc-14de1816cfbc
2023-11-03 05:26:38,214 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:38,254 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39403', status: init, memory: 0, processing: 0>
2023-11-03 05:26:38,255 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39403
2023-11-03 05:26:38,255 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51000
2023-11-03 05:26:38,257 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:38,258 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:38,258 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:38,261 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:38,266 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:26:38,269 - distributed.scheduler - INFO - Remove client Client-8cf1e4f0-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:38,270 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50980; closing.
2023-11-03 05:26:38,270 - distributed.scheduler - INFO - Remove client Client-8cf1e4f0-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:38,270 - distributed.scheduler - INFO - Close client connection: Client-8cf1e4f0-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:26:38,271 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41487'. Reason: nanny-close
2023-11-03 05:26:38,292 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:38,293 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39403. Reason: nanny-close
2023-11-03 05:26:38,296 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51000; closing.
2023-11-03 05:26:38,296 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:38,296 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39403', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989198.2968645')
2023-11-03 05:26:38,297 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:26:38,298 - distributed.nanny - INFO - Worker closed
2023-11-03 05:26:38,995 - distributed.scheduler - INFO - Receive client connection: Client-9055b737-7a09-11ee-90fa-d8c49764f6bb
2023-11-03 05:26:38,996 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51016
2023-11-03 05:26:39,588 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-03 05:26:39,589 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-03 05:26:39,589 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:26:39,590 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-03 05:26:39,591 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-11-03 05:26:43,665 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:43,669 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35537 instead
  warnings.warn(
2023-11-03 05:26:43,673 - distributed.scheduler - INFO - State start
2023-11-03 05:26:44,355 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:44,356 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-03 05:26:44,357 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:26:44,358 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-11-03 05:26:44,473 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40523'
2023-11-03 05:26:45,414 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40523'. Reason: nanny-close
2023-11-03 05:26:46,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:26:46,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:26:46,812 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:26:47,653 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33489
2023-11-03 05:26:47,654 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33489
2023-11-03 05:26:47,654 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45565
2023-11-03 05:26:47,654 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:26:47,654 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:47,654 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:26:47,654 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-03 05:26:47,654 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h3zbf3sa
2023-11-03 05:26:47,654 - distributed.worker - INFO - Starting Worker plugin PreImport-8af6c7c7-2bf7-449c-adcc-f2849ca90640
2023-11-03 05:26:47,655 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ae7f76b9-2a4a-4772-91db-a252c57fc668
2023-11-03 05:26:47,656 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c6d4f642-b527-4b38-8be3-d1c759c36869
2023-11-03 05:26:47,656 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:49,417 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:26:49,419 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:26:49,419 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:26:49,420 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:26:49,422 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:26:49,423 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33489. Reason: nanny-close
2023-11-03 05:26:49,426 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:26:49,428 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-11-03 05:26:52,273 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:52,277 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36667 instead
  warnings.warn(
2023-11-03 05:26:52,280 - distributed.scheduler - INFO - State start
2023-11-03 05:26:52,300 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:26:52,301 - distributed.scheduler - INFO - Scheduler closing due to failure-to-start-<class 'OSError'>...
2023-11-03 05:26:52,302 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:26:52,302 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 616, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3951, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 810, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 256, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 573, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 129, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 247, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 227, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 624, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-11-03 05:27:10,395 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:27:10,399 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38173 instead
  warnings.warn(
2023-11-03 05:27:10,402 - distributed.scheduler - INFO - State start
2023-11-03 05:27:10,426 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:27:10,427 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-11-03 05:27:10,428 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38173/status
2023-11-03 05:27:10,428 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-03 05:27:10,514 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38105'
2023-11-03 05:27:10,899 - distributed.scheduler - INFO - Receive client connection: Client-a2196ad7-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:10,913 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40824
2023-11-03 05:27:12,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:12,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:12,055 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:12,849 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35797
2023-11-03 05:27:12,850 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35797
2023-11-03 05:27:12,850 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36867
2023-11-03 05:27:12,850 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-03 05:27:12,850 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:12,850 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:12,850 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-03 05:27:12,850 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-8xw1eos5
2023-11-03 05:27:12,851 - distributed.worker - INFO - Starting Worker plugin PreImport-97822a43-badc-43d4-b1be-8e232e3bdc2d
2023-11-03 05:27:12,851 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0941cce1-2ebd-42e2-b397-e56afe96a03e
2023-11-03 05:27:12,851 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7cf5d24e-905d-44e3-bf39-a665c92eb6a8
2023-11-03 05:27:12,851 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:12,872 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35797', status: init, memory: 0, processing: 0>
2023-11-03 05:27:12,873 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35797
2023-11-03 05:27:12,873 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40850
2023-11-03 05:27:12,874 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:12,874 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-03 05:27:12,874 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:12,876 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-03 05:27:12,950 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:12,953 - distributed.scheduler - INFO - Remove client Client-a2196ad7-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:12,953 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40824; closing.
2023-11-03 05:27:12,953 - distributed.scheduler - INFO - Remove client Client-a2196ad7-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:12,953 - distributed.scheduler - INFO - Close client connection: Client-a2196ad7-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:12,954 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38105'. Reason: nanny-close
2023-11-03 05:27:12,955 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:12,956 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35797. Reason: nanny-close
2023-11-03 05:27:12,957 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-03 05:27:12,957 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40850; closing.
2023-11-03 05:27:12,958 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35797', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989232.9581084')
2023-11-03 05:27:12,958 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:27:12,959 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:13,820 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-03 05:27:13,820 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-03 05:27:13,821 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:27:13,822 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-11-03 05:27:13,822 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-11-03 05:27:15,795 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:27:15,799 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-11-03 05:27:15,802 - distributed.scheduler - INFO - State start
2023-11-03 05:27:15,822 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:27:15,823 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-03 05:27:15,823 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-11-03 05:27:15,824 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-03 05:27:15,924 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43251'
2023-11-03 05:27:15,935 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35961'
2023-11-03 05:27:15,942 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46795'
2023-11-03 05:27:15,956 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37157'
2023-11-03 05:27:15,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41813'
2023-11-03 05:27:15,968 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46667'
2023-11-03 05:27:15,976 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34669'
2023-11-03 05:27:15,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39429'
2023-11-03 05:27:17,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:17,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:17,561 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:17,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:17,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:17,857 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:17,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:17,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:17,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:17,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:17,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:17,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:17,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:17,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:17,861 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:17,862 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:17,864 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:17,864 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:17,865 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:17,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:17,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:17,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:17,869 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:17,872 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:18,286 - distributed.scheduler - INFO - Receive client connection: Client-a550385a-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:18,297 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47700
2023-11-03 05:27:19,233 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44855
2023-11-03 05:27:19,234 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44855
2023-11-03 05:27:19,234 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38465
2023-11-03 05:27:19,234 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:19,234 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:19,234 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:19,234 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:27:19,234 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mfy5wbil
2023-11-03 05:27:19,235 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-17def11f-d864-45ee-8d7c-ba1cbeeb6c50
2023-11-03 05:27:19,235 - distributed.worker - INFO - Starting Worker plugin PreImport-2bcbaa5e-fe4d-4555-be37-be3fc3e6b089
2023-11-03 05:27:19,239 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3abca3e0-0ec0-4e5a-9019-ccc3f1def1c3
2023-11-03 05:27:19,590 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:19,625 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44855', status: init, memory: 0, processing: 0>
2023-11-03 05:27:19,627 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44855
2023-11-03 05:27:19,627 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47708
2023-11-03 05:27:19,628 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:19,629 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:19,630 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:19,631 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:20,361 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38425
2023-11-03 05:27:20,362 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38425
2023-11-03 05:27:20,362 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40617
2023-11-03 05:27:20,362 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,362 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,362 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:20,362 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:27:20,363 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-25h43u43
2023-11-03 05:27:20,363 - distributed.worker - INFO - Starting Worker plugin PreImport-91852325-194b-432a-9638-06fd831b78ba
2023-11-03 05:27:20,363 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-df81cec3-a58b-4605-927b-338eb834f48f
2023-11-03 05:27:20,363 - distributed.worker - INFO - Starting Worker plugin RMMSetup-61d04155-ccce-4930-a7b1-2c6e101a28a0
2023-11-03 05:27:20,367 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40289
2023-11-03 05:27:20,367 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40289
2023-11-03 05:27:20,367 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43163
2023-11-03 05:27:20,367 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,368 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,368 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:20,368 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:27:20,368 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-esks1gob
2023-11-03 05:27:20,368 - distributed.worker - INFO - Starting Worker plugin PreImport-9df6d6e7-c3ff-4ad0-bf37-33a6ae9efcb9
2023-11-03 05:27:20,368 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-994cab10-2533-492d-8f67-166782f78ab3
2023-11-03 05:27:20,367 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38391
2023-11-03 05:27:20,369 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38391
2023-11-03 05:27:20,369 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32803
2023-11-03 05:27:20,369 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,369 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,369 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:20,369 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f96b9bee-f85b-4176-ba9a-35a52d23206c
2023-11-03 05:27:20,369 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:27:20,369 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-87k12rdc
2023-11-03 05:27:20,370 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c250a6d2-4b1f-4dec-aa9d-617249242cbe
2023-11-03 05:27:20,371 - distributed.worker - INFO - Starting Worker plugin PreImport-4ebe50be-48ee-49b7-853b-ebcf0c3d6a80
2023-11-03 05:27:20,371 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fed277df-a290-4e63-9c2e-8dddeacaa62c
2023-11-03 05:27:20,374 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45951
2023-11-03 05:27:20,375 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45951
2023-11-03 05:27:20,375 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39941
2023-11-03 05:27:20,375 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,375 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,375 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:20,376 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:27:20,376 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-42xw8g4x
2023-11-03 05:27:20,376 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-59d02825-631a-417a-918d-e1cfaa74c243
2023-11-03 05:27:20,376 - distributed.worker - INFO - Starting Worker plugin PreImport-11901125-64b1-47f3-a275-43a69eca1d94
2023-11-03 05:27:20,376 - distributed.worker - INFO - Starting Worker plugin RMMSetup-03f1038f-a6db-4ddd-b6ed-b6f7c38aa59c
2023-11-03 05:27:20,420 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43701
2023-11-03 05:27:20,421 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43701
2023-11-03 05:27:20,421 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40239
2023-11-03 05:27:20,421 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,421 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,421 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:20,422 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:27:20,422 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qk2hhiym
2023-11-03 05:27:20,422 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-76748709-cfce-473f-bedb-77e33bf5f8b3
2023-11-03 05:27:20,422 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45695
2023-11-03 05:27:20,423 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45695
2023-11-03 05:27:20,423 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38565
2023-11-03 05:27:20,423 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43863
2023-11-03 05:27:20,423 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,423 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,423 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43863
2023-11-03 05:27:20,423 - distributed.worker - INFO - Starting Worker plugin PreImport-b49567c4-de34-46a5-811b-904be30b9426
2023-11-03 05:27:20,424 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36179
2023-11-03 05:27:20,423 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:20,424 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,424 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6b3c9070-f1a3-42a2-a747-4febcfbec4ce
2023-11-03 05:27:20,424 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,424 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:27:20,424 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ophrq1ru
2023-11-03 05:27:20,424 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:20,424 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-03 05:27:20,424 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7pbip_ur
2023-11-03 05:27:20,424 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bd18edf3-e371-4807-97af-2dddc6769d7a
2023-11-03 05:27:20,424 - distributed.worker - INFO - Starting Worker plugin PreImport-f281493b-b333-4388-a408-03af5fa01b52
2023-11-03 05:27:20,424 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dbecd79c-78df-45e8-8b9b-ee73679c70f1
2023-11-03 05:27:20,424 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-740abb1e-981c-4b38-afd9-001fa8fba2af
2023-11-03 05:27:20,426 - distributed.worker - INFO - Starting Worker plugin PreImport-c95455b8-192a-4877-82c0-a0da8e5e1d0b
2023-11-03 05:27:20,426 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b0d78d05-e8fc-4cff-9f50-33707450a241
2023-11-03 05:27:20,534 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,534 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,534 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,534 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,537 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,547 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,550 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,562 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45951', status: init, memory: 0, processing: 0>
2023-11-03 05:27:20,563 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45951
2023-11-03 05:27:20,563 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58812
2023-11-03 05:27:20,563 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38391', status: init, memory: 0, processing: 0>
2023-11-03 05:27:20,564 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:20,564 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38391
2023-11-03 05:27:20,564 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58814
2023-11-03 05:27:20,564 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,565 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,565 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:20,566 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,566 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,566 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:20,568 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38425', status: init, memory: 0, processing: 0>
2023-11-03 05:27:20,568 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:20,568 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38425
2023-11-03 05:27:20,568 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58836
2023-11-03 05:27:20,569 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43701', status: init, memory: 0, processing: 0>
2023-11-03 05:27:20,570 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43701
2023-11-03 05:27:20,570 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58838
2023-11-03 05:27:20,570 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:20,570 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40289', status: init, memory: 0, processing: 0>
2023-11-03 05:27:20,571 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,571 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,571 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40289
2023-11-03 05:27:20,571 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58822
2023-11-03 05:27:20,571 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:20,572 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,572 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,572 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:20,573 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:20,574 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,574 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,575 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:20,576 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45695', status: init, memory: 0, processing: 0>
2023-11-03 05:27:20,576 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:20,576 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45695
2023-11-03 05:27:20,576 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58846
2023-11-03 05:27:20,577 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:20,578 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,578 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,579 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43863', status: init, memory: 0, processing: 0>
2023-11-03 05:27:20,579 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43863
2023-11-03 05:27:20,579 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58842
2023-11-03 05:27:20,579 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:20,580 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:20,581 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:20,581 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:20,583 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:20,652 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:27:20,653 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:27:20,653 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:27:20,653 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:27:20,653 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:27:20,653 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:27:20,653 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:27:20,653 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-03 05:27:20,666 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:20,666 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:20,666 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:20,666 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:20,666 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:20,666 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:20,666 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:20,666 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:20,670 - distributed.scheduler - INFO - Remove client Client-a550385a-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:20,670 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47700; closing.
2023-11-03 05:27:20,671 - distributed.scheduler - INFO - Remove client Client-a550385a-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:20,671 - distributed.scheduler - INFO - Close client connection: Client-a550385a-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:20,672 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43251'. Reason: nanny-close
2023-11-03 05:27:20,672 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:20,673 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35961'. Reason: nanny-close
2023-11-03 05:27:20,673 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:20,673 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43863. Reason: nanny-close
2023-11-03 05:27:20,674 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46795'. Reason: nanny-close
2023-11-03 05:27:20,674 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:20,674 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43701. Reason: nanny-close
2023-11-03 05:27:20,675 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37157'. Reason: nanny-close
2023-11-03 05:27:20,675 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:20,675 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38391. Reason: nanny-close
2023-11-03 05:27:20,675 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41813'. Reason: nanny-close
2023-11-03 05:27:20,676 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:20,676 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:20,676 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45951. Reason: nanny-close
2023-11-03 05:27:20,676 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58842; closing.
2023-11-03 05:27:20,676 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46667'. Reason: nanny-close
2023-11-03 05:27:20,676 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43863', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989240.6764903')
2023-11-03 05:27:20,676 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:20,676 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38425. Reason: nanny-close
2023-11-03 05:27:20,676 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:20,676 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34669'. Reason: nanny-close
2023-11-03 05:27:20,677 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:20,677 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:20,677 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40289. Reason: nanny-close
2023-11-03 05:27:20,677 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39429'. Reason: nanny-close
2023-11-03 05:27:20,677 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:20,677 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:20,678 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:20,678 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44855. Reason: nanny-close
2023-11-03 05:27:20,678 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58814; closing.
2023-11-03 05:27:20,678 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58838; closing.
2023-11-03 05:27:20,678 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:20,679 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45695. Reason: nanny-close
2023-11-03 05:27:20,679 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:20,679 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38391', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989240.6792622')
2023-11-03 05:27:20,679 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:20,679 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43701', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989240.67963')
2023-11-03 05:27:20,679 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:20,679 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58812; closing.
2023-11-03 05:27:20,680 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:20,680 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45951', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989240.6804059')
2023-11-03 05:27:20,680 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:20,681 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:20,681 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58836; closing.
2023-11-03 05:27:20,681 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58822; closing.
2023-11-03 05:27:20,681 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:20,681 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:20,682 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38425', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989240.68219')
2023-11-03 05:27:20,682 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40289', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989240.6826036')
2023-11-03 05:27:20,682 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:20,682 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47708; closing.
2023-11-03 05:27:20,683 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:20,683 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58846; closing.
2023-11-03 05:27:20,683 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44855', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989240.6834466')
2023-11-03 05:27:20,683 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45695', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989240.6838434')
2023-11-03 05:27:20,684 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:27:22,290 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-03 05:27:22,290 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-03 05:27:22,290 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:27:22,291 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-03 05:27:22,292 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-11-03 05:27:24,537 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:27:24,542 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-11-03 05:27:24,546 - distributed.scheduler - INFO - State start
2023-11-03 05:27:24,936 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:27:24,937 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-03 05:27:24,937 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-11-03 05:27:24,938 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-03 05:27:25,029 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33713'
2023-11-03 05:27:26,228 - distributed.scheduler - INFO - Receive client connection: Client-aa6e0bf3-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:26,238 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58972
2023-11-03 05:27:26,890 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:26,890 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:26,894 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:27,941 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35065
2023-11-03 05:27:27,942 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35065
2023-11-03 05:27:27,942 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40387
2023-11-03 05:27:27,942 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:27,942 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:27,942 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:27,942 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-03 05:27:27,943 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w2fblm_a
2023-11-03 05:27:27,943 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bdbcb173-18bd-4fc0-ace9-937443c25c22
2023-11-03 05:27:27,943 - distributed.worker - INFO - Starting Worker plugin PreImport-6cc44b9d-a839-477f-8efd-391132fd86dc
2023-11-03 05:27:27,944 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3e6ba21c-0860-4ad6-a911-59dd21a56090
2023-11-03 05:27:28,036 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:28,062 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35065', status: init, memory: 0, processing: 0>
2023-11-03 05:27:28,063 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35065
2023-11-03 05:27:28,063 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58988
2023-11-03 05:27:28,064 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:28,065 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:28,065 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:28,067 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:28,076 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:27:28,079 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:28,081 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:28,083 - distributed.scheduler - INFO - Remove client Client-aa6e0bf3-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:28,083 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58972; closing.
2023-11-03 05:27:28,083 - distributed.scheduler - INFO - Remove client Client-aa6e0bf3-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:28,084 - distributed.scheduler - INFO - Close client connection: Client-aa6e0bf3-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:28,085 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33713'. Reason: nanny-close
2023-11-03 05:27:28,114 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:28,115 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35065. Reason: nanny-close
2023-11-03 05:27:28,116 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:28,116 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58988; closing.
2023-11-03 05:27:28,117 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35065', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989248.1171532')
2023-11-03 05:27:28,117 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:27:28,118 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:29,100 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-03 05:27:29,101 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-03 05:27:29,101 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:27:29,102 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-03 05:27:29,103 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-11-03 05:27:31,171 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:27:31,176 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46127 instead
  warnings.warn(
2023-11-03 05:27:31,179 - distributed.scheduler - INFO - State start
2023-11-03 05:27:31,201 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-03 05:27:31,202 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-03 05:27:31,203 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46127/status
2023-11-03 05:27:31,203 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-03 05:27:31,232 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39753'
2023-11-03 05:27:32,715 - distributed.scheduler - INFO - Receive client connection: Client-ae6dd36f-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:32,729 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60702
2023-11-03 05:27:33,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-03 05:27:33,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-03 05:27:33,052 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-03 05:27:35,411 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43817
2023-11-03 05:27:35,412 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43817
2023-11-03 05:27:35,412 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37059
2023-11-03 05:27:35,412 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-03 05:27:35,412 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:35,412 - distributed.worker - INFO -               Threads:                          1
2023-11-03 05:27:35,412 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-03 05:27:35,412 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-talhbutj
2023-11-03 05:27:35,413 - distributed.worker - INFO - Starting Worker plugin PreImport-8bf4a91b-28b4-4bda-8869-f55b8cb6ebb0
2023-11-03 05:27:35,413 - distributed.worker - INFO - Starting Worker plugin RMMSetup-83640ea6-7ba0-4221-97b2-28f94b2a28fa
2023-11-03 05:27:35,517 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-57849991-0222-4e16-8f7f-86caa707f8a1
2023-11-03 05:27:35,518 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:35,547 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43817', status: init, memory: 0, processing: 0>
2023-11-03 05:27:35,549 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43817
2023-11-03 05:27:35,549 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:60728
2023-11-03 05:27:35,550 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-03 05:27:35,551 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-03 05:27:35,551 - distributed.worker - INFO - -------------------------------------------------
2023-11-03 05:27:35,554 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-03 05:27:35,590 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-11-03 05:27:35,595 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-03 05:27:35,599 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:35,600 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-03 05:27:35,603 - distributed.scheduler - INFO - Remove client Client-ae6dd36f-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:35,603 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60702; closing.
2023-11-03 05:27:35,603 - distributed.scheduler - INFO - Remove client Client-ae6dd36f-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:35,604 - distributed.scheduler - INFO - Close client connection: Client-ae6dd36f-7a09-11ee-913e-d8c49764f6bb
2023-11-03 05:27:35,605 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39753'. Reason: nanny-close
2023-11-03 05:27:35,605 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-03 05:27:35,606 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43817. Reason: nanny-close
2023-11-03 05:27:35,608 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:60728; closing.
2023-11-03 05:27:35,609 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-03 05:27:35,609 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43817', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1698989255.6092024')
2023-11-03 05:27:35,609 - distributed.scheduler - INFO - Lost all workers
2023-11-03 05:27:35,610 - distributed.nanny - INFO - Worker closed
2023-11-03 05:27:36,671 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-03 05:27:36,672 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-03 05:27:36,672 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-03 05:27:36,673 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-03 05:27:36,674 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34583 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37993 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43015 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46639 instead
  warnings.warn(
2023-11-03 05:28:23,880 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-03 05:28:23,882 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-03 05:28:23,883 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:60081', name: 5, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-03 05:28:23,883 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-03 05:28:23,886 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:58169', name: 3, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-03 05:28:23,886 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:50325', name: 0, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41693 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42425 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33045 instead
  warnings.warn(
2023-11-03 05:29:01,005 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-03 05:29:01,008 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:52369', name: 6, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43497 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45923 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46461 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36925 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41765 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] [1698989572.312734] [dgx13:63278:0]            sock.c:470  UCX  ERROR bind(fd=159 addr=0.0.0.0:46288) failed: Address already in use
[1698989572.313093] [dgx13:63278:0]            sock.c:470  UCX  ERROR bind(fd=161 addr=0.0.0.0:37790) failed: Address already in use
[1698989573.762257] [dgx13:63450:0]            sock.c:470  UCX  ERROR bind(fd=122 addr=0.0.0.0:36024) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35351 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46831 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44335 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33765 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45413 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41807 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46189 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45643 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37659 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42429 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42613 instead
  warnings.warn(
[1698989873.685307] [dgx13:68687:0]            sock.c:470  UCX  ERROR bind(fd=135 addr=0.0.0.0:38569) failed: Address already in use
2023-11-03 05:38:02,532 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-f73efbd5-2871-4b91-b47e-81977d8651f3
Function:  _run_coroutine_on_worker
args:      (227033009446310295861918819065406554892, <function shuffle_task at 0x7fba74cc3160>, ('explicit-comms-shuffle-8a9c181b2d24bc345fc4f6aca80171aa', {0: {('from_pandas-eaba71b388f24e387b93842f216e4045', 4), ('from_pandas-eaba71b388f24e387b93842f216e4045', 0)}, 1: {('from_pandas-eaba71b388f24e387b93842f216e4045', 2)}, 2: {('from_pandas-eaba71b388f24e387b93842f216e4045', 1)}, 3: {('from_pandas-eaba71b388f24e387b93842f216e4045', 3)}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')"

2023-11-03 05:38:02,532 - distributed.worker - WARNING - Compute Failed
Key:       _run_coroutine_on_worker-0a17ffc0-191d-4f87-a97f-1ecddfdde147
Function:  _run_coroutine_on_worker
args:      (227033009446310295861918819065406554892, <function shuffle_task at 0x7fdad9184040>, ('explicit-comms-shuffle-8a9c181b2d24bc345fc4f6aca80171aa', {0: {('from_pandas-eaba71b388f24e387b93842f216e4045', 4), ('from_pandas-eaba71b388f24e387b93842f216e4045', 0)}, 1: {('from_pandas-eaba71b388f24e387b93842f216e4045', 2)}, 2: {('from_pandas-eaba71b388f24e387b93842f216e4045', 1)}, 3: {('from_pandas-eaba71b388f24e387b93842f216e4045', 3)}}, {0: {0, 4}, 1: {1}, 2: {2}, 3: {3}}, ['key'], 5, False, 2, 1))
kwargs:    {}
Exception: "CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 24 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
