2023-03-17 00:59:45,486 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 00:59:45,486 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-03-17 00:59:45,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 00:59:45,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-03-17 00:59:45,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 00:59:45,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-03-17 00:59:45,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 00:59:45,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-03-17 00:59:45,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 00:59:45,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-03-17 00:59:45,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 00:59:45,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-03-17 00:59:45,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 00:59:45,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-03-17 00:59:45,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 00:59:45,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[1679039995.374181] [dgx13:57474:0]    ib_mlx5dv_md.c:462  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:57474:0:57474]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  57474) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7fc36122a4f4]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0xb8) [0x7fc361227498]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2b579) [0x7fc361227579]
 3  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(+0x7e375) [0x7fc3614de375]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7fc3614b3d0f]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1c) [0x7fc3614f8bbc]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x761) [0x7fc3614fdbb1]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4e) [0x7fc3614fd32e]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x81fda) [0x7fc3617c8fda]
 9  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyCFunction_Call+0x52) [0x55b566e26052]
10  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55b566e0e178]
11  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b566e072f1]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b566e1893c]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55b566e0953f]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b566e072f1]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b566e1893c]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55b566e0953f]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55b566e2d1e8]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55b566e0d202]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55b566e2d1e8]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55b566e0d202]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55b566e2d1e8]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55b566e0d202]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55b566e2d1e8]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55b566e0d202]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55b566e2d1e8]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55b566e0d202]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55b566e2d1e8]
28  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7fc371495003]
29  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x77f3) [0x7fc3714957f3]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x55b566e1130b]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x55b566dcfb07]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x55b566e0ff96]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x55b566e261ea]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55b566e0e178]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b566e188a6]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b566e08a55]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b566e188a6]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b566e08a55]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b566e188a6]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b566e08a55]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b566e188a6]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b566e08a55]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b566e072f1]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b566e1893c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x55b566e0cefb]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b566e072f1]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b566e1893c]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55b566e25e8c]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x55b566e10a92]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x55b566edd049]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x55b566e28283]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55b566e0a3de]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b566e188a6]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55b566e25e8c]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55b566e281fa]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55b566e0a3de]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b566e188a6]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b566e08a55]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b566e072f1]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b566e1893c]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b566e08a55]
=================================
Task exception was never retrieved
future: <Task finished name='Task-1033' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-986' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-03-17 00:59:55,576 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45605
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7ffab4009280, tag: 0x418c144b18a2336d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7ffab4009280, tag: 0x418c144b18a2336d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-03-17 00:59:55,745 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45605
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f7580e4a240, tag: 0x85e23df502706909, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f7580e4a240, tag: 0x85e23df502706909, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-03-17 00:59:55,785 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45605
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #007] ep: 0x7fe200000200, tag: 0x2a712483fd0658b0, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #007] ep: 0x7fe200000200, tag: 0x2a712483fd0658b0, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
Task exception was never retrieved
future: <Task finished name='Task-1047' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-03-17 00:59:55,866 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45605
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f8f9a3e21c0, tag: 0x675dbe726a9d06bf, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 494, in wait_for
    return fut.result()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f8f9a3e21c0, tag: 0x675dbe726a9d06bf, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2885, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:45605 after 30 s
Task exception was never retrieved
future: <Task finished name='Task-1144' coro=<_listener_handler_coroutine() done, defined at /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-03-17 00:59:56,220 - distributed.nanny - WARNING - Restarting worker
2023-03-17 00:59:58,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 00:59:58,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-03-17 01:00:24,654 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45605
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXNotConnected: <stream_recv>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 494, in wait_for
    return fut.result()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2885, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:45605 after 30 s
2023-03-17 01:00:24,660 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:45605
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXNotConnected: <stream_recv>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 494, in wait_for
    return fut.result()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2885, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:45605 after 30 s
2023-03-17 01:00:39,912 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48080
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f7580e4a140, tag: 0xc75cb202b27433d9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f7580e4a140, tag: 0xc75cb202b27433d9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-03-17 01:00:40,432 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48080
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f8f9a3e2140, tag: 0x255af82898a5104b, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f8f9a3e2140, tag: 0x255af82898a5104b, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-03-17 01:00:40,617 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46966 -> ucx://127.0.0.1:48080
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #012] ep: 0x7ffab4009400, tag: 0x450f9b2989cb1994, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1790, in get_data
    response = await comm.read(deserializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #012] ep: 0x7ffab4009400, tag: 0x450f9b2989cb1994, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-03-17 01:00:40,617 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48080
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7fe200000100, tag: 0x600469ce09cbb11e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7fe200000100, tag: 0x600469ce09cbb11e, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-03-17 01:00:40,618 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48080
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #019] ep: 0x7f1d44e86180, tag: 0xf35fbaedf43e2785, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #019] ep: 0x7f1d44e86180, tag: 0xf35fbaedf43e2785, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
[1679040041.379601] [dgx13:57495:0]    ib_mlx5dv_md.c:462  UCX  ERROR mlx5_3: LRU push returned Unsupported operation
[dgx13:57495:0:57495]        rndv.c:165  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  57495) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7f1d858544f4]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0xb8) [0x7f1d85851498]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2b579) [0x7f1d85851579]
 3  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(+0x7e375) [0x7f1d85b08375]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f1d85addd0f]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1c) [0x7f1d85b22bbc]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x761) [0x7f1d85b27bb1]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4e) [0x7f1d85b2732e]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x81fda) [0x7f1d85df2fda]
 9  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyCFunction_Call+0x52) [0x55e9630cc052]
10  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55e9630b4178]
11  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55e9630ad2f1]
12  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55e9630be93c]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55e9630af53f]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55e9630ad2f1]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55e9630be93c]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55e9630af53f]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55e9630d31e8]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55e9630b3202]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55e9630d31e8]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55e9630b3202]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55e9630d31e8]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55e9630b3202]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55e9630d31e8]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55e9630b3202]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55e9630d31e8]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e82) [0x55e9630b3202]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x55e9630d31e8]
28  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7f1d95a9e003]
29  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x77f3) [0x7f1d95a9e7f3]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x55e9630b730b]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x55e963075b07]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x55e9630b5f96]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x55e9630cc1ea]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55e9630b4178]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55e9630be8a6]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55e9630aea55]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55e9630be8a6]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55e9630aea55]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55e9630be8a6]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55e9630aea55]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55e9630be8a6]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55e9630aea55]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55e9630ad2f1]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55e9630be93c]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x55e9630b2efb]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55e9630ad2f1]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55e9630be93c]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55e9630cbe8c]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x55e9630b6a92]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x55e963183049]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x55e9630ce283]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55e9630b03de]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55e9630be8a6]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55e9630cbe8c]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55e9630ce1fa]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55e9630b03de]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55e9630be8a6]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55e9630aea55]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55e9630ad2f1]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55e9630be93c]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55e9630aea55]
=================================
2023-03-17 01:00:41,597 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37295
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #032] ep: 0x7fe2000001c0, tag: 0xf54596e082a56df0, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #032] ep: 0x7fe2000001c0, tag: 0xf54596e082a56df0, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-03-17 01:00:41,598 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37295
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #027] ep: 0x7f8f9a3e2240, tag: 0x1579f0f30032bec5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #027] ep: 0x7f8f9a3e2240, tag: 0x1579f0f30032bec5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-03-17 01:00:41,598 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37295
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #027] ep: 0x7f7580e4a200, tag: 0x41bdca97e526df2d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #027] ep: 0x7f7580e4a200, tag: 0x41bdca97e526df2d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-03-17 01:00:41,600 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37295
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #024] ep: 0x7fc051420180, tag: 0xbe7333932358852f, nbytes: 99977344, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #024] ep: 0x7fc051420180, tag: 0xbe7333932358852f, nbytes: 99977344, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-03-17 01:00:41,651 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37295
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #046] ep: 0x7ffab4009240, tag: 0xa4cd9f008d54b69a, nbytes: 100004448, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #046] ep: 0x7ffab4009240, tag: 0xa4cd9f008d54b69a, nbytes: 100004448, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-03-17 01:00:42,301 - distributed.nanny - WARNING - Restarting worker
2023-03-17 01:00:44,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-03-17 01:00:44,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-03-17 01:00:53,062 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-102fe9551a3aaf122c38ba2afe556bbf', 1)
Function:  subgraph_callable-2bc5d2b2-1ae6-4442-b362-42b7788a
args:      (               key   payload
shuffle                     
0           227636   3043095
0           181050  99411771
0           186099  94266054
0           129170  72013305
0           784760  51748821
...            ...       ...
7        799968836  47067762
7        799999690  40889943
7        799909998  64644105
7        799976973   7190833
7        799999710  49055398

[100005187 rows x 2 columns],                  key   payload
11397      853270254  11449536
31801      816397419  82810017
11402      825217534  21086548
11407      830760261  34873350
11408      818009762  49076612
...              ...       ...
99998655  1550760382  66995007
99998688    93791337  48346623
99998691  1559724843  36492139
99998699  1543291741  11283834
99998706   291443011  30627853

[99996328 rows x 2 columns])
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /datasets/pentschev/miniconda3/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')"

2023-03-17 01:00:53,194 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-102fe9551a3aaf122c38ba2afe556bbf', 7)
Function:  subgraph_callable-2bc5d2b2-1ae6-4442-b362-42b7788a
args:      (               key   payload
shuffle                     
0           241536  39917173
0           222673  99936646
0           230563  52324906
0           722908  28143246
0           746372  25476949
...            ...       ...
7        799979704  55029473
7        799970304  80312547
7        799923842  78865760
7        799970305  76690724
7        799925440  39967781

[100001353 rows x 2 columns],                  key   payload
11406      826442993  14911233
31783      853630633  89204134
11417      826337630  20681154
31784      411607621  87845027
31786      603970846  86214391
...              ...       ...
99998623   594492805  71592438
99998647   399587589  60473655
99998692   296457427  84292315
99998695  1502364940  22372362
99998716  1519941350  31579534

[99993358 rows x 2 columns])
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/datasets/pentschev/miniconda3/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:195: Maximum pool size exceeded')"

2023-03-17 01:00:53,396 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/datasets/pentschev/miniconda3/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:195: Maximum pool size exceeded
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/datasets/pentschev/miniconda3/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:195: Maximum pool size exceeded
2023-03-17 01:00:53,396 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/datasets/pentschev/miniconda3/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:195: Maximum pool size exceeded
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2888, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/datasets/pentschev/miniconda3/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:195: Maximum pool size exceeded
2023-03-17 01:00:55,025 - distributed.nanny - WARNING - Worker process still alive after 3.1999992370605472 seconds, killing
2023-03-17 01:01:11,606 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:37295
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXNotConnected: <stream_recv>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/asyncio/tasks.py", line 494, in wait_for
    return fut.result()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2063, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2885, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/core.py", line 318, in connect
    raise OSError(
OSError: Timed out trying to connect to ucx://127.0.0.1:37295 after 30 s
/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 42 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
