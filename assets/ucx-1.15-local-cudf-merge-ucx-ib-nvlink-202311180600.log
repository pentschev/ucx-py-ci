/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44453 instead
  warnings.warn(
[1700290734.600799] [dgx13:85536:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:85536:0:85536]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  85536) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f194cac707d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f194cac4c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f194cac4dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f194cb6f9f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f194cb46d8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f194cb82afd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f194cb879ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f194cb8872f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f194cc366f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x559a2fd6644c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x559a2fd4b6fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559a2fd47094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559a2fd58519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x559a2fd49128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559a2fd47094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559a2fd58519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x559a2fd49128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559a2fdfb162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559a2fd4de64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559a2fdfb162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559a2fd4de64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559a2fdfb162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559a2fd4de64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559a2fdfb162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559a2fd4de64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559a2fdfb162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x559a2fd4de64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x559a2fdfb162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f19d5e591e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f19d5e59aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x559a2fd5077c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x559a2fd02d05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x559a2fd4f7f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x559a2fd4d929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559a2fd587c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559a2fd485c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559a2fd587c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559a2fd485c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559a2fd587c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559a2fd485c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559a2fd587c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559a2fd485c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559a2fd47094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559a2fd58519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x559a2fd49128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559a2fd47094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x559a2fd65ccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x559a2fd6644c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x559a2fe2910e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x559a2fd5077c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x559a2fd4b6fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559a2fd587c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x559a2fd65dac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x559a2fd4b6fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559a2fd587c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559a2fd485c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559a2fd47094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x559a2fd58519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x559a2fd485c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x559a2fd587c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x559a2fd48312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x559a2fd47094]
=================================
2023-11-18 06:58:57,792 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39814
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7f3a703301c0, tag: 0x33b04c8355e5dc83, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7f3a703301c0, tag: 0x33b04c8355e5dc83, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 06:58:57,792 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39814
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #032] ep: 0x7f6c7097a1c0, tag: 0xacbdd10a99a47268, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #032] ep: 0x7f6c7097a1c0, tag: 0xacbdd10a99a47268, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 06:58:57,791 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39814
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #029] ep: 0x7f9f6c010180, tag: 0xff4977e62fb535f7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #029] ep: 0x7f9f6c010180, tag: 0xff4977e62fb535f7, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-18 06:58:57,791 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39814
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7f011c73d140, tag: 0xc780fe3ba9ffcf3f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7f011c73d140, tag: 0xc780fe3ba9ffcf3f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 06:58:57,792 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39814
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7f83cc9381c0, tag: 0x2226ba1df59c9feb, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7f83cc9381c0, tag: 0x2226ba1df59c9feb, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 06:58:57,791 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39814
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7f606000e140, tag: 0x43c226bfd92dc7f8, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7f606000e140, tag: 0x43c226bfd92dc7f8, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 06:58:57,792 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:39814
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #025] ep: 0x7fdc85fe0140, tag: 0x3b403c06036e2a3d, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #025] ep: 0x7fdc85fe0140, tag: 0x3b403c06036e2a3d, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
[1700290738.751197] [dgx13:85531:0]    ib_mlx5dv_md.c:468  UCX  ERROR mlx5_1: LRU push returned Unsupported operation
[dgx13:85531:0:85531]        rndv.c:166  Fatal: failed to pack rendezvous remote key: Unsupported operation
==== backtrace (tid:  85531) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f01339b407d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7f01339b1c21]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x27dbc) [0x7f01339b1dbc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(+0x739f8) [0x7f0133a5c9f8]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_do_am_single+0xdf) [0x7f0133a33d8f]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_proto_progress_tag_rndv_rts+0x1d) [0x7f0133a6fafd]
 6  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nbx+0x6da) [0x7f0133a749ea]
 7  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_send_nb+0x4f) [0x7f0133a7572f]
 8  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x6c6f0) [0x7f0133b236f0]
 9  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55800d01344c]
10  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55800cff86fb]
11  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55800cff4094]
12  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55800d005519]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55800cff6128]
14  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55800cff4094]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55800d005519]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55800cff6128]
17  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55800d0a8162]
18  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55800cffae64]
19  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55800d0a8162]
20  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55800cffae64]
21  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55800d0a8162]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55800cffae64]
23  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55800d0a8162]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55800cffae64]
25  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55800d0a8162]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f34) [0x55800cffae64]
27  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x55800d0a8162]
28  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f01d0c161e9]
29  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8aa6) [0x7f01d0c16aa6]
30  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55800cffd77c]
31  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55800cfafd05]
32  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55800cffc7f3]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55800cffa929]
34  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55800d0057c2]
35  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55800cff55c6]
36  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55800d0057c2]
37  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55800cff55c6]
38  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55800d0057c2]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55800cff55c6]
40  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55800d0057c2]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55800cff55c6]
42  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55800cff4094]
43  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55800d005519]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55800cff6128]
45  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55800cff4094]
46  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55800d012ccb]
47  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55800d01344c]
48  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55800d0d610e]
49  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55800cffd77c]
50  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55800cff86fb]
51  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55800d0057c2]
52  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55800d012dac]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55800cff86fb]
54  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55800d0057c2]
55  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55800cff55c6]
56  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55800cff4094]
57  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55800d005519]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55800cff55c6]
59  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55800d0057c2]
60  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55800cff5312]
61  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55800cff4094]
=================================
2023-11-18 06:59:02,173 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54923
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #052] ep: 0x7f6c7097a280, tag: 0xe4edf45c4be57ea6, nbytes: 100028872, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #052] ep: 0x7f6c7097a280, tag: 0xe4edf45c4be57ea6, nbytes: 100028872, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-18 06:59:02,173 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54923
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #046] ep: 0x7f3a70330140, tag: 0x3356cf1f4f049c45, nbytes: 99968864, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #046] ep: 0x7f3a70330140, tag: 0x3356cf1f4f049c45, nbytes: 99968864, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-18 06:59:02,173 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54923
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #060] ep: 0x7f606000e100, tag: 0x39e844528e886ad3, nbytes: 99954360, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #060] ep: 0x7f606000e100, tag: 0x39e844528e886ad3, nbytes: 99954360, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-18 06:59:02,173 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54923
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #047] ep: 0x7f9f6c010100, tag: 0xd911fd233fd9f283, nbytes: 99981592, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #047] ep: 0x7f9f6c010100, tag: 0xd911fd233fd9f283, nbytes: 99981592, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-18 06:59:02,174 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54923
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #048] ep: 0x7fdc85fe0100, tag: 0xa939161216695a0e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #048] ep: 0x7fdc85fe0100, tag: 0xa939161216695a0e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-11-18 06:59:02,174 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54923
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #053] ep: 0x7f83cc938280, tag: 0x469259706da2e16e, nbytes: 100059872, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #053] ep: 0x7f83cc938280, tag: 0x469259706da2e16e, nbytes: 100059872, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-11-18 06:59:02,382 - distributed.nanny - WARNING - Restarting worker
2023-11-18 06:59:03,375 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  _concat
args:      ([                key   payload
103053    807786036   4264616
103059    509062674  61189718
23105     401280486  48221798
103060    834361200  88466956
23119     842998068  95654573
...             ...       ...
99993056  828279077  27495179
99993057  302352586   7948883
99993062  709081526  23022687
99993085  809244562  36369367
99993086  407123090  79176741

[12497796 rows x 2 columns],                 key   payload
73249     516297088  35296400
23247     905849361   3182779
73253     953758954  18427141
23251     119373453   1335066
73270     930169196  66015422
...             ...       ...
99992872  949887748  70140622
99992874  223138379  48510313
99992875  929825909  29431789
99992879  964062667  83066447
99992886  911959469  98888890

[12497151 rows x 2 columns],                  key   payload
8403      1049069520  73154722
64227      637016962  91465759
8410      1052414173  77375646
84584     1053742638  91208300
8411      1026587310   4558470
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-11-18 06:59:06,058 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  _concat
args:      ([                key   payload
43015     851032910  59566571
43024     836076219   1471704
52418     850289617  49431465
43026       8010999  35349673
31915     813045907  71912211
...             ...       ...
99980611  866900140  72061928
99980614  861474875  55689830
99980627  856557183  45553454
99980632  859007565  87307453
99980596  849113791  24064406

[12497796 rows x 2 columns],                 key   payload
63554     903048654  57843484
84069     935465891  32471365
41601      16543983  41709201
63555     907474590  16151269
41612     118974512  31669982
...             ...       ...
99998047  119168479  18819904
99997962  926906387  18071901
99997971  717944019  25840093
99997972  910304969  61136189
99997978  619162169  28322010

[12497151 rows x 2 columns],                  key   payload
31780     1038548995  23423011
31789     1001254597   6370510
31806     1050859104  10059434
52832     1020698935  58245953
52839      531405566  96319063
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-11-18 06:59:06,121 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2023-11-18 06:59:06,121 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2023-11-18 06:59:06,248 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 7)
Function:  _concat
args:      ([               key   payload
shuffle                     
0          1156258  45724689
0          1128605  83876433
0          1123564  72007882
0          1105557  28186337
0          1091592  45580900
...            ...       ...
0        799941129  26216997
0        799980529  57384937
0        799992905  28594731
0        799850015  37588263
0        799920807  77062350

[12498151 rows x 2 columns],                key   payload
shuffle                     
1           299646  78951906
1           630264   7254368
1           101124  35483292
1           393432  86074925
1           630816  66205741
...            ...       ...
1        799956236  28566459
1        799836683  47200821
1        799989683  80316499
1        799946474  51898060
1        799849165  30853089

[12498591 rows x 2 columns],                key   payload
shuffle                     
2            12939  41225955
2            22230  35475341
2           141826  29926049
2           135980  81358981
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-11-18 06:59:06,318 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2023-11-18 06:59:06,318 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2023-11-18 06:59:06,391 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-adccb87e3fee0e0ff9c5206a34e9fe09', 4)
Function:  subgraph_callable-a8f36fbb-1d3d-40e6-883c-0e7bf06f
args:      (               key   payload
shuffle                     
0          1144945  64297591
0          1125558  48621681
0          1140891  49015914
0          1002780  63627456
0          1118904  23151544
...            ...       ...
7        799966745  22574389
7        799924764  95648777
7        799861273  14968819
7        799862307  36691361
7        799895107  87365879

[100023899 rows x 2 columns],                  key   payload
43008      510417057  23754948
43010      805375978  69199776
52416      814810013  88407381
43013      307954517  21490608
31910      833069741  40986150
...              ...       ...
99976164  1528710477  17577258
99976179   396419906  56427399
99976049  1550691998  95306532
99976055  1555500551  71746866
99976063  1521920054  31765008

[99980499 rows x 2 columns], 'simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

2023-11-18 06:59:07,278 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
