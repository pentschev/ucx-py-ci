2023-05-28 07:11:24,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5n5rx2aw', purging
2023-05-28 07:11:24,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:24,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:24,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:24,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:24,538 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:24,538 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:24,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:24,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:24,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:24,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:24,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:24,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:24,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:24,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:24,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:24,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:26,601 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:26,629 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:26,678 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:26,707 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:26,736 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:26,758 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:26,783 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:26,959 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:27,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kl9bunkv', purging
2023-05-28 07:11:27,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r_bm4ykn', purging
2023-05-28 07:11:27,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zc4b570t', purging
2023-05-28 07:11:27,992 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_xf9911t', purging
2023-05-28 07:11:27,992 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hyyhlk2n', purging
2023-05-28 07:11:27,992 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b85nkdq3', purging
2023-05-28 07:11:27,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-538i1jlm', purging
2023-05-28 07:11:27,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-je4q9u8f', purging
2023-05-28 07:11:27,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:27,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:28,172 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:28,172 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:28,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:28,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:28,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:28,209 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:28,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:28,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:28,255 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:28,255 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:28,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:28,302 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:28,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:28,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:30,171 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:30,242 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:30,270 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:30,300 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:30,344 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:30,345 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:30,364 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:30,653 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:31,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zelx5bra', purging
2023-05-28 07:11:31,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xllmzjfb', purging
2023-05-28 07:11:31,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4_m1uqlp', purging
2023-05-28 07:11:31,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h_sihevy', purging
2023-05-28 07:11:31,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7t61fm8_', purging
2023-05-28 07:11:31,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l93vq6na', purging
2023-05-28 07:11:31,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s4e_dmra', purging
2023-05-28 07:11:31,755 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hk66ifxh', purging
2023-05-28 07:11:31,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:31,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:31,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:31,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:31,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:31,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:31,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:31,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:31,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:31,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:31,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:31,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:31,927 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:31,927 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:32,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:32,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:33,954 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:33,995 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:34,033 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:34,059 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:34,086 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:34,109 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:34,137 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:34,318 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:35,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xv2apalb', purging
2023-05-28 07:11:35,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-annhgf12', purging
2023-05-28 07:11:35,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-31g7tvjb', purging
2023-05-28 07:11:35,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k2el6ws8', purging
2023-05-28 07:11:35,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dqk0o0nd', purging
2023-05-28 07:11:35,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6rw39iy', purging
2023-05-28 07:11:35,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c8s2uuw8', purging
2023-05-28 07:11:35,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cl3zflo_', purging
2023-05-28 07:11:35,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:35,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:35,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:35,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:35,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:35,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:35,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:35,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:35,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:35,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:35,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:35,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:35,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:35,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:35,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:35,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:37,750 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:37,773 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:37,832 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:37,855 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:37,877 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:37,903 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:37,927 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:38,089 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:39,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qik5f_27', purging
2023-05-28 07:11:39,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r5p5uvew', purging
2023-05-28 07:11:39,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vwvquzbb', purging
2023-05-28 07:11:39,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gld0mkoz', purging
2023-05-28 07:11:39,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mwadg8wq', purging
2023-05-28 07:11:39,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vcu6_lnf', purging
2023-05-28 07:11:39,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yaum8vqh', purging
2023-05-28 07:11:39,229 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hbgkd0b2', purging
2023-05-28 07:11:39,230 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:39,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:39,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:39,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:39,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:39,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:39,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:39,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:39,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:39,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:39,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:39,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:39,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:39,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:39,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:39,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:41,409 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:41,444 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:41,499 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:41,521 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:41,547 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:41,573 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:41,598 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:41,768 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:42,846 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_raa6kb5', purging
2023-05-28 07:11:42,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-moboqc88', purging
2023-05-28 07:11:42,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jwlxwujb', purging
2023-05-28 07:11:42,847 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eqylz1qm', purging
2023-05-28 07:11:42,848 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gi1w1qwl', purging
2023-05-28 07:11:42,848 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzms9q64', purging
2023-05-28 07:11:42,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jlod0rdg', purging
2023-05-28 07:11:42,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bwl__6ut', purging
2023-05-28 07:11:42,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:42,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:42,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:42,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:43,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:43,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:43,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:43,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:43,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:43,056 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:43,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:43,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:43,128 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:43,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:43,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:43,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:45,022 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:45,068 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:45,115 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:45,140 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:45,166 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:45,193 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:45,220 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:45,491 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:46,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mleia7yv', purging
2023-05-28 07:11:46,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ghx4gv_k', purging
2023-05-28 07:11:46,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tf938lkz', purging
2023-05-28 07:11:46,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q4c_lo6n', purging
2023-05-28 07:11:46,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3hra_wi1', purging
2023-05-28 07:11:46,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1s113y9_', purging
2023-05-28 07:11:46,490 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8xv_ikjl', purging
2023-05-28 07:11:46,490 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m0bfk88j', purging
2023-05-28 07:11:46,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:46,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:46,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:46,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:46,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:46,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:46,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:46,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:46,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:46,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:46,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:46,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:46,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:46,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:47,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:47,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:48,528 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:48,550 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:48,751 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:48,778 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:48,832 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:48,833 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:48,859 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:49,125 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:50,086 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nob01cky', purging
2023-05-28 07:11:50,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wpslhpzi', purging
2023-05-28 07:11:50,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-etfv4s8c', purging
2023-05-28 07:11:50,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-206c5lgh', purging
2023-05-28 07:11:50,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e9z20tih', purging
2023-05-28 07:11:50,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-obp9e9cx', purging
2023-05-28 07:11:50,089 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ai3o4fxy', purging
2023-05-28 07:11:50,089 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jtsedt1i', purging
2023-05-28 07:11:50,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:50,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:50,090 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:50,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:50,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:50,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:50,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:50,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:50,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:50,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:50,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:50,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:50,379 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:50,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:50,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:50,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:52,085 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:52,290 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:52,315 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:52,341 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:52,367 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:52,391 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:52,413 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:52,712 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:53,512 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-62q76uu8', purging
2023-05-28 07:11:53,513 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u2g04h0r', purging
2023-05-28 07:11:53,513 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ux3vthak', purging
2023-05-28 07:11:53,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5u7esp3a', purging
2023-05-28 07:11:53,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pax4qsmz', purging
2023-05-28 07:11:53,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_s0o3wby', purging
2023-05-28 07:11:53,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eg6vuetb', purging
2023-05-28 07:11:53,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fzqc5jnh', purging
2023-05-28 07:11:53,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:53,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:53,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:53,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:53,856 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:53,856 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:53,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:53,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:53,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:53,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:53,911 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:53,911 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:54,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:54,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:54,292 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:54,292 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:55,224 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:55,748 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:55,774 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:55,842 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:55,864 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:55,894 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:55,912 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:56,205 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:56,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7jlywa0e', purging
2023-05-28 07:11:56,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gxbnxhd6', purging
2023-05-28 07:11:56,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qofv06c5', purging
2023-05-28 07:11:56,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9nz4rp29', purging
2023-05-28 07:11:56,789 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-an5jhlyq', purging
2023-05-28 07:11:56,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hvj14kv3', purging
2023-05-28 07:11:56,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q1z6rzu_', purging
2023-05-28 07:11:56,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-brdot595', purging
2023-05-28 07:11:56,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:56,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:57,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:57,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:57,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:57,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:57,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:57,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:57,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:57,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:57,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:57,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:57,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:57,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:57,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:57,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:57,845 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:58,059 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:58,951 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:11:59,238 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:59,278 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:59,313 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:59,340 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:59,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9c4aht0v', purging
2023-05-28 07:11:59,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-soyvm_us', purging
2023-05-28 07:11:59,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-un8egtms', purging
2023-05-28 07:11:59,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lvddktc9', purging
2023-05-28 07:11:59,350 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-axtn72xj', purging
2023-05-28 07:11:59,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eo5v3k7i', purging
2023-05-28 07:11:59,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nmggh8ne', purging
2023-05-28 07:11:59,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:59,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:11:59,523 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:11:59,532 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-grwljcug', purging
2023-05-28 07:11:59,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:11:59,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:00,359 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:00,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gi32hv4y', purging
2023-05-28 07:12:00,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:00,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:00,525 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:00,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ofyg5sl2', purging
2023-05-28 07:12:00,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:00,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:00,784 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:00,784 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:00,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:00,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:00,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:00,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:00,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:00,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:01,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a6ub_e1e', purging
2023-05-28 07:12:01,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:01,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:01,986 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:02,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:02,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:02,238 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:02,450 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:02,491 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:02,685 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:02,711 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:03,083 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:03,252 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:03,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hy7z2gmg', purging
2023-05-28 07:12:03,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0m_sdwx6', purging
2023-05-28 07:12:03,437 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4h1jzzse', purging
2023-05-28 07:12:03,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0z7rsggl', purging
2023-05-28 07:12:03,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fr2oeyje', purging
2023-05-28 07:12:03,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bh94seck', purging
2023-05-28 07:12:03,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uis4_bzh', purging
2023-05-28 07:12:03,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:03,440 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:03,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:03,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:03,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:03,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:04,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:04,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:04,185 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:04,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:04,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:04,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:04,291 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:04,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8h79p_fo', purging
2023-05-28 07:12:04,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:04,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:04,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:04,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:04,887 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:05,415 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:05,642 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:05,818 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w3k74i2b', purging
2023-05-28 07:12:05,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ly7uf3er', purging
2023-05-28 07:12:05,819 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8r2er5ch', purging
2023-05-28 07:12:05,820 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:05,820 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:05,905 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:05,930 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:06,235 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:06,267 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:06,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o07nx181', purging
2023-05-28 07:12:06,449 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gmxqviy8', purging
2023-05-28 07:12:06,449 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9laht332', purging
2023-05-28 07:12:06,449 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pd0j9raf', purging
2023-05-28 07:12:06,450 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:06,450 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:06,570 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:06,997 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pcogc397', purging
2023-05-28 07:12:06,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:06,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:07,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:07,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:07,403 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:07,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0f77t7ju', purging
2023-05-28 07:12:07,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:07,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:07,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:07,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:07,736 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:07,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e706ywoe', purging
2023-05-28 07:12:07,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:07,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:07,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:07,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:08,039 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:08,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sowfow60', purging
2023-05-28 07:12:08,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:08,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:08,745 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:08,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9a6u9fwk', purging
2023-05-28 07:12:08,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wdkoxyzh', purging
2023-05-28 07:12:08,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:08,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:09,191 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:09,215 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:09,223 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-br6gixr4', purging
2023-05-28 07:12:09,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hy8bw0o5', purging
2023-05-28 07:12:09,224 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:09,224 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:09,440 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:09,510 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a4qw9p54', purging
2023-05-28 07:12:09,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:09,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:09,750 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:10,075 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:10,214 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ood09i8s', purging
2023-05-28 07:12:10,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_vlbsm49', purging
2023-05-28 07:12:10,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:10,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:10,307 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:10,730 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-be3msgrz', purging
2023-05-28 07:12:10,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:10,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:10,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:10,737 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:10,947 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e9mj400s', purging
2023-05-28 07:12:10,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:10,948 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:11,068 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:11,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:11,207 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:11,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:11,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:11,628 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:11,674 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:11,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-48v_p4rb', purging
2023-05-28 07:12:11,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tc6jroz5', purging
2023-05-28 07:12:11,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:11,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:12,178 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:12,233 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:12,540 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:12,568 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ojb9a138', purging
2023-05-28 07:12:12,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ljpdv2bk', purging
2023-05-28 07:12:12,569 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lzjkmor0', purging
2023-05-28 07:12:12,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:12,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:12,728 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:13,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8yc00t4t', purging
2023-05-28 07:12:13,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:13,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:13,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:13,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:13,434 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:13,693 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o1es_jjh', purging
2023-05-28 07:12:13,694 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:13,694 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:13,756 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5svvr7qs', purging
2023-05-28 07:12:13,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:13,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:13,774 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:14,002 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:14,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-93a20srm', purging
2023-05-28 07:12:14,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:14,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:14,250 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:14,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:14,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:14,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:15,170 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:15,197 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:15,247 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:15,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-05dd87re', purging
2023-05-28 07:12:15,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jul2q9e_', purging
2023-05-28 07:12:15,275 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8w9_ax9h', purging
2023-05-28 07:12:15,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:15,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:15,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:15,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:15,554 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:15,826 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:16,160 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:16,328 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:16,629 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ylxrwz2', purging
2023-05-28 07:12:16,629 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d8vpp4od', purging
2023-05-28 07:12:16,630 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rzc1xfh7', purging
2023-05-28 07:12:16,630 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5derzpm6', purging
2023-05-28 07:12:16,631 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:16,631 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:16,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:16,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:16,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:16,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:17,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:17,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:17,305 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:17,305 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:17,643 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:17,643 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:17,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:17,794 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:18,147 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:18,183 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:18,209 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:18,780 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:18,806 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:18,885 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:19,123 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:19,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3pgqw0k9', purging
2023-05-28 07:12:19,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d_6omt0n', purging
2023-05-28 07:12:19,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xe0j9j2t', purging
2023-05-28 07:12:19,627 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gnucxa3_', purging
2023-05-28 07:12:19,627 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ec82q6a1', purging
2023-05-28 07:12:19,627 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ipgm8_b', purging
2023-05-28 07:12:19,628 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tjafaegr', purging
2023-05-28 07:12:19,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:19,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:19,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:19,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:19,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:19,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:20,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:20,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:20,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:20,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:20,355 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:20,355 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:20,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:20,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:21,295 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:21,321 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:21,347 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:21,783 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:21,805 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:21,834 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:21,994 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:22,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-91bn8whf', purging
2023-05-28 07:12:22,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iz_22f0x', purging
2023-05-28 07:12:22,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sblfnvc8', purging
2023-05-28 07:12:22,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jmbr5km5', purging
2023-05-28 07:12:22,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wfz13ke_', purging
2023-05-28 07:12:22,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y29el93d', purging
2023-05-28 07:12:22,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zjsos28e', purging
2023-05-28 07:12:22,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:22,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:22,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:22,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:22,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:22,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:23,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:23,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:23,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:23,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:23,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:23,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:23,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:23,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:24,408 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:24,584 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:24,610 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:24,882 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:24,917 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:24,941 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:25,122 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:25,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_1trgxu1', purging
2023-05-28 07:12:25,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sgva5hdr', purging
2023-05-28 07:12:25,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kh5j31rd', purging
2023-05-28 07:12:25,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-omz4j9sl', purging
2023-05-28 07:12:25,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zaagyc8a', purging
2023-05-28 07:12:25,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2b4h9lxn', purging
2023-05-28 07:12:25,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u385amof', purging
2023-05-28 07:12:25,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:25,963 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:26,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:26,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:26,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:26,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:26,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:26,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:26,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:26,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:26,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:26,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:26,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:26,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:27,754 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:27,780 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:27,817 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:28,052 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:28,080 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:28,116 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:28,283 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:29,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kiby2zl1', purging
2023-05-28 07:12:29,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nbfoza_w', purging
2023-05-28 07:12:29,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a9mka1z3', purging
2023-05-28 07:12:29,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t7igkeps', purging
2023-05-28 07:12:29,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iei7ast2', purging
2023-05-28 07:12:29,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ik8i8ks6', purging
2023-05-28 07:12:29,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k3z51ieo', purging
2023-05-28 07:12:29,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:29,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:29,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:29,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:29,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:29,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:29,568 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:29,568 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:29,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:29,582 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:29,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:29,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:29,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:29,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:30,649 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:30,806 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:30,835 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:31,274 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:12:31,336 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:31,497 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:32,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4aseurll', purging
2023-05-28 07:12:32,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wjzzhwjx', purging
2023-05-28 07:12:32,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qon5oh60', purging
2023-05-28 07:12:32,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vmumof4c', purging
2023-05-28 07:12:32,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_gtxb74', purging
2023-05-28 07:12:32,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aqdtpyrx', purging
2023-05-28 07:12:32,069 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-861vuvh1', purging
2023-05-28 07:12:32,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:32,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:32,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:32,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:32,303 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:32,303 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:32,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:32,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:32,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:32,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:32,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:32,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:33,351 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:33,385 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:33,431 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:33,927 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:33,963 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:34,154 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:34,840 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p8qro343', purging
2023-05-28 07:12:34,841 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ebw1s_vy', purging
2023-05-28 07:12:34,841 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ssy7axr_', purging
2023-05-28 07:12:34,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ot_40jgk', purging
2023-05-28 07:12:34,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-670rsb6b', purging
2023-05-28 07:12:34,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yrxcnmrp', purging
2023-05-28 07:12:34,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:34,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:34,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:34,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:34,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:34,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:35,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:35,380 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:35,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:35,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:35,635 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:35,635 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:36,353 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:36,541 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:36,567 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:36,782 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:36,829 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:36,998 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:37,872 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wzzkho98', purging
2023-05-28 07:12:37,872 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqfm0qn0', purging
2023-05-28 07:12:37,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mwp640rx', purging
2023-05-28 07:12:37,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xia8jnuc', purging
2023-05-28 07:12:37,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hte0kdmh', purging
2023-05-28 07:12:37,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_j_g88_8', purging
2023-05-28 07:12:37,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:37,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:38,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:38,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:38,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:38,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:38,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:38,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:38,330 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:38,330 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:38,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:38,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:39,510 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:39,552 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:39,583 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:39,645 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:39,803 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:39,965 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:40,991 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u2b16ox0', purging
2023-05-28 07:12:40,992 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2vczs1g0', purging
2023-05-28 07:12:40,992 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zcof4pch', purging
2023-05-28 07:12:40,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fjem9gol', purging
2023-05-28 07:12:40,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8gxvjfll', purging
2023-05-28 07:12:40,994 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-el98w53h', purging
2023-05-28 07:12:40,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:40,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:41,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:41,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:41,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:41,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:41,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:41,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:41,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:41,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:41,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:41,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:42,708 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:42,730 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:42,756 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:42,782 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:42,806 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:43,106 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:44,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ygg1uzid', purging
2023-05-28 07:12:44,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oq1w7u2j', purging
2023-05-28 07:12:44,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-falqnlhj', purging
2023-05-28 07:12:44,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rhyrs7k_', purging
2023-05-28 07:12:44,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0pzmlann', purging
2023-05-28 07:12:44,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ykccv123', purging
2023-05-28 07:12:44,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:44,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:44,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:44,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:44,224 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:44,224 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:44,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:44,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:44,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:44,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:44,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:44,582 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:45,857 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:45,884 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:45,937 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:45,962 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:45,985 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:46,239 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:47,330 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25x6ax_2', purging
2023-05-28 07:12:47,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8hdf9w0v', purging
2023-05-28 07:12:47,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f3s09wor', purging
2023-05-28 07:12:47,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h3_6fmgv', purging
2023-05-28 07:12:47,331 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a6ioooqx', purging
2023-05-28 07:12:47,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yiyig8ug', purging
2023-05-28 07:12:47,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:47,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:47,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:47,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:47,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:47,391 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:47,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:47,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:47,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:47,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:47,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:47,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:49,083 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:49,113 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:49,135 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:49,156 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:49,181 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:49,410 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:50,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-06seq2jg', purging
2023-05-28 07:12:50,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dju0bhv1', purging
2023-05-28 07:12:50,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4hgakv8v', purging
2023-05-28 07:12:50,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nuur8mvl', purging
2023-05-28 07:12:50,538 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yqcb32xi', purging
2023-05-28 07:12:50,538 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qxktwk3z', purging
2023-05-28 07:12:50,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:50,539 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:50,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:50,546 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:50,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:50,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:50,571 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:50,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:50,635 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:50,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:50,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:50,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:52,224 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:52,282 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:52,355 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:52,356 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:52,367 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:52,525 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:53,693 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-227t8jbw', purging
2023-05-28 07:12:53,694 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h_ntmog2', purging
2023-05-28 07:12:53,694 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1secp4cj', purging
2023-05-28 07:12:53,694 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lpnbqj_i', purging
2023-05-28 07:12:53,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cuurbjvo', purging
2023-05-28 07:12:53,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p7lx23im', purging
2023-05-28 07:12:53,695 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:53,695 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:53,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:53,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:53,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:53,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:53,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:53,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:53,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:53,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:53,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:53,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:55,417 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:55,440 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:55,463 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:55,488 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:55,517 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:55,678 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:56,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ka2zdj16', purging
2023-05-28 07:12:56,862 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gydy2_y9', purging
2023-05-28 07:12:56,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wwagkmf', purging
2023-05-28 07:12:56,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8788hmnv', purging
2023-05-28 07:12:56,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wcadzksb', purging
2023-05-28 07:12:56,864 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5vnmanc', purging
2023-05-28 07:12:56,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:56,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:56,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:56,933 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:56,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:56,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:56,961 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:56,961 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:57,014 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:57,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:12:57,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:12:57,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:12:58,640 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:58,666 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:58,691 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:58,718 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:58,744 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:12:58,894 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:00,109 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-716vfxuj', purging
2023-05-28 07:13:00,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9wnvtno_', purging
2023-05-28 07:13:00,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-elx2ch06', purging
2023-05-28 07:13:00,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2j6qifoe', purging
2023-05-28 07:13:00,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ck21aslz', purging
2023-05-28 07:13:00,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iu0_xgar', purging
2023-05-28 07:13:00,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:00,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:00,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:00,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:00,164 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:00,164 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:00,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:00,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:00,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:00,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:00,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:00,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:01,813 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:01,871 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:01,897 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:01,923 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:01,950 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:02,123 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:03,284 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8630gv3k', purging
2023-05-28 07:13:03,284 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ogu80qv5', purging
2023-05-28 07:13:03,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1kk7paot', purging
2023-05-28 07:13:03,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9zi8qic', purging
2023-05-28 07:13:03,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h8tn_wb5', purging
2023-05-28 07:13:03,285 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-atgj638v', purging
2023-05-28 07:13:03,286 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:03,286 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:03,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:03,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:03,343 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:03,343 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:03,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:03,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:03,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:03,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:03,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:03,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:04,966 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:05,019 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:05,041 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:05,090 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:05,112 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:05,267 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:06,377 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jbfufqus', purging
2023-05-28 07:13:06,378 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p39p0u8f', purging
2023-05-28 07:13:06,378 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y17n9_mp', purging
2023-05-28 07:13:06,378 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rku9ilio', purging
2023-05-28 07:13:06,379 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tdm0n9b5', purging
2023-05-28 07:13:06,379 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vhshvoit', purging
2023-05-28 07:13:06,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:06,380 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:06,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:06,470 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:06,499 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:06,499 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:06,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:06,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:06,607 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:06,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:06,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:06,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:08,062 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:08,118 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:08,146 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:08,173 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:08,216 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:08,472 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:09,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5buiy6_2', purging
2023-05-28 07:13:09,528 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e9gzobez', purging
2023-05-28 07:13:09,528 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jx_xelxq', purging
2023-05-28 07:13:09,528 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0nvkvqt6', purging
2023-05-28 07:13:09,529 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d5ulkfxb', purging
2023-05-28 07:13:09,529 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4xvbvgoo', purging
2023-05-28 07:13:09,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:09,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:09,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:09,535 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:09,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:09,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:09,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:09,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:09,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:09,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:09,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:09,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:11,247 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:11,271 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:11,298 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:11,322 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:11,350 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:11,589 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:12,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qotpcnd9', purging
2023-05-28 07:13:12,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ds2zkr9t', purging
2023-05-28 07:13:12,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-22o0uo8i', purging
2023-05-28 07:13:12,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_p5x_i0j', purging
2023-05-28 07:13:12,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ouuttlh6', purging
2023-05-28 07:13:12,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t0y83_44', purging
2023-05-28 07:13:12,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:12,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:12,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:12,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:12,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:12,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:12,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:12,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:12,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:12,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:13,076 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:13,076 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:14,449 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:14,492 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:14,506 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:14,529 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:14,555 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:14,721 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:15,861 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xhwqhgx9', purging
2023-05-28 07:13:15,862 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e1mknprj', purging
2023-05-28 07:13:15,862 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6bgq0wly', purging
2023-05-28 07:13:15,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1v998rwt', purging
2023-05-28 07:13:15,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0n6my0b0', purging
2023-05-28 07:13:15,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ch4il_e3', purging
2023-05-28 07:13:15,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:15,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:15,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:15,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:15,970 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:15,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:16,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:16,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:16,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:16,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:16,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:16,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:17,588 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:17,650 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:17,676 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:17,702 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:17,725 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:17,878 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:18,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ozf8jk1w', purging
2023-05-28 07:13:18,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lif9iply', purging
2023-05-28 07:13:18,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5yk1v_x2', purging
2023-05-28 07:13:18,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yh2u4y5b', purging
2023-05-28 07:13:18,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fu_7buwl', purging
2023-05-28 07:13:18,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h7_42sna', purging
2023-05-28 07:13:18,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:18,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:19,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:19,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:19,168 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:19,168 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:19,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:19,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:19,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:19,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:19,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:19,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:20,626 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:20,697 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:20,723 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:20,744 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:20,792 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:21,052 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:22,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-skmr24v7', purging
2023-05-28 07:13:22,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7sknqs70', purging
2023-05-28 07:13:22,027 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h6p950n5', purging
2023-05-28 07:13:22,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ttoh86q2', purging
2023-05-28 07:13:22,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5tosiasw', purging
2023-05-28 07:13:22,028 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dp58d4rb', purging
2023-05-28 07:13:22,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:22,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:22,195 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:22,195 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:22,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:22,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:22,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:22,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:22,298 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:22,298 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:22,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:22,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:23,720 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:23,748 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:23,771 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:23,798 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:23,837 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:24,097 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:25,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-il44qat9', purging
2023-05-28 07:13:25,102 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m58_3g5f', purging
2023-05-28 07:13:25,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dnfdz49p', purging
2023-05-28 07:13:25,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qmd8lhtc', purging
2023-05-28 07:13:25,103 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2lbfmq1v', purging
2023-05-28 07:13:25,104 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-213pwfua', purging
2023-05-28 07:13:25,104 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:25,104 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:25,111 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:25,111 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:25,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:25,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:25,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:25,247 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:25,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:25,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:25,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:25,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:26,609 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:26,641 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:26,830 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:26,856 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:26,883 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:27,160 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:28,016 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ae9mqmn7', purging
2023-05-28 07:13:28,017 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ce0xy842', purging
2023-05-28 07:13:28,017 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yq1glge4', purging
2023-05-28 07:13:28,017 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eqmnjnzr', purging
2023-05-28 07:13:28,017 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-po_fk9g_', purging
2023-05-28 07:13:28,018 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-704ekrgu', purging
2023-05-28 07:13:28,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:28,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:28,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:28,153 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:28,292 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:28,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:28,325 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:28,325 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:28,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:28,339 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:28,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:28,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:29,487 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:29,555 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:29,819 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:29,876 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:29,918 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:30,116 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:30,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v7yotvre', purging
2023-05-28 07:13:30,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kq5zx_yy', purging
2023-05-28 07:13:30,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e669g2jk', purging
2023-05-28 07:13:30,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fhhd3h22', purging
2023-05-28 07:13:30,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8k66yy5p', purging
2023-05-28 07:13:30,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hkg2wh62', purging
2023-05-28 07:13:30,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:30,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:30,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:30,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:31,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:31,317 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:31,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:31,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:31,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:31,384 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:31,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:31,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:32,388 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:32,421 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:32,813 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:32,860 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:32,884 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:33,055 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:33,806 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ti0o767', purging
2023-05-28 07:13:33,807 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iwzm6evj', purging
2023-05-28 07:13:33,807 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xcphn0m9', purging
2023-05-28 07:13:33,807 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-maexg1v0', purging
2023-05-28 07:13:33,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wcc3sduf', purging
2023-05-28 07:13:33,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hmow2zu8', purging
2023-05-28 07:13:33,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:33,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:33,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:33,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:34,317 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:34,317 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:34,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:34,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:34,339 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:34,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:34,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:34,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:35,348 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:35,380 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:35,642 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:35,689 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:35,719 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:35,879 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:36,749 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_9usudae', purging
2023-05-28 07:13:36,750 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nne14o4s', purging
2023-05-28 07:13:36,750 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hg6j1yze', purging
2023-05-28 07:13:36,750 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2hpnscz9', purging
2023-05-28 07:13:36,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i3m9q10y', purging
2023-05-28 07:13:36,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ow7hh63u', purging
2023-05-28 07:13:36,752 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:36,752 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:36,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:36,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:37,138 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:37,138 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:37,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:37,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:37,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:37,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:37,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:37,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:38,289 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:38,579 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:38,630 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:38,653 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:38,825 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:39,730 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ifg_zqfo', purging
2023-05-28 07:13:39,730 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1h0vt3w3', purging
2023-05-28 07:13:39,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7w4fbvr', purging
2023-05-28 07:13:39,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-90qlcyc0', purging
2023-05-28 07:13:39,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w0gnb2s6', purging
2023-05-28 07:13:39,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-acuucff7', purging
2023-05-28 07:13:39,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:39,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:39,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:39,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:40,055 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:40,055 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:40,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:40,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:40,275 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:40,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:40,941 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:40,982 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:41,372 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:41,395 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:41,571 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:42,354 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w76cimoz', purging
2023-05-28 07:13:42,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u1jagl4i', purging
2023-05-28 07:13:42,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-98rg8nsx', purging
2023-05-28 07:13:42,355 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hb8u1qc6', purging
2023-05-28 07:13:42,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3qsmq81v', purging
2023-05-28 07:13:42,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:42,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:42,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:42,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:42,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:42,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:42,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:42,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:42,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:42,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:43,603 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:43,630 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:44,006 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:44,049 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:44,234 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:45,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1mzkwz3r', purging
2023-05-28 07:13:45,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pnw5ebru', purging
2023-05-28 07:13:45,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yzfs6nhg', purging
2023-05-28 07:13:45,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5oncquvm', purging
2023-05-28 07:13:45,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k2ba24s6', purging
2023-05-28 07:13:45,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:45,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:45,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:45,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:45,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:45,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:45,483 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:45,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:45,653 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:45,653 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:46,397 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:46,432 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:46,614 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:46,656 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:46,811 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:47,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6r_thy1t', purging
2023-05-28 07:13:47,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nw8w1ptb', purging
2023-05-28 07:13:47,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q36iy8uc', purging
2023-05-28 07:13:47,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-86000tjn', purging
2023-05-28 07:13:47,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a16soxsc', purging
2023-05-28 07:13:47,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:47,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:47,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:47,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:48,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:48,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:48,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:48,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:48,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:48,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:49,189 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:49,214 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:49,334 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:49,371 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:49,585 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:50,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-81jzkdwy', purging
2023-05-28 07:13:50,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z4jeg1z1', purging
2023-05-28 07:13:50,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z8g2rl05', purging
2023-05-28 07:13:50,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wpuskgbb', purging
2023-05-28 07:13:50,580 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-34y_mucp', purging
2023-05-28 07:13:50,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:50,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:50,648 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:50,648 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:50,790 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:50,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:50,793 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:50,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:50,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:50,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:52,030 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:52,056 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:52,107 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:52,131 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:52,422 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:53,441 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r29kfzkx', purging
2023-05-28 07:13:53,442 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-79bvwq3g', purging
2023-05-28 07:13:53,442 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5tx50_o', purging
2023-05-28 07:13:53,443 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3kmdr_g4', purging
2023-05-28 07:13:53,443 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sc1knngq', purging
2023-05-28 07:13:53,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:53,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:53,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:53,495 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:53,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:53,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:53,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:53,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:53,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:53,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:54,904 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:54,934 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:54,966 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:54,988 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:55,248 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:56,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jd8ddf0e', purging
2023-05-28 07:13:56,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tzrtkq0s', purging
2023-05-28 07:13:56,389 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0i75bpqm', purging
2023-05-28 07:13:56,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7_f02ty_', purging
2023-05-28 07:13:56,390 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pg8jmw5m', purging
2023-05-28 07:13:56,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:56,391 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:56,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:56,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:56,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:56,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:56,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:56,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:56,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:56,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:13:57,871 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:57,923 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:57,947 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:57,969 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:58,140 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:13:59,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k7_gflll', purging
2023-05-28 07:13:59,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i38jkort', purging
2023-05-28 07:13:59,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-463q4i5w', purging
2023-05-28 07:13:59,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ypkwvppz', purging
2023-05-28 07:13:59,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jqfmfzhl', purging
2023-05-28 07:13:59,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:59,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:59,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:59,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:59,378 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:59,378 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:59,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:59,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:13:59,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:13:59,571 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:00,741 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:00,765 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:00,808 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:00,836 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:00,990 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:02,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3_unlfdg', purging
2023-05-28 07:14:02,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qt_m7ko9', purging
2023-05-28 07:14:02,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9feie3_h', purging
2023-05-28 07:14:02,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7quq7ggu', purging
2023-05-28 07:14:02,145 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nmpm55ul', purging
2023-05-28 07:14:02,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:02,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:02,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:02,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:02,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:02,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:02,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:02,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:02,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:02,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:03,620 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:03,672 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:03,697 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:03,723 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:03,879 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:05,077 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2x5m1lk2', purging
2023-05-28 07:14:05,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p4huqxuu', purging
2023-05-28 07:14:05,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zr8tz6ml', purging
2023-05-28 07:14:05,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-irzm1czq', purging
2023-05-28 07:14:05,079 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fds_a4rk', purging
2023-05-28 07:14:05,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:05,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:05,091 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:05,091 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:05,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:05,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:05,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:05,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:05,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:05,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:06,543 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:06,592 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:06,618 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:06,640 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:06,800 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:07,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dus1mjv4', purging
2023-05-28 07:14:07,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sye38bg6', purging
2023-05-28 07:14:07,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xexcz93c', purging
2023-05-28 07:14:07,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1iof7al5', purging
2023-05-28 07:14:07,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y4t9jsjb', purging
2023-05-28 07:14:07,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:07,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:08,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:08,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:08,064 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:08,064 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:08,083 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:08,083 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:08,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:08,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:09,435 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:09,460 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:09,494 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:09,519 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:09,684 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:10,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1w8hdx27', purging
2023-05-28 07:14:10,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kll888qb', purging
2023-05-28 07:14:10,854 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9cd36r8i', purging
2023-05-28 07:14:10,854 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l51may75', purging
2023-05-28 07:14:10,855 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vwo4vb0s', purging
2023-05-28 07:14:10,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:10,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:10,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:10,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:10,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:10,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:10,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:10,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:11,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:11,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:12,361 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:12,397 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:12,422 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:12,450 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:12,606 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:13,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-isk4vad1', purging
2023-05-28 07:14:13,783 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eb0009e5', purging
2023-05-28 07:14:13,783 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bekv187g', purging
2023-05-28 07:14:13,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hekirzny', purging
2023-05-28 07:14:13,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o_s6n0us', purging
2023-05-28 07:14:13,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:13,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:13,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:13,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:13,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:13,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:13,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:13,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:14,103 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:14,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:15,268 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:15,349 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:15,350 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:15,379 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:15,528 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:16,737 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-82m_utfn', purging
2023-05-28 07:14:16,737 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-temyhdet', purging
2023-05-28 07:14:16,738 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ucpbxg1y', purging
2023-05-28 07:14:16,738 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rgcbzvlo', purging
2023-05-28 07:14:16,738 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr1xdmu9', purging
2023-05-28 07:14:16,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:16,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:16,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:16,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:16,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:16,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:16,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:16,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:16,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:16,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:18,213 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:18,264 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:18,291 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:18,315 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:18,484 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:19,636 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kcjuonj7', purging
2023-05-28 07:14:19,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ve22ndch', purging
2023-05-28 07:14:19,637 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t508du36', purging
2023-05-28 07:14:19,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ssgkmdl', purging
2023-05-28 07:14:19,638 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zguo7t6r', purging
2023-05-28 07:14:19,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:19,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:19,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:19,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:19,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:19,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:19,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:19,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:19,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:19,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:21,129 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:21,159 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:21,192 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:21,219 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:21,384 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:22,526 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0vr9b1w3', purging
2023-05-28 07:14:22,526 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r8ihu93o', purging
2023-05-28 07:14:22,526 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w_ge5plv', purging
2023-05-28 07:14:22,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iybmha51', purging
2023-05-28 07:14:22,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jxnfy5yu', purging
2023-05-28 07:14:22,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:22,528 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:22,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:22,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:22,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:22,635 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:22,635 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:22,635 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:22,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:22,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:24,021 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:24,047 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:24,083 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:24,106 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:24,267 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:25,434 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-igtvy4qt', purging
2023-05-28 07:14:25,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-egjc2s_h', purging
2023-05-28 07:14:25,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mo9i5744', purging
2023-05-28 07:14:25,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-py_m_tvu', purging
2023-05-28 07:14:25,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:25,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:25,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m5w9kk6h', purging
2023-05-28 07:14:25,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:25,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:25,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:25,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:25,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:25,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:25,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:25,712 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:26,956 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:26,978 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:27,003 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:27,026 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:27,184 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:28,399 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tlha6ra1', purging
2023-05-28 07:14:28,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cs2n6djt', purging
2023-05-28 07:14:28,400 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z1ad7mt8', purging
2023-05-28 07:14:28,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4xar6a3n', purging
2023-05-28 07:14:28,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x_i73ukz', purging
2023-05-28 07:14:28,402 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:28,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:28,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:28,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:28,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:28,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:28,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:28,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:28,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:28,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:29,927 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:29,956 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:29,980 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:30,004 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:30,164 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:31,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hr5ihuer', purging
2023-05-28 07:14:31,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qb90kbd3', purging
2023-05-28 07:14:31,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kqktdh75', purging
2023-05-28 07:14:31,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qxmsuzrg', purging
2023-05-28 07:14:31,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8scn9bhk', purging
2023-05-28 07:14:31,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:31,397 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:31,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:31,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:31,470 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:31,471 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:31,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:31,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:31,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:31,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:32,911 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:32,938 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:32,976 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:33,000 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:33,164 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:34,246 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nokk1ln8', purging
2023-05-28 07:14:34,247 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a1qp2qwj', purging
2023-05-28 07:14:34,247 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nxvn2f8y', purging
2023-05-28 07:14:34,247 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eiydp0lr', purging
2023-05-28 07:14:34,248 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cngp1tl0', purging
2023-05-28 07:14:34,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:34,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:34,330 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:34,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:34,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:34,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:34,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:34,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:34,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:34,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:35,692 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:35,718 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:35,747 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:35,774 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:36,005 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:37,023 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ths4qm19', purging
2023-05-28 07:14:37,023 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ed7mz_x5', purging
2023-05-28 07:14:37,024 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_h_m4znc', purging
2023-05-28 07:14:37,024 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-77suhu28', purging
2023-05-28 07:14:37,024 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-khmxjjbw', purging
2023-05-28 07:14:37,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:37,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:37,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:37,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:37,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:37,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:37,235 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:37,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:37,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:37,438 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:38,485 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:38,513 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:38,534 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:38,575 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:38,859 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:39,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xbk6nstb', purging
2023-05-28 07:14:39,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l_0bzzwi', purging
2023-05-28 07:14:39,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1g36h5rp', purging
2023-05-28 07:14:39,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lx4mf92m', purging
2023-05-28 07:14:39,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_em7g_jg', purging
2023-05-28 07:14:39,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:39,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:39,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:39,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:39,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:39,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:39,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:39,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:40,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:40,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:41,431 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:41,460 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:41,496 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:41,522 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:41,701 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:42,834 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l1lhvf6r', purging
2023-05-28 07:14:42,834 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e731kk8b', purging
2023-05-28 07:14:42,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uwykhrv3', purging
2023-05-28 07:14:42,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9tl9r_py', purging
2023-05-28 07:14:42,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n88r0rhn', purging
2023-05-28 07:14:42,836 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:42,836 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:42,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:42,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:42,957 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:42,957 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:43,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:43,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:43,155 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:43,155 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:44,334 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:44,373 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:44,403 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:44,429 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:44,607 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:45,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3o6xahev', purging
2023-05-28 07:14:45,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-di72l1ey', purging
2023-05-28 07:14:45,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tb8f4hsv', purging
2023-05-28 07:14:45,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vrnhx6_f', purging
2023-05-28 07:14:45,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-faqw6uqb', purging
2023-05-28 07:14:45,778 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:45,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:45,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:45,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:45,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:45,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:45,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:45,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:46,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:46,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:47,321 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:47,346 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:47,373 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:47,398 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:47,557 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:48,750 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gw55pnwj', purging
2023-05-28 07:14:48,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-444os69u', purging
2023-05-28 07:14:48,751 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-adxirdyo', purging
2023-05-28 07:14:48,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-060ldbw6', purging
2023-05-28 07:14:48,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lzrmz93e', purging
2023-05-28 07:14:48,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:48,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:48,798 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:48,798 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:48,823 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:48,823 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:48,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:48,876 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:48,997 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:48,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:50,271 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:50,300 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:50,352 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:50,370 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:50,530 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:51,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qnheh2_m', purging
2023-05-28 07:14:51,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_s6thaav', purging
2023-05-28 07:14:51,657 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2qs0syf', purging
2023-05-28 07:14:51,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-flmht4rk', purging
2023-05-28 07:14:51,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oyyzqcxw', purging
2023-05-28 07:14:51,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:51,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:51,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:51,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:51,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:51,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:51,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:51,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:51,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:51,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:53,160 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:53,211 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:53,226 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:53,263 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:53,423 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:54,557 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g7jvj0w6', purging
2023-05-28 07:14:54,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fqrr8md6', purging
2023-05-28 07:14:54,558 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xsd75md9', purging
2023-05-28 07:14:54,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2rqot6tq', purging
2023-05-28 07:14:54,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f41q14k_', purging
2023-05-28 07:14:54,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:54,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:54,650 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:54,650 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:54,700 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:54,700 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:54,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:54,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:54,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:54,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:56,038 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:56,108 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:56,124 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:56,160 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:56,308 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:57,480 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bk0xoaog', purging
2023-05-28 07:14:57,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mjtz5os1', purging
2023-05-28 07:14:57,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j7yvm04j', purging
2023-05-28 07:14:57,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e6ajiuld', purging
2023-05-28 07:14:57,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z_b8s5jv', purging
2023-05-28 07:14:57,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:57,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:57,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:57,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:57,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:57,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:57,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:57,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:14:57,696 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:14:57,696 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:14:58,985 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:59,041 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:59,067 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:59,090 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:14:59,272 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:00,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k1d5c56h', purging
2023-05-28 07:15:00,415 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z1lua0tq', purging
2023-05-28 07:15:00,415 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ty2dsx0i', purging
2023-05-28 07:15:00,415 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5pc562_d', purging
2023-05-28 07:15:00,416 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0hi8a65v', purging
2023-05-28 07:15:00,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:00,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:00,450 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:00,450 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:00,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:00,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:00,550 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:00,550 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:00,716 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:00,716 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:01,883 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:01,937 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:01,962 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:01,987 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:02,155 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:03,239 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hva194mq', purging
2023-05-28 07:15:03,240 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sg46kemh', purging
2023-05-28 07:15:03,240 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qt5_aoxw', purging
2023-05-28 07:15:03,241 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ht9nwhw8', purging
2023-05-28 07:15:03,241 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jfnc8sjx', purging
2023-05-28 07:15:03,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:03,242 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:03,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:03,391 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:03,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:03,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:03,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:03,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:03,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:03,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:04,665 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:04,724 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:04,754 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:04,788 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:05,053 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:06,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3uki5w1q', purging
2023-05-28 07:15:06,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7suhwu_9', purging
2023-05-28 07:15:06,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mq55h3mk', purging
2023-05-28 07:15:06,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d6bldnlw', purging
2023-05-28 07:15:06,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4emfysll', purging
2023-05-28 07:15:06,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:06,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:06,190 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:06,190 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:06,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:06,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:06,236 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:06,236 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:06,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:06,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:07,482 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:07,504 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:07,535 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:07,556 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:07,854 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:08,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y30c1lgl', purging
2023-05-28 07:15:08,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5oz8gvxz', purging
2023-05-28 07:15:08,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ig_3t_9p', purging
2023-05-28 07:15:08,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ezcrtcbz', purging
2023-05-28 07:15:08,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xgzki5tq', purging
2023-05-28 07:15:08,869 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:08,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:08,938 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:08,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:08,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:08,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:08,991 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:08,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:09,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:09,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:10,349 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:10,378 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:10,405 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:10,425 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:10,673 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:11,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:11,711 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hq4gjbiv', purging
2023-05-28 07:15:11,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:11,711 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1_0m0rzd', purging
2023-05-28 07:15:11,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-45f66m7q', purging
2023-05-28 07:15:11,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ws66yiy9', purging
2023-05-28 07:15:11,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h1worz44', purging
2023-05-28 07:15:11,713 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:11,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:11,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:11,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:11,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:11,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:12,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:12,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:13,181 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:13,200 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:13,234 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:13,255 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:13,494 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:14,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ejrmalwh', purging
2023-05-28 07:15:14,609 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-enid7jqg', purging
2023-05-28 07:15:14,610 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-unkp7nl0', purging
2023-05-28 07:15:14,610 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7gzi9j1z', purging
2023-05-28 07:15:14,610 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-udw1ge25', purging
2023-05-28 07:15:14,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:14,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:14,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:14,623 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:14,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:14,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:14,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:14,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:14,923 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:14,923 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:16,125 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:16,155 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:16,176 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:16,209 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:16,368 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:17,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qjls5bs3', purging
2023-05-28 07:15:17,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kwpzvtdw', purging
2023-05-28 07:15:17,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j_venv6u', purging
2023-05-28 07:15:17,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04nqm017', purging
2023-05-28 07:15:17,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wtrs1lj8', purging
2023-05-28 07:15:17,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:17,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:17,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:17,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:17,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:17,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:17,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:17,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:17,848 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:17,848 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:19,015 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:19,044 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:19,087 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:19,111 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:19,296 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:20,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1__4wyzv', purging
2023-05-28 07:15:20,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-za4_gs8_', purging
2023-05-28 07:15:20,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rhcgwybg', purging
2023-05-28 07:15:20,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ur6snk0q', purging
2023-05-28 07:15:20,489 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w5rpvcy2', purging
2023-05-28 07:15:20,489 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:20,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:20,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:20,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:20,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:20,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:20,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:20,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:20,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:20,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:22,005 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:22,046 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:22,058 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:22,098 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:22,255 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:23,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i2877ogp', purging
2023-05-28 07:15:23,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-001htjsd', purging
2023-05-28 07:15:23,446 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-taqubi7o', purging
2023-05-28 07:15:23,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vt1tnzxi', purging
2023-05-28 07:15:23,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hsvqml4w', purging
2023-05-28 07:15:23,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:23,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:23,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:23,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:23,524 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:23,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:23,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:23,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:23,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:23,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:24,957 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:24,987 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:25,015 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:25,039 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:25,223 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:26,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bbn8khlo', purging
2023-05-28 07:15:26,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hxhahch6', purging
2023-05-28 07:15:26,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1zg2qeg4', purging
2023-05-28 07:15:26,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0hpluhhv', purging
2023-05-28 07:15:26,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7mtro0iz', purging
2023-05-28 07:15:26,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:26,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:26,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:26,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:26,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:26,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:26,488 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:26,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:26,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:26,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:27,897 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:27,951 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:27,981 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:27,998 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:28,175 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:29,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w8pc1hgm', purging
2023-05-28 07:15:29,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vpaq_ame', purging
2023-05-28 07:15:29,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zngubpvj', purging
2023-05-28 07:15:29,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-02y53t11', purging
2023-05-28 07:15:29,353 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psvkspx5', purging
2023-05-28 07:15:29,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:29,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:29,392 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:29,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:29,446 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:29,446 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:29,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:29,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:29,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:29,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:30,867 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:30,890 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:30,920 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:30,938 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:31,108 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:32,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2jq2rh1y', purging
2023-05-28 07:15:32,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v9dwkmce', purging
2023-05-28 07:15:32,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dubh03vv', purging
2023-05-28 07:15:32,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sphotsca', purging
2023-05-28 07:15:32,321 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rtoymqc2', purging
2023-05-28 07:15:32,322 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:32,322 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:32,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:32,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:32,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:32,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:32,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:32,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:32,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:32,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:33,827 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:33,846 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:33,881 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:33,896 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:34,063 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:35,266 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hu6dhxqd', purging
2023-05-28 07:15:35,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0u7uy5l2', purging
2023-05-28 07:15:35,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-90fdhtz3', purging
2023-05-28 07:15:35,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-djb3d29f', purging
2023-05-28 07:15:35,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qw534gso', purging
2023-05-28 07:15:35,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:35,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:35,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:35,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:35,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:35,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:35,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:35,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:35,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:35,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:36,757 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:36,787 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:36,846 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:36,847 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:37,000 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:38,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nqg6xkld', purging
2023-05-28 07:15:38,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vgu7rzlh', purging
2023-05-28 07:15:38,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3q146yrk', purging
2023-05-28 07:15:38,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-akxc1113', purging
2023-05-28 07:15:38,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y30ttj2l', purging
2023-05-28 07:15:38,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:38,228 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:38,264 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:38,264 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:38,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:38,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:38,328 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:38,328 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:38,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:38,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:39,758 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:39,801 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:39,821 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:39,853 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:40,019 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:41,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2n78ak0b', purging
2023-05-28 07:15:41,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hymxjnll', purging
2023-05-28 07:15:41,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-90xtjjnr', purging
2023-05-28 07:15:41,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8q_9zvf6', purging
2023-05-28 07:15:41,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bvqwt744', purging
2023-05-28 07:15:41,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:41,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:41,298 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:41,298 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:41,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:41,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:41,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:41,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:41,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:41,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:42,745 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:15:43,008 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:44,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ahadroxi', purging
2023-05-28 07:15:44,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6fly9wz0', purging
2023-05-28 07:15:44,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x9qruafc', purging
2023-05-28 07:15:44,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-metwp9dr', purging
2023-05-28 07:15:44,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2mh8pf9', purging
2023-05-28 07:15:44,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:44,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:44,331 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:44,331 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:44,956 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:45,119 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:46,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cbjbub2c', purging
2023-05-28 07:15:46,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pnzjinst', purging
2023-05-28 07:15:46,295 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:46,295 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:46,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:46,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:47,136 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:47,299 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:48,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7u3k3t8j', purging
2023-05-28 07:15:48,465 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mxi9bv_f', purging
2023-05-28 07:15:48,465 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:48,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:48,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:48,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:49,272 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:49,446 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:50,627 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t1huiell', purging
2023-05-28 07:15:50,627 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kt8ey7vo', purging
2023-05-28 07:15:50,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:50,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:50,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:50,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:51,456 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:51,619 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:52,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y5d3x2s4', purging
2023-05-28 07:15:52,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v7us1cj8', purging
2023-05-28 07:15:52,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:52,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:52,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:52,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:53,637 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:53,805 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:54,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1o90f0ye', purging
2023-05-28 07:15:54,980 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ylyybckg', purging
2023-05-28 07:15:54,981 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:54,981 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:55,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:55,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:55,816 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:55,991 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:57,156 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pgwr5rse', purging
2023-05-28 07:15:57,156 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c15l1w6g', purging
2023-05-28 07:15:57,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:57,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:57,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:57,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:15:57,983 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:58,155 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:15:59,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bm0btipe', purging
2023-05-28 07:15:59,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i7gp3l53', purging
2023-05-28 07:15:59,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:59,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:15:59,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:15:59,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:00,158 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:00,328 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:01,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iqhbsaac', purging
2023-05-28 07:16:01,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lo968xl2', purging
2023-05-28 07:16:01,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:01,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:01,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:01,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:02,369 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:02,542 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:03,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l1c8ir__', purging
2023-05-28 07:16:03,709 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fi8wj5qd', purging
2023-05-28 07:16:03,710 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:03,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 07:16:03,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:03,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:04,549 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-28 07:16:05,881 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0rj3wn21', purging
2023-05-28 07:16:05,881 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6xln9j67', purging
2023-05-28 07:16:05,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:05,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:06,644 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:07,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rr0ufjit', purging
2023-05-28 07:16:07,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:07,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:08,763 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:10,085 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jr7eamzp', purging
2023-05-28 07:16:10,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:10,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:10,860 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:12,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-grxko2as', purging
2023-05-28 07:16:12,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:12,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:12,949 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:14,259 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iorr0fpw', purging
2023-05-28 07:16:14,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:14,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:15,043 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:16,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n822ug_n', purging
2023-05-28 07:16:16,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:16,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:17,137 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:18,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-11mvvoj3', purging
2023-05-28 07:16:18,460 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:18,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:19,236 - distributed.nanny - WARNING - Restarting worker
2023-05-28 07:16:20,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_i4l1zip', purging
2023-05-28 07:16:20,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 07:16:20,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 07:16:21,358 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 273 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
