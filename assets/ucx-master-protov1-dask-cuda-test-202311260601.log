============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.3, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1197 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-11-26 06:35:34,207 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:35:34,211 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37775 instead
  warnings.warn(
2023-11-26 06:35:34,215 - distributed.scheduler - INFO - State start
2023-11-26 06:35:34,390 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:35:34,391 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-11-26 06:35:34,391 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:37775/status
2023-11-26 06:35:34,392 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:35:34,519 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39687'
2023-11-26 06:35:34,542 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34381'
2023-11-26 06:35:34,544 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42205'
2023-11-26 06:35:34,552 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44073'
2023-11-26 06:35:35,094 - distributed.scheduler - INFO - Receive client connection: Client-ff930824-8c25-11ee-8546-d8c49764f6bb
2023-11-26 06:35:35,103 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57642
2023-11-26 06:35:36,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:36,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:36,243 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:36,258 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:36,258 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:36,262 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:36,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:36,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:36,303 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-11-26 06:35:36,321 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40353
2023-11-26 06:35:36,321 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40353
2023-11-26 06:35:36,321 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40497
2023-11-26 06:35:36,321 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-26 06:35:36,322 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:36,322 - distributed.worker - INFO -               Threads:                          4
2023-11-26 06:35:36,322 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-26 06:35:36,322 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-f59d73cc
2023-11-26 06:35:36,322 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9fe48f2f-aa70-4f32-b42e-46077de1fb77
2023-11-26 06:35:36,322 - distributed.worker - INFO - Starting Worker plugin PreImport-e061b74f-8ad9-49a7-8f2e-c99d3f3c0db6
2023-11-26 06:35:36,322 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9c648d8c-6add-49ac-8037-636a3f6a49b5
2023-11-26 06:35:36,322 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:36,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:36,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:36,353 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:36,851 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40353', status: init, memory: 0, processing: 0>
2023-11-26 06:35:36,853 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40353
2023-11-26 06:35:36,853 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57656
2023-11-26 06:35:36,854 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:36,854 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-26 06:35:36,855 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:36,856 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-26 06:35:37,501 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40743
2023-11-26 06:35:37,502 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40743
2023-11-26 06:35:37,503 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44283
2023-11-26 06:35:37,503 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-26 06:35:37,503 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:37,503 - distributed.worker - INFO -               Threads:                          4
2023-11-26 06:35:37,503 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-26 06:35:37,503 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-6erjkp4u
2023-11-26 06:35:37,504 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-630643e6-3f76-4a3f-9dbc-7c58a9adeb96
2023-11-26 06:35:37,504 - distributed.worker - INFO - Starting Worker plugin PreImport-e5ea3e50-b5be-46a5-bfe9-ec096c738422
2023-11-26 06:35:37,505 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4f908d8e-2728-4f44-875a-af56ca5bf6e1
2023-11-26 06:35:37,505 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:37,530 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40743', status: init, memory: 0, processing: 0>
2023-11-26 06:35:37,531 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40743
2023-11-26 06:35:37,531 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57666
2023-11-26 06:35:37,532 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:37,533 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-26 06:35:37,533 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:37,535 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-26 06:35:37,629 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45429
2023-11-26 06:35:37,630 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45429
2023-11-26 06:35:37,630 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42423
2023-11-26 06:35:37,630 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-26 06:35:37,630 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:37,630 - distributed.worker - INFO -               Threads:                          4
2023-11-26 06:35:37,631 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-26 06:35:37,631 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-kbzzwial
2023-11-26 06:35:37,631 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a25a2c9d-a506-47e5-8e7b-09f733abb609
2023-11-26 06:35:37,631 - distributed.worker - INFO - Starting Worker plugin PreImport-91be1619-b2b1-4bbf-89d9-2ad2dfc1f7ef
2023-11-26 06:35:37,632 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-850cdf27-8187-409c-b128-48624b715da6
2023-11-26 06:35:37,632 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:37,673 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45429', status: init, memory: 0, processing: 0>
2023-11-26 06:35:37,674 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45429
2023-11-26 06:35:37,674 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57680
2023-11-26 06:35:37,676 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:37,678 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-26 06:35:37,678 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:37,681 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-26 06:35:37,683 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37101
2023-11-26 06:35:37,683 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37101
2023-11-26 06:35:37,683 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37511
2023-11-26 06:35:37,683 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-26 06:35:37,684 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:37,684 - distributed.worker - INFO -               Threads:                          4
2023-11-26 06:35:37,684 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-11-26 06:35:37,684 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-f6lx9297
2023-11-26 06:35:37,684 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a2511e19-73c4-4a7b-991b-2426ee580b0c
2023-11-26 06:35:37,685 - distributed.worker - INFO - Starting Worker plugin PreImport-5329a178-f713-417e-9974-bc69d776d0b0
2023-11-26 06:35:37,685 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4aac09ce-c8d5-4739-9a50-7128dcbd3704
2023-11-26 06:35:37,686 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:37,740 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37101', status: init, memory: 0, processing: 0>
2023-11-26 06:35:37,741 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37101
2023-11-26 06:35:37,741 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57694
2023-11-26 06:35:37,743 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:37,744 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-26 06:35:37,744 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:37,747 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-26 06:35:37,771 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-26 06:35:37,771 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-26 06:35:37,771 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-26 06:35:37,771 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2023-11-26 06:35:37,778 - distributed.scheduler - INFO - Remove client Client-ff930824-8c25-11ee-8546-d8c49764f6bb
2023-11-26 06:35:37,778 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57642; closing.
2023-11-26 06:35:37,778 - distributed.scheduler - INFO - Remove client Client-ff930824-8c25-11ee-8546-d8c49764f6bb
2023-11-26 06:35:37,778 - distributed.scheduler - INFO - Close client connection: Client-ff930824-8c25-11ee-8546-d8c49764f6bb
2023-11-26 06:35:37,780 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39687'. Reason: nanny-close
2023-11-26 06:35:37,781 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:37,782 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34381'. Reason: nanny-close
2023-11-26 06:35:37,783 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:37,783 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37101. Reason: nanny-close
2023-11-26 06:35:37,783 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42205'. Reason: nanny-close
2023-11-26 06:35:37,784 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:37,785 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40743. Reason: nanny-close
2023-11-26 06:35:37,786 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57694; closing.
2023-11-26 06:35:37,787 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-26 06:35:37,787 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37101', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980537.7871182')
2023-11-26 06:35:37,787 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-26 06:35:37,788 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57666; closing.
2023-11-26 06:35:37,788 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44073'. Reason: nanny-close
2023-11-26 06:35:37,788 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40743', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980537.7885988')
2023-11-26 06:35:37,788 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:37,789 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45429. Reason: nanny-close
2023-11-26 06:35:37,789 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40353. Reason: nanny-close
2023-11-26 06:35:37,790 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:37,791 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57680; closing.
2023-11-26 06:35:37,791 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-26 06:35:37,792 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45429', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980537.7920725')
2023-11-26 06:35:37,792 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57656; closing.
2023-11-26 06:35:37,792 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-26 06:35:37,793 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40353', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980537.7930415')
2023-11-26 06:35:37,793 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:35:37,793 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:37,794 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:37,794 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:39,096 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:35:39,097 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:35:39,097 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:35:39,098 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-11-26 06:35:39,098 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-11-26 06:35:41,283 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:35:41,288 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43343 instead
  warnings.warn(
2023-11-26 06:35:41,292 - distributed.scheduler - INFO - State start
2023-11-26 06:35:41,372 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:35:41,373 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:35:41,374 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43343/status
2023-11-26 06:35:41,374 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:35:41,679 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39229'
2023-11-26 06:35:41,694 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37157'
2023-11-26 06:35:41,716 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33067'
2023-11-26 06:35:41,731 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41879'
2023-11-26 06:35:41,734 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43933'
2023-11-26 06:35:41,746 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38017'
2023-11-26 06:35:41,760 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36855'
2023-11-26 06:35:41,772 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35955'
2023-11-26 06:35:43,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:43,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:43,488 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:43,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:43,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:43,582 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:43,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:43,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:43,632 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:43,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:43,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:43,810 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:43,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:43,811 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:43,818 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:43,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:43,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:43,856 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:43,862 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:43,862 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:43,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:43,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:43,868 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:43,873 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:45,437 - distributed.scheduler - INFO - Receive client connection: Client-03d10cb4-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:35:45,449 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58276
2023-11-26 06:35:45,614 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40823
2023-11-26 06:35:45,616 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40823
2023-11-26 06:35:45,616 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39313
2023-11-26 06:35:45,616 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:45,616 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:45,616 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:45,616 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:45,616 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o93rrl3a
2023-11-26 06:35:45,618 - distributed.worker - INFO - Starting Worker plugin PreImport-08cff98e-7b29-4ab8-9800-8d398a720bac
2023-11-26 06:35:45,618 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-20074545-99f8-45cc-9402-260c24edde97
2023-11-26 06:35:45,618 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a9d02c2c-a1b6-433a-8452-b753ad06155d
2023-11-26 06:35:46,317 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:46,387 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40823', status: init, memory: 0, processing: 0>
2023-11-26 06:35:46,389 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40823
2023-11-26 06:35:46,389 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58294
2023-11-26 06:35:46,390 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:46,392 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:46,392 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:46,393 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:47,532 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35051
2023-11-26 06:35:47,533 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35051
2023-11-26 06:35:47,533 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46445
2023-11-26 06:35:47,533 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,533 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,533 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:47,533 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:47,533 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gh5bfnm8
2023-11-26 06:35:47,534 - distributed.worker - INFO - Starting Worker plugin RMMSetup-99126610-005f-40b0-afc6-32a0105e3e4a
2023-11-26 06:35:47,554 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40715
2023-11-26 06:35:47,555 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40715
2023-11-26 06:35:47,555 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41407
2023-11-26 06:35:47,555 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,555 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,555 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:47,555 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:47,556 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jaiwio9g
2023-11-26 06:35:47,556 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-94dd0fe0-aafd-4d86-9445-a50f2bbae526
2023-11-26 06:35:47,556 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4ac39d24-aa7a-4588-a82c-5a5c7350d852
2023-11-26 06:35:47,567 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39377
2023-11-26 06:35:47,567 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39377
2023-11-26 06:35:47,568 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37429
2023-11-26 06:35:47,568 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,568 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,568 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:47,568 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:47,568 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-abxwncxc
2023-11-26 06:35:47,568 - distributed.worker - INFO - Starting Worker plugin RMMSetup-73555b37-125a-48da-bebe-6153f19df7e6
2023-11-26 06:35:47,576 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35563
2023-11-26 06:35:47,576 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35563
2023-11-26 06:35:47,576 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33377
2023-11-26 06:35:47,577 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,577 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,577 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:47,577 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:47,577 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7c4il828
2023-11-26 06:35:47,577 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f404a01b-2de1-4c1e-963f-33db01718403
2023-11-26 06:35:47,579 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35859
2023-11-26 06:35:47,580 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35859
2023-11-26 06:35:47,580 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37987
2023-11-26 06:35:47,580 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,580 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,580 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:47,581 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:47,581 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c9sppqkr
2023-11-26 06:35:47,581 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-71a5a881-39bd-407a-8f86-d4e9234d51ab
2023-11-26 06:35:47,582 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5dc28be5-c6a0-4746-8d7f-bc89809c6ba9
2023-11-26 06:35:47,582 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43699
2023-11-26 06:35:47,583 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43699
2023-11-26 06:35:47,583 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32935
2023-11-26 06:35:47,583 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,583 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,583 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:47,584 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:47,584 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nwg6j9e7
2023-11-26 06:35:47,584 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8a405e7d-f4a6-45bc-a181-c72e5da4821e
2023-11-26 06:35:47,584 - distributed.worker - INFO - Starting Worker plugin RMMSetup-947bb295-56de-4bd6-91bd-211f13cc065f
2023-11-26 06:35:47,585 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37009
2023-11-26 06:35:47,585 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37009
2023-11-26 06:35:47,585 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40095
2023-11-26 06:35:47,586 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,586 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,586 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:47,586 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:47,586 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mknz4bbt
2023-11-26 06:35:47,586 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f030df19-e901-42e8-b4b6-584c63e198ba
2023-11-26 06:35:47,850 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4fc96761-505e-4967-80b8-177f168fd7a3
2023-11-26 06:35:47,850 - distributed.worker - INFO - Starting Worker plugin PreImport-02682f0d-7b62-41eb-a886-48e35de692e7
2023-11-26 06:35:47,851 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,857 - distributed.worker - INFO - Starting Worker plugin PreImport-e5c4d082-8012-4cae-a19b-dec07671de3f
2023-11-26 06:35:47,857 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,869 - distributed.worker - INFO - Starting Worker plugin PreImport-76f044de-246a-450b-ae83-19dc88167527
2023-11-26 06:35:47,869 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,869 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eedb742d-b656-4a26-a7f1-531932774926
2023-11-26 06:35:47,869 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-50cab5b9-7e9c-4a2e-92d3-1ae855714b98
2023-11-26 06:35:47,869 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f6872e93-a04f-479e-89ce-8c4a0b8e5d9f
2023-11-26 06:35:47,869 - distributed.worker - INFO - Starting Worker plugin PreImport-52aeeb56-ec03-4845-b65b-1916c8674920
2023-11-26 06:35:47,869 - distributed.worker - INFO - Starting Worker plugin PreImport-0f6f8ba3-a1c8-4678-8bbb-f6c371fe2d0f
2023-11-26 06:35:47,870 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,870 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,871 - distributed.worker - INFO - Starting Worker plugin PreImport-d1cde909-4e34-4b07-ab37-bb514689b59c
2023-11-26 06:35:47,872 - distributed.worker - INFO - Starting Worker plugin PreImport-17f98b08-8845-4fa1-b065-6ed1c403ad54
2023-11-26 06:35:47,872 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,873 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,878 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39377', status: init, memory: 0, processing: 0>
2023-11-26 06:35:47,879 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39377
2023-11-26 06:35:47,879 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58322
2023-11-26 06:35:47,880 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43699', status: init, memory: 0, processing: 0>
2023-11-26 06:35:47,880 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:47,881 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43699
2023-11-26 06:35:47,881 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58338
2023-11-26 06:35:47,881 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,881 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,882 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:47,883 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,883 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,883 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:47,884 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:47,892 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40715', status: init, memory: 0, processing: 0>
2023-11-26 06:35:47,892 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40715
2023-11-26 06:35:47,892 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58342
2023-11-26 06:35:47,893 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:47,894 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35051', status: init, memory: 0, processing: 0>
2023-11-26 06:35:47,894 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,894 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,894 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35051
2023-11-26 06:35:47,894 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58346
2023-11-26 06:35:47,895 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:47,896 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:47,896 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,896 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,897 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:47,909 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35563', status: init, memory: 0, processing: 0>
2023-11-26 06:35:47,910 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35563
2023-11-26 06:35:47,910 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58376
2023-11-26 06:35:47,912 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:47,913 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35859', status: init, memory: 0, processing: 0>
2023-11-26 06:35:47,913 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35859
2023-11-26 06:35:47,913 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58362
2023-11-26 06:35:47,914 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37009', status: init, memory: 0, processing: 0>
2023-11-26 06:35:47,914 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,914 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,914 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37009
2023-11-26 06:35:47,914 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58364
2023-11-26 06:35:47,915 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:47,916 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:47,917 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:47,918 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,918 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,918 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:47,918 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:47,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:47,920 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:48,006 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:48,006 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:48,006 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:48,007 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:48,007 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:48,007 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:48,007 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:48,007 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:48,011 - distributed.scheduler - INFO - Remove client Client-03d10cb4-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:35:48,011 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58276; closing.
2023-11-26 06:35:48,012 - distributed.scheduler - INFO - Remove client Client-03d10cb4-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:35:48,012 - distributed.scheduler - INFO - Close client connection: Client-03d10cb4-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:35:48,013 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39229'. Reason: nanny-close
2023-11-26 06:35:48,013 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:48,014 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37157'. Reason: nanny-close
2023-11-26 06:35:48,014 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:48,014 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35859. Reason: nanny-close
2023-11-26 06:35:48,014 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33067'. Reason: nanny-close
2023-11-26 06:35:48,015 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:48,015 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40823. Reason: nanny-close
2023-11-26 06:35:48,015 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41879'. Reason: nanny-close
2023-11-26 06:35:48,015 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:48,015 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35051. Reason: nanny-close
2023-11-26 06:35:48,016 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43933'. Reason: nanny-close
2023-11-26 06:35:48,016 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:48,016 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40715. Reason: nanny-close
2023-11-26 06:35:48,016 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38017'. Reason: nanny-close
2023-11-26 06:35:48,017 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:48,017 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36855'. Reason: nanny-close
2023-11-26 06:35:48,017 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37009. Reason: nanny-close
2023-11-26 06:35:48,017 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:48,017 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:48,017 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58362; closing.
2023-11-26 06:35:48,017 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:48,017 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:48,018 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58346; closing.
2023-11-26 06:35:48,018 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35955'. Reason: nanny-close
2023-11-26 06:35:48,018 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35563. Reason: nanny-close
2023-11-26 06:35:48,018 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:48,018 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:48,018 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35859', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980548.0183654')
2023-11-26 06:35:48,018 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39377. Reason: nanny-close
2023-11-26 06:35:48,019 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35051', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980548.0190227')
2023-11-26 06:35:48,019 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43699. Reason: nanny-close
2023-11-26 06:35:48,019 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58294; closing.
2023-11-26 06:35:48,019 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:48,020 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:48,020 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:48,020 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:48,020 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40823', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980548.0201268')
2023-11-26 06:35:48,020 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58342; closing.
2023-11-26 06:35:48,020 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:48,020 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:48,021 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:48,021 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:48,021 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40715', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980548.0216665')
2023-11-26 06:35:48,022 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:48,022 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:48,022 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:48,022 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:58294>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-26 06:35:48,024 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:48,024 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58364; closing.
2023-11-26 06:35:48,025 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58322; closing.
2023-11-26 06:35:48,025 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58376; closing.
2023-11-26 06:35:48,025 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37009', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980548.025731')
2023-11-26 06:35:48,026 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39377', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980548.0260763')
2023-11-26 06:35:48,026 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35563', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980548.0263345')
2023-11-26 06:35:48,026 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58338; closing.
2023-11-26 06:35:48,027 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43699', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980548.0269558')
2023-11-26 06:35:48,027 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:35:49,631 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:35:49,631 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:35:49,632 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:35:49,633 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:35:49,633 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-11-26 06:35:51,663 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:35:51,667 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45483 instead
  warnings.warn(
2023-11-26 06:35:51,671 - distributed.scheduler - INFO - State start
2023-11-26 06:35:51,703 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:35:51,704 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:35:51,704 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:45483/status
2023-11-26 06:35:51,705 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:35:51,868 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40669'
2023-11-26 06:35:51,880 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36759'
2023-11-26 06:35:51,891 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38793'
2023-11-26 06:35:51,905 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44545'
2023-11-26 06:35:51,907 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34279'
2023-11-26 06:35:51,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39725'
2023-11-26 06:35:51,924 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41565'
2023-11-26 06:35:51,933 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33381'
2023-11-26 06:35:53,424 - distributed.scheduler - INFO - Receive client connection: Client-0a183c6d-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:35:53,435 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52756
2023-11-26 06:35:53,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:53,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:53,645 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:53,760 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:53,760 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:53,763 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:53,763 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:53,764 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:53,767 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:53,768 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:53,768 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:53,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:53,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:53,772 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:53,776 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:53,790 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:53,790 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:53,794 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:53,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:53,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:53,804 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:53,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:35:53,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:35:53,816 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:35:55,552 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44745
2023-11-26 06:35:55,553 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44745
2023-11-26 06:35:55,553 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46093
2023-11-26 06:35:55,553 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:55,553 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:55,553 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:55,553 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:55,553 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rs7k1a80
2023-11-26 06:35:55,554 - distributed.worker - INFO - Starting Worker plugin PreImport-87315796-421b-41b2-8155-fed114149f68
2023-11-26 06:35:55,554 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c1a4bbc5-0264-4030-a2d3-65ef92e0e9e5
2023-11-26 06:35:55,554 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9fc4820b-690e-4553-8d6e-ce60d4816d9e
2023-11-26 06:35:55,635 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:55,660 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44745', status: init, memory: 0, processing: 0>
2023-11-26 06:35:55,661 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44745
2023-11-26 06:35:55,661 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52776
2023-11-26 06:35:55,662 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:55,663 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:55,663 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:55,665 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:56,524 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45911
2023-11-26 06:35:56,524 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45911
2023-11-26 06:35:56,524 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32963
2023-11-26 06:35:56,524 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,525 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,525 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:56,525 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:56,525 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wsq_fu3d
2023-11-26 06:35:56,525 - distributed.worker - INFO - Starting Worker plugin RMMSetup-92b02bc1-de7d-4966-9fb2-9d6640820e1e
2023-11-26 06:35:56,526 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41107
2023-11-26 06:35:56,527 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41107
2023-11-26 06:35:56,527 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38327
2023-11-26 06:35:56,527 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,527 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,527 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:56,528 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:56,528 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wxf5wadi
2023-11-26 06:35:56,528 - distributed.worker - INFO - Starting Worker plugin RMMSetup-41a42e39-7267-4dc3-b7eb-82c666097340
2023-11-26 06:35:56,532 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41385
2023-11-26 06:35:56,533 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41385
2023-11-26 06:35:56,533 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32935
2023-11-26 06:35:56,533 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,533 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,533 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:56,533 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:56,533 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l2_1vwki
2023-11-26 06:35:56,534 - distributed.worker - INFO - Starting Worker plugin RMMSetup-afa66920-0ae7-4b38-ab02-1a4086c14aed
2023-11-26 06:35:56,536 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45061
2023-11-26 06:35:56,537 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45061
2023-11-26 06:35:56,537 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36081
2023-11-26 06:35:56,537 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,537 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,537 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:56,537 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:56,537 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-udm1dodb
2023-11-26 06:35:56,538 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e37afb9f-d40d-473d-9899-cd2e9eaf33e9
2023-11-26 06:35:56,538 - distributed.worker - INFO - Starting Worker plugin RMMSetup-238ecd6c-1e8d-47e1-98d4-19804fab72c7
2023-11-26 06:35:56,539 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b0c95897-a33a-4a8d-bcef-1d304cf4fbcb
2023-11-26 06:35:56,540 - distributed.worker - INFO - Starting Worker plugin PreImport-470440d4-06b5-4e6c-9df8-d8d0ef03ed10
2023-11-26 06:35:56,540 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,543 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e606b20e-4e9d-40e9-bbf6-f724684cd810
2023-11-26 06:35:56,543 - distributed.worker - INFO - Starting Worker plugin PreImport-5234ecaf-2bf3-4e97-92a5-55cddbbe8426
2023-11-26 06:35:56,543 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,546 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c41a00e6-8c88-4aaa-addd-a2d1abb7d6e9
2023-11-26 06:35:56,546 - distributed.worker - INFO - Starting Worker plugin PreImport-a7d8ef4c-dfc2-4818-837b-ccc98433b09f
2023-11-26 06:35:56,546 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,546 - distributed.worker - INFO - Starting Worker plugin PreImport-7e19a622-72af-4f7c-93af-40be14f6aaf3
2023-11-26 06:35:56,547 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,564 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41107', status: init, memory: 0, processing: 0>
2023-11-26 06:35:56,564 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41107
2023-11-26 06:35:56,565 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52782
2023-11-26 06:35:56,565 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:56,566 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,566 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41385', status: init, memory: 0, processing: 0>
2023-11-26 06:35:56,566 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,567 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41385
2023-11-26 06:35:56,567 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52786
2023-11-26 06:35:56,568 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:56,568 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:56,568 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,568 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,570 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:56,570 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45061', status: init, memory: 0, processing: 0>
2023-11-26 06:35:56,571 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45061
2023-11-26 06:35:56,571 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52794
2023-11-26 06:35:56,572 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:56,572 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,572 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,574 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:56,587 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45911', status: init, memory: 0, processing: 0>
2023-11-26 06:35:56,588 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45911
2023-11-26 06:35:56,588 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52810
2023-11-26 06:35:56,590 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:56,591 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,591 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,594 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:56,602 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38345
2023-11-26 06:35:56,603 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38345
2023-11-26 06:35:56,603 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43253
2023-11-26 06:35:56,603 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,603 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,603 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:56,604 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:56,604 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-276up1lp
2023-11-26 06:35:56,604 - distributed.worker - INFO - Starting Worker plugin RMMSetup-801cebd0-4308-42cb-94b8-d709f4425662
2023-11-26 06:35:56,604 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33559
2023-11-26 06:35:56,605 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33559
2023-11-26 06:35:56,605 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40209
2023-11-26 06:35:56,605 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,605 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,605 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:56,605 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:56,605 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-97esqfkq
2023-11-26 06:35:56,606 - distributed.worker - INFO - Starting Worker plugin PreImport-6cecb308-db65-4d43-afe5-ee507a41cee0
2023-11-26 06:35:56,605 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40387
2023-11-26 06:35:56,606 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40387
2023-11-26 06:35:56,606 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b89ef63-0ebf-4624-9907-c9edad06fee2
2023-11-26 06:35:56,606 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41715
2023-11-26 06:35:56,606 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,606 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,606 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:35:56,606 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:35:56,606 - distributed.worker - INFO - Starting Worker plugin RMMSetup-21cac17d-0272-4d2e-bc97-d92a5f6bc555
2023-11-26 06:35:56,606 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2btltbpp
2023-11-26 06:35:56,607 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a5d07135-99f6-41e1-be68-eed3a6b435fc
2023-11-26 06:35:56,613 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6ff20076-b169-4503-83de-103a5a72a469
2023-11-26 06:35:56,613 - distributed.worker - INFO - Starting Worker plugin PreImport-f1eecd2c-6f86-420b-b9cc-0cb5f582727a
2023-11-26 06:35:56,613 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,619 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-506bca79-31d7-4a45-92d2-32914f20f8f0
2023-11-26 06:35:56,619 - distributed.worker - INFO - Starting Worker plugin PreImport-6ccc2964-6843-4e78-a3d8-65b1983a09b8
2023-11-26 06:35:56,620 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,620 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,631 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38345', status: init, memory: 0, processing: 0>
2023-11-26 06:35:56,632 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38345
2023-11-26 06:35:56,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52818
2023-11-26 06:35:56,633 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:56,634 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,634 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:56,656 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33559', status: init, memory: 0, processing: 0>
2023-11-26 06:35:56,657 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33559
2023-11-26 06:35:56,657 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52846
2023-11-26 06:35:56,657 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40387', status: init, memory: 0, processing: 0>
2023-11-26 06:35:56,658 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40387
2023-11-26 06:35:56,658 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52834
2023-11-26 06:35:56,658 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:56,659 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,659 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,660 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:35:56,661 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:35:56,662 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:35:56,662 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:56,664 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:35:56,683 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:56,683 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:56,683 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:56,683 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:56,684 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:56,684 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:56,684 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:56,684 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:35:56,688 - distributed.scheduler - INFO - Remove client Client-0a183c6d-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:35:56,689 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52756; closing.
2023-11-26 06:35:56,689 - distributed.scheduler - INFO - Remove client Client-0a183c6d-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:35:56,689 - distributed.scheduler - INFO - Close client connection: Client-0a183c6d-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:35:56,690 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40669'. Reason: nanny-close
2023-11-26 06:35:56,690 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:56,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36759'. Reason: nanny-close
2023-11-26 06:35:56,691 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:56,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38793'. Reason: nanny-close
2023-11-26 06:35:56,692 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44745. Reason: nanny-close
2023-11-26 06:35:56,692 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:56,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44545'. Reason: nanny-close
2023-11-26 06:35:56,692 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45911. Reason: nanny-close
2023-11-26 06:35:56,692 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:56,692 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45061. Reason: nanny-close
2023-11-26 06:35:56,693 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34279'. Reason: nanny-close
2023-11-26 06:35:56,693 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38345. Reason: nanny-close
2023-11-26 06:35:56,693 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:56,694 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39725'. Reason: nanny-close
2023-11-26 06:35:56,694 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:56,694 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41565'. Reason: nanny-close
2023-11-26 06:35:56,694 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:56,694 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40387. Reason: nanny-close
2023-11-26 06:35:56,694 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:56,695 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:56,695 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52776; closing.
2023-11-26 06:35:56,695 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33559. Reason: nanny-close
2023-11-26 06:35:56,695 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33381'. Reason: nanny-close
2023-11-26 06:35:56,695 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:35:56,695 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44745', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980556.6955488')
2023-11-26 06:35:56,695 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:56,695 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41385. Reason: nanny-close
2023-11-26 06:35:56,695 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:56,696 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52794; closing.
2023-11-26 06:35:56,696 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41107. Reason: nanny-close
2023-11-26 06:35:56,696 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45061', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980556.6965592')
2023-11-26 06:35:56,696 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:56,696 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52818; closing.
2023-11-26 06:35:56,697 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:56,697 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:56,697 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:56,697 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38345', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980556.6977568')
2023-11-26 06:35:56,697 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:56,698 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52810; closing.
2023-11-26 06:35:56,698 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:56,698 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:56,698 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:35:56,699 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:56,698 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:52794>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-26 06:35:56,699 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:56,700 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45911', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980556.7001014')
2023-11-26 06:35:56,700 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:56,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52834; closing.
2023-11-26 06:35:56,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52786; closing.
2023-11-26 06:35:56,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52846; closing.
2023-11-26 06:35:56,701 - distributed.nanny - INFO - Worker closed
2023-11-26 06:35:56,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52782; closing.
2023-11-26 06:35:56,701 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40387', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980556.701797')
2023-11-26 06:35:56,702 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41385', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980556.7022183')
2023-11-26 06:35:56,702 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33559', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980556.7025838')
2023-11-26 06:35:56,702 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41107', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980556.7029426')
2023-11-26 06:35:56,703 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:35:58,209 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:35:58,209 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:35:58,210 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:35:58,212 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:35:58,212 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-11-26 06:36:00,473 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:00,477 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39623 instead
  warnings.warn(
2023-11-26 06:36:00,481 - distributed.scheduler - INFO - State start
2023-11-26 06:36:00,502 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:00,503 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:36:00,503 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39623/status
2023-11-26 06:36:00,503 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:36:00,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36793'
2023-11-26 06:36:00,701 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43767'
2023-11-26 06:36:00,717 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34773'
2023-11-26 06:36:00,719 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36685'
2023-11-26 06:36:00,727 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39833'
2023-11-26 06:36:00,736 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34787'
2023-11-26 06:36:00,744 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43411'
2023-11-26 06:36:00,753 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36523'
2023-11-26 06:36:01,232 - distributed.scheduler - INFO - Receive client connection: Client-0f4d8cac-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:01,250 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54338
2023-11-26 06:36:02,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:02,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:02,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:02,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:02,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:02,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:02,559 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:02,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:02,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:02,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:02,562 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:02,562 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:02,563 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:02,563 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:02,566 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:02,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:02,588 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:02,596 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:02,623 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:02,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:02,628 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:02,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:02,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:02,727 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:05,146 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39027
2023-11-26 06:36:05,147 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39027
2023-11-26 06:36:05,148 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43331
2023-11-26 06:36:05,148 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,148 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,148 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:05,148 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:05,148 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i3q0q9um
2023-11-26 06:36:05,149 - distributed.worker - INFO - Starting Worker plugin RMMSetup-83984cb3-6402-428b-af81-d6a142a17b7b
2023-11-26 06:36:05,161 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45413
2023-11-26 06:36:05,162 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45413
2023-11-26 06:36:05,162 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41549
2023-11-26 06:36:05,162 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,162 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,162 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:05,162 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:05,162 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-003sw8t9
2023-11-26 06:36:05,163 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4772c51f-5c29-41d2-b45b-77b780350648
2023-11-26 06:36:05,174 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39601
2023-11-26 06:36:05,175 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39601
2023-11-26 06:36:05,175 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46095
2023-11-26 06:36:05,176 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,176 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,176 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:05,176 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:05,176 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-je_7vy8_
2023-11-26 06:36:05,176 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1993681d-c96b-4a02-9570-0490645f0cf0
2023-11-26 06:36:05,235 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38179
2023-11-26 06:36:05,236 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38179
2023-11-26 06:36:05,237 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36981
2023-11-26 06:36:05,237 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,237 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,237 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:05,237 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:05,237 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-czgwkcvt
2023-11-26 06:36:05,238 - distributed.worker - INFO - Starting Worker plugin RMMSetup-639d92af-7288-4158-bdf7-61fefc310b11
2023-11-26 06:36:05,301 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-33d92374-682f-4fc6-8c01-2319078a4639
2023-11-26 06:36:05,301 - distributed.worker - INFO - Starting Worker plugin PreImport-aedf80c1-8bed-40e6-9a8d-a1ebf19b258d
2023-11-26 06:36:05,301 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,311 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2b5e2e1e-866c-497c-a6ef-a56da7995a69
2023-11-26 06:36:05,312 - distributed.worker - INFO - Starting Worker plugin PreImport-1ab11b7d-c2d0-4d83-9d9c-2229f0316f9a
2023-11-26 06:36:05,312 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,317 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cde3c565-d1a0-437c-81a6-ee1cd49ce7d8
2023-11-26 06:36:05,317 - distributed.worker - INFO - Starting Worker plugin PreImport-e1897acf-14ae-4d07-bb8a-6bbef606b860
2023-11-26 06:36:05,318 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,333 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39027', status: init, memory: 0, processing: 0>
2023-11-26 06:36:05,335 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39027
2023-11-26 06:36:05,335 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54356
2023-11-26 06:36:05,336 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:05,337 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,337 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,338 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:05,341 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45413', status: init, memory: 0, processing: 0>
2023-11-26 06:36:05,341 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45413
2023-11-26 06:36:05,341 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54368
2023-11-26 06:36:05,342 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:05,343 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,343 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,345 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:05,348 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39601', status: init, memory: 0, processing: 0>
2023-11-26 06:36:05,348 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39601
2023-11-26 06:36:05,348 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54380
2023-11-26 06:36:05,349 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:05,350 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,350 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,351 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:05,369 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-829783cc-cfdd-433f-8efa-1d640f972ab5
2023-11-26 06:36:05,369 - distributed.worker - INFO - Starting Worker plugin PreImport-91a54f52-66da-4ac1-a878-0009fe7f97cd
2023-11-26 06:36:05,370 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,408 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38179', status: init, memory: 0, processing: 0>
2023-11-26 06:36:05,408 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38179
2023-11-26 06:36:05,408 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54390
2023-11-26 06:36:05,410 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:05,411 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,411 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,413 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:05,503 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35439
2023-11-26 06:36:05,504 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35439
2023-11-26 06:36:05,504 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46133
2023-11-26 06:36:05,504 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,504 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,504 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:05,505 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:05,505 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7mly_pf2
2023-11-26 06:36:05,505 - distributed.worker - INFO - Starting Worker plugin RMMSetup-485075f8-3b48-481b-8f73-f8cea9c90f82
2023-11-26 06:36:05,509 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37193
2023-11-26 06:36:05,509 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37193
2023-11-26 06:36:05,509 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32995
2023-11-26 06:36:05,510 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,510 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,510 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:05,510 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:05,510 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-egjcct4m
2023-11-26 06:36:05,510 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3c7dc1cb-f60f-4b2b-a51a-3dc65639cc7c
2023-11-26 06:36:05,510 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42771
2023-11-26 06:36:05,511 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42771
2023-11-26 06:36:05,511 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33741
2023-11-26 06:36:05,511 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,511 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,511 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aab76134-e7c9-4a51-bae4-e6a3eaea40c1
2023-11-26 06:36:05,511 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:05,511 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:05,511 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-m8wwwsx_
2023-11-26 06:36:05,512 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-87eaaa97-4734-44e1-82bd-946ce99e8992
2023-11-26 06:36:05,512 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e4302390-ceac-47f9-93f1-84fe2d88b179
2023-11-26 06:36:05,520 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40363
2023-11-26 06:36:05,522 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40363
2023-11-26 06:36:05,522 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39643
2023-11-26 06:36:05,522 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,522 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,522 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:05,523 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:05,523 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8581dx64
2023-11-26 06:36:05,524 - distributed.worker - INFO - Starting Worker plugin PreImport-f65de8a6-a1fb-43ae-9332-547de0569e8b
2023-11-26 06:36:05,524 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d1947389-e27a-4e2c-a57e-12083faf082a
2023-11-26 06:36:05,524 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0cc0db35-5e22-4328-9d69-8547f16af958
2023-11-26 06:36:05,638 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-940ce17e-ec9a-48f4-ba65-2ca3fb2138a2
2023-11-26 06:36:05,640 - distributed.worker - INFO - Starting Worker plugin PreImport-2b4bf287-f314-4013-9840-63c22df5ddcc
2023-11-26 06:36:05,640 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,652 - distributed.worker - INFO - Starting Worker plugin PreImport-2b50ba80-fbca-4cd9-a810-e1e35b0cbb06
2023-11-26 06:36:05,652 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,669 - distributed.worker - INFO - Starting Worker plugin PreImport-6e40eb8d-97ff-485b-8a38-a48fef29003a
2023-11-26 06:36:05,670 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,673 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,673 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42771', status: init, memory: 0, processing: 0>
2023-11-26 06:36:05,673 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42771
2023-11-26 06:36:05,674 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54408
2023-11-26 06:36:05,674 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:05,675 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,675 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,677 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:05,678 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35439', status: init, memory: 0, processing: 0>
2023-11-26 06:36:05,678 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35439
2023-11-26 06:36:05,678 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54404
2023-11-26 06:36:05,680 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:05,681 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,681 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,683 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:05,707 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37193', status: init, memory: 0, processing: 0>
2023-11-26 06:36:05,708 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37193
2023-11-26 06:36:05,708 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54416
2023-11-26 06:36:05,708 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40363', status: init, memory: 0, processing: 0>
2023-11-26 06:36:05,709 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40363
2023-11-26 06:36:05,709 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:54430
2023-11-26 06:36:05,709 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:05,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:05,710 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,711 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,712 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:05,712 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:05,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:05,714 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:05,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:05,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:05,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:05,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:05,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:05,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:05,742 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:05,743 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:05,753 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:05,753 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:05,753 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:05,753 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:05,753 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:05,753 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:05,753 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:05,754 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:05,760 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:05,761 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:05,763 - distributed.scheduler - INFO - Remove client Client-0f4d8cac-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:05,763 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54338; closing.
2023-11-26 06:36:05,764 - distributed.scheduler - INFO - Remove client Client-0f4d8cac-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:05,764 - distributed.scheduler - INFO - Close client connection: Client-0f4d8cac-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:05,765 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36793'. Reason: nanny-close
2023-11-26 06:36:05,766 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:05,767 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43767'. Reason: nanny-close
2023-11-26 06:36:05,767 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:05,767 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35439. Reason: nanny-close
2023-11-26 06:36:05,767 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34773'. Reason: nanny-close
2023-11-26 06:36:05,767 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:05,768 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36685'. Reason: nanny-close
2023-11-26 06:36:05,768 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37193. Reason: nanny-close
2023-11-26 06:36:05,768 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:05,768 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45413. Reason: nanny-close
2023-11-26 06:36:05,768 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39833'. Reason: nanny-close
2023-11-26 06:36:05,769 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:05,769 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39027. Reason: nanny-close
2023-11-26 06:36:05,769 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34787'. Reason: nanny-close
2023-11-26 06:36:05,769 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:05,770 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40363. Reason: nanny-close
2023-11-26 06:36:05,770 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:05,770 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54404; closing.
2023-11-26 06:36:05,770 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43411'. Reason: nanny-close
2023-11-26 06:36:05,770 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:05,770 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35439', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980565.7703366')
2023-11-26 06:36:05,770 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:05,770 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:05,770 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36523'. Reason: nanny-close
2023-11-26 06:36:05,770 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38179. Reason: nanny-close
2023-11-26 06:36:05,770 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:05,770 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:05,771 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42771. Reason: nanny-close
2023-11-26 06:36:05,771 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54356; closing.
2023-11-26 06:36:05,771 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54368; closing.
2023-11-26 06:36:05,771 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39601. Reason: nanny-close
2023-11-26 06:36:05,771 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:05,772 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:05,772 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:05,772 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:05,772 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:05,772 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39027', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980565.772594')
2023-11-26 06:36:05,773 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45413', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980565.7730205')
2023-11-26 06:36:05,773 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:05,773 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54416; closing.
2023-11-26 06:36:05,773 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:05,774 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:05,774 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:05,775 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:05,774 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:54356>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:54356>: Stream is closed
2023-11-26 06:36:05,775 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:05,775 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:05,776 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37193', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980565.7760808')
2023-11-26 06:36:05,776 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54430; closing.
2023-11-26 06:36:05,777 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40363', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980565.7771344')
2023-11-26 06:36:05,777 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54408; closing.
2023-11-26 06:36:05,777 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54390; closing.
2023-11-26 06:36:05,778 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42771', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980565.7785442')
2023-11-26 06:36:05,779 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38179', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980565.7790103')
2023-11-26 06:36:05,779 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54380; closing.
2023-11-26 06:36:05,780 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39601', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980565.7800026')
2023-11-26 06:36:05,780 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:36:05,780 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:54380>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-26 06:36:07,483 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:36:07,484 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:36:07,484 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:36:07,486 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:36:07,486 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2023-11-26 06:36:09,576 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:09,580 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34961 instead
  warnings.warn(
2023-11-26 06:36:09,583 - distributed.scheduler - INFO - State start
2023-11-26 06:36:09,603 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:09,604 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:36:09,605 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34961/status
2023-11-26 06:36:09,605 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:36:09,810 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36141'
2023-11-26 06:36:09,822 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33931'
2023-11-26 06:36:09,831 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33891'
2023-11-26 06:36:09,839 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33405'
2023-11-26 06:36:09,847 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37551'
2023-11-26 06:36:09,862 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33449'
2023-11-26 06:36:09,864 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43223'
2023-11-26 06:36:09,873 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32919'
2023-11-26 06:36:10,116 - distributed.scheduler - INFO - Receive client connection: Client-14bf85b9-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:10,130 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51908
2023-11-26 06:36:11,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:11,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:11,748 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:11,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:11,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:11,760 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:11,775 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:11,775 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:11,779 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:11,805 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:11,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:11,810 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:11,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:11,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:11,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:11,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:11,815 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:11,817 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:12,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:12,483 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:12,490 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:12,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:12,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:12,508 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:18,973 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37067
2023-11-26 06:36:18,973 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37067
2023-11-26 06:36:18,974 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45773
2023-11-26 06:36:18,974 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:18,974 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:18,974 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:18,974 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:18,974 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_y3w3m7s
2023-11-26 06:36:18,974 - distributed.worker - INFO - Starting Worker plugin RMMSetup-894358ba-b95e-43a9-a9a0-b4286840c255
2023-11-26 06:36:19,111 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-530e327a-752a-4598-80fd-e2e973b9f6cd
2023-11-26 06:36:19,111 - distributed.worker - INFO - Starting Worker plugin PreImport-054d62ea-ede9-4c81-9e45-40fae7e26056
2023-11-26 06:36:19,114 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,155 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37067', status: init, memory: 0, processing: 0>
2023-11-26 06:36:19,157 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37067
2023-11-26 06:36:19,157 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51938
2023-11-26 06:36:19,158 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:19,159 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,159 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,168 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:19,180 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38633
2023-11-26 06:36:19,182 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38633
2023-11-26 06:36:19,183 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36585
2023-11-26 06:36:19,183 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,183 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,183 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:19,183 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:19,183 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_grbf4yz
2023-11-26 06:36:19,184 - distributed.worker - INFO - Starting Worker plugin PreImport-14624159-87b6-4a28-bffa-0c88beca8c3a
2023-11-26 06:36:19,185 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0771f50d-9fc1-4dd9-8602-56c531594c43
2023-11-26 06:36:19,185 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3e943e27-ae7a-4168-b56c-6b3a2c72fa52
2023-11-26 06:36:19,431 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33647
2023-11-26 06:36:19,432 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33647
2023-11-26 06:36:19,432 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38403
2023-11-26 06:36:19,432 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,432 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,432 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:19,433 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:19,433 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fse83pg3
2023-11-26 06:36:19,433 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9a33449a-d49a-4b09-ab14-f96b5fb089a1
2023-11-26 06:36:19,434 - distributed.worker - INFO - Starting Worker plugin RMMSetup-16f8f99f-58f1-473d-845f-5b78622d720f
2023-11-26 06:36:19,460 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44433
2023-11-26 06:36:19,461 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44433
2023-11-26 06:36:19,461 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36797
2023-11-26 06:36:19,462 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,462 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,462 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:19,462 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:19,462 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-23u_ddvn
2023-11-26 06:36:19,462 - distributed.worker - INFO - Starting Worker plugin RMMSetup-56c38624-8863-4fe9-ad43-4db76b316aac
2023-11-26 06:36:19,470 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45243
2023-11-26 06:36:19,471 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45243
2023-11-26 06:36:19,471 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39901
2023-11-26 06:36:19,471 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,471 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,471 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:19,471 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:19,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zthz8q2o
2023-11-26 06:36:19,472 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-99d2dfda-cc9a-43e4-a6cf-fc6dc30df49a
2023-11-26 06:36:19,472 - distributed.worker - INFO - Starting Worker plugin RMMSetup-088ddac4-0143-49e9-8f93-26fa2c07a6e1
2023-11-26 06:36:19,526 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35967
2023-11-26 06:36:19,526 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35967
2023-11-26 06:36:19,527 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42913
2023-11-26 06:36:19,527 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,527 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,527 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:19,527 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:19,527 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c7vvhdyc
2023-11-26 06:36:19,528 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e89218a6-0ff5-448b-9375-dd983dfa0c6e
2023-11-26 06:36:19,562 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44477
2023-11-26 06:36:19,563 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44477
2023-11-26 06:36:19,563 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43985
2023-11-26 06:36:19,563 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,563 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,563 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:19,564 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:19,564 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_vgwe2vh
2023-11-26 06:36:19,565 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f56eb47f-f42c-4f3d-b731-7741bd27bab0
2023-11-26 06:36:19,572 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40841
2023-11-26 06:36:19,573 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40841
2023-11-26 06:36:19,573 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39873
2023-11-26 06:36:19,573 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,573 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,573 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:19,573 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:19,573 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y1wzx9dm
2023-11-26 06:36:19,574 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7bdec07d-8f86-4210-931e-52089c25f75c
2023-11-26 06:36:19,585 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,620 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38633', status: init, memory: 0, processing: 0>
2023-11-26 06:36:19,621 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38633
2023-11-26 06:36:19,621 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51940
2023-11-26 06:36:19,623 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:19,624 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,624 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:19,665 - distributed.worker - INFO - Starting Worker plugin PreImport-44b48f1d-fc0a-40e8-9257-b43caba458a3
2023-11-26 06:36:19,665 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,669 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-75ed160d-c9a5-4f0c-a574-2837fa91bb09
2023-11-26 06:36:19,669 - distributed.worker - INFO - Starting Worker plugin PreImport-1766b772-55e3-4df0-abe6-58e331558a5c
2023-11-26 06:36:19,669 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,695 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44433', status: init, memory: 0, processing: 0>
2023-11-26 06:36:19,696 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44433
2023-11-26 06:36:19,696 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51956
2023-11-26 06:36:19,697 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:19,697 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,697 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,699 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33647', status: init, memory: 0, processing: 0>
2023-11-26 06:36:19,700 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33647
2023-11-26 06:36:19,700 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51942
2023-11-26 06:36:19,701 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:19,701 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:19,702 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,702 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,710 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:19,718 - distributed.worker - INFO - Starting Worker plugin PreImport-60089906-6f77-42fd-bfea-3fc3aa70e85e
2023-11-26 06:36:19,718 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,739 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-95db6ef0-8773-47ae-bbbf-3261c4a23a2b
2023-11-26 06:36:19,739 - distributed.worker - INFO - Starting Worker plugin PreImport-2bb1c16b-7242-4910-b011-081fcc7fa145
2023-11-26 06:36:19,739 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,742 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45243', status: init, memory: 0, processing: 0>
2023-11-26 06:36:19,743 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45243
2023-11-26 06:36:19,743 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51964
2023-11-26 06:36:19,744 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:19,745 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3c0acebf-2485-438d-bc1f-527f1f4a7ee2
2023-11-26 06:36:19,745 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,745 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,745 - distributed.worker - INFO - Starting Worker plugin PreImport-9511da64-21b2-4529-8639-a31dc6527bff
2023-11-26 06:36:19,745 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,746 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6554f9d1-eb3b-438a-ae1b-9a91737fbf59
2023-11-26 06:36:19,746 - distributed.worker - INFO - Starting Worker plugin PreImport-4b2c49a7-5f41-4486-b8fb-a19323ad7eb4
2023-11-26 06:36:19,746 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,749 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:19,762 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35967', status: init, memory: 0, processing: 0>
2023-11-26 06:36:19,762 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35967
2023-11-26 06:36:19,762 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51974
2023-11-26 06:36:19,763 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:19,764 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,764 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,768 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:19,769 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40841', status: init, memory: 0, processing: 0>
2023-11-26 06:36:19,769 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40841
2023-11-26 06:36:19,769 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51994
2023-11-26 06:36:19,770 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:19,771 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,771 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44477', status: init, memory: 0, processing: 0>
2023-11-26 06:36:19,771 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,771 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44477
2023-11-26 06:36:19,771 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51986
2023-11-26 06:36:19,772 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:19,773 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:19,773 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:19,775 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:19,778 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:19,854 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,854 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,854 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,854 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,855 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,855 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,855 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,855 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,867 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:19,867 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:19,868 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:19,868 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:19,868 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:19,868 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:19,868 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:19,868 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:36:19,876 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,877 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:19,881 - distributed.scheduler - INFO - Remove client Client-14bf85b9-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:19,881 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51908; closing.
2023-11-26 06:36:19,881 - distributed.scheduler - INFO - Remove client Client-14bf85b9-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:19,882 - distributed.scheduler - INFO - Close client connection: Client-14bf85b9-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:19,883 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36141'. Reason: nanny-close
2023-11-26 06:36:19,883 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:19,884 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33931'. Reason: nanny-close
2023-11-26 06:36:19,884 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:19,885 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33891'. Reason: nanny-close
2023-11-26 06:36:19,885 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37067. Reason: nanny-close
2023-11-26 06:36:19,885 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:19,885 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33405'. Reason: nanny-close
2023-11-26 06:36:19,885 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:19,885 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33647. Reason: nanny-close
2023-11-26 06:36:19,886 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44433. Reason: nanny-close
2023-11-26 06:36:19,886 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37551'. Reason: nanny-close
2023-11-26 06:36:19,886 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:19,886 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35967. Reason: nanny-close
2023-11-26 06:36:19,886 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33449'. Reason: nanny-close
2023-11-26 06:36:19,887 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:19,887 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43223'. Reason: nanny-close
2023-11-26 06:36:19,887 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38633. Reason: nanny-close
2023-11-26 06:36:19,887 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:19,887 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:19,887 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:19,888 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51938; closing.
2023-11-26 06:36:19,888 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32919'. Reason: nanny-close
2023-11-26 06:36:19,888 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44477. Reason: nanny-close
2023-11-26 06:36:19,888 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:19,888 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37067', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980579.8883383')
2023-11-26 06:36:19,888 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45243. Reason: nanny-close
2023-11-26 06:36:19,888 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:19,889 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51956; closing.
2023-11-26 06:36:19,889 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40841. Reason: nanny-close
2023-11-26 06:36:19,889 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:19,889 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:19,889 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51974; closing.
2023-11-26 06:36:19,889 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:19,889 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44433', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980579.8898087')
2023-11-26 06:36:19,889 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:19,890 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:19,890 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:19,890 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:19,890 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35967', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980579.8909187')
2023-11-26 06:36:19,891 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:19,891 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51942; closing.
2023-11-26 06:36:19,891 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:19,891 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:19,891 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:19,892 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:19,892 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:19,891 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:51974>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 316, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 327, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:51974>: Stream is closed
2023-11-26 06:36:19,893 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:51956>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 268, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-11-26 06:36:19,893 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51940; closing.
2023-11-26 06:36:19,894 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51986; closing.
2023-11-26 06:36:19,894 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33647', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980579.8943245')
2023-11-26 06:36:19,895 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38633', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980579.8950148')
2023-11-26 06:36:19,895 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44477', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980579.8953733')
2023-11-26 06:36:19,895 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51964; closing.
2023-11-26 06:36:19,896 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51994; closing.
2023-11-26 06:36:19,896 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45243', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980579.8964982')
2023-11-26 06:36:19,896 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40841', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980579.896867')
2023-11-26 06:36:19,897 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:36:21,852 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:36:21,852 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:36:21,853 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:36:21,854 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:36:21,854 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-11-26 06:36:24,174 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:24,179 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40089 instead
  warnings.warn(
2023-11-26 06:36:24,183 - distributed.scheduler - INFO - State start
2023-11-26 06:36:24,225 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:24,227 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:36:24,228 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:40089/status
2023-11-26 06:36:24,228 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:36:24,541 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40879'
2023-11-26 06:36:24,558 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36125'
2023-11-26 06:36:24,580 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46805'
2023-11-26 06:36:24,581 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38401'
2023-11-26 06:36:24,591 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45171'
2023-11-26 06:36:24,600 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42493'
2023-11-26 06:36:24,607 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36635'
2023-11-26 06:36:24,620 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40995'
2023-11-26 06:36:24,658 - distributed.scheduler - INFO - Receive client connection: Client-1d4843ce-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:24,670 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44704
2023-11-26 06:36:26,433 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:26,433 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:26,437 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:26,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:26,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:26,500 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:26,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:26,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:26,559 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:26,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:26,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:26,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:26,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:26,564 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:26,565 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:26,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:26,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:26,576 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:26,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:26,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:26,584 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:26,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:26,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:26,644 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:30,642 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35889
2023-11-26 06:36:30,643 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35889
2023-11-26 06:36:30,644 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45701
2023-11-26 06:36:30,644 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:30,644 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:30,644 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:30,644 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:30,644 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b8vetprm
2023-11-26 06:36:30,645 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f9ecd0f1-8164-42af-983a-7b10176d4f78
2023-11-26 06:36:30,645 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a8da5414-8174-4ec6-9176-e42ec5eea72b
2023-11-26 06:36:30,653 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41267
2023-11-26 06:36:30,654 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41267
2023-11-26 06:36:30,654 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41279
2023-11-26 06:36:30,654 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:30,654 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:30,654 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:30,655 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:30,655 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xz8th5_0
2023-11-26 06:36:30,655 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b0dd7f21-fa49-46d5-b954-01acfb8b65f9
2023-11-26 06:36:30,667 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37705
2023-11-26 06:36:30,667 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37705
2023-11-26 06:36:30,667 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39803
2023-11-26 06:36:30,667 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:30,668 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:30,668 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:30,668 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:30,668 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jilwjsv1
2023-11-26 06:36:30,668 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9f303834-8f96-404b-992f-d79b3c27417d
2023-11-26 06:36:30,674 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39459
2023-11-26 06:36:30,675 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39459
2023-11-26 06:36:30,675 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42147
2023-11-26 06:36:30,675 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:30,675 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:30,675 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:30,675 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:30,675 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-670g2f0_
2023-11-26 06:36:30,676 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f7f8ab3a-011f-4ff9-a5de-9a6ab0a7db68
2023-11-26 06:36:30,683 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41475
2023-11-26 06:36:30,683 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41475
2023-11-26 06:36:30,683 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34459
2023-11-26 06:36:30,684 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:30,684 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:30,684 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:30,684 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:30,684 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pa2uqxtn
2023-11-26 06:36:30,684 - distributed.worker - INFO - Starting Worker plugin RMMSetup-338dd278-df6a-4339-8493-8fdedb061a3a
2023-11-26 06:36:30,693 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39527
2023-11-26 06:36:30,693 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39527
2023-11-26 06:36:30,694 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44795
2023-11-26 06:36:30,694 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:30,694 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:30,694 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:30,694 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:30,694 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v0aygcd3
2023-11-26 06:36:30,694 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-91d68314-b7ea-47a1-a0a1-a9392d114c49
2023-11-26 06:36:30,695 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7e65736e-d162-4225-a1e7-f2db950d997b
2023-11-26 06:36:30,701 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38975
2023-11-26 06:36:30,702 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38975
2023-11-26 06:36:30,702 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39493
2023-11-26 06:36:30,702 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:30,702 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:30,702 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:30,702 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:30,702 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wyhthrnj
2023-11-26 06:36:30,703 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1671c857-7d2b-4608-a92e-c7c0d974612d
2023-11-26 06:36:30,705 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40059
2023-11-26 06:36:30,707 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40059
2023-11-26 06:36:30,707 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45973
2023-11-26 06:36:30,707 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:30,707 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:30,707 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:30,707 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:36:30,707 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-07m9omsd
2023-11-26 06:36:30,708 - distributed.worker - INFO - Starting Worker plugin PreImport-363663b3-181f-4d93-9a64-7483821e17ed
2023-11-26 06:36:30,708 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0a0a41f2-90a2-4f3f-8b8b-c1dd20a59dc1
2023-11-26 06:36:30,711 - distributed.worker - INFO - Starting Worker plugin RMMSetup-587721d1-36f2-4f58-be9f-8bf4014287c4
2023-11-26 06:36:31,198 - distributed.worker - INFO - Starting Worker plugin PreImport-d6306995-8229-461b-a669-63644cc4b49e
2023-11-26 06:36:31,198 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e96db997-0a1b-4b00-bc8e-e88c42d3150c
2023-11-26 06:36:31,198 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,198 - distributed.worker - INFO - Starting Worker plugin PreImport-8b3c1133-6736-47e3-a005-194fd6d3d13b
2023-11-26 06:36:31,199 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,206 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7677ee03-23c8-4093-beb6-d541b90df2ef
2023-11-26 06:36:31,206 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cfcdc418-105f-4413-abb8-e519a8898c0a
2023-11-26 06:36:31,206 - distributed.worker - INFO - Starting Worker plugin PreImport-45cb8950-183e-4edb-a16c-8c372226e219
2023-11-26 06:36:31,207 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,208 - distributed.worker - INFO - Starting Worker plugin PreImport-18680b41-875c-478c-994f-a52309a64978
2023-11-26 06:36:31,208 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,214 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ff01ea5e-7fc4-4fb3-bb7e-1d2497cbc42e
2023-11-26 06:36:31,214 - distributed.worker - INFO - Starting Worker plugin PreImport-fec7782b-6ec6-4b52-a193-9f89eeb6f738
2023-11-26 06:36:31,214 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,224 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35889', status: init, memory: 0, processing: 0>
2023-11-26 06:36:31,226 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35889
2023-11-26 06:36:31,226 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49586
2023-11-26 06:36:31,227 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:31,228 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:31,228 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:31,233 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39459', status: init, memory: 0, processing: 0>
2023-11-26 06:36:31,233 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39459
2023-11-26 06:36:31,233 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49592
2023-11-26 06:36:31,234 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37705', status: init, memory: 0, processing: 0>
2023-11-26 06:36:31,235 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37705
2023-11-26 06:36:31,235 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49594
2023-11-26 06:36:31,235 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:31,236 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:31,236 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:31,236 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,237 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:31,237 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,238 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:31,239 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:31,242 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41267', status: init, memory: 0, processing: 0>
2023-11-26 06:36:31,242 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41267
2023-11-26 06:36:31,242 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49606
2023-11-26 06:36:31,243 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41475', status: init, memory: 0, processing: 0>
2023-11-26 06:36:31,243 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41475
2023-11-26 06:36:31,244 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49612
2023-11-26 06:36:31,244 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:31,245 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:31,245 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,245 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:31,245 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:31,245 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,247 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:31,247 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:31,261 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-33e6f23f-ec65-49d6-8835-f0525104e098
2023-11-26 06:36:31,262 - distributed.worker - INFO - Starting Worker plugin PreImport-069806d7-1d52-4e76-9b14-84d4e7b27033
2023-11-26 06:36:31,262 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,264 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,266 - distributed.worker - INFO - Starting Worker plugin PreImport-f602d057-c771-45cd-9812-096f94846a59
2023-11-26 06:36:31,266 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,288 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39527', status: init, memory: 0, processing: 0>
2023-11-26 06:36:31,289 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39527
2023-11-26 06:36:31,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49626
2023-11-26 06:36:31,290 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:31,291 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:31,291 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38975', status: init, memory: 0, processing: 0>
2023-11-26 06:36:31,291 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,291 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38975
2023-11-26 06:36:31,291 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49622
2023-11-26 06:36:31,293 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:31,293 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:31,293 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:31,293 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,294 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40059', status: init, memory: 0, processing: 0>
2023-11-26 06:36:31,294 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40059
2023-11-26 06:36:31,294 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49640
2023-11-26 06:36:31,295 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:31,296 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:31,296 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:31,297 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:31,299 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:31,385 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:31,385 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:31,385 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:31,385 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:31,385 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:31,385 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:31,386 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:31,386 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:36:31,390 - distributed.scheduler - INFO - Remove client Client-1d4843ce-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:31,390 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44704; closing.
2023-11-26 06:36:31,391 - distributed.scheduler - INFO - Remove client Client-1d4843ce-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:31,391 - distributed.scheduler - INFO - Close client connection: Client-1d4843ce-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:31,392 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40879'. Reason: nanny-close
2023-11-26 06:36:31,392 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:31,393 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36125'. Reason: nanny-close
2023-11-26 06:36:31,394 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41475. Reason: nanny-close
2023-11-26 06:36:31,394 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:31,394 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46805'. Reason: nanny-close
2023-11-26 06:36:31,394 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:31,394 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39527. Reason: nanny-close
2023-11-26 06:36:31,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38401'. Reason: nanny-close
2023-11-26 06:36:31,395 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:31,395 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41267. Reason: nanny-close
2023-11-26 06:36:31,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45171'. Reason: nanny-close
2023-11-26 06:36:31,395 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:31,395 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:31,396 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49612; closing.
2023-11-26 06:36:31,396 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38975. Reason: nanny-close
2023-11-26 06:36:31,396 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41475', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980591.3963606')
2023-11-26 06:36:31,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42493'. Reason: nanny-close
2023-11-26 06:36:31,396 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:31,396 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40059. Reason: nanny-close
2023-11-26 06:36:31,396 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:31,397 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36635'. Reason: nanny-close
2023-11-26 06:36:31,397 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:31,397 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37705. Reason: nanny-close
2023-11-26 06:36:31,397 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:31,397 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40995'. Reason: nanny-close
2023-11-26 06:36:31,397 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49626; closing.
2023-11-26 06:36:31,397 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:31,398 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35889. Reason: nanny-close
2023-11-26 06:36:31,398 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:31,398 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39527', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980591.3986132')
2023-11-26 06:36:31,398 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39459. Reason: nanny-close
2023-11-26 06:36:31,398 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49606; closing.
2023-11-26 06:36:31,399 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:31,399 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:31,399 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41267', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980591.3993697')
2023-11-26 06:36:31,399 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:31,399 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:31,400 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:31,400 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49622; closing.
2023-11-26 06:36:31,400 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49640; closing.
2023-11-26 06:36:31,401 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:31,401 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:31,401 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:31,401 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38975', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980591.401212')
2023-11-26 06:36:31,401 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40059', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980591.4016643')
2023-11-26 06:36:31,401 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:31,401 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:31,402 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49594; closing.
2023-11-26 06:36:31,402 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49586; closing.
2023-11-26 06:36:31,402 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:31,402 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37705', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980591.4027774')
2023-11-26 06:36:31,403 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:31,403 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35889', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980591.4032338')
2023-11-26 06:36:31,403 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49592; closing.
2023-11-26 06:36:31,404 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39459', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980591.404014')
2023-11-26 06:36:31,404 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:36:32,910 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:36:32,910 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:36:32,911 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:36:32,912 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:36:32,913 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-11-26 06:36:35,085 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:35,089 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39921 instead
  warnings.warn(
2023-11-26 06:36:35,093 - distributed.scheduler - INFO - State start
2023-11-26 06:36:35,114 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:35,115 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:36:35,115 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39921/status
2023-11-26 06:36:35,116 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:36:35,195 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35217'
2023-11-26 06:36:36,634 - distributed.scheduler - INFO - Receive client connection: Client-23e0ec70-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:36,647 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49740
2023-11-26 06:36:36,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:36,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:37,371 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:38,552 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35977
2023-11-26 06:36:38,553 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35977
2023-11-26 06:36:38,553 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2023-11-26 06:36:38,553 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:38,553 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:38,553 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:38,553 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-26 06:36:38,553 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-li1vfvm6
2023-11-26 06:36:38,554 - distributed.worker - INFO - Starting Worker plugin RMMSetup-01c15002-0cf8-4b3f-bf63-3e62bd541ee3
2023-11-26 06:36:38,554 - distributed.worker - INFO - Starting Worker plugin PreImport-e6c98137-0192-4f1f-9481-43708200d442
2023-11-26 06:36:38,554 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c810069e-30bf-484d-b80a-6e9e01b66b6f
2023-11-26 06:36:38,554 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:38,580 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35977', status: init, memory: 0, processing: 0>
2023-11-26 06:36:38,581 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35977
2023-11-26 06:36:38,581 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49750
2023-11-26 06:36:38,582 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:38,583 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:38,583 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:38,584 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:38,587 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:38,589 - distributed.scheduler - INFO - Remove client Client-23e0ec70-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:38,590 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49740; closing.
2023-11-26 06:36:38,590 - distributed.scheduler - INFO - Remove client Client-23e0ec70-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:38,590 - distributed.scheduler - INFO - Close client connection: Client-23e0ec70-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:38,591 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35217'. Reason: nanny-close
2023-11-26 06:36:38,632 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:38,633 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35977. Reason: nanny-close
2023-11-26 06:36:38,635 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:38,635 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49750; closing.
2023-11-26 06:36:38,635 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35977', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980598.6353383')
2023-11-26 06:36:38,635 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:36:38,636 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:39,708 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:36:39,708 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:36:39,709 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:36:39,710 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:36:39,710 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-11-26 06:36:43,847 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:43,851 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44609 instead
  warnings.warn(
2023-11-26 06:36:43,855 - distributed.scheduler - INFO - State start
2023-11-26 06:36:44,172 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:44,173 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:36:44,174 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:44609/status
2023-11-26 06:36:44,174 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:36:44,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39495'
2023-11-26 06:36:45,352 - distributed.scheduler - INFO - Receive client connection: Client-2927671b-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:45,365 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34116
2023-11-26 06:36:45,970 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:45,970 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:46,521 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:36:47,426 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46805
2023-11-26 06:36:47,427 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46805
2023-11-26 06:36:47,427 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41973
2023-11-26 06:36:47,427 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:36:47,427 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:47,427 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:36:47,427 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-26 06:36:47,427 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ckmv2pim
2023-11-26 06:36:47,428 - distributed.worker - INFO - Starting Worker plugin PreImport-2c4314b2-76c3-4b86-9b8e-98f2983d54b7
2023-11-26 06:36:47,429 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0cb12d73-9765-41e9-ae28-c61a21a2d1d0
2023-11-26 06:36:47,429 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0c27322e-6195-495a-b193-2fcd71dfb359
2023-11-26 06:36:47,430 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:47,472 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46805', status: init, memory: 0, processing: 0>
2023-11-26 06:36:47,473 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46805
2023-11-26 06:36:47,473 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34134
2023-11-26 06:36:47,475 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:36:47,477 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:36:47,477 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:36:47,479 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:36:47,507 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:36:47,509 - distributed.scheduler - INFO - Remove client Client-2927671b-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:47,510 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34116; closing.
2023-11-26 06:36:47,510 - distributed.scheduler - INFO - Remove client Client-2927671b-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:47,510 - distributed.scheduler - INFO - Close client connection: Client-2927671b-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:36:47,511 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39495'. Reason: nanny-close
2023-11-26 06:36:47,512 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:36:47,513 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46805. Reason: nanny-close
2023-11-26 06:36:47,516 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:34134; closing.
2023-11-26 06:36:47,516 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:36:47,516 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46805', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980607.5163221')
2023-11-26 06:36:47,516 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:36:47,518 - distributed.nanny - INFO - Worker closed
2023-11-26 06:36:48,928 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:36:48,929 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:36:48,929 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:36:48,930 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:36:48,930 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-11-26 06:36:51,243 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:51,248 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-11-26 06:36:51,251 - distributed.scheduler - INFO - State start
2023-11-26 06:36:51,275 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:51,276 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:36:51,277 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-11-26 06:36:51,277 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:36:55,259 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:57786'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 224, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 921, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4351, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 240, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:57786>: Stream is closed
2023-11-26 06:36:55,520 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:36:55,521 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:36:55,521 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:36:55,522 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:36:55,522 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-11-26 06:36:57,746 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:57,751 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43235 instead
  warnings.warn(
2023-11-26 06:36:57,755 - distributed.scheduler - INFO - State start
2023-11-26 06:36:57,778 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:36:57,779 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-11-26 06:36:57,780 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:43235/status
2023-11-26 06:36:57,780 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:36:57,998 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37215'
2023-11-26 06:36:59,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:36:59,710 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:36:59,713 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:02,069 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39337
2023-11-26 06:37:02,070 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39337
2023-11-26 06:37:02,070 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39485
2023-11-26 06:37:02,071 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-11-26 06:37:02,071 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:02,071 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:02,071 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-26 06:37:02,071 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-x_y5r0la
2023-11-26 06:37:02,072 - distributed.worker - INFO - Starting Worker plugin PreImport-a7da26ca-7834-40d7-ba89-254aef04a242
2023-11-26 06:37:02,072 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1b3d984d-f86b-40b4-bd44-9cac035730ff
2023-11-26 06:37:02,072 - distributed.worker - INFO - Starting Worker plugin RMMSetup-40eb0125-5813-4489-8950-ce1433783062
2023-11-26 06:37:02,073 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:02,112 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39337', status: init, memory: 0, processing: 0>
2023-11-26 06:37:02,131 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39337
2023-11-26 06:37:02,132 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40754
2023-11-26 06:37:02,133 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:02,134 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-11-26 06:37:02,134 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:02,136 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2023-11-26 06:37:07,372 - distributed.scheduler - INFO - Receive client connection: Client-314ed184-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:07,373 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40768
2023-11-26 06:37:07,383 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:07,386 - distributed.scheduler - INFO - Remove client Client-314ed184-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:07,386 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40768; closing.
2023-11-26 06:37:07,386 - distributed.scheduler - INFO - Remove client Client-314ed184-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:07,387 - distributed.scheduler - INFO - Close client connection: Client-314ed184-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:07,388 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37215'. Reason: nanny-close
2023-11-26 06:37:07,388 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:07,390 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39337. Reason: nanny-close
2023-11-26 06:37:07,392 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40754; closing.
2023-11-26 06:37:07,393 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2023-11-26 06:37:07,393 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39337', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980627.3931732')
2023-11-26 06:37:07,393 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:37:07,395 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:08,655 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:37:08,655 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:37:08,656 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:37:08,658 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-11-26 06:37:08,658 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-11-26 06:37:11,198 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:37:11,202 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41639 instead
  warnings.warn(
2023-11-26 06:37:11,206 - distributed.scheduler - INFO - State start
2023-11-26 06:37:11,349 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:37:11,350 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:37:11,351 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41639/status
2023-11-26 06:37:11,352 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:37:11,591 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39553'
2023-11-26 06:37:11,618 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38119'
2023-11-26 06:37:11,621 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36121'
2023-11-26 06:37:11,630 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39967'
2023-11-26 06:37:11,639 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43379'
2023-11-26 06:37:11,648 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43305'
2023-11-26 06:37:11,657 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38479'
2023-11-26 06:37:11,668 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32863'
2023-11-26 06:37:13,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:13,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:13,512 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:13,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:13,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:13,531 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:13,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:13,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:13,542 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:13,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:13,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:13,567 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:13,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:13,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:13,592 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:13,604 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:13,604 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:13,609 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:13,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:13,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:13,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:13,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:13,630 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:13,631 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:16,272 - distributed.scheduler - INFO - Receive client connection: Client-3938fdce-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:16,284 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52822
2023-11-26 06:37:16,838 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43107
2023-11-26 06:37:16,839 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43107
2023-11-26 06:37:16,839 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39947
2023-11-26 06:37:16,840 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:16,840 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:16,840 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:16,840 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:37:16,840 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6kjlo_bq
2023-11-26 06:37:16,839 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46473
2023-11-26 06:37:16,840 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46473
2023-11-26 06:37:16,840 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46071
2023-11-26 06:37:16,840 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:16,840 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:16,840 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3b936958-b1f4-499e-92be-1d4fa4741d93
2023-11-26 06:37:16,840 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:16,841 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:37:16,841 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mljyjt_i
2023-11-26 06:37:16,840 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38199
2023-11-26 06:37:16,841 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38199
2023-11-26 06:37:16,841 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33553
2023-11-26 06:37:16,841 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:16,841 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:16,841 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d39f188c-7f95-411b-8ed2-c33398b58cd0
2023-11-26 06:37:16,841 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:16,841 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:37:16,841 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nastwkin
2023-11-26 06:37:16,842 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1b7ae360-1063-449d-9ea0-06bc497d6471
2023-11-26 06:37:16,842 - distributed.worker - INFO - Starting Worker plugin RMMSetup-62109e23-f163-44b9-b0f3-c1b340158c89
2023-11-26 06:37:16,853 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43771
2023-11-26 06:37:16,854 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43771
2023-11-26 06:37:16,854 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44087
2023-11-26 06:37:16,854 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:16,854 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:16,854 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:16,854 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:37:16,854 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lhmzcghd
2023-11-26 06:37:16,854 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-05b2d1b0-309b-413e-bcd6-4a17715079f4
2023-11-26 06:37:16,855 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a8ed14e3-67ea-49ca-9cb9-8799af842619
2023-11-26 06:37:17,220 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-24128222-922f-49f0-984a-0527c7be01a1
2023-11-26 06:37:17,222 - distributed.worker - INFO - Starting Worker plugin PreImport-113303c8-4086-4e62-8626-2df306b04402
2023-11-26 06:37:17,222 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,223 - distributed.worker - INFO - Starting Worker plugin PreImport-c8d0884d-b1e3-4da8-8996-01fcb30b94f7
2023-11-26 06:37:17,223 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,223 - distributed.worker - INFO - Starting Worker plugin PreImport-15731ab8-23f7-489e-a2c1-a682abff54af
2023-11-26 06:37:17,224 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,227 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f8c82c93-4ff5-4066-866f-cbd560749650
2023-11-26 06:37:17,227 - distributed.worker - INFO - Starting Worker plugin PreImport-d06899cc-c166-4b7b-8274-b7a1e72f9a31
2023-11-26 06:37:17,227 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,251 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43771', status: init, memory: 0, processing: 0>
2023-11-26 06:37:17,252 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43771
2023-11-26 06:37:17,252 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52850
2023-11-26 06:37:17,253 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:17,254 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,254 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,255 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:17,259 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43107', status: init, memory: 0, processing: 0>
2023-11-26 06:37:17,259 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43107
2023-11-26 06:37:17,259 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52882
2023-11-26 06:37:17,260 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:17,261 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,261 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,262 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:17,264 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38199', status: init, memory: 0, processing: 0>
2023-11-26 06:37:17,265 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38199
2023-11-26 06:37:17,265 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52866
2023-11-26 06:37:17,266 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:17,267 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,267 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,270 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:17,271 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46473', status: init, memory: 0, processing: 0>
2023-11-26 06:37:17,272 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46473
2023-11-26 06:37:17,272 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52836
2023-11-26 06:37:17,273 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:17,274 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,274 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,277 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:17,297 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38017
2023-11-26 06:37:17,298 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38017
2023-11-26 06:37:17,298 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33387
2023-11-26 06:37:17,298 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,298 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,298 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:17,298 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:37:17,299 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oowe5jh3
2023-11-26 06:37:17,299 - distributed.worker - INFO - Starting Worker plugin RMMSetup-202e6af3-c591-457a-a143-0e6e8f53b327
2023-11-26 06:37:17,303 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33255
2023-11-26 06:37:17,304 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33255
2023-11-26 06:37:17,304 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37967
2023-11-26 06:37:17,303 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34035
2023-11-26 06:37:17,304 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,304 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34035
2023-11-26 06:37:17,304 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,304 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33525
2023-11-26 06:37:17,304 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,304 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,304 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:17,304 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:17,304 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:37:17,304 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:37:17,304 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9t8vr9tt
2023-11-26 06:37:17,304 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jm_8661q
2023-11-26 06:37:17,305 - distributed.worker - INFO - Starting Worker plugin RMMSetup-26898843-14ea-4ea0-bb27-8b0cb0575f28
2023-11-26 06:37:17,305 - distributed.worker - INFO - Starting Worker plugin PreImport-6ee0d27b-b495-4e85-8fb7-eafb879b1ec1
2023-11-26 06:37:17,305 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-942217a4-acb2-4ee6-a971-9cca9d8e234c
2023-11-26 06:37:17,306 - distributed.worker - INFO - Starting Worker plugin RMMSetup-07b0bfef-fa6a-4624-b61d-0ce6223c56c4
2023-11-26 06:37:17,306 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44273
2023-11-26 06:37:17,307 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44273
2023-11-26 06:37:17,307 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41809
2023-11-26 06:37:17,307 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,307 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,307 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:17,308 - distributed.worker - INFO -                Memory:                 125.97 GiB
2023-11-26 06:37:17,308 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-km381ml4
2023-11-26 06:37:17,308 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e4a79449-f98b-4730-9bb8-a24f6db24224
2023-11-26 06:37:17,689 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-da742cf1-9a92-409e-9166-07c93045f0bd
2023-11-26 06:37:17,690 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3fa94667-c1f9-46b5-a607-8e1c77a45026
2023-11-26 06:37:17,690 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-de5d66d2-55e8-4718-96bc-91118da8f255
2023-11-26 06:37:17,690 - distributed.worker - INFO - Starting Worker plugin PreImport-8f5893ce-c7e0-4fbd-82e7-fa7a8cbcd49a
2023-11-26 06:37:17,690 - distributed.worker - INFO - Starting Worker plugin PreImport-d3e47c5c-3d65-4847-b282-b35207c9865d
2023-11-26 06:37:17,690 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,690 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,690 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,691 - distributed.worker - INFO - Starting Worker plugin PreImport-4521b4f1-3669-4acf-b110-2cded4363a3a
2023-11-26 06:37:17,691 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,717 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44273', status: init, memory: 0, processing: 0>
2023-11-26 06:37:17,718 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44273
2023-11-26 06:37:17,718 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52898
2023-11-26 06:37:17,719 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:17,720 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,720 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,720 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34035', status: init, memory: 0, processing: 0>
2023-11-26 06:37:17,721 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34035
2023-11-26 06:37:17,721 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52906
2023-11-26 06:37:17,721 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:17,722 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33255', status: init, memory: 0, processing: 0>
2023-11-26 06:37:17,722 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:17,722 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33255
2023-11-26 06:37:17,722 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52908
2023-11-26 06:37:17,723 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,723 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,723 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38017', status: init, memory: 0, processing: 0>
2023-11-26 06:37:17,723 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38017
2023-11-26 06:37:17,723 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:52918
2023-11-26 06:37:17,723 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:17,724 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,724 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,725 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:17,725 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:17,726 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:17,726 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:17,727 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:17,728 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:17,825 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:37:17,825 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:37:17,825 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:37:17,825 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:37:17,825 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:37:17,825 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:37:17,825 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:37:17,826 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2023-11-26 06:37:17,839 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:17,839 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:17,839 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:17,839 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:17,839 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:17,839 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:17,840 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:17,840 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:17,844 - distributed.scheduler - INFO - Remove client Client-3938fdce-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:17,844 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52822; closing.
2023-11-26 06:37:17,844 - distributed.scheduler - INFO - Remove client Client-3938fdce-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:17,845 - distributed.scheduler - INFO - Close client connection: Client-3938fdce-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:17,955 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39967'. Reason: nanny-close
2023-11-26 06:37:17,956 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:17,957 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43379'. Reason: nanny-close
2023-11-26 06:37:17,957 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44273. Reason: nanny-close
2023-11-26 06:37:17,957 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:17,957 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38479'. Reason: nanny-close
2023-11-26 06:37:17,958 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:17,958 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43771. Reason: nanny-close
2023-11-26 06:37:17,958 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32863'. Reason: nanny-close
2023-11-26 06:37:17,958 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:17,958 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33255. Reason: nanny-close
2023-11-26 06:37:17,958 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39553'. Reason: nanny-close
2023-11-26 06:37:17,959 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:17,959 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:17,959 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52898; closing.
2023-11-26 06:37:17,959 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38119'. Reason: nanny-close
2023-11-26 06:37:17,959 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38017. Reason: nanny-close
2023-11-26 06:37:17,959 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44273', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980637.9595947')
2023-11-26 06:37:17,959 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:17,959 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34035. Reason: nanny-close
2023-11-26 06:37:17,960 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:17,960 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36121'. Reason: nanny-close
2023-11-26 06:37:17,960 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:17,960 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43107. Reason: nanny-close
2023-11-26 06:37:17,960 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43305'. Reason: nanny-close
2023-11-26 06:37:17,960 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:17,960 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:17,961 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38199. Reason: nanny-close
2023-11-26 06:37:17,961 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52850; closing.
2023-11-26 06:37:17,961 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:17,961 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:17,961 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46473. Reason: nanny-close
2023-11-26 06:37:17,962 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43771', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980637.9621866')
2023-11-26 06:37:17,962 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:17,962 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52908; closing.
2023-11-26 06:37:17,962 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:17,962 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:17,963 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33255', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980637.963009')
2023-11-26 06:37:17,963 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:17,963 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52918; closing.
2023-11-26 06:37:17,963 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:17,964 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:17,964 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52906; closing.
2023-11-26 06:37:17,964 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52882; closing.
2023-11-26 06:37:17,964 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:17,964 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:17,964 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:17,964 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38017', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980637.964936')
2023-11-26 06:37:17,965 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34035', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980637.9653246')
2023-11-26 06:37:17,965 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43107', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980637.9657106')
2023-11-26 06:37:17,965 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:17,966 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52866; closing.
2023-11-26 06:37:17,966 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:17,966 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38199', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980637.9666185')
2023-11-26 06:37:17,967 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:52836; closing.
2023-11-26 06:37:17,967 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46473', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980637.967396')
2023-11-26 06:37:17,967 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:37:20,064 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:37:20,065 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:37:20,065 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:37:20,067 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:37:20,068 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-11-26 06:37:22,305 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:37:22,310 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32941 instead
  warnings.warn(
2023-11-26 06:37:22,314 - distributed.scheduler - INFO - State start
2023-11-26 06:37:22,338 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:37:22,339 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:37:22,340 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:32941/status
2023-11-26 06:37:22,340 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:37:22,365 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44047'
2023-11-26 06:37:24,401 - distributed.scheduler - INFO - Receive client connection: Client-3ff85365-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:24,414 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57668
2023-11-26 06:37:24,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:24,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:24,668 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:26,452 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36953
2023-11-26 06:37:26,454 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36953
2023-11-26 06:37:26,454 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43317
2023-11-26 06:37:26,454 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:26,454 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:26,454 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:26,454 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-26 06:37:26,454 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-alq_y_wx
2023-11-26 06:37:26,455 - distributed.worker - INFO - Starting Worker plugin PreImport-d53a3c1e-7e16-4684-988b-7eb244fedcbd
2023-11-26 06:37:26,455 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-40f7da60-7308-4bdc-a15c-7c0cbf120b57
2023-11-26 06:37:26,456 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0a76f8ae-0ccb-4d12-a89b-6ab057176f30
2023-11-26 06:37:26,557 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:26,579 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36953', status: init, memory: 0, processing: 0>
2023-11-26 06:37:26,581 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36953
2023-11-26 06:37:26,581 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57678
2023-11-26 06:37:26,582 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:26,582 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:26,583 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:26,584 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:26,586 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:37:26,590 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:26,592 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:26,594 - distributed.scheduler - INFO - Remove client Client-3ff85365-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:26,595 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57668; closing.
2023-11-26 06:37:26,595 - distributed.scheduler - INFO - Remove client Client-3ff85365-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:26,595 - distributed.scheduler - INFO - Close client connection: Client-3ff85365-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:26,596 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44047'. Reason: nanny-close
2023-11-26 06:37:26,613 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:26,614 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36953. Reason: nanny-close
2023-11-26 06:37:26,616 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57678; closing.
2023-11-26 06:37:26,616 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:26,616 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36953', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980646.616497')
2023-11-26 06:37:26,616 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:37:26,617 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:27,663 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:37:27,663 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:37:27,663 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:37:27,664 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:37:27,665 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-11-26 06:37:30,035 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:37:30,039 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35389 instead
  warnings.warn(
2023-11-26 06:37:30,043 - distributed.scheduler - INFO - State start
2023-11-26 06:37:30,376 - distributed.scheduler - INFO - -----------------------------------------------
2023-11-26 06:37:30,377 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-11-26 06:37:30,377 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35389/status
2023-11-26 06:37:30,378 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2023-11-26 06:37:30,536 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36567'
2023-11-26 06:37:31,621 - distributed.scheduler - INFO - Receive client connection: Client-4485fcad-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:31,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41286
2023-11-26 06:37:32,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-11-26 06:37:32,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-11-26 06:37:32,353 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-11-26 06:37:33,434 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45003
2023-11-26 06:37:33,434 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45003
2023-11-26 06:37:33,434 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46333
2023-11-26 06:37:33,434 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2023-11-26 06:37:33,434 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:33,434 - distributed.worker - INFO -               Threads:                          1
2023-11-26 06:37:33,435 - distributed.worker - INFO -                Memory:                   0.98 TiB
2023-11-26 06:37:33,435 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wz3r64s2
2023-11-26 06:37:33,435 - distributed.worker - INFO - Starting Worker plugin PreImport-dba4c541-57e8-4945-b15c-ec897c172434
2023-11-26 06:37:33,435 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a8d50956-4c4e-47bf-bc1f-21a51c9dbabe
2023-11-26 06:37:33,435 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d9242e7e-6b1d-4ba2-98b4-968f7a19b4d0
2023-11-26 06:37:33,544 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:33,568 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45003', status: init, memory: 0, processing: 0>
2023-11-26 06:37:33,570 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45003
2023-11-26 06:37:33,570 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:41318
2023-11-26 06:37:33,571 - distributed.worker - INFO - Starting Worker plugin shuffle
2023-11-26 06:37:33,572 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2023-11-26 06:37:33,572 - distributed.worker - INFO - -------------------------------------------------
2023-11-26 06:37:33,574 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2023-11-26 06:37:33,577 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2023-11-26 06:37:33,582 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2023-11-26 06:37:33,586 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:33,588 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-11-26 06:37:33,591 - distributed.scheduler - INFO - Remove client Client-4485fcad-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:33,591 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41286; closing.
2023-11-26 06:37:33,591 - distributed.scheduler - INFO - Remove client Client-4485fcad-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:33,592 - distributed.scheduler - INFO - Close client connection: Client-4485fcad-8c26-11ee-8546-d8c49764f6bb
2023-11-26 06:37:33,593 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36567'. Reason: nanny-close
2023-11-26 06:37:33,622 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-11-26 06:37:33,623 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45003. Reason: nanny-close
2023-11-26 06:37:33,625 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2023-11-26 06:37:33,625 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:41318; closing.
2023-11-26 06:37:33,626 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45003', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1700980653.6262016')
2023-11-26 06:37:33,626 - distributed.scheduler - INFO - Lost all workers
2023-11-26 06:37:33,627 - distributed.nanny - INFO - Worker closed
2023-11-26 06:37:34,609 - distributed._signals - INFO - Received signal SIGINT (2)
2023-11-26 06:37:34,609 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2023-11-26 06:37:34,610 - distributed.scheduler - INFO - Scheduler closing all comms
2023-11-26 06:37:34,610 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-11-26 06:37:34,611 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45219 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33655 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35025 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41503 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46447 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39207 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40561 instead
  warnings.warn(
2023-11-26 06:39:21,982 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-11-26 06:39:21,983 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-11-26 06:39:21,990 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1920, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 466, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1628, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2023-11-26 06:39:21,996 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-26 06:39:22,000 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'ucx://10.33.225.163:34317', name: 6, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
Task exception was never retrieved
future: <Task finished name='Task-1406' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33171 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42969 instead
  warnings.warn(
2023-11-26 06:39:45,102 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-26 06:39:45,102 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-26 06:39:45,103 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-26 06:39:45,105 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:46025', name: 0, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-26 06:39:45,106 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:36305', name: 3, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2023-11-26 06:39:45,106 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:42863', name: 2, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1253, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 454, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 433, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1344, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1543, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45399 instead
  warnings.warn(
[1700980793.313069] [dgx13:56067:0]            sock.c:470  UCX  ERROR bind(fd=132 addr=0.0.0.0:55302) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42861 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43087 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34073 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41027 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39105 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36001 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35175 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42855 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39957 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37947 instead
  warnings.warn(
Future exception was never retrieved
future: <Future finished exception=UCXCanceled('<[Recv shutdown] ep: 0x7f314d038140, tag: 0x6b709198b1290421>: ')>
ucp._libs.exceptions.UCXCanceled: <[Recv shutdown] ep: 0x7f314d038140, tag: 0x6b709198b1290421>: 
Future exception was never retrieved
future: <Future finished exception=UCXCanceled('<[Recv shutdown] ep: 0x7fbb92b0b140, tag: 0xd0f952bd4aa99476>: ')>
ucp._libs.exceptions.UCXCanceled: <[Recv shutdown] ep: 0x7fbb92b0b140, tag: 0xd0f952bd4aa99476>: 
sys:1: RuntimeWarning: coroutine 'BlockingMode._arm_worker' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task cancelling name='Task-3671' coro=<BlockingMode._arm_worker() running at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/continuous_ucx_progress.py:88>>
sys:1: RuntimeWarning: coroutine 'BlockingMode._arm_worker' was never awaited
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task cancelling name='Task-4327' coro=<BlockingMode._arm_worker() running at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/continuous_ucx_progress.py:88>>
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36031 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40603 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43705 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38273 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40333 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46529 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33787 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40375 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34041 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36485 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35207 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41873 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46591 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38183 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41281 instead
  warnings.warn(
[1700981258.400106] [dgx13:64785:0]            sock.c:470  UCX  ERROR bind(fd=124 addr=0.0.0.0:51335) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33877 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33623 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46185 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46217 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42537 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44731 instead
  warnings.warn(
2023-11-26 06:48:58,192 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 27, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 47, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-11-26 06:48:58,204 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:39341'.
2023-11-26 06:48:58,205 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:39341'. Shutting down.
2023-11-26 06:48:58,207 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7fca510c79a0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 27, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 47, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=CudaAPIError(2, 'Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/__init__.py", line 27, in <module>
    from cudf.core.algorithms import factorize
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/algorithms.py", line 10, in <module>
    from cudf.core.indexed_frame import IndexedFrame
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/indexed_frame.py", line 59, in <module>
    from cudf.core.groupby.groupby import GroupBy
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/__init__.py", line 3, in <module>
    from cudf.core.groupby.groupby import GroupBy, Grouper
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/groupby/groupby.py", line 31, in <module>
    from cudf.core.udf.groupby_utils import _can_be_jitted, jit_groupby_apply
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/groupby_utils.py", line 11, in <module>
    import cudf.core.udf.utils
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/udf/utils.py", line 66, in <module>
    _PTX_FILE = _get_ptx_file(os.path.dirname(__file__), "shim_")
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/utils/_numba.py", line 47, in _get_ptx_file
    dev = cuda.get_current_device()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/api.py", line 443, in get_current_device
    return current_context().device
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 220, in get_context
    return _runtime.get_or_create_context(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 138, in get_or_create_context
    return self._get_or_create_context_uncached(devnum)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 155, in _get_or_create_context_uncached
    return self._activate_context_for(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py", line 177, in _activate_context_for
    newctx = gpu.get_primary_context()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 675, in get_primary_context
    driver.cuDevicePrimaryCtxRetain(byref(hctx), self.id)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 331, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 399, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [2] Call to cuDevicePrimaryCtxRetain results in CUDA_ERROR_OUT_OF_MEMORY
2023-11-26 06:48:58,534 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-26 06:48:58,542 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:42657'.
2023-11-26 06:48:58,543 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:42657'. Shutting down.
2023-11-26 06:48:58,545 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f34df1789d0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-26 06:48:59,073 - distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-26 06:48:59,082 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:39901'.
2023-11-26 06:48:59,082 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:39901'. Shutting down.
2023-11-26 06:48:59,085 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f30bb0259a0>>, <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-5' coro=<Worker.handle_scheduler() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py:202> exception=MemoryError('std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 738, in _run_callback
    ret = callback()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 762, in _discard_future_result
    future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 205, in wrapper
    return await method(self, *args, **kwargs)  # type: ignore
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1300, in handle_scheduler
    await self.handle_stream(comm)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 974, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 253, in read
    msg = await from_frames(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 100, in from_frames
    res = _from_frames()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 83, in _from_frames
    return protocol.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 108, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/compat.py", line 97, in _decode_default
    return pickle.loads(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 172, in host_deserialize
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/abc.py", line 173, in <listcomp>
    cudf.core.buffer.as_buffer(f) if c else f
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/utils.py", line 82, in as_buffer
    return Buffer._from_host_memory(data)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/cudf/core/buffer/buffer.py", line 167, in _from_host_memory
    buf = rmm.DeviceBuffer(ptr=ptr, size=size)
  File "device_buffer.pyx", line 87, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/gdf/include/rmm/mr/device/cuda_memory_resource.hpp
2023-11-26 06:49:00,211 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-11-26 06:49:00,548 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-11-26 06:49:01,088 - distributed.nanny - ERROR - Worker process died unexpectedly
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
