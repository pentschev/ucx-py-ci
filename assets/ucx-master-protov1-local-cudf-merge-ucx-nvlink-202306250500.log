2023-06-25 06:14:27,466 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:27,466 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:27,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:27,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:27,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:27,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:27,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:27,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:27,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:27,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:27,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:27,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:27,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:27,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:27,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:27,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:72893:0:72893] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  72893) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f1074611c8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2ae84) [0x7f1074611e84]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b04a) [0x7f107461204a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f1114e16420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f1074690ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f10746b7dc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f10745cb45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7f10745ce8c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f107461b299]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f10745cd65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f107468dd9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f107473f17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55634e5d2b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55634e5c3112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55634e5bc27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55634e5cdc05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55634e5bd81b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55634e5e270e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7f110842d2fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55634e5c62bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55634e579817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55634e5c4f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55634e5c2d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55634e5cdef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55634e5bd81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55634e5cdef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55634e5bd81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55634e5cdef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55634e5bd81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55634e5cdef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55634e5bd81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55634e5bc27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55634e5cdc05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55634e5c1fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55634e5bc27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55634e5db935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55634e5dc104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55634e6a2fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55634e5c62bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55634e5c11bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55634e5cdef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55634e5dbc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55634e5c11bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55634e5cdef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55634e5bd81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55634e5bc27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55634e5cdc05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55634e5bd81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55634e5cdef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55634e5bd568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55634e5bc27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55634e5cdc05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55634e5be3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55634e5bc27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55634e5bbf07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55634e5bbeb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55634e66c8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55634e69aadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55634e696c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55634e68e7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55634e68e6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55634e68d8a2]
=================================
2023-06-25 06:14:36,488 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46147 -> ucx://127.0.0.1:36739
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd9238d0100, tag: 0xcd9c9a31db5ab958, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:36,488 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49643 -> ucx://127.0.0.1:36739
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcd41d5b100, tag: 0x5f72257cbdda22ed, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
Task exception was never retrieved
future: <Task finished name='Task-779' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
Task exception was never retrieved
future: <Task finished name='Task-788' coro=<_listener_handler_coroutine() done, defined at /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py:128> exception=UCXError('<stream_send>: Connection reset by remote peer')>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 143, in _listener_handler_coroutine
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 51, in exchange_peer_info
    await comm.stream_send(endpoint, my_info_arr, my_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_send>: Connection reset by remote peer
2023-06-25 06:14:36,571 - distributed.nanny - WARNING - Restarting worker
[dgx13:72898:0:72898] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  72898) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fe6d71bec8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2ae84) [0x7fe6d71bee84]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b04a) [0x7fe6d71bf04a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fe77b9da420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fe6d723dba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fe6d7264dc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fe6d717845f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7fe6d717b8c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fe6d71c8299]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fe6d717a65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fe6d723ad9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fe6d72ec17a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x561ab0cfeb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x561ab0cef112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x561ab0ce827a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x561ab0cf9c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x561ab0ce981b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x561ab0cf9ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x561ab0d07a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x561ab0e179b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x561ab0ca5817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x561ab0cf0f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x561ab0ceed36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x561ab0cf9ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x561ab0ce981b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x561ab0cf9ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x561ab0ce981b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x561ab0cf9ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x561ab0ce981b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x561ab0cf9ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x561ab0ce981b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x561ab0ce827a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x561ab0cf9c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x561ab0cedfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x561ab0ce827a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x561ab0d07935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x561ab0d08104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x561ab0dcefc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x561ab0cf22bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x561ab0ced1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x561ab0cf9ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x561ab0d07c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x561ab0ced1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x561ab0cf9ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x561ab0ce981b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x561ab0ce827a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x561ab0cf9c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x561ab0ce981b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x561ab0cf9ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x561ab0ce9568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x561ab0ce827a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x561ab0cf9c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x561ab0cea3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x561ab0ce827a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x561ab0ce7f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x561ab0ce7eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x561ab0d988bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x561ab0dc6adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x561ab0dc2c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x561ab0dba7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x561ab0dba6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x561ab0db98a2]
=================================
2023-06-25 06:14:36,935 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49643 -> ucx://127.0.0.1:51005
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7fcd41d5b100, tag: 0x3a85eb4bf9c30399, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:36,935 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60263 -> ucx://127.0.0.1:51005
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc2e8ba4100, tag: 0x6184e4b44f54f5ca, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:37,021 - distributed.nanny - WARNING - Restarting worker
[dgx13:72906:0:72906] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  72906) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fcfb74f5c8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2ae84) [0x7fcfb74f5e84]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b04a) [0x7fcfb74f604a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fd05bd5e420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fcfb7574ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fcfb759bdc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fcfbc03045f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7fcfbc0338c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fcfb74ff299]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fcfbc03265d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fcfb7571d9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fcfb762317a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5591fa162b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5591fa153112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5591fa14c27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5591fa15dc05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5591fa14d81b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5591fa17270e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fcfdb8ef2fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5591fa1562bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5591fa109817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5591fa154f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5591fa152d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5591fa15def3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5591fa14d81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5591fa15def3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5591fa14d81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5591fa15def3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5591fa14d81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5591fa15def3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5591fa14d81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5591fa14c27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5591fa15dc05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5591fa151fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5591fa14c27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5591fa16b935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5591fa16c104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5591fa232fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5591fa1562bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5591fa1511bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5591fa15def3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5591fa16bc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5591fa1511bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5591fa15def3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5591fa14d81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5591fa14c27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5591fa15dc05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5591fa14d81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5591fa15def3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5591fa14d568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5591fa14c27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5591fa15dc05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5591fa14e3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5591fa14c27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5591fa14bf07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5591fa14beb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5591fa1fc8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5591fa22aadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5591fa226c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5591fa21e7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5591fa21e6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5591fa21d8a2]
=================================
[dgx13:72905:0:72905] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  72905) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f2665e63c8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2ae84) [0x7f2665e63e84]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b04a) [0x7f2665e6404a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f270c6bb420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7f2665ee2ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7f2665f09dc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7f266c04345f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7f266c0468c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f2665e6d299]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f266c04565d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f2665edfd9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7f2665f9117a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x559ffa054b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x559ffa045112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559ffa03e27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559ffa04fc05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559ffa03f81b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559ffa04fef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x559ffa05da16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x559ffa16d9b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x559ff9ffb817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x559ffa046f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x559ffa044d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559ffa04fef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559ffa03f81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559ffa04fef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559ffa03f81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559ffa04fef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559ffa03f81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559ffa04fef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559ffa03f81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559ffa03e27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559ffa04fc05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x559ffa043fa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559ffa03e27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x559ffa05d935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x559ffa05e104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x559ffa124fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x559ffa0482bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x559ffa0431bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559ffa04fef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x559ffa05dc72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x559ffa0431bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559ffa04fef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559ffa03f81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559ffa03e27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559ffa04fc05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x559ffa03f81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x559ffa04fef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x559ffa03f568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559ffa03e27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x559ffa04fc05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x559ffa0403cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x559ffa03e27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x559ffa03df07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x559ffa03deb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x559ffa0ee8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x559ffa11cadc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x559ffa118c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x559ffa1107ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x559ffa1106bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x559ffa10f8a2]
=================================
2023-06-25 06:14:37,592 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55697
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fd9238d0140, tag: 0x88116f51e032aa4, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fd9238d0140, tag: 0x88116f51e032aa4, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-25 06:14:37,592 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55697
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f2bc01361c0, tag: 0x93cbc18e9a371337, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f2bc01361c0, tag: 0x93cbc18e9a371337, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-25 06:14:37,593 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55697
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7fcd41d5b200, tag: 0x957d607a4e69f29f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 329, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7fcd41d5b200, tag: 0x957d607a4e69f29f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 334, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to ucx://127.0.0.1:55697 after 30 s
2023-06-25 06:14:37,593 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46147 -> ucx://127.0.0.1:55697
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd9238d02c0, tag: 0xcec03a73f59b5ac8, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:37,597 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:55697
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-06-25 06:14:37,616 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fcd41d5b1c0, tag: 0x82e1f0ce6df36cda, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fcd41d5b1c0, tag: 0x82e1f0ce6df36cda, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-25 06:14:37,616 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60263 -> ucx://127.0.0.1:55697
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc2e8ba4100, tag: 0x9311cece0e5f112b, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:37,616 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60263 -> ucx://127.0.0.1:38189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc2e8ba4200, tag: 0xbdbfb7727abd40ab, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:37,617 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49643 -> ucx://127.0.0.1:38189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcd41d5b300, tag: 0xb9ea0e481c16d14, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:37,619 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 466, in connect
    ep = await ucp.create_endpoint(ip, port)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 1004, in create_endpoint
    return await _get_ctx().create_endpoint(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 316, in create_endpoint
    peer_info = await exchange_peer_info(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 54, in exchange_peer_info
    await comm.stream_recv(endpoint, peer_info_arr, peer_info_arr.nbytes)
ucp._libs.exceptions.UCXError: <stream_recv>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 292, in connect
    comm = await wait_for(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 479, in wait_for
    return fut.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 468, in connect
    raise CommClosedError("Connection closed before handshake completed")
distributed.comm.core.CommClosedError: Connection closed before handshake completed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1427, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 316, in connect
    await asyncio.sleep(backoff)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2889, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1506, in connect
    return await connect_attempt
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1450, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-06-25 06:14:37,638 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd9238d0180, tag: 0x427d0f7f8f658a18, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd9238d0180, tag: 0x427d0f7f8f658a18, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:37,690 - distributed.nanny - WARNING - Restarting worker
2023-06-25 06:14:37,712 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33199 -> ucx://127.0.0.1:38189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f2bc0136300, tag: 0x59b3075ed86c66c9, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:37,715 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:38189
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f2bc0136180, tag: 0x48ee5490163356d6, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f2bc0136180, tag: 0x48ee5490163356d6, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-25 06:14:37,763 - distributed.nanny - WARNING - Restarting worker
2023-06-25 06:14:38,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:38,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:38,614 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:38,614 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:39,077 - distributed.worker - WARNING - Compute Failed
Key:       ('group-simple-shuffle-400415cd9041483324fd5163807a7fc4', 7)
Function:  <dask.layers.CallableLazyImport object at 0x7fc7f7
args:      (               key   payload
shuffle                     
7             2755  36376872
7             2757  48340943
7             2761  52126459
7            73345  45380071
7             2776  10427217
...            ...       ...
7        799968934  92574207
7        799988863   9466008
7        799968942  80860256
7        799968947  18585909
7        799968955  60535704

[100000000 rows x 2 columns], ['key'], 0, 8, 8, False, 8)
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-25 06:14:39,210 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 3)
Function:  <dask.layers.CallableLazyImport object at 0x7fc7f7
args:      ([                key   payload
18659     111762394  66961037
18674     808967725  82259974
18678     846540297  92759345
23104     805951423  88481962
73250     846158454  61327338
...             ...       ...
99987272  710237679  83976238
99987276  858853508  33487556
99987279  702016098  55844090
99987289  849608516  10941321
99987290  407247335  19941117

[12498632 rows x 2 columns],                 key   payload
2257      213569317  79290285
2260      964177000  28396306
2267      925546397  33261564
113730    940494684  36960089
2271      931727153  39042098
...             ...       ...
99991413  913440848  20044448
99991414   19301861  71908656
99985724  413680238  24755279
99991415   13416895  67772195
99985726   22125524  19537786

[12502237 rows x 2 columns],                  key   payload
31749     1000691494  18667423
11400     1063809893  55002864
123562    1057351620  51737647
123579    1014903498  64358750
11404     1005235652  53774876
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-25 06:14:39,375 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 7)
Function:  <dask.layers.CallableLazyImport object at 0x7fbd90
args:      ([                key   payload
18671     508674524  38798352
18672     863260844  45553535
18675     805716499  71106662
18681     107264867  37082414
23107     104653432  21576214
...             ...       ...
99987252  860766726   3959175
99987256  602190385   8277748
99987275  823177837  42039685
99987278  206571931  95421978
99987287  837803743  78366489

[12500893 rows x 2 columns],                 key   payload
2241      123631834  83187778
2244      963900443  97652588
2258      421683285  27879693
113731    924486272  29484830
2265      931558644  50347824
...             ...       ...
99985725  901119416  76855444
99991394  954480522   3344506
99991395  957908684   3929853
99991406  908245174  15012571
99991419  915984923  36647761

[12495890 rows x 2 columns],                  key   payload
31760      535871347  56584102
31761     1054166200  67401134
11399      728563997  56006970
123560     232581790  48044231
31762      633347465  35684498
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-25 06:14:39,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:39,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:39,398 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 6)
Function:  <dask.layers.CallableLazyImport object at 0x7fd3d4
args:      ([                key   payload
18664     829329505  17725989
18669     834491910  10668727
18679     831029412  24894980
18686     403260140  17397801
23105     401280486  48221798
...             ...       ...
99987243  867864457  68087905
99987254  834037784  41104398
99987265  821346155  25252355
99987284  855562153  77245431
99987291    7419677  12540994

[12497796 rows x 2 columns],                 key   payload
2240      417553187  97253677
2249      963444648  57470589
2262      414608376  15349076
113729    324295883  27287266
19008     964198906  29054385
...             ...       ...
99985711  913998261  87622007
99985716  424080916  89623841
99991404  954986992  89789718
99991405  421528961  68012169
99991409  952949866  53875641

[12497151 rows x 2 columns],                  key   payload
31747     1053018020  71366446
31755     1053009930  43041975
11394      336455332  66327578
123553    1023418517  76278515
123557      32481176  71947971
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-06-25 06:14:39,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:39,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:73415:0:73415] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73415) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc2b0052c8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2ae84) [0x7fc2b0052e84]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b04a) [0x7fc2b005304a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc341da1420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fc29d6e1ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fc29d708dc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fc29d67c45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7fc29d67f8c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc2b005c299]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fc29d67e65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fc29d6ded9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fc29d79017a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5557024b0b08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5557024a1112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55570249a27a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5557024abc05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55570249b81b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5557024c070e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fc2c19332fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5557024a42bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x555702457817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5557024a2f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5557024a0d36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5557024abef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55570249b81b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5557024abef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55570249b81b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5557024abef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55570249b81b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5557024abef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55570249b81b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55570249a27a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5557024abc05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55570249ffa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55570249a27a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5557024b9935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5557024ba104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x555702580fc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5557024a42bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55570249f1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5557024abef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5557024b9c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55570249f1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5557024abef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55570249b81b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55570249a27a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5557024abc05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55570249b81b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5557024abef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55570249b568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55570249a27a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5557024abc05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55570249c3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55570249a27a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x555702499f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x555702499eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55570254a8bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x555702578adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x555702574c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55570256c7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55570256c6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55570256b8a2]
=================================
[dgx13:73431:0:73431] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73431) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7efc5c619c8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2ae84) [0x7efc5c619e84]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b04a) [0x7efc5c61a04a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7efcfccd0420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7efc5c698ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7efc5c6bfdc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7efc5c5d345f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7efc5c5d68c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7efc5c623299]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7efc5c5d565d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7efc5c695d9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7efc5c74717a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x555bc7d2eb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x555bc7d1f112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555bc7d1827a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555bc7d29c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555bc7d1981b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555bc7d29ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x555bc7d37a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x555bc7e479b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x555bc7cd5817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x555bc7d20f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x555bc7d1ed36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555bc7d29ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555bc7d1981b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555bc7d29ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555bc7d1981b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555bc7d29ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555bc7d1981b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555bc7d29ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555bc7d1981b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555bc7d1827a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555bc7d29c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x555bc7d1dfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555bc7d1827a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x555bc7d37935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x555bc7d38104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x555bc7dfefc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x555bc7d222bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x555bc7d1d1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555bc7d29ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x555bc7d37c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x555bc7d1d1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555bc7d29ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555bc7d1981b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555bc7d1827a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555bc7d29c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x555bc7d1981b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x555bc7d29ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x555bc7d19568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555bc7d1827a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x555bc7d29c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x555bc7d1a3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x555bc7d1827a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x555bc7d17f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x555bc7d17eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x555bc7dc88bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x555bc7df6adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x555bc7df2c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x555bc7dea7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x555bc7dea6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x555bc7de98a2]
=================================
2023-06-25 06:14:42,696 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59327
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fcd41d5b1c0, tag: 0xa163f3097b4a67ba, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fcd41d5b1c0, tag: 0xa163f3097b4a67ba, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:42,696 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46147 -> ucx://127.0.0.1:59327
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd9238d0300, tag: 0xa891aa03cdfd502d, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:42,697 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49643 -> ucx://127.0.0.1:59327
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcd41d5b200, tag: 0x68f17d40e61bc8ee, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:42,696 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59327
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f2bc0136180, tag: 0xacdf8e6651a59c1b, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f2bc0136180, tag: 0xacdf8e6651a59c1b, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:42,697 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59327
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc2e8ba4100, tag: 0x81c0ce7cf7c7b75f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc2e8ba4100, tag: 0x81c0ce7cf7c7b75f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:42,697 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59327
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd9238d0180, tag: 0x8d63d2847721e1be, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd9238d0180, tag: 0x8d63d2847721e1be, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:42,766 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33199 -> ucx://127.0.0.1:48703
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f2bc0136240, tag: 0x8354c4a6ecc3d19b, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:42,766 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49643 -> ucx://127.0.0.1:48703
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcd41d5b280, tag: 0x17ca19046332a04f, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:42,766 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46147 -> ucx://127.0.0.1:48703
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd9238d02c0, tag: 0x709d4dbb0a0fddd4, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:42,767 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60263 -> ucx://127.0.0.1:48703
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc2e8ba43c0, tag: 0xdf37844090aaaff5, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:42,767 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33199 -> ucx://127.0.0.1:59327
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f2bc0136300, tag: 0xfd8dc96e18380d9e, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:42,778 - distributed.nanny - WARNING - Restarting worker
2023-06-25 06:14:42,828 - distributed.nanny - WARNING - Restarting worker
[dgx13:73420:0:73420] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73420) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fcc30c12c8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2ae84) [0x7fcc30c12e84]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b04a) [0x7fcc30c1304a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fccc32f5420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fcc30c91ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fcc30cb8dc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fcc30bcc45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7fcc30bcf8c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fcc30c1c299]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fcc30bce65d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fcc30c8ed9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fcc30d4017a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x5599aabdeb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x5599aabcf112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5599aabc827a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5599aabd9c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5599aabc981b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x5599aabee70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fcc42e892fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5599aabd22bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x5599aab85817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x5599aabd0f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x5599aabced36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5599aabd9ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5599aabc981b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5599aabd9ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5599aabc981b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5599aabd9ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5599aabc981b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5599aabd9ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5599aabc981b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5599aabc827a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5599aabd9c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x5599aabcdfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5599aabc827a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x5599aabe7935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x5599aabe8104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x5599aacaefc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x5599aabd22bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5599aabcd1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5599aabd9ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x5599aabe7c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x5599aabcd1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5599aabd9ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5599aabc981b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5599aabc827a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5599aabd9c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x5599aabc981b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x5599aabd9ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x5599aabc9568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5599aabc827a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x5599aabd9c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x5599aabca3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x5599aabc827a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x5599aabc7f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5599aabc7eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5599aac788bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x5599aaca6adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x5599aaca2c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x5599aac9a7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x5599aac9a6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x5599aac998a2]
=================================
2023-06-25 06:14:43,382 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49643 -> ucx://127.0.0.1:32863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcd41d5b200, tag: 0xacc39f199f5971d1, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:43,382 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:32863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd9238d02c0, tag: 0x24a020feb7298be4, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd9238d02c0, tag: 0x24a020feb7298be4, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:43,382 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33199 -> ucx://127.0.0.1:32863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f2bc0136240, tag: 0xce508609de388c0, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:43,382 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60263 -> ucx://127.0.0.1:32863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc2e8ba4100, tag: 0x9a407740c9c12567, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:43,382 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:32863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fcd41d5b280, tag: 0x67db572dd5e739ff, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fcd41d5b280, tag: 0x67db572dd5e739ff, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:43,382 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46147 -> ucx://127.0.0.1:32863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd9238d0180, tag: 0x6b210f8d2259185, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:43,383 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:32863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f2bc0136300, tag: 0x6ea50f720b290ad6, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f2bc0136300, tag: 0x6ea50f720b290ad6, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:43,383 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:32863
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc2e8ba43c0, tag: 0xd25278fa2208852e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc2e8ba43c0, tag: 0xd25278fa2208852e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:43,456 - distributed.nanny - WARNING - Restarting worker
2023-06-25 06:14:44,360 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:44,360 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:44,364 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:44,364 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:44,970 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:44,970 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:73428:0:73428] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73428) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc931d95c8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2ae84) [0x7fc931d95e84]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b04a) [0x7fc931d9604a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc9d4459420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fc931e14ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fc931e3bdc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fc931d4f45f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7fc931d528c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc931d9f299]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fc931d5165d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fc931e11d9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fc931ec317a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55e1b98beb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55e1b98af112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e1b98a827a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e1b98b9c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e1b98a981b]
17  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x55e1b98ce70e]
18  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fc953fee2fe]
19  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55e1b98b22bc]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55e1b9865817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55e1b98b0f83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55e1b98aed36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e1b98b9ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e1b98a981b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e1b98b9ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e1b98a981b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e1b98b9ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e1b98a981b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e1b98b9ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e1b98a981b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e1b98a827a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e1b98b9c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55e1b98adfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e1b98a827a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55e1b98c7935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55e1b98c8104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55e1b998efc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55e1b98b22bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e1b98ad1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e1b98b9ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55e1b98c7c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55e1b98ad1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e1b98b9ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e1b98a981b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e1b98a827a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e1b98b9c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55e1b98a981b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55e1b98b9ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55e1b98a9568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e1b98a827a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55e1b98b9c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55e1b98aa3cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55e1b98a827a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55e1b98a7f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55e1b98a7eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55e1b99588bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55e1b9986adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55e1b9982c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55e1b997a7ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55e1b997a6bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55e1b99798a2]
=================================
2023-06-25 06:14:46,887 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49643 -> ucx://127.0.0.1:40991
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcd41d5b200, tag: 0xeae067b113111c27, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:46,888 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33199 -> ucx://127.0.0.1:40991
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f2bc0136240, tag: 0x28a53cac9232dbc7, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:46,888 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60263 -> ucx://127.0.0.1:40991
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fc2e8ba4100, tag: 0xd485f85a00bb6011, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:46,888 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46147 -> ucx://127.0.0.1:40991
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd9238d02c0, tag: 0xb498583d0813b4b0, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:46,888 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40991
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fcd41d5b280, tag: 0x22bda649f5b053bb, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fcd41d5b280, tag: 0x22bda649f5b053bb, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:46,888 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40991
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f2bc0136300, tag: 0x12c8a396e3fbc92b, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f2bc0136300, tag: 0x12c8a396e3fbc92b, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:46,888 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40991
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc2e8ba43c0, tag: 0xb85c12b02c8ab883, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc2e8ba43c0, tag: 0xb85c12b02c8ab883, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:46,888 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:40991
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fd9238d0180, tag: 0xa4aaa22fcf295bcf, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fd9238d0180, tag: 0xa4aaa22fcf295bcf, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-06-25 06:14:46,954 - distributed.nanny - WARNING - Restarting worker
2023-06-25 06:14:48,452 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:48,452 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:73574:0:73574] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  73574) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc46c6e8c8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2ae84) [0x7fc46c6e8e84]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2b04a) [0x7fc46c6e904a]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fc50cd99420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x14) [0x7fc46c767ba4]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x4e9) [0x7fc46c78edc9]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2045f) [0x7fc46c6a245f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x238c8) [0x7fc46c6a58c8]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc46c6f2299]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fc46c6a465d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fc46c764d9a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x2b17a) [0x7fc46c81617a]
12  /opt/conda/envs/gdf/bin/python(+0x13eb08) [0x55dc3cc2cb08]
13  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5f82) [0x55dc3cc1d112]
14  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55dc3cc1627a]
15  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55dc3cc27c05]
16  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55dc3cc1781b]
17  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55dc3cc27ef3]
18  /opt/conda/envs/gdf/bin/python(+0x147a16) [0x55dc3cc35a16]
19  /opt/conda/envs/gdf/bin/python(+0x2579b1) [0x55dc3cd459b1]
20  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x55dc3cbd3817]
21  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x55dc3cc1ef83]
22  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x55dc3cc1cd36]
23  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55dc3cc27ef3]
24  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55dc3cc1781b]
25  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55dc3cc27ef3]
26  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55dc3cc1781b]
27  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55dc3cc27ef3]
28  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55dc3cc1781b]
29  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55dc3cc27ef3]
30  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55dc3cc1781b]
31  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55dc3cc1627a]
32  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55dc3cc27c05]
33  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x55dc3cc1bfa7]
34  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55dc3cc1627a]
35  /opt/conda/envs/gdf/bin/python(+0x147935) [0x55dc3cc35935]
36  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x55dc3cc36104]
37  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x55dc3ccfcfc8]
38  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x55dc3cc202bc]
39  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55dc3cc1b1bb]
40  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55dc3cc27ef3]
41  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x55dc3cc35c72]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x55dc3cc1b1bb]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55dc3cc27ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55dc3cc1781b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55dc3cc1627a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55dc3cc27c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x55dc3cc1781b]
48  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x55dc3cc27ef3]
49  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3d8) [0x55dc3cc17568]
50  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55dc3cc1627a]
51  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x55dc3cc27c05]
52  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x55dc3cc183cb]
53  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x55dc3cc1627a]
54  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x47) [0x55dc3cc15f07]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55dc3cc15eb9]
56  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55dc3ccc68bb]
57  /opt/conda/envs/gdf/bin/python(+0x206adc) [0x55dc3ccf4adc]
58  /opt/conda/envs/gdf/bin/python(+0x202c24) [0x55dc3ccf0c24]
59  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9d) [0x55dc3cce87ed]
60  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3d) [0x55dc3cce86bd]
61  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x262) [0x55dc3cce78a2]
=================================
[1687673689.776981] [dgx13:72910:0]    cuda_copy_md.c:229  UCX  ERROR   cuMemAlloc_v2((CUdeviceptr*)address_p, *length_p)() failed: out of memory
[1687673689.776999] [dgx13:72910:0]         uct_mem.c:155  UCX  ERROR   failed to allocate 536870912 bytes using md cuda_cpy for ucp_rndv_frags: Input/output error
[1687673689.777004] [dgx13:72910:0]           mpool.c:269  UCX  ERROR Failed to allocate memory pool (name=ucp_rndv_frags) chunk: Out of memory
[dgx13:72910:0:72910]        rndv.c:1357 Fatal: failed to allocate fragment memory buffer
==== backtrace (tid:  72910) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fc2e8e5ac8d]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_fatal_error_message+0x51) [0x7fc2e8e58841]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x289dc) [0x7fc2e8e589dc]
 3  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_receive+0xf2c) [0x7fc2e8f0431c]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_recv_nbx+0xb6a) [0x7fc2e8f17d6a]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_tag_recv_nb+0x57) [0x7fc2e8f18027]
 6  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x4fb0b) [0x7fc2e8facb0b]
 7  /opt/conda/envs/gdf/bin/python(+0x149dc7) [0x564a84eb2dc7]
 8  /opt/conda/envs/gdf/bin/python(PyObject_Call+0x158) [0x564a84eb11a8]
 9  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x564a84e97d36]
10  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564a84e9127a]
11  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564a84ea2c05]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x564a84e933cb]
13  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564a84e9127a]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564a84ea2c05]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x123b) [0x564a84e933cb]
16  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564a84eb770e]
17  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x564a84e98923]
18  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564a84eb770e]
19  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x564a84e98923]
20  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564a84eb770e]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x564a84e98923]
22  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564a84eb770e]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x564a84e98923]
24  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564a84eb770e]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x564a84e98923]
26  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564a84eb770e]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x564a84e98923]
28  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564a84eb770e]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6793) [0x564a84e98923]
30  /opt/conda/envs/gdf/bin/python(+0x14e70e) [0x564a84eb770e]
31  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x82fe) [0x7fc30920c2fe]
32  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x8b4e) [0x7fc30920cb4e]
33  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x564a84e9b2bc]
34  /opt/conda/envs/gdf/bin/python(+0xe5817) [0x564a84e4e817]
35  /opt/conda/envs/gdf/bin/python(+0x130f83) [0x564a84e99f83]
36  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5ba6) [0x564a84e97d36]
37  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564a84ea2ef3]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564a84e9281b]
39  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564a84ea2ef3]
40  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564a84e9281b]
41  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564a84ea2ef3]
42  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564a84e9281b]
43  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564a84ea2ef3]
44  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564a84e9281b]
45  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564a84e9127a]
46  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564a84ea2c05]
47  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4e17) [0x564a84e96fa7]
48  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564a84e9127a]
49  /opt/conda/envs/gdf/bin/python(+0x147935) [0x564a84eb0935]
50  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xb4) [0x564a84eb1104]
51  /opt/conda/envs/gdf/bin/python(+0x20efc8) [0x564a84f77fc8]
52  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2fc) [0x564a84e9b2bc]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x564a84e961bb]
54  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564a84ea2ef3]
55  /opt/conda/envs/gdf/bin/python(+0x147c72) [0x564a84eb0c72]
56  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x402b) [0x564a84e961bb]
57  /opt/conda/envs/gdf/bin/python(+0x139ef3) [0x564a84ea2ef3]
58  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564a84e9281b]
59  /opt/conda/envs/gdf/bin/python(+0x12827a) [0x564a84e9127a]
60  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd5) [0x564a84ea2c05]
61  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x68b) [0x564a84e9281b]
=================================
2023-06-25 06:14:49,992 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:33199 -> ucx://127.0.0.1:36489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f2bc0136240, tag: 0x3b4087a88ef51ec1, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:49,992 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49643 -> ucx://127.0.0.1:36489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcd41d5b200, tag: 0xf0f8d581d997861e, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:49,992 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fd9238d0180, tag: 0x18102d2c2726ea52, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fd9238d0180, tag: 0x18102d2c2726ea52, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-25 06:14:49,993 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #008] ep: 0x7f2bc0136300, tag: 0x38cf3d9d54102ae9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #008] ep: 0x7f2bc0136300, tag: 0x38cf3d9d54102ae9, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-06-25 06:14:49,993 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:36489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fcd41d5b280, tag: 0xb9b4a2ac402e81eb, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fcd41d5b280, tag: 0xb9b4a2ac402e81eb, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-06-25 06:14:49,993 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46147 -> ucx://127.0.0.1:36489
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fd9238d02c0, tag: 0x749bb897a83ec9d8, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-06-25 06:14:50,065 - distributed.nanny - WARNING - Restarting worker
2023-06-25 06:14:50,130 - distributed.nanny - WARNING - Restarting worker
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Exception ignored in: 'cupy.cuda.thrust.cupy_malloc'
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-25 06:14:50,248 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-5366301a596b755bb8c33997d3ce7726', 1)
Function:  generate_chunk
args:      (1, 100000000, 8, 'build', 0.3, True)
kwargs:    {}
Exception: "RuntimeError('transform: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered')"

2023-06-25 06:14:50,252 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-3393696d3757f92da87d0dddd0c6ae01', 6)
Function:  generate_chunk
args:      (6, 100000000, 8, 'other', 0.3, True)
kwargs:    {}
Exception: "CUDADriverError('CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered')"

Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Exception ignored in: 'cupy.cuda.thrust.cupy_malloc'
Traceback (most recent call last):
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/allocators/cupy.py", line 37, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-06-25 06:14:50,311 - distributed.worker - WARNING - Compute Failed
Key:       ('generate-data-3393696d3757f92da87d0dddd0c6ae01', 0)
Function:  generate_chunk
args:      (0, 100000000, 8, 'other', 0.3, True)
kwargs:    {}
Exception: "RuntimeError('transform: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered')"

2023-06-25 06:14:51,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:51,677 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:51,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-25 06:14:51,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-25 06:14:53,355 - distributed.core - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 387, in read
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2254, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 340, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 408, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-06-25 06:14:53,355 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 387, in read
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2254, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 340, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 408, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-06-25 06:14:53,359 - distributed.core - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 387, in read
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2254, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 340, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 408, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-06-25 06:14:53,359 - distributed.worker - ERROR - [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 387, in read
    synchronize_stream(0)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 94, in synchronize_stream
    stream.synchronize()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 2254, in synchronize
    driver.cuStreamSynchronize(self.handle)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 340, in safe_cuda_api_call
    self._check_ctypes_error(fname, retcode)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py", line 408, in _check_ctypes_error
    raise CudaAPIError(retcode, msg)
numba.cuda.cudadrv.driver.CudaAPIError: [700] Call to cuStreamSynchronize results in UNKNOWN_CUDA_ERROR
2023-06-25 06:14:53,365 - distributed.core - ERROR - Unable to allocate 86.2 TiB for an array with shape (94816372629088,) and data type uint8
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 32, in numpy_host_array
    return numpy.empty((n,), dtype="u1").data
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 86.2 TiB for an array with shape (94816372629088,) and data type uint8
2023-06-25 06:14:53,365 - distributed.worker - ERROR - Unable to allocate 86.2 TiB for an array with shape (94816372629088,) and data type uint8
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 373, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/utils.py", line 32, in numpy_host_array
    return numpy.empty((n,), dtype="u1").data
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 86.2 TiB for an array with shape (94816372629088,) and data type uint8
2023-06-25 06:14:53,369 - distributed.core - ERROR - not enough values to unpack (expected 2, got 0)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 376, in read
    cuda_recv_frames, recv_frames = zip(
ValueError: not enough values to unpack (expected 2, got 0)
2023-06-25 06:14:53,369 - distributed.worker - ERROR - not enough values to unpack (expected 2, got 0)
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 376, in read
    cuda_recv_frames, recv_frames = zip(
ValueError: not enough values to unpack (expected 2, got 0)
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 42 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
