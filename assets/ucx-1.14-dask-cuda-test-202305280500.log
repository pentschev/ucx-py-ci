============================= test session starts ==============================
platform linux -- Python 3.9.16, pytest-7.3.1, pluggy-1.0.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.12.0
collecting ... collected 1181 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2023-05-28 06:08:45,403 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:08:45,407 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40687 instead
  warnings.warn(
2023-05-28 06:08:45,411 - distributed.scheduler - INFO - State start
2023-05-28 06:08:45,430 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:08:45,431 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:08:45,431 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:08:45,432 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-28 06:08:45,490 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35947'
2023-05-28 06:08:45,504 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41063'
2023-05-28 06:08:45,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35623'
2023-05-28 06:08:45,514 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41261'
2023-05-28 06:08:46,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:46,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7mbrl7mz', purging
2023-05-28 06:08:46,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:46,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fx2iq1vh', purging
2023-05-28 06:08:46,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hcvwvpcd', purging
2023-05-28 06:08:46,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w1z875qq', purging
2023-05-28 06:08:46,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2l0bj5nd', purging
2023-05-28 06:08:46,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:46,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:46,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:46,959 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:46,960 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:46,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:46,964 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:46,965 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:46,965 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:46,967 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
Unable to start CUDA Context
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/initialize.py", line 31, in _create_cuda_context
    distributed.comm.ucx.init_once()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 133, in init_once
    cuda_visible_device = get_device_index_and_uuid(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/diagnostics/nvml.py", line 256, in get_device_index_and_uuid
    device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 1655, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/pynvml/nvml.py", line 765, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.nvml.NVMLError_InvalidArgument: Invalid Argument
2023-05-28 06:08:46,981 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46597
2023-05-28 06:08:46,981 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46597
2023-05-28 06:08:46,981 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36809
2023-05-28 06:08:46,981 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2023-05-28 06:08:46,981 - distributed.worker - INFO - -------------------------------------------------
2023-05-28 06:08:46,981 - distributed.worker - INFO -               Threads:                          4
2023-05-28 06:08:46,981 - distributed.worker - INFO -                Memory:                 251.94 GiB
2023-05-28 06:08:46,981 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-356ivv8j
2023-05-28 06:08:46,981 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fbd100c3-bf69-4ffd-a928-b706e6b080c0
2023-05-28 06:08:46,981 - distributed.worker - INFO - Starting Worker plugin PreImport-63ffe91b-c35a-48a7-a8d7-550d10b3baaf
2023-05-28 06:08:46,981 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b5e4849b-3148-4249-ad64-774359423d85
2023-05-28 06:08:46,982 - distributed.worker - INFO - -------------------------------------------------
2023-05-28 06:08:46,996 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2023-05-28 06:08:46,996 - distributed.worker - INFO - -------------------------------------------------
2023-05-28 06:08:46,998 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:08:47,750 - distributed.nanny - INFO - Worker process 26335 exited with status 127
2023-05-28 06:08:47,751 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:47,771 - distributed.nanny - INFO - Worker process 26342 exited with status 127
2023-05-28 06:08:47,771 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:47,796 - distributed.nanny - INFO - Worker process 26338 exited with status 127
2023-05-28 06:08:47,797 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:49,196 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cp84grks', purging
2023-05-28 06:08:49,196 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:49,196 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:49,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vuykluof', purging
2023-05-28 06:08:49,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8p8zisyg', purging
2023-05-28 06:08:49,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:49,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:49,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:49,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:49,204 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:49,205 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:49,207 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:08:50,074 - distributed.nanny - INFO - Worker process 26383 exited with status 127
2023-05-28 06:08:50,075 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:50,112 - distributed.nanny - INFO - Worker process 26380 exited with status 127
2023-05-28 06:08:50,113 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:50,135 - distributed.nanny - INFO - Worker process 26377 exited with status 127
2023-05-28 06:08:50,135 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:51,071 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46597. Reason: scheduler-close
2023-05-28 06:08:51,071 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:9359; closing.
2023-05-28 06:08:51,072 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://127.0.0.1:34306 remote=tcp://127.0.0.1:9359>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-05-28 06:08:51,075 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://127.0.0.1:41261'. Reason: scheduler-close
2023-05-28 06:08:51,078 - distributed.nanny - INFO - Worker closed
2023-05-28 06:08:51,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hyof1s9w', purging
2023-05-28 06:08:51,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-98xb__2e', purging
2023-05-28 06:08:51,564 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-myqhgu1v', purging
2023-05-28 06:08:51,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:51,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:51,571 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:51,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:51,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:51,603 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:51,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:51,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:51,639 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:08:52,359 - distributed.nanny - INFO - Worker process 26407 exited with status 127
2023-05-28 06:08:52,360 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:08:52,485 - distributed.nanny - INFO - Worker process 26413 exited with status 127
2023-05-28 06:08:52,486 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:52,518 - distributed.nanny - INFO - Worker process 26410 exited with status 127
2023-05-28 06:08:52,519 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:53,336 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41261'. Reason: nanny-close-gracefully
2023-05-28 06:08:53,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_rgr9_dj', purging
2023-05-28 06:08:53,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgruid2m', purging
2023-05-28 06:08:53,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ydws4vj_', purging
2023-05-28 06:08:53,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:53,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:53,867 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:54,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:54,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:54,056 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:54,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:54,068 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:54,079 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:08:56,852 - distributed.nanny - INFO - Worker process 26437 exited with status 127
2023-05-28 06:08:56,852 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:56,936 - distributed.nanny - INFO - Worker process 26445 exited with status 127
2023-05-28 06:08:56,936 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:56,982 - distributed.nanny - INFO - Worker process 26442 exited with status 127
2023-05-28 06:08:56,983 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:08:58,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-te0v7r4s', purging
2023-05-28 06:08:58,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9a2e46wa', purging
2023-05-28 06:08:58,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ielshoya', purging
2023-05-28 06:08:58,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:58,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:58,512 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:58,583 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:58,583 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:58,591 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:08:58,592 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:08:58,592 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:08:58,599 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:02,268 - distributed.nanny - INFO - Worker process 26470 exited with status 127
2023-05-28 06:09:02,269 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:02,325 - distributed.nanny - INFO - Worker process 26473 exited with status 127
2023-05-28 06:09:02,326 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:02,367 - distributed.nanny - INFO - Worker process 26476 exited with status 127
2023-05-28 06:09:02,367 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:03,841 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fy3vo9wx', purging
2023-05-28 06:09:03,841 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ras36ob7', purging
2023-05-28 06:09:03,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ni85i6xq', purging
2023-05-28 06:09:03,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:03,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:03,849 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:04,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:04,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:04,042 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:04,140 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:04,140 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:04,147 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:07,591 - distributed.nanny - INFO - Worker process 26500 exited with status 127
2023-05-28 06:09:07,592 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:07,942 - distributed.nanny - INFO - Worker process 26506 exited with status 127
2023-05-28 06:09:07,943 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:07,982 - distributed.nanny - INFO - Worker process 26503 exited with status 127
2023-05-28 06:09:07,982 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:09,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3rz9fj85', purging
2023-05-28 06:09:09,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2o96u6lw', purging
2023-05-28 06:09:09,133 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6q2i9npo', purging
2023-05-28 06:09:09,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:09,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:09,141 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:09,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:09,611 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:09,611 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:09,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:09,618 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:09,619 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:11,974 - distributed.nanny - INFO - Worker process 26528 exited with status 127
2023-05-28 06:09:11,975 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:12,094 - distributed.nanny - INFO - Worker process 26536 exited with status 127
2023-05-28 06:09:12,095 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:12,120 - distributed.nanny - INFO - Worker process 26533 exited with status 127
2023-05-28 06:09:12,121 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:13,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-77a4u3y0', purging
2023-05-28 06:09:13,447 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o1r9oecd', purging
2023-05-28 06:09:13,448 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h54gpcgk', purging
2023-05-28 06:09:13,448 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:13,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:13,455 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:13,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:13,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:13,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:13,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:13,682 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:13,687 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:14,328 - distributed.nanny - INFO - Worker process 26560 exited with status 127
2023-05-28 06:09:14,329 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:14,449 - distributed.nanny - INFO - Worker process 26563 exited with status 127
2023-05-28 06:09:14,449 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:14,483 - distributed.nanny - INFO - Worker process 26566 exited with status 127
2023-05-28 06:09:14,484 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:15,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hbe1dcu1', purging
2023-05-28 06:09:15,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8_yxctn7', purging
2023-05-28 06:09:15,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_umwvwj', purging
2023-05-28 06:09:15,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:15,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:15,790 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:15,858 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:15,858 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:15,865 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:15,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:15,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:15,892 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:16,498 - distributed.nanny - INFO - Worker process 26588 exited with status 127
2023-05-28 06:09:16,499 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:16,628 - distributed.nanny - INFO - Worker process 26593 exited with status 127
2023-05-28 06:09:16,629 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:16,651 - distributed.nanny - INFO - Worker process 26596 exited with status 127
2023-05-28 06:09:16,652 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:18,012 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gvbiho8y', purging
2023-05-28 06:09:18,012 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g04q7882', purging
2023-05-28 06:09:18,012 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cnhkez9x', purging
2023-05-28 06:09:18,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:18,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:18,019 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:18,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:18,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:18,047 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:18,047 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:18,055 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:18,055 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:18,813 - distributed.nanny - INFO - Worker process 26618 exited with status 127
2023-05-28 06:09:18,815 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:19,018 - distributed.nanny - INFO - Worker process 26623 exited with status 127
2023-05-28 06:09:19,019 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:19,041 - distributed.nanny - INFO - Worker process 26626 exited with status 127
2023-05-28 06:09:19,042 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:20,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dm61j9ht', purging
2023-05-28 06:09:20,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aossuqa3', purging
2023-05-28 06:09:20,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mtk7kqet', purging
2023-05-28 06:09:20,269 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:20,269 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:20,276 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:20,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:20,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:20,491 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:20,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:20,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:20,510 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:20,959 - distributed.nanny - INFO - Worker process 26648 exited with status 127
2023-05-28 06:09:20,960 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:21,110 - distributed.nanny - INFO - Worker process 26653 exited with status 127
2023-05-28 06:09:21,111 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:21,133 - distributed.nanny - INFO - Worker process 26656 exited with status 127
2023-05-28 06:09:21,134 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:09:21,173 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client
2023-05-28 06:09:21,180 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35947'. Reason: nanny-close
2023-05-28 06:09:21,181 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41063'. Reason: nanny-close
2023-05-28 06:09:21,181 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35623'. Reason: nanny-close
2023-05-28 06:09:22,408 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6fx6uyie', purging
2023-05-28 06:09:22,409 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qjb5qv8_', purging
2023-05-28 06:09:22,409 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mv2hk84q', purging
2023-05-28 06:09:22,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:22,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:22,417 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:22,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:22,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:22,626 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:22,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:22,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:22,649 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:23,097 - distributed.nanny - INFO - Worker process 26678 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:09:23,354 - distributed.nanny - INFO - Worker process 26686 exited with status 127
2023-05-28 06:09:23,394 - distributed.nanny - INFO - Worker process 26683 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2023-05-28 06:09:53,571 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:09:53,575 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43483 instead
  warnings.warn(
2023-05-28 06:09:53,579 - distributed.scheduler - INFO - State start
2023-05-28 06:09:53,758 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:09:53,759 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:09:53,759 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:09:53,760 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-28 06:09:54,823 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35875'
2023-05-28 06:09:54,840 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34753'
2023-05-28 06:09:54,842 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38117'
2023-05-28 06:09:54,849 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41149'
2023-05-28 06:09:54,857 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40409'
2023-05-28 06:09:54,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41797'
2023-05-28 06:09:54,875 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45463'
2023-05-28 06:09:54,885 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41745'
2023-05-28 06:09:56,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3tcy8xny', purging
2023-05-28 06:09:56,514 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rtg90nb9', purging
2023-05-28 06:09:56,515 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__6126u8', purging
2023-05-28 06:09:56,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:56,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:56,520 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:56,520 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:56,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:56,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:56,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:56,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:56,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:56,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:56,569 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:56,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:56,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:56,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:56,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:09:56,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:09:57,097 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:57,106 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:57,107 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:57,112 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:57,115 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:57,119 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:57,127 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:09:57,127 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:02,085 - distributed.nanny - INFO - Worker process 26893 exited with status 127
2023-05-28 06:10:02,086 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:02,165 - distributed.nanny - INFO - Worker process 26888 exited with status 127
2023-05-28 06:10:02,166 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:02,192 - distributed.nanny - INFO - Worker process 26895 exited with status 127
2023-05-28 06:10:02,193 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:02,232 - distributed.nanny - INFO - Worker process 26901 exited with status 127
2023-05-28 06:10:02,233 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:02,288 - distributed.nanny - INFO - Worker process 26898 exited with status 127
2023-05-28 06:10:02,289 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:02,375 - distributed.nanny - INFO - Worker process 26880 exited with status 127
2023-05-28 06:10:02,376 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:02,538 - distributed.nanny - INFO - Worker process 26877 exited with status 127
2023-05-28 06:10:02,539 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:02,564 - distributed.nanny - INFO - Worker process 26884 exited with status 127
2023-05-28 06:10:02,565 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:03,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xf39ngqp', purging
2023-05-28 06:10:03,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7467iv8', purging
2023-05-28 06:10:03,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xcjny2nf', purging
2023-05-28 06:10:03,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0h9nflok', purging
2023-05-28 06:10:03,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fzksumqz', purging
2023-05-28 06:10:03,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gdxsk6al', purging
2023-05-28 06:10:03,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fimbdqy4', purging
2023-05-28 06:10:03,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3jpej5o4', purging
2023-05-28 06:10:03,780 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:03,780 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:03,805 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:03,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:03,863 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:03,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:03,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:03,892 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:03,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:03,946 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:03,995 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:03,995 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:04,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:04,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:04,068 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:04,096 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:04,096 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:04,121 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:04,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:04,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:04,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:04,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:04,324 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:04,377 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:04,749 - distributed.nanny - INFO - Worker process 26960 exited with status 127
2023-05-28 06:10:04,750 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:06,300 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e9lwtwqw', purging
2023-05-28 06:10:06,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:06,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:07,362 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:07,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38117'. Reason: nanny-close
2023-05-28 06:10:07,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35875'. Reason: nanny-close
2023-05-28 06:10:07,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34753'. Reason: nanny-close
2023-05-28 06:10:07,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41149'. Reason: nanny-close
2023-05-28 06:10:07,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40409'. Reason: nanny-close
2023-05-28 06:10:07,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41797'. Reason: nanny-close
2023-05-28 06:10:07,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45463'. Reason: nanny-close
2023-05-28 06:10:07,895 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41745'. Reason: nanny-close
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:08,175 - distributed.nanny - INFO - Worker process 26963 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:08,423 - distributed.nanny - INFO - Worker process 26975 exited with status 127
2023-05-28 06:10:08,446 - distributed.nanny - INFO - Worker process 26966 exited with status 127
2023-05-28 06:10:08,523 - distributed.nanny - INFO - Worker process 26969 exited with status 127
2023-05-28 06:10:08,625 - distributed.nanny - INFO - Worker process 26972 exited with status 127
2023-05-28 06:10:08,674 - distributed.nanny - INFO - Worker process 26978 exited with status 127
2023-05-28 06:10:08,723 - distributed.nanny - INFO - Worker process 26981 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:09,037 - distributed.nanny - INFO - Worker process 27019 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2023-05-28 06:10:39,920 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:10:39,924 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35923 instead
  warnings.warn(
2023-05-28 06:10:39,928 - distributed.scheduler - INFO - State start
2023-05-28 06:10:40,100 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:10:40,101 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:10:40,101 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:10:40,102 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-28 06:10:40,676 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43481'
2023-05-28 06:10:40,694 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41927'
2023-05-28 06:10:40,711 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38811'
2023-05-28 06:10:40,713 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39371'
2023-05-28 06:10:40,724 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37359'
2023-05-28 06:10:40,734 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34245'
2023-05-28 06:10:40,743 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39525'
2023-05-28 06:10:40,751 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38195'
2023-05-28 06:10:42,267 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5zxxsb93', purging
2023-05-28 06:10:42,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-biok3idd', purging
2023-05-28 06:10:42,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9ky4dx3', purging
2023-05-28 06:10:42,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8sqkgms8', purging
2023-05-28 06:10:42,268 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-44bwsi5w', purging
2023-05-28 06:10:42,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g3_0mxb3', purging
2023-05-28 06:10:42,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zxkmmytq', purging
2023-05-28 06:10:42,269 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3yhut9nf', purging
2023-05-28 06:10:42,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:42,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:42,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:42,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:42,405 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:42,405 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:42,431 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:42,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:42,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:42,527 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:42,568 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:42,568 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:42,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:42,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:42,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:42,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:43,065 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:43,068 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:43,079 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:43,085 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:43,095 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:43,105 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:43,255 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:43,261 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:47,293 - distributed.nanny - INFO - Worker process 27217 exited with status 127
2023-05-28 06:10:47,294 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:47,354 - distributed.nanny - INFO - Worker process 27235 exited with status 127
2023-05-28 06:10:47,354 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:47,379 - distributed.nanny - INFO - Worker process 27241 exited with status 127
2023-05-28 06:10:47,380 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:47,493 - distributed.nanny - INFO - Worker process 27238 exited with status 127
2023-05-28 06:10:47,494 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:47,520 - distributed.nanny - INFO - Worker process 27232 exited with status 127
2023-05-28 06:10:47,521 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:47,569 - distributed.nanny - INFO - Worker process 27228 exited with status 127
2023-05-28 06:10:47,570 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:47,613 - distributed.nanny - INFO - Worker process 27224 exited with status 127
2023-05-28 06:10:47,614 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:47,665 - distributed.nanny - INFO - Worker process 27220 exited with status 127
2023-05-28 06:10:47,666 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:48,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h9l27eea', purging
2023-05-28 06:10:48,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8fgzizg3', purging
2023-05-28 06:10:48,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-619g_6zd', purging
2023-05-28 06:10:48,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5d309yt7', purging
2023-05-28 06:10:48,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5pwwc5mp', purging
2023-05-28 06:10:48,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rc5wpj_c', purging
2023-05-28 06:10:48,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fhycciuj', purging
2023-05-28 06:10:48,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mbvqskgm', purging
2023-05-28 06:10:48,966 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:48,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:49,026 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:49,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:49,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:49,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:49,056 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:49,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:49,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:49,131 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:49,155 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:49,166 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:49,166 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:49,208 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:49,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:49,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:49,313 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:49,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:49,322 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:49,350 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:49,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:49,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:49,410 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:49,510 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:52,272 - distributed.nanny - INFO - Worker process 27302 exited with status 127
2023-05-28 06:10:52,274 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:52,309 - distributed.nanny - INFO - Worker process 27297 exited with status 127
2023-05-28 06:10:52,310 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:52,383 - distributed.nanny - INFO - Worker process 27312 exited with status 127
2023-05-28 06:10:52,384 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:52,485 - distributed.nanny - INFO - Worker process 27305 exited with status 127
2023-05-28 06:10:52,486 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:52,510 - distributed.nanny - INFO - Worker process 27315 exited with status 127
2023-05-28 06:10:52,510 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:52,547 - distributed.nanny - INFO - Worker process 27309 exited with status 127
2023-05-28 06:10:52,548 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:52,608 - distributed.nanny - INFO - Worker process 27321 exited with status 127
2023-05-28 06:10:52,609 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:53,839 - distributed.nanny - INFO - Worker process 27318 exited with status 127
2023-05-28 06:10:53,840 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:10:53,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zdjkyz_z', purging
2023-05-28 06:10:53,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3lkvapcn', purging
2023-05-28 06:10:53,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vteqjcof', purging
2023-05-28 06:10:53,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h6foor0e', purging
2023-05-28 06:10:53,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-47v551ws', purging
2023-05-28 06:10:53,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ne8vesmw', purging
2023-05-28 06:10:53,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-08xiij_7', purging
2023-05-28 06:10:53,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0jlruwp1', purging
2023-05-28 06:10:53,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:53,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:53,977 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:53,977 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:54,039 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:54,039 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:54,067 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:54,081 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:54,129 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:54,166 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:54,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:54,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:54,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:54,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:54,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:54,268 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:54,289 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:54,298 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43481'. Reason: nanny-close
2023-05-28 06:10:54,299 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41927'. Reason: nanny-close
2023-05-28 06:10:54,299 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38811'. Reason: nanny-close
2023-05-28 06:10:54,299 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39371'. Reason: nanny-close
2023-05-28 06:10:54,299 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37359'. Reason: nanny-close
2023-05-28 06:10:54,300 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34245'. Reason: nanny-close
2023-05-28 06:10:54,300 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39525'. Reason: nanny-close
2023-05-28 06:10:54,300 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38195'. Reason: nanny-close
2023-05-28 06:10:54,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:54,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:54,330 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:54,413 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:10:55,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:10:55,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:10:55,495 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:56,756 - distributed.nanny - INFO - Worker process 27381 exited with status 127
2023-05-28 06:10:56,779 - distributed.nanny - INFO - Worker process 27378 exited with status 127
2023-05-28 06:10:56,801 - distributed.nanny - INFO - Worker process 27389 exited with status 127
2023-05-28 06:10:56,824 - distributed.nanny - INFO - Worker process 27385 exited with status 127
2023-05-28 06:10:57,020 - distributed.nanny - INFO - Worker process 27398 exited with status 127
2023-05-28 06:10:57,041 - distributed.nanny - INFO - Worker process 27392 exited with status 127
2023-05-28 06:10:57,062 - distributed.nanny - INFO - Worker process 27395 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:10:57,208 - distributed.nanny - INFO - Worker process 27408 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2023-05-28 06:11:26,389 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:11:26,393 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45083 instead
  warnings.warn(
2023-05-28 06:11:26,397 - distributed.scheduler - INFO - State start
2023-05-28 06:11:26,487 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:11:26,488 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:11:26,489 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:11:26,489 - distributed.scheduler - INFO - End scheduler
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 536, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1849, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 3844, in start_unsafe
    await self.listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 719, in listen
    listener = await listen(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 213, in _
    await self.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 580, in start
    sockets = netutil.bind_sockets(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/netutil.py", line 162, in bind_sockets
    sock.bind(sockaddr)
OSError: [Errno 98] Address already in use

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/bin/dask", line 10, in <module>
    sys.exit(main())
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/__main__.py", line 5, in main
    run_cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask/cli.py", line 81, in run_cli
    cli()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 249, in main
    asyncio.run(run())
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in run
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 245, in <listcomp>
    [task.result() for task in done]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/cli/dask_scheduler.py", line 225, in wait_for_scheduler_to_finish
    await scheduler
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 544, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Scheduler failed to start.
2023-05-28 06:11:27,043 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38757'
2023-05-28 06:11:27,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43645'
2023-05-28 06:11:27,076 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42935'
2023-05-28 06:11:27,078 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40797'
2023-05-28 06:11:27,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45561'
2023-05-28 06:11:27,095 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33333'
2023-05-28 06:11:27,104 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37147'
2023-05-28 06:11:27,106 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36039'
2023-05-28 06:11:28,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2j_0wn7w', purging
2023-05-28 06:11:28,779 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h8qfxvo3', purging
2023-05-28 06:11:28,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bru02ys9', purging
2023-05-28 06:11:28,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-281qmscd', purging
2023-05-28 06:11:28,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aryo64j_', purging
2023-05-28 06:11:28,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xvt8dzs3', purging
2023-05-28 06:11:28,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-obtoj1mj', purging
2023-05-28 06:11:28,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fy8xa37z', purging
2023-05-28 06:11:28,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:28,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:28,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:28,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:28,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:28,800 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:28,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:28,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:28,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:28,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:28,841 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:28,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:28,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:28,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:28,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:28,867 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:28,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:29,024 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:29,026 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:29,700 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:29,884 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:29,893 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:29,895 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:29,903 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:11:34,571 - distributed.nanny - INFO - Worker process 27638 exited with status 127
2023-05-28 06:11:34,572 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:34,635 - distributed.nanny - INFO - Worker process 27648 exited with status 127
2023-05-28 06:11:34,636 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:11:34,747 - distributed.nanny - INFO - Worker process 27627 exited with status 127
2023-05-28 06:11:34,748 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:34,775 - distributed.nanny - INFO - Worker process 27634 exited with status 127
2023-05-28 06:11:34,776 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:34,815 - distributed.nanny - INFO - Worker process 27630 exited with status 127
2023-05-28 06:11:34,816 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:34,845 - distributed.nanny - INFO - Worker process 27651 exited with status 127
2023-05-28 06:11:34,846 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:34,878 - distributed.nanny - INFO - Worker process 27642 exited with status 127
2023-05-28 06:11:34,878 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:34,932 - distributed.nanny - INFO - Worker process 27646 exited with status 127
2023-05-28 06:11:34,933 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:36,199 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-urxgk_bn', purging
2023-05-28 06:11:36,199 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pk5s55wx', purging
2023-05-28 06:11:36,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u7ofh738', purging
2023-05-28 06:11:36,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1yfcdp_p', purging
2023-05-28 06:11:36,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-19uej0ac', purging
2023-05-28 06:11:36,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-skt3w51d', purging
2023-05-28 06:11:36,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7cie3am2', purging
2023-05-28 06:11:36,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t_263gny', purging
2023-05-28 06:11:36,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:36,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:36,288 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:36,288 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:36,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:36,392 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:36,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:36,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:36,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:36,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:36,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:36,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:36,501 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:36,501 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:36,594 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:36,594 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:36,722 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:36,744 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:36,745 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:36,749 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:36,750 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:36,751 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:36,753 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:36,757 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:11:39,322 - distributed.nanny - INFO - Worker process 27709 exited with status 127
2023-05-28 06:11:39,323 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:11:39,447 - distributed.nanny - INFO - Worker process 27728 exited with status 127
2023-05-28 06:11:39,448 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:39,510 - distributed.nanny - INFO - Worker process 27719 exited with status 127
2023-05-28 06:11:39,511 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:39,538 - distributed.nanny - INFO - Worker process 27725 exited with status 127
2023-05-28 06:11:39,539 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:39,565 - distributed.nanny - INFO - Worker process 27731 exited with status 127
2023-05-28 06:11:39,565 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:39,595 - distributed.nanny - INFO - Worker process 27722 exited with status 127
2023-05-28 06:11:39,596 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:39,628 - distributed.nanny - INFO - Worker process 27716 exited with status 127
2023-05-28 06:11:39,629 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:39,664 - distributed.nanny - INFO - Worker process 27712 exited with status 127
2023-05-28 06:11:39,665 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:11:40,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6vyyv723', purging
2023-05-28 06:11:40,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mwf1up36', purging
2023-05-28 06:11:40,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ovyhyhir', purging
2023-05-28 06:11:40,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y_sa3kx5', purging
2023-05-28 06:11:40,960 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rbn5s6_x', purging
2023-05-28 06:11:40,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eq3elo9n', purging
2023-05-28 06:11:40,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lx45okw1', purging
2023-05-28 06:11:40,961 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6uao5u92', purging
2023-05-28 06:11:40,962 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:40,962 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:41,096 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:41,096 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:41,161 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:41,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:41,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:41,212 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:41,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:41,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:41,227 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:41,227 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:41,298 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:41,298 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:41,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:41,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:41,327 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:11:41,327 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:11:41,338 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:41,353 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:41,363 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:41,428 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:41,445 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:41,473 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:11:41,774 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38757'. Reason: nanny-close
2023-05-28 06:11:41,775 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45561'. Reason: nanny-close
2023-05-28 06:11:41,775 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33333'. Reason: nanny-close
2023-05-28 06:11:41,775 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37147'. Reason: nanny-close
2023-05-28 06:11:41,775 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36039'. Reason: nanny-close
2023-05-28 06:11:41,775 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43645'. Reason: nanny-close
2023-05-28 06:11:41,775 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42935'. Reason: nanny-close
2023-05-28 06:11:41,776 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40797'. Reason: nanny-close
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:11:44,201 - distributed.nanny - INFO - Worker process 27793 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:11:44,262 - distributed.nanny - INFO - Worker process 27796 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:11:44,308 - distributed.nanny - INFO - Worker process 27786 exited with status 127
2023-05-28 06:11:44,368 - distributed.nanny - INFO - Worker process 27802 exited with status 127
2023-05-28 06:11:44,393 - distributed.nanny - INFO - Worker process 27805 exited with status 127
2023-05-28 06:11:44,441 - distributed.nanny - INFO - Worker process 27811 exited with status 127
2023-05-28 06:11:44,468 - distributed.nanny - INFO - Worker process 27808 exited with status 127
2023-05-28 06:11:45,758 - distributed.nanny - INFO - Worker process 27799 exited with status 127
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2023-05-28 06:12:13,538 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:12:13,542 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-28 06:12:13,545 - distributed.scheduler - INFO - State start
2023-05-28 06:12:13,563 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:12:13,564 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-28 06:12:13,564 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-28 06:12:13,585 - distributed.scheduler - INFO - Receive client connection: Client-95b24809-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:12:13,599 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48792
2023-05-28 06:12:13,634 - distributed.scheduler - INFO - Receive client connection: Client-96a05cb6-fd1e-11ed-a65f-d8c49764f6bb
2023-05-28 06:12:13,635 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:48812
2023-05-28 06:12:13,682 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33537'
2023-05-28 06:12:13,700 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38249'
2023-05-28 06:12:13,709 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39757'
2023-05-28 06:12:13,711 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43999'
2023-05-28 06:12:13,719 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42401'
2023-05-28 06:12:13,727 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36255'
2023-05-28 06:12:13,735 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34801'
2023-05-28 06:12:13,743 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36745'
2023-05-28 06:12:15,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iishniuw', purging
2023-05-28 06:12:15,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-19omnzhc', purging
2023-05-28 06:12:15,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6jy6rjuw', purging
2023-05-28 06:12:15,358 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qsi48ula', purging
2023-05-28 06:12:15,358 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-omhkopm2', purging
2023-05-28 06:12:15,358 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4e2ljrf0', purging
2023-05-28 06:12:15,359 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r8h26yie', purging
2023-05-28 06:12:15,359 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4frmvvue', purging
2023-05-28 06:12:15,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:15,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:15,384 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:15,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:15,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:15,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:15,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:15,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:15,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:15,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:15,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:15,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:15,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:15,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:15,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:15,439 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:15,440 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:15,441 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:15,443 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:15,446 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:15,451 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:15,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:15,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:15,506 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:17,379 - distributed.nanny - INFO - Worker process 28041 exited with status 127
2023-05-28 06:12:17,380 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:17,460 - distributed.nanny - INFO - Worker process 28049 exited with status 127
2023-05-28 06:12:17,461 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:17,483 - distributed.nanny - INFO - Worker process 28045 exited with status 127
2023-05-28 06:12:17,484 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:17,507 - distributed.nanny - INFO - Worker process 28056 exited with status 127
2023-05-28 06:12:17,508 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:17,563 - distributed.nanny - INFO - Worker process 28062 exited with status 127
2023-05-28 06:12:17,564 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:17,587 - distributed.nanny - INFO - Worker process 28054 exited with status 127
2023-05-28 06:12:17,588 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:17,630 - distributed.nanny - INFO - Worker process 28038 exited with status 127
2023-05-28 06:12:17,631 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:17,654 - distributed.nanny - INFO - Worker process 28059 exited with status 127
2023-05-28 06:12:17,655 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:18,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6aavcirp', purging
2023-05-28 06:12:18,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ienujry7', purging
2023-05-28 06:12:18,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-evp1tpsj', purging
2023-05-28 06:12:18,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mrki7q34', purging
2023-05-28 06:12:18,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x4ryhuh4', purging
2023-05-28 06:12:18,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7h4m156v', purging
2023-05-28 06:12:18,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m29j6vw_', purging
2023-05-28 06:12:18,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wbh4me13', purging
2023-05-28 06:12:18,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:18,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:18,919 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:19,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:19,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:19,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:19,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:19,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:19,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:19,163 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:19,163 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:19,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:19,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:19,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:19,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:19,183 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:19,217 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:19,218 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:19,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:19,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:19,256 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:19,256 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:19,297 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:19,298 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:19,386 - distributed.nanny - INFO - Worker process 28125 exited with status 127
2023-05-28 06:12:19,387 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:20,975 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iiucf5t4', purging
2023-05-28 06:12:20,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:20,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:21,209 - distributed.nanny - INFO - Worker process 28122 exited with status 127
2023-05-28 06:12:21,210 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:21,219 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:21,246 - distributed.nanny - INFO - Worker process 28117 exited with status 127
2023-05-28 06:12:21,247 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:21,285 - distributed.nanny - INFO - Worker process 28128 exited with status 127
2023-05-28 06:12:21,286 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:21,373 - distributed.nanny - INFO - Worker process 28136 exited with status 127
2023-05-28 06:12:21,374 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:21,422 - distributed.nanny - INFO - Worker process 28133 exited with status 127
2023-05-28 06:12:21,423 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:21,522 - distributed.nanny - INFO - Worker process 28142 exited with status 127
2023-05-28 06:12:21,523 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:21,559 - distributed.nanny - INFO - Worker process 28139 exited with status 127
2023-05-28 06:12:21,559 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:21,921 - distributed.nanny - INFO - Worker process 28180 exited with status 127
2023-05-28 06:12:21,922 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:22,865 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3jib3jii', purging
2023-05-28 06:12:22,865 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7jsuhysu', purging
2023-05-28 06:12:22,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r24j3ls1', purging
2023-05-28 06:12:22,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-444jujov', purging
2023-05-28 06:12:22,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c9ts80xr', purging
2023-05-28 06:12:22,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_j94ryr', purging
2023-05-28 06:12:22,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0mzn924', purging
2023-05-28 06:12:22,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-odnc489a', purging
2023-05-28 06:12:22,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:22,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:22,893 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:22,906 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:22,906 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:22,931 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:22,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:22,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:22,975 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:23,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:23,074 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:23,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:23,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:23,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:23,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:23,196 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:23,201 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:23,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:23,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:23,234 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:23,258 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:23,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:23,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:23,679 - distributed.scheduler - INFO - Remove client Client-96a05cb6-fd1e-11ed-a65f-d8c49764f6bb
2023-05-28 06:12:23,679 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48812; closing.
2023-05-28 06:12:23,680 - distributed.scheduler - INFO - Remove client Client-96a05cb6-fd1e-11ed-a65f-d8c49764f6bb
2023-05-28 06:12:23,680 - distributed.scheduler - INFO - Close client connection: Client-96a05cb6-fd1e-11ed-a65f-d8c49764f6bb
2023-05-28 06:12:23,760 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:24,178 - distributed.nanny - INFO - Worker process 28205 exited with status 127
2023-05-28 06:12:24,179 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:24,847 - distributed.nanny - INFO - Worker process 28208 exited with status 127
2023-05-28 06:12:24,848 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:25,236 - distributed.nanny - INFO - Worker process 28211 exited with status 127
2023-05-28 06:12:25,237 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:25,299 - distributed.nanny - INFO - Worker process 28215 exited with status 127
2023-05-28 06:12:25,300 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:25,349 - distributed.nanny - INFO - Worker process 28218 exited with status 127
2023-05-28 06:12:25,350 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:25,397 - distributed.nanny - INFO - Worker process 28224 exited with status 127
2023-05-28 06:12:25,398 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:25,440 - distributed.nanny - INFO - Worker process 28228 exited with status 127
2023-05-28 06:12:25,441 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:25,561 - distributed.nanny - INFO - Worker process 28235 exited with status 127
2023-05-28 06:12:25,562 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:25,785 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rbkj76dd', purging
2023-05-28 06:12:25,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-je0zsrfm', purging
2023-05-28 06:12:25,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6cit9w39', purging
2023-05-28 06:12:25,786 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7wutx69a', purging
2023-05-28 06:12:25,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzwrvvsx', purging
2023-05-28 06:12:25,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-688e99h1', purging
2023-05-28 06:12:25,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yjfuoqnh', purging
2023-05-28 06:12:25,788 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w4j0_58w', purging
2023-05-28 06:12:25,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:25,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:25,813 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:26,225 - distributed.nanny - INFO - Worker process 28278 exited with status 127
2023-05-28 06:12:26,226 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:26,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rczd7o9s', purging
2023-05-28 06:12:26,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:26,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:26,459 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:26,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:26,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:26,734 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:26,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:26,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:26,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:26,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:26,980 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:26,980 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:26,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:26,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:26,993 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:27,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:27,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:27,019 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:27,021 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:27,054 - distributed.nanny - INFO - Worker process 28287 exited with status 127
2023-05-28 06:12:27,055 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:27,061 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:27,074 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:27,438 - distributed.nanny - INFO - Worker process 28299 exited with status 127
2023-05-28 06:12:27,439 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:12:27,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-idu9zs0h', purging
2023-05-28 06:12:27,761 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9yr_dfu2', purging
2023-05-28 06:12:27,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:27,762 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:28,152 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:28,165 - distributed.scheduler - INFO - Remove client Client-95b24809-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:12:28,166 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:48792; closing.
2023-05-28 06:12:28,166 - distributed.scheduler - INFO - Remove client Client-95b24809-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:12:28,166 - distributed.scheduler - INFO - Close client connection: Client-95b24809-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:12:28,168 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43999'. Reason: nanny-close
2023-05-28 06:12:28,169 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42401'. Reason: nanny-close
2023-05-28 06:12:28,169 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33537'. Reason: nanny-close
2023-05-28 06:12:28,169 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38249'. Reason: nanny-close
2023-05-28 06:12:28,170 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39757'. Reason: nanny-close
2023-05-28 06:12:28,170 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36255'. Reason: nanny-close
2023-05-28 06:12:28,170 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34801'. Reason: nanny-close
2023-05-28 06:12:28,170 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36745'. Reason: nanny-close
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:28,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7deozgh4', purging
2023-05-28 06:12:28,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:28,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:28,499 - distributed.nanny - INFO - Worker process 28295 exited with status 127
2023-05-28 06:12:28,668 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:12:28,694 - distributed.nanny - INFO - Worker process 28303 exited with status 127
2023-05-28 06:12:28,717 - distributed.nanny - INFO - Worker process 28309 exited with status 127
2023-05-28 06:12:28,738 - distributed.nanny - INFO - Worker process 28306 exited with status 127
2023-05-28 06:12:28,766 - distributed.nanny - INFO - Worker process 28314 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:28,945 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2fius38y', purging
2023-05-28 06:12:28,945 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nau6edrh', purging
2023-05-28 06:12:28,946 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gbirg0tw', purging
2023-05-28 06:12:28,946 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ak4kysyr', purging
2023-05-28 06:12:28,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:12:28,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:12:29,056 - distributed.nanny - INFO - Worker process 28329 exited with status 127
2023-05-28 06:12:29,063 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:29,343 - distributed.nanny - INFO - Worker process 28357 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:12:29,483 - distributed.nanny - INFO - Worker process 28365 exited with status 127
2023-05-28 06:12:40,358 - distributed.scheduler - INFO - Receive client connection: Client-a68e0add-fd1e-11ed-a637-d8c49764f6bb
2023-05-28 06:12:40,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44408
2023-05-28 06:12:50,435 - distributed.scheduler - INFO - Remove client Client-a68e0add-fd1e-11ed-a637-d8c49764f6bb
2023-05-28 06:12:50,435 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:44408; closing.
2023-05-28 06:12:50,435 - distributed.scheduler - INFO - Remove client Client-a68e0add-fd1e-11ed-a637-d8c49764f6bb
2023-05-28 06:12:50,436 - distributed.scheduler - INFO - Close client connection: Client-a68e0add-fd1e-11ed-a637-d8c49764f6bb
2023-05-28 06:12:55,580 - distributed.scheduler - INFO - Receive client connection: Client-afa0c978-fd1e-11ed-a65f-d8c49764f6bb
2023-05-28 06:12:55,581 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47012
2023-05-28 06:12:58,200 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-28 06:12:58,200 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:12:58,201 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:12:58,202 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-28 06:12:58,203 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2023-05-28 06:13:00,285 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:13:00,288 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-28 06:13:00,291 - distributed.scheduler - INFO - State start
2023-05-28 06:13:00,309 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:13:00,309 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-28 06:13:00,310 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-28 06:13:00,396 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46129'
2023-05-28 06:13:01,036 - distributed.scheduler - INFO - Receive client connection: Client-b193faf8-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:13:01,047 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43370
2023-05-28 06:13:01,585 - distributed.scheduler - INFO - Receive client connection: Client-afa0c978-fd1e-11ed-a65f-d8c49764f6bb
2023-05-28 06:13:01,585 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:43390
2023-05-28 06:13:01,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q456yp7j', purging
2023-05-28 06:13:01,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v3k3qjpd', purging
2023-05-28 06:13:01,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m05cqddx', purging
2023-05-28 06:13:01,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:01,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:01,967 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:02,334 - distributed.nanny - INFO - Worker process 28568 exited with status 127
2023-05-28 06:13:02,335 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:03,663 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tdkh70en', purging
2023-05-28 06:13:03,663 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:03,663 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:03,921 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:04,297 - distributed.nanny - INFO - Worker process 28579 exited with status 127
2023-05-28 06:13:04,297 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:05,611 - distributed.scheduler - INFO - Remove client Client-afa0c978-fd1e-11ed-a65f-d8c49764f6bb
2023-05-28 06:13:05,611 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43390; closing.
2023-05-28 06:13:05,612 - distributed.scheduler - INFO - Remove client Client-afa0c978-fd1e-11ed-a65f-d8c49764f6bb
2023-05-28 06:13:05,612 - distributed.scheduler - INFO - Close client connection: Client-afa0c978-fd1e-11ed-a65f-d8c49764f6bb
2023-05-28 06:13:05,622 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9fv1azf', purging
2023-05-28 06:13:05,622 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:05,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:05,877 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:06,245 - distributed.nanny - INFO - Worker process 28589 exited with status 127
2023-05-28 06:13:06,246 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:07,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ocadhtx_', purging
2023-05-28 06:13:07,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:07,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:07,817 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:08,183 - distributed.nanny - INFO - Worker process 28599 exited with status 127
2023-05-28 06:13:08,183 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:09,499 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__ezj6i_', purging
2023-05-28 06:13:09,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:09,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:09,752 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:10,130 - distributed.nanny - INFO - Worker process 28609 exited with status 127
2023-05-28 06:13:10,131 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:11,071 - distributed.scheduler - INFO - Remove client Client-b193faf8-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:13:11,071 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:43370; closing.
2023-05-28 06:13:11,071 - distributed.scheduler - INFO - Remove client Client-b193faf8-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:13:11,072 - distributed.scheduler - INFO - Close client connection: Client-b193faf8-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:13:11,073 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46129'. Reason: nanny-close
2023-05-28 06:13:11,463 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nyt9t07z', purging
2023-05-28 06:13:11,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:11,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:11,720 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:12,091 - distributed.nanny - INFO - Worker process 28619 exited with status 127
2023-05-28 06:13:41,136 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-28 06:13:41,137 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:13:41,137 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:13:41,138 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-28 06:13:41,139 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2023-05-28 06:13:44,628 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:13:44,632 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-28 06:13:44,635 - distributed.scheduler - INFO - State start
2023-05-28 06:13:44,653 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:13:44,654 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-28 06:13:44,654 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-28 06:13:44,733 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46499'
2023-05-28 06:13:45,201 - distributed.scheduler - INFO - Receive client connection: Client-cc056c9e-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:13:45,217 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:33146
2023-05-28 06:13:46,094 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-esugt3cz', purging
2023-05-28 06:13:46,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:46,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:46,352 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:46,759 - distributed.nanny - INFO - Worker process 28877 exited with status 127
2023-05-28 06:13:46,760 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:48,115 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-562c847m', purging
2023-05-28 06:13:48,115 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:48,115 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:48,372 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:48,766 - distributed.nanny - INFO - Worker process 28888 exited with status 127
2023-05-28 06:13:48,768 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:50,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t9jltqs0', purging
2023-05-28 06:13:50,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:50,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:50,383 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:50,778 - distributed.nanny - INFO - Worker process 28898 exited with status 127
2023-05-28 06:13:50,779 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:52,155 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r58hvl2x', purging
2023-05-28 06:13:52,156 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:52,156 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:52,416 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:52,811 - distributed.nanny - INFO - Worker process 28908 exited with status 127
2023-05-28 06:13:52,812 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:54,181 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ve4ki5ds', purging
2023-05-28 06:13:54,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:54,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:54,443 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:54,838 - distributed.nanny - INFO - Worker process 28918 exited with status 127
2023-05-28 06:13:54,839 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:13:55,308 - distributed.scheduler - INFO - Remove client Client-cc056c9e-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:13:55,309 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:33146; closing.
2023-05-28 06:13:55,309 - distributed.scheduler - INFO - Remove client Client-cc056c9e-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:13:55,310 - distributed.scheduler - INFO - Close client connection: Client-cc056c9e-fd1e-11ed-a568-d8c49764f6bb
2023-05-28 06:13:55,311 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46499'. Reason: nanny-close
2023-05-28 06:13:56,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zhi79lg_', purging
2023-05-28 06:13:56,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:13:56,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:13:56,462 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:13:56,854 - distributed.nanny - INFO - Worker process 28928 exited with status 127
2023-05-28 06:14:25,327 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-28 06:14:25,327 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:14:25,328 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:14:25,329 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-28 06:14:25,329 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2023-05-28 06:14:27,505 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:14:27,509 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-28 06:14:27,512 - distributed.scheduler - INFO - State start
2023-05-28 06:14:27,531 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:14:27,532 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-28 06:14:27,532 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-28 06:32:09,876 - distributed.scheduler - INFO - Receive client connection: Client-5fa40886-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:32:09,889 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:38792
2023-05-28 06:32:25,937 - distributed.scheduler - INFO - Remove client Client-5fa40886-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:32:25,937 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:38792; closing.
2023-05-28 06:32:25,938 - distributed.scheduler - INFO - Remove client Client-5fa40886-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:32:25,938 - distributed.scheduler - INFO - Close client connection: Client-5fa40886-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:32:56,288 - distributed.scheduler - INFO - Receive client connection: Client-7b4e2e36-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:32:56,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:57304
2023-05-28 06:33:06,383 - distributed.scheduler - INFO - Remove client Client-7b4e2e36-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:33:06,383 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:57304; closing.
2023-05-28 06:33:06,383 - distributed.scheduler - INFO - Remove client Client-7b4e2e36-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:33:06,384 - distributed.scheduler - INFO - Close client connection: Client-7b4e2e36-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:33:36,745 - distributed.scheduler - INFO - Receive client connection: Client-936b6d75-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:33:36,746 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:49006
2023-05-28 06:33:46,783 - distributed.scheduler - INFO - Remove client Client-936b6d75-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:33:46,783 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:49006; closing.
2023-05-28 06:33:46,784 - distributed.scheduler - INFO - Remove client Client-936b6d75-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:33:46,784 - distributed.scheduler - INFO - Close client connection: Client-936b6d75-fd21-11ed-a65f-d8c49764f6bb
2023-05-28 06:35:08,064 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-28 06:35:08,064 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:35:08,065 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:35:08,066 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-28 06:35:08,067 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2023-05-28 06:35:10,042 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:35:10,046 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-28 06:35:10,049 - distributed.scheduler - INFO - State start
2023-05-28 06:35:10,072 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:35:10,073 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2023-05-28 06:35:10,073 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-28 06:35:10,650 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43397'
2023-05-28 06:35:12,049 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pox6okbr', purging
2023-05-28 06:35:12,050 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:12,050 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:12,056 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:35:12,345 - distributed.scheduler - INFO - Receive client connection: Client-ca1fb11f-fd21-11ed-a568-d8c49764f6bb
2023-05-28 06:35:12,356 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55678
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:35:13,594 - distributed.nanny - INFO - Worker process 35052 exited with status 127
2023-05-28 06:35:13,595 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:35:15,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_spwn2is', purging
2023-05-28 06:35:15,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:15,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:15,041 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:35:16,038 - distributed.nanny - INFO - Worker process 35063 exited with status 127
2023-05-28 06:35:16,039 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:35:17,418 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v1y6vn3t', purging
2023-05-28 06:35:17,419 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:17,419 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:17,425 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:35:18,609 - distributed.nanny - INFO - Worker process 35073 exited with status 127
2023-05-28 06:35:18,610 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:35:20,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2gwnnw52', purging
2023-05-28 06:35:20,075 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:20,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:20,082 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:35:21,426 - distributed.nanny - INFO - Worker process 35083 exited with status 127
2023-05-28 06:35:21,427 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:35:22,380 - distributed.scheduler - INFO - Remove client Client-ca1fb11f-fd21-11ed-a568-d8c49764f6bb
2023-05-28 06:35:22,380 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55678; closing.
2023-05-28 06:35:22,381 - distributed.scheduler - INFO - Remove client Client-ca1fb11f-fd21-11ed-a568-d8c49764f6bb
2023-05-28 06:35:22,382 - distributed.scheduler - INFO - Close client connection: Client-ca1fb11f-fd21-11ed-a568-d8c49764f6bb
2023-05-28 06:35:22,382 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43397'. Reason: nanny-close
2023-05-28 06:35:22,887 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-njk11ssu', purging
2023-05-28 06:35:22,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:22,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:22,895 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:35:23,853 - distributed.nanny - INFO - Worker process 35093 exited with status 127
2023-05-28 06:35:52,547 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-28 06:35:52,548 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:35:52,548 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:35:52,549 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2023-05-28 06:35:52,550 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2023-05-28 06:35:54,815 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:35:54,818 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-28 06:35:54,821 - distributed.scheduler - INFO - State start
2023-05-28 06:35:55,335 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:35:55,336 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-28 06:35:55,337 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-28 06:35:55,549 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36133'
2023-05-28 06:35:55,566 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37037'
2023-05-28 06:35:55,575 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40211'
2023-05-28 06:35:55,577 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33107'
2023-05-28 06:35:55,584 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34781'
2023-05-28 06:35:55,593 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41223'
2023-05-28 06:35:55,600 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41475'
2023-05-28 06:35:55,609 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45187'
2023-05-28 06:35:55,626 - distributed.scheduler - INFO - Receive client connection: Client-e4d5c6de-fd21-11ed-a568-d8c49764f6bb
2023-05-28 06:35:55,642 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39762
2023-05-28 06:35:57,237 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6e8g2vfr', purging
2023-05-28 06:35:57,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:57,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:57,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:57,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:57,246 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:57,247 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:57,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:57,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:57,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:57,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:57,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:57,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:57,308 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:57,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:57,326 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:35:57,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:35:57,364 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:35:57,366 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:35:57,371 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:35:57,372 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:35:57,373 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:35:57,373 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:35:57,374 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:35:57,376 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:00,783 - distributed.nanny - INFO - Worker process 35285 exited with status 127
2023-05-28 06:36:00,784 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:00,983 - distributed.nanny - INFO - Worker process 35277 exited with status 127
2023-05-28 06:36:00,984 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:01,006 - distributed.nanny - INFO - Worker process 35292 exited with status 127
2023-05-28 06:36:01,007 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:01,212 - distributed.nanny - INFO - Worker process 35273 exited with status 127
2023-05-28 06:36:01,213 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:01,265 - distributed.nanny - INFO - Worker process 35281 exited with status 127
2023-05-28 06:36:01,266 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:01,455 - distributed.nanny - INFO - Worker process 35294 exited with status 127
2023-05-28 06:36:01,456 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:01,555 - distributed.nanny - INFO - Worker process 35288 exited with status 127
2023-05-28 06:36:01,556 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:01,769 - distributed.nanny - INFO - Worker process 35270 exited with status 127
2023-05-28 06:36:01,770 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:02,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9aj5hbev', purging
2023-05-28 06:36:02,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-npcey81s', purging
2023-05-28 06:36:02,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j3nimkxv', purging
2023-05-28 06:36:02,404 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iics21_h', purging
2023-05-28 06:36:02,404 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wg_ch8jh', purging
2023-05-28 06:36:02,404 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dkkj8krp', purging
2023-05-28 06:36:02,405 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nnihoaeg', purging
2023-05-28 06:36:02,405 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o_i61h4h', purging
2023-05-28 06:36:02,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:02,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:02,488 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:02,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:02,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:02,636 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:02,636 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:02,759 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:02,760 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:02,921 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gmvsjbm4', purging
2023-05-28 06:36:02,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:02,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:02,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:02,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:03,082 - distributed.nanny - INFO - Worker process 35354 exited with status 127
2023-05-28 06:36:03,083 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:03,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:03,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:03,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:03,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:03,289 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:03,291 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:03,306 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:03,316 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:03,412 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:03,412 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:03,472 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:03,667 - distributed.nanny - INFO - Worker process 35360 exited with status 127
2023-05-28 06:36:03,668 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:04,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k9lk5atv', purging
2023-05-28 06:36:04,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:04,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:05,026 - distributed.nanny - INFO - Worker process 35357 exited with status 127
2023-05-28 06:36:05,026 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:05,039 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:05,260 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1h2y8ayh', purging
2023-05-28 06:36:05,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:05,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:05,536 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:05,905 - distributed.nanny - INFO - Worker process 35363 exited with status 127
2023-05-28 06:36:05,906 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:06,594 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lbdx_8w5', purging
2023-05-28 06:36:06,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:06,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:07,474 - distributed.nanny - INFO - Worker process 35378 exited with status 127
2023-05-28 06:36:07,475 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:07,492 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3_rw7gf1', purging
2023-05-28 06:36:07,492 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7m53ddqj', purging
2023-05-28 06:36:07,492 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2wv8_qk', purging
2023-05-28 06:36:07,493 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qf_pk9cw', purging
2023-05-28 06:36:07,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:07,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:07,502 - distributed.nanny - INFO - Worker process 35370 exited with status 127
2023-05-28 06:36:07,503 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:07,560 - distributed.nanny - INFO - Worker process 35366 exited with status 127
2023-05-28 06:36:07,561 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:07,605 - distributed.nanny - INFO - Worker process 35373 exited with status 127
2023-05-28 06:36:07,606 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:07,624 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:07,660 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:08,412 - distributed.nanny - INFO - Worker process 35404 exited with status 127
2023-05-28 06:36:08,413 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:09,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t16itcmb', purging
2023-05-28 06:36:09,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qip9f1km', purging
2023-05-28 06:36:09,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:09,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:09,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:09,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:09,140 - distributed.nanny - INFO - Worker process 35422 exited with status 127
2023-05-28 06:36:09,140 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:09,188 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:09,189 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:09,262 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:09,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:09,268 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:09,268 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:09,350 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:09,351 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:09,534 - distributed.nanny - INFO - Worker process 35438 exited with status 127
2023-05-28 06:36:09,534 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:09,603 - distributed.nanny - INFO - Worker process 35451 exited with status 127
2023-05-28 06:36:09,604 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:10,043 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rjdn_298', purging
2023-05-28 06:36:10,043 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8iz04qjn', purging
2023-05-28 06:36:10,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:10,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:10,110 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:10,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:10,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:10,906 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:11,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:11,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:11,233 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:11,251 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:11,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:11,288 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:36:11,737 - distributed.scheduler - INFO - Remove client Client-e4d5c6de-fd21-11ed-a568-d8c49764f6bb
2023-05-28 06:36:11,737 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39762; closing.
2023-05-28 06:36:11,738 - distributed.scheduler - INFO - Remove client Client-e4d5c6de-fd21-11ed-a568-d8c49764f6bb
2023-05-28 06:36:11,739 - distributed.scheduler - INFO - Close client connection: Client-e4d5c6de-fd21-11ed-a568-d8c49764f6bb
2023-05-28 06:36:11,739 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33107'. Reason: nanny-close
2023-05-28 06:36:11,740 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34781'. Reason: nanny-close
2023-05-28 06:36:11,740 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36133'. Reason: nanny-close
2023-05-28 06:36:11,740 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37037'. Reason: nanny-close
2023-05-28 06:36:11,741 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40211'. Reason: nanny-close
2023-05-28 06:36:11,741 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41223'. Reason: nanny-close
2023-05-28 06:36:11,741 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41475'. Reason: nanny-close
2023-05-28 06:36:11,741 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45187'. Reason: nanny-close
2023-05-28 06:36:12,609 - distributed.nanny - INFO - Worker process 35461 exited with status 127
2023-05-28 06:36:12,645 - distributed.nanny - INFO - Worker process 35465 exited with status 127
2023-05-28 06:36:12,667 - distributed.nanny - INFO - Worker process 35471 exited with status 127
2023-05-28 06:36:12,702 - distributed.nanny - INFO - Worker process 35468 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:13,692 - distributed.nanny - INFO - Worker process 35485 exited with status 127
2023-05-28 06:36:14,153 - distributed.nanny - INFO - Worker process 35494 exited with status 127
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:14,406 - distributed.nanny - INFO - Worker process 35509 exited with status 127
2023-05-28 06:36:14,451 - distributed.nanny - INFO - Worker process 35512 exited with status 127
2023-05-28 06:36:42,104 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-28 06:36:42,104 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:36:42,105 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:36:42,106 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-28 06:36:42,106 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2023-05-28 06:36:44,304 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:36:44,308 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-28 06:36:44,311 - distributed.scheduler - INFO - State start
2023-05-28 06:36:44,343 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:36:44,344 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-28 06:36:44,344 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-28 06:36:44,444 - distributed.scheduler - INFO - Receive client connection: Client-024f3ac1-fd22-11ed-a568-d8c49764f6bb
2023-05-28 06:36:44,456 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45580
2023-05-28 06:36:44,772 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36887'
2023-05-28 06:36:46,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vpqhhgba', purging
2023-05-28 06:36:46,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mvzk4vq4', purging
2023-05-28 06:36:46,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sf0zvmnz', purging
2023-05-28 06:36:46,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7n389co2', purging
2023-05-28 06:36:46,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b90kvg6w', purging
2023-05-28 06:36:46,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0tv38rr8', purging
2023-05-28 06:36:46,222 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hxowz8ma', purging
2023-05-28 06:36:46,223 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cv4uxo8i', purging
2023-05-28 06:36:46,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:46,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:46,297 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:47,847 - distributed.nanny - INFO - Worker process 35722 exited with status 127
2023-05-28 06:36:47,848 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:49,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-17m__27m', purging
2023-05-28 06:36:49,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:49,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:49,310 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:50,463 - distributed.nanny - INFO - Worker process 35732 exited with status 127
2023-05-28 06:36:50,464 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:51,884 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rojfy2vk', purging
2023-05-28 06:36:51,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:51,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:51,964 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:53,393 - distributed.nanny - INFO - Worker process 35742 exited with status 127
2023-05-28 06:36:53,394 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:36:54,484 - distributed.scheduler - INFO - Remove client Client-024f3ac1-fd22-11ed-a568-d8c49764f6bb
2023-05-28 06:36:54,485 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45580; closing.
2023-05-28 06:36:54,486 - distributed.scheduler - INFO - Remove client Client-024f3ac1-fd22-11ed-a568-d8c49764f6bb
2023-05-28 06:36:54,487 - distributed.scheduler - INFO - Close client connection: Client-024f3ac1-fd22-11ed-a568-d8c49764f6bb
2023-05-28 06:36:54,487 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36887'. Reason: nanny-close
2023-05-28 06:36:54,872 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_sfi5azf', purging
2023-05-28 06:36:54,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:36:54,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:36:54,991 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:36:56,156 - distributed.nanny - INFO - Worker process 35752 exited with status 127
2023-05-28 06:37:24,519 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-28 06:37:24,520 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:37:24,521 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:37:24,522 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-28 06:37:24,522 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2023-05-28 06:37:26,970 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:37:26,975 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2023-05-28 06:37:26,978 - distributed.scheduler - INFO - State start
2023-05-28 06:37:27,044 - distributed.scheduler - INFO - -----------------------------------------------
2023-05-28 06:37:27,045 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2023-05-28 06:37:27,046 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2023-05-28 06:37:27,223 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38021'
2023-05-28 06:37:27,986 - distributed.scheduler - INFO - Receive client connection: Client-1ba9bdba-fd22-11ed-a568-d8c49764f6bb
2023-05-28 06:37:28,000 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:51720
2023-05-28 06:37:28,621 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8utt3cix', purging
2023-05-28 06:37:28,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:37:28,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:37:28,793 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:37:30,235 - distributed.nanny - INFO - Worker process 35929 exited with status 127
2023-05-28 06:37:30,236 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:37:31,645 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u8d973ti', purging
2023-05-28 06:37:31,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:37:31,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:37:31,736 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:37:32,649 - distributed.nanny - INFO - Worker process 35940 exited with status 127
2023-05-28 06:37:32,650 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:37:34,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cvajjqbl', purging
2023-05-28 06:37:34,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:37:34,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:37:34,234 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:37:35,795 - distributed.nanny - INFO - Worker process 35950 exited with status 127
2023-05-28 06:37:35,796 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:37:37,205 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j5wqxicd', purging
2023-05-28 06:37:37,206 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:37:37,206 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:37:37,250 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-05-28 06:37:38,014 - distributed.scheduler - INFO - Remove client Client-1ba9bdba-fd22-11ed-a568-d8c49764f6bb
2023-05-28 06:37:38,015 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:51720; closing.
2023-05-28 06:37:38,015 - distributed.scheduler - INFO - Remove client Client-1ba9bdba-fd22-11ed-a568-d8c49764f6bb
2023-05-28 06:37:38,017 - distributed.scheduler - INFO - Close client connection: Client-1ba9bdba-fd22-11ed-a568-d8c49764f6bb
2023-05-28 06:37:38,017 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38021'. Reason: nanny-close
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:37:38,440 - distributed.nanny - INFO - Worker process 35960 exited with status 127
2023-05-28 06:38:08,051 - distributed._signals - INFO - Received signal SIGINT (2)
2023-05-28 06:38:08,051 - distributed.scheduler - INFO - Scheduler closing...
2023-05-28 06:38:08,052 - distributed.scheduler - INFO - Scheduler closing all comms
2023-05-28 06:38:08,053 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2023-05-28 06:38:08,054 - distributed.scheduler - INFO - End scheduler
FAILED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default 2023-05-28 06:38:17,888 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i_sxwlaz', purging
2023-05-28 06:38:17,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:17,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:17,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:17,889 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:17,896 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:17,896 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:17,915 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:17,915 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:17,918 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:17,918 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:17,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:17,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:17,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:17,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:17,970 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:17,970 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:20,427 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:20,461 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:21,724 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:21,749 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:21,942 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:21,955 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ejfs7lzi', purging
2023-05-28 06:38:21,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e0_o7b4a', purging
2023-05-28 06:38:21,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aaf_0nn2', purging
2023-05-28 06:38:21,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_i387tml', purging
2023-05-28 06:38:21,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cweecnp3', purging
2023-05-28 06:38:21,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0svm6zzk', purging
2023-05-28 06:38:21,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6e2f01sn', purging
2023-05-28 06:38:21,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_t15tm_e', purging
2023-05-28 06:38:21,958 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:21,958 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:21,963 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:21,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:21,975 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:22,017 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:22,043 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:23,336 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:23,346 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2fp6qtq3', purging
2023-05-28 06:38:23,346 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f7tq8bvt', purging
2023-05-28 06:38:23,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:23,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:23,363 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:23,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:23,386 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:23,569 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:23,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:23,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:23,579 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:23,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:23,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:23,654 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:23,654 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:24,065 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:24,909 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:24,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h0vlmo1b', purging
2023-05-28 06:38:24,970 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tykpdvvu', purging
2023-05-28 06:38:24,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:24,971 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:24,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:24,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:25,381 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:25,456 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:25,536 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:25,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4za5u7wb', purging
2023-05-28 06:38:25,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m0yxi63c', purging
2023-05-28 06:38:25,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l066uavm', purging
2023-05-28 06:38:25,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:25,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:26,513 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:26,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:26,954 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ycn1nvji', purging
2023-05-28 06:38:26,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:26,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:27,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:27,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:27,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:27,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:27,282 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:28,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0_tk4k9w', purging
2023-05-28 06:38:28,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vywe8b5w', purging
2023-05-28 06:38:28,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:28,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:28,948 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:28,979 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:29,481 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:29,693 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:29,720 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:29,747 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:29,784 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:29,932 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:30,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9s16v_00', purging
2023-05-28 06:38:30,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_8ew3h1v', purging
2023-05-28 06:38:30,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dtpqyfi7', purging
2023-05-28 06:38:30,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-65dfkqtu', purging
2023-05-28 06:38:30,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zswmj24b', purging
2023-05-28 06:38:30,567 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ycra67sb', purging
2023-05-28 06:38:30,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:30,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:30,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:30,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:31,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:31,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:31,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:31,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:31,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:31,394 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:31,473 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:31,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:31,490 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:31,490 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:31,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:31,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:34,384 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:34,477 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:34,557 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:34,981 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:35,006 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:35,033 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:35,059 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:35,117 - distributed.nanny - WARNING - Restarting worker
2023-05-28 06:38:35,986 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lcq4y22l', purging
2023-05-28 06:38:35,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8248ou6', purging
2023-05-28 06:38:35,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8oso2eq1', purging
2023-05-28 06:38:35,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ke6ei8oa', purging
2023-05-28 06:38:35,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ca0c57au', purging
2023-05-28 06:38:35,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hpls_y07', purging
2023-05-28 06:38:35,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mme_n0s9', purging
2023-05-28 06:38:35,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v9tb52um', purging
2023-05-28 06:38:35,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:35,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:36,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:36,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:36,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:36,201 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:36,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:36,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:36,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:36,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:36,713 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:36,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:36,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:36,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-28 06:38:36,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-28 06:38:36,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:37,645 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python3.9: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-28 06:38:38,843 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 150 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
