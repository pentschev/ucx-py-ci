2023-05-29 06:58:31,223 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6yx1ivc3', purging
2023-05-29 06:58:31,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y2onw8cu', purging
2023-05-29 06:58:31,224 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:31,224 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:31,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:31,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:31,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:31,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:31,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:31,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:31,371 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:31,371 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:31,372 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:31,372 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:31,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:31,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:31,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:31,438 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:33,424 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:33,451 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:33,521 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:33,546 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:33,566 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:33,618 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:33,620 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:33,788 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:34,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:34,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oz9jsw16', purging
2023-05-29 06:58:34,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:34,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qfv19hbi', purging
2023-05-29 06:58:34,970 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1fv_rpf3', purging
2023-05-29 06:58:34,970 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qq4ehzy7', purging
2023-05-29 06:58:34,971 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1aouuboq', purging
2023-05-29 06:58:34,971 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r50sf6j_', purging
2023-05-29 06:58:34,971 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tulqanel', purging
2023-05-29 06:58:34,972 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n2ekljwp', purging
2023-05-29 06:58:34,972 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:34,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:35,026 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:35,026 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:35,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:35,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:35,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:35,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:35,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:35,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:35,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:35,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:35,195 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:35,195 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:37,171 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:37,232 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:37,262 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:37,285 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:37,310 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:37,338 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:37,371 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:37,541 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:38,725 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mgje8zh5', purging
2023-05-29 06:58:38,725 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fuyentzz', purging
2023-05-29 06:58:38,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fah9w9l1', purging
2023-05-29 06:58:38,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_jv699vf', purging
2023-05-29 06:58:38,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijyqvv7r', purging
2023-05-29 06:58:38,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-buvy0v2s', purging
2023-05-29 06:58:38,727 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7lve3hh_', purging
2023-05-29 06:58:38,728 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hi8ks8fe', purging
2023-05-29 06:58:38,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:38,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:38,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:38,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:38,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:38,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:38,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:38,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:38,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:38,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:38,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:38,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:38,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:38,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:39,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:39,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:40,935 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:41,003 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:41,032 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:41,052 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:41,078 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:41,101 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:41,127 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:41,296 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:42,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-knmbfjai', purging
2023-05-29 06:58:42,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t0nyv37f', purging
2023-05-29 06:58:42,438 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fc5xxf0m', purging
2023-05-29 06:58:42,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jpf24clk', purging
2023-05-29 06:58:42,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t4sjpx5x', purging
2023-05-29 06:58:42,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xqc9of3c', purging
2023-05-29 06:58:42,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4xcx8r70', purging
2023-05-29 06:58:42,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a5mnafll', purging
2023-05-29 06:58:42,440 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:42,440 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:42,480 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:42,480 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:42,541 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:42,541 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:42,601 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:42,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:42,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:42,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:42,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:42,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:42,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:42,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:42,713 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:42,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:44,642 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:44,671 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:44,697 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:44,727 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:44,758 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:44,783 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:44,807 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:44,964 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:46,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9ry5o9i', purging
2023-05-29 06:58:46,193 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lp3v4h1e', purging
2023-05-29 06:58:46,193 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p0hd4fo7', purging
2023-05-29 06:58:46,193 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b02v_0eh', purging
2023-05-29 06:58:46,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mq6_6xrc', purging
2023-05-29 06:58:46,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gnnziqwx', purging
2023-05-29 06:58:46,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-km3qx9p6', purging
2023-05-29 06:58:46,194 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-slogv15h', purging
2023-05-29 06:58:46,195 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:46,195 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:46,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:46,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:46,205 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:46,205 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:46,234 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:46,234 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:46,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:46,302 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:46,302 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:46,302 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:46,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:46,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:46,442 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:46,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:48,372 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:48,394 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:48,454 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:48,480 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:48,506 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:48,529 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:48,554 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:48,717 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:49,829 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03ybcb4f', purging
2023-05-29 06:58:49,830 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1h3dox1d', purging
2023-05-29 06:58:49,830 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4vmh2sql', purging
2023-05-29 06:58:49,830 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xq173ppj', purging
2023-05-29 06:58:49,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cy422sko', purging
2023-05-29 06:58:49,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qbfcjkbd', purging
2023-05-29 06:58:49,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03u3o6x8', purging
2023-05-29 06:58:49,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p24du368', purging
2023-05-29 06:58:49,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:49,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:49,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:49,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:49,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:49,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:50,005 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:50,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:50,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:50,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:50,050 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:50,050 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:50,068 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:50,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:50,218 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:50,218 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:52,102 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:52,178 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:52,205 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:52,229 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:52,256 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:52,281 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:52,307 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:52,455 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:53,624 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:53,624 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yms3r_mp', purging
2023-05-29 06:58:53,624 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:53,624 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x15knkjv', purging
2023-05-29 06:58:53,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijtt7tvc', purging
2023-05-29 06:58:53,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ac85rmq6', purging
2023-05-29 06:58:53,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jwg58rr6', purging
2023-05-29 06:58:53,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psp72f5v', purging
2023-05-29 06:58:53,626 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iu1pocjb', purging
2023-05-29 06:58:53,627 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_e_qgdoc', purging
2023-05-29 06:58:53,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:53,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:53,684 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:53,684 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:53,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:53,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:53,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:53,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:53,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:53,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:53,830 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:53,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:53,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:53,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:55,799 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:55,873 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:55,899 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:55,925 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:55,950 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:55,984 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:56,009 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:56,169 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:57,304 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-txgxtnsu', purging
2023-05-29 06:58:57,304 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z_pc3ioc', purging
2023-05-29 06:58:57,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eb1ehjn2', purging
2023-05-29 06:58:57,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j1f32xwh', purging
2023-05-29 06:58:57,305 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_xf7996o', purging
2023-05-29 06:58:57,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-elyr6mmz', purging
2023-05-29 06:58:57,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kn_waw4_', purging
2023-05-29 06:58:57,306 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4j61u55o', purging
2023-05-29 06:58:57,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:57,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:57,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:57,401 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:57,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:57,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:57,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:57,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:57,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:57,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:57,495 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:57,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:57,507 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:57,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:58:57,660 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:58:57,660 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:58:59,503 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:59,578 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:59,692 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:59,693 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:59,704 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:59,713 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:59,722 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:58:59,853 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:01,056 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jtx_mb3l', purging
2023-05-29 06:59:01,056 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qhpkg_dl', purging
2023-05-29 06:59:01,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijxk44kp', purging
2023-05-29 06:59:01,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5b_9_mga', purging
2023-05-29 06:59:01,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ir6g367', purging
2023-05-29 06:59:01,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sap0k9sl', purging
2023-05-29 06:59:01,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i78_vbjv', purging
2023-05-29 06:59:01,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tzax5g_o', purging
2023-05-29 06:59:01,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:01,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:01,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:01,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:01,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:01,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:01,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:01,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:01,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:01,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:01,276 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:01,276 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:01,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:01,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:01,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:01,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:03,259 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:03,335 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:03,359 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:03,382 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:03,407 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:03,428 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:03,452 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:03,620 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:04,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fqjks09t', purging
2023-05-29 06:59:04,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lvfx1vme', purging
2023-05-29 06:59:04,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0s9pozlk', purging
2023-05-29 06:59:04,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ayezofn', purging
2023-05-29 06:59:04,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4eeec4y0', purging
2023-05-29 06:59:04,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-en_e386o', purging
2023-05-29 06:59:04,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4xvnh1lh', purging
2023-05-29 06:59:04,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dilecek3', purging
2023-05-29 06:59:04,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:04,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:04,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:04,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:04,884 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:04,884 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:04,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:04,903 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:04,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:04,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:04,979 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:04,979 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:05,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:05,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:05,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:05,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:06,975 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:06,998 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:07,060 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:07,085 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:07,129 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:07,131 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:07,155 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:07,322 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:08,472 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nxrdwyt1', purging
2023-05-29 06:59:08,473 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7_lejxpk', purging
2023-05-29 06:59:08,473 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b27iuepu', purging
2023-05-29 06:59:08,474 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i5zvzxns', purging
2023-05-29 06:59:08,474 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b52noszj', purging
2023-05-29 06:59:08,475 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_mgs_mae', purging
2023-05-29 06:59:08,475 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jgu8408b', purging
2023-05-29 06:59:08,475 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-so9c3tea', purging
2023-05-29 06:59:08,476 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:08,476 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:08,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:08,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:08,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:08,609 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:08,674 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:08,674 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:08,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:08,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:08,692 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:08,692 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:08,729 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:08,729 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:08,855 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:08,855 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:10,709 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:10,779 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:10,807 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:10,829 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:10,856 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:10,882 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:10,918 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:11,071 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:12,231 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ay4gggl', purging
2023-05-29 06:59:12,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cdq6_9an', purging
2023-05-29 06:59:12,232 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4532zmpx', purging
2023-05-29 06:59:12,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jjlltqdd', purging
2023-05-29 06:59:12,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8mjviouj', purging
2023-05-29 06:59:12,233 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fjbdxx8p', purging
2023-05-29 06:59:12,234 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pg6cymrb', purging
2023-05-29 06:59:12,234 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wr178a5d', purging
2023-05-29 06:59:12,235 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:12,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:12,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:12,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:12,311 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:12,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:12,367 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:12,367 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:12,415 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:12,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:12,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:12,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:12,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:12,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:12,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:12,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:14,437 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:14,470 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:14,502 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:14,526 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:14,554 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:14,576 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:14,602 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:14,777 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:15,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3fgur7wf', purging
2023-05-29 06:59:15,948 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r4usii_0', purging
2023-05-29 06:59:15,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yocwoo5y', purging
2023-05-29 06:59:15,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_qf5a2pm', purging
2023-05-29 06:59:15,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xe6c1fqd', purging
2023-05-29 06:59:15,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0twlfvxd', purging
2023-05-29 06:59:15,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8d73ii0v', purging
2023-05-29 06:59:15,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6h4e53y3', purging
2023-05-29 06:59:15,951 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:15,951 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:15,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:15,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:15,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:15,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:15,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:15,991 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:16,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:16,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:16,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:16,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:16,156 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:16,156 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:16,295 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:16,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:18,152 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:18,208 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:18,234 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:18,264 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:18,291 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:18,316 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:18,341 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:18,500 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:19,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gvhjem_a', purging
2023-05-29 06:59:19,695 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rdnk0p7d', purging
2023-05-29 06:59:19,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g988_rh8', purging
2023-05-29 06:59:19,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hov5hovg', purging
2023-05-29 06:59:19,696 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jh7srz_j', purging
2023-05-29 06:59:19,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mgc30it5', purging
2023-05-29 06:59:19,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k70twy_8', purging
2023-05-29 06:59:19,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qcsdfn3o', purging
2023-05-29 06:59:19,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:19,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:19,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:19,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:19,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:19,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:19,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:19,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:19,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:19,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:19,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:19,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:19,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:19,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:20,044 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:20,044 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:21,936 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:21,958 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:21,987 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:22,009 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:22,031 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:22,052 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:22,079 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:22,245 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:23,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2r8b4xht', purging
2023-05-29 06:59:23,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ixhce829', purging
2023-05-29 06:59:23,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4u04y_q3', purging
2023-05-29 06:59:23,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9r2w61f7', purging
2023-05-29 06:59:23,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y3abk5hs', purging
2023-05-29 06:59:23,462 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-943beezw', purging
2023-05-29 06:59:23,462 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t6n9de9s', purging
2023-05-29 06:59:23,462 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pq3ks_ae', purging
2023-05-29 06:59:23,463 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:23,463 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:23,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:23,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:23,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:23,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:23,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:23,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:23,539 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:23,540 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:23,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:23,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:23,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:23,632 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:23,787 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:23,787 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:25,654 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:25,730 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:25,751 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:25,771 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:25,800 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:25,827 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:25,852 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:26,000 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:27,159 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kk1i83b4', purging
2023-05-29 06:59:27,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-scztnz2h', purging
2023-05-29 06:59:27,160 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6c3tyji0', purging
2023-05-29 06:59:27,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-onqurfxg', purging
2023-05-29 06:59:27,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y_wwr5gt', purging
2023-05-29 06:59:27,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmoj57e6', purging
2023-05-29 06:59:27,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v6ubn3el', purging
2023-05-29 06:59:27,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8f3suvh9', purging
2023-05-29 06:59:27,163 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:27,163 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:27,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:27,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:27,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:27,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:27,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:27,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:27,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:27,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:27,390 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:27,391 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:27,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:27,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:27,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:27,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:29,366 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:29,394 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:29,449 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:29,475 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:29,500 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:29,521 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:29,559 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:29,707 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:30,765 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x7d9nprl', purging
2023-05-29 06:59:30,765 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8mqtpm1t', purging
2023-05-29 06:59:30,765 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-39hhdr31', purging
2023-05-29 06:59:30,766 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kpwav1mj', purging
2023-05-29 06:59:30,766 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24bauvfe', purging
2023-05-29 06:59:30,767 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7803nqv', purging
2023-05-29 06:59:30,767 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j10_sjst', purging
2023-05-29 06:59:30,767 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-il_snr63', purging
2023-05-29 06:59:30,768 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:30,768 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:30,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:30,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:30,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:30,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:31,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:31,020 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:31,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:31,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:31,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:31,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:31,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:31,121 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:31,159 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:31,159 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:32,980 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:33,012 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:33,050 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:33,081 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:33,124 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:33,146 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:33,177 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:33,332 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:34,523 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zibtfy9a', purging
2023-05-29 06:59:34,524 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ywjwo4mf', purging
2023-05-29 06:59:34,524 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ecqxnds9', purging
2023-05-29 06:59:34,524 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vyozg58j', purging
2023-05-29 06:59:34,524 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x9802inb', purging
2023-05-29 06:59:34,525 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-czc7q501', purging
2023-05-29 06:59:34,525 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q_53hxax', purging
2023-05-29 06:59:34,525 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fk1uktap', purging
2023-05-29 06:59:34,526 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:34,526 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:34,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:34,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:34,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:34,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:34,630 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:34,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:34,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:34,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:34,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:34,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:34,734 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:34,734 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:34,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:34,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:36,743 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:36,808 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:36,837 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:36,861 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:36,885 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:36,913 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:36,947 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:37,121 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:38,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v8g4sptp', purging
2023-05-29 06:59:38,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-htqngbjh', purging
2023-05-29 06:59:38,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cld81r4t', purging
2023-05-29 06:59:38,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wmiahzwk', purging
2023-05-29 06:59:38,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bts31n58', purging
2023-05-29 06:59:38,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kcb10pna', purging
2023-05-29 06:59:38,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xao1cfh9', purging
2023-05-29 06:59:38,297 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g4ln3_3u', purging
2023-05-29 06:59:38,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:38,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:38,323 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:38,323 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:38,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:38,374 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:38,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:38,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:38,391 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:38,391 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:38,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:38,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:38,472 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:38,472 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:38,632 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:38,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:40,485 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:40,550 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:40,579 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:40,653 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:40,654 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:40,666 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:40,692 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:40,858 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:41,956 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ordmzglo', purging
2023-05-29 06:59:41,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jvair7_5', purging
2023-05-29 06:59:41,957 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d_qxqk0h', purging
2023-05-29 06:59:41,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w8vyungv', purging
2023-05-29 06:59:41,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1yry5pqb', purging
2023-05-29 06:59:41,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fl5nfgpe', purging
2023-05-29 06:59:41,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-plukes61', purging
2023-05-29 06:59:41,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eet_p0i9', purging
2023-05-29 06:59:41,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:41,959 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:42,092 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:42,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:42,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:42,151 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:42,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:42,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:42,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:42,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:42,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:42,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:42,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:42,243 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:42,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:42,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:44,124 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:44,176 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:44,223 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:44,283 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:44,310 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:44,333 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:44,361 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:44,576 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:45,577 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5rptvnmy', purging
2023-05-29 06:59:45,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gl_p5jix', purging
2023-05-29 06:59:45,578 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u1nnv81m', purging
2023-05-29 06:59:45,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-masyt_s0', purging
2023-05-29 06:59:45,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2128fj7x', purging
2023-05-29 06:59:45,579 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z8zis1m5', purging
2023-05-29 06:59:45,580 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ow5mekuk', purging
2023-05-29 06:59:45,580 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-76cbv3jl', purging
2023-05-29 06:59:45,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:45,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:45,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:45,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:45,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:45,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:45,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:45,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:45,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:45,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:45,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:45,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:45,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:45,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:46,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:46,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:47,734 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:47,772 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:47,824 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:47,856 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:47,876 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:47,907 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:47,935 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:48,191 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:49,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y6qxyq1p', purging
2023-05-29 06:59:49,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z_r12v3l', purging
2023-05-29 06:59:49,226 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e5g2cc6p', purging
2023-05-29 06:59:49,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v9gkh4er', purging
2023-05-29 06:59:49,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-46s78x3w', purging
2023-05-29 06:59:49,227 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pwecduu5', purging
2023-05-29 06:59:49,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_kiiggfq', purging
2023-05-29 06:59:49,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oyqlhj7b', purging
2023-05-29 06:59:49,228 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:49,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:49,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:49,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:49,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:49,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:49,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:49,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:49,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:49,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:49,464 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:49,464 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:49,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:49,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:49,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:49,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:51,435 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:51,458 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:51,513 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:51,542 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:51,570 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:51,623 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:51,625 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:51,883 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:52,949 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-njfqeygi', purging
2023-05-29 06:59:52,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oxgijd3z', purging
2023-05-29 06:59:52,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5i3o57g5', purging
2023-05-29 06:59:52,950 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hrmpo6b_', purging
2023-05-29 06:59:52,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w3x2gqag', purging
2023-05-29 06:59:52,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3sub6dn_', purging
2023-05-29 06:59:52,951 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uuv1h_hm', purging
2023-05-29 06:59:52,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q3lnf8ez', purging
2023-05-29 06:59:52,952 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:52,952 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:52,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:52,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:52,986 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:52,986 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:53,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:53,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:53,155 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:53,156 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:53,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:53,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:53,200 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:53,200 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:53,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:53,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:55,185 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:55,261 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:55,284 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:55,313 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:55,339 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:55,378 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:55,415 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:55,650 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:56,630 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-arepy816', purging
2023-05-29 06:59:56,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d45hei1_', purging
2023-05-29 06:59:56,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-71jglhnp', purging
2023-05-29 06:59:56,631 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-roc3zefz', purging
2023-05-29 06:59:56,632 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gidfwayn', purging
2023-05-29 06:59:56,632 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1xz94r__', purging
2023-05-29 06:59:56,632 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ub9gwsdc', purging
2023-05-29 06:59:56,632 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h8ua57gt', purging
2023-05-29 06:59:56,633 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:56,633 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:56,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:56,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:56,842 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:56,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:56,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:56,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:56,919 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:56,919 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:56,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:56,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:56,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:56,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 06:59:57,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 06:59:57,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:58,625 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:58,840 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:58,872 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:58,910 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:58,950 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:58,991 - distributed.nanny - WARNING - Restarting worker
2023-05-29 06:59:59,037 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 06:59:59,296 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:00,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ga273978', purging
2023-05-29 07:00:00,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jdlo6da9', purging
2023-05-29 07:00:00,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iuthlst4', purging
2023-05-29 07:00:00,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dlasf4tg', purging
2023-05-29 07:00:00,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n81vqgaa', purging
2023-05-29 07:00:00,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iipe018k', purging
2023-05-29 07:00:00,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9px5eped', purging
2023-05-29 07:00:00,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9h6fv4ek', purging
2023-05-29 07:00:00,125 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:00,125 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:00,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:00,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:00,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:00,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:00,434 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:00,434 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:00,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:00,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:00,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:00,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:00,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:00,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:00,802 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:00,802 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:02,177 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:02,203 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:02,514 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:02,546 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:02,609 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:02,634 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:02,670 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:02,830 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:03,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oh76es8i', purging
2023-05-29 07:00:03,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-atbo_wy7', purging
2023-05-29 07:00:03,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ifqhsetk', purging
2023-05-29 07:00:03,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1fhegyim', purging
2023-05-29 07:00:03,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pib4x37z', purging
2023-05-29 07:00:03,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ymz9fnf_', purging
2023-05-29 07:00:03,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w15rnx5i', purging
2023-05-29 07:00:03,772 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fi0j6lmu', purging
2023-05-29 07:00:03,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:03,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:03,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:03,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:04,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:04,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:04,099 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:04,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:04,149 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:04,149 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:04,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:04,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:04,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:04,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:04,361 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:04,361 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:05,312 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:05,344 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:05,384 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:06,132 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:06,177 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:06,225 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:06,268 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:06,435 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:06,811 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-asyasvvv', purging
2023-05-29 07:00:06,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wmu_r3z5', purging
2023-05-29 07:00:06,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e6jhxe9k', purging
2023-05-29 07:00:06,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rcw_q0uu', purging
2023-05-29 07:00:06,813 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4u5cadfz', purging
2023-05-29 07:00:06,813 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6m1umwmo', purging
2023-05-29 07:00:06,813 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ft7si5di', purging
2023-05-29 07:00:06,813 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0c9xt1f2', purging
2023-05-29 07:00:06,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:06,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:06,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:06,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:06,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:06,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:07,642 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:07,642 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:07,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:07,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:07,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:07,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:07,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:07,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:07,971 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:07,972 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:08,063 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:08,745 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:08,773 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:09,230 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:09,269 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:09,293 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:09,321 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:09,529 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k5zcuxrb', purging
2023-05-29 07:00:09,529 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-96fp_ymw', purging
2023-05-29 07:00:09,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iva65x2e', purging
2023-05-29 07:00:09,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fny34zgs', purging
2023-05-29 07:00:09,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w1jdkxj8', purging
2023-05-29 07:00:09,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v9zlikq0', purging
2023-05-29 07:00:09,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vf79i5cr', purging
2023-05-29 07:00:09,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:09,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:09,578 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:10,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ypgfnxaj', purging
2023-05-29 07:00:10,171 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:10,171 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:10,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:10,310 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:10,370 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:10,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oaqiirsf', purging
2023-05-29 07:00:10,708 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:10,708 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:10,773 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:10,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:10,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:10,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:10,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:10,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:11,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:11,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:11,850 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3wqx3by4', purging
2023-05-29 07:00:11,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:11,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:11,958 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:11,989 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:12,487 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:12,542 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:12,575 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:12,597 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:12,849 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:13,099 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:13,570 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-94r3q_w6', purging
2023-05-29 07:00:13,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3_0sjg0a', purging
2023-05-29 07:00:13,571 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vbik_mgw', purging
2023-05-29 07:00:13,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ec5gksq2', purging
2023-05-29 07:00:13,572 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pb7sw8uw', purging
2023-05-29 07:00:13,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tp3zdcnn', purging
2023-05-29 07:00:13,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-llrbterc', purging
2023-05-29 07:00:13,574 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:13,574 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:13,586 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:13,586 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:13,966 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:13,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:14,066 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:14,066 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:14,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:14,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:14,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:14,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:14,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:14,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:14,639 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:14,639 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:15,218 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:15,250 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:15,741 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:15,964 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:15,991 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:16,021 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:16,093 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:16,329 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:16,711 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2_hge6ca', purging
2023-05-29 07:00:16,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rldhxy43', purging
2023-05-29 07:00:16,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5tvztneo', purging
2023-05-29 07:00:16,712 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l8426if2', purging
2023-05-29 07:00:16,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-emc3qcl6', purging
2023-05-29 07:00:16,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5_y_ecy7', purging
2023-05-29 07:00:16,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3_p2ybew', purging
2023-05-29 07:00:16,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jizxxzd2', purging
2023-05-29 07:00:16,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:16,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:16,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:16,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:17,209 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:17,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:17,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:17,448 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:17,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:17,512 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:17,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:17,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:17,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:17,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:17,799 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:17,805 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-43zshvuq', purging
2023-05-29 07:00:17,806 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mhu9hvi2', purging
2023-05-29 07:00:17,807 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:17,807 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:17,827 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:18,569 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:19,132 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:19,201 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:19,228 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:19,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nr35jzou', purging
2023-05-29 07:00:19,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t6zfzq_4', purging
2023-05-29 07:00:19,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yn83gjnh', purging
2023-05-29 07:00:19,295 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i5vvvqfi', purging
2023-05-29 07:00:19,296 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gn7fpjvh', purging
2023-05-29 07:00:19,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:19,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:19,297 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:19,336 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:19,336 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:19,507 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:20,045 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7yjqfxv5', purging
2023-05-29 07:00:20,046 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:20,046 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:20,490 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:20,521 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:20,655 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ctbigdrd', purging
2023-05-29 07:00:20,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1qfc3rm8', purging
2023-05-29 07:00:20,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:20,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:20,726 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rpufmgba', purging
2023-05-29 07:00:20,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:20,727 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:20,752 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:20,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:20,767 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:20,840 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:20,840 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:20,984 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:20,984 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:21,987 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:21,987 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:22,004 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:22,004 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:22,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:22,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:22,396 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:22,461 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:22,638 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:22,674 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:22,690 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:23,268 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:23,296 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:23,477 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:23,900 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x131gatz', purging
2023-05-29 07:00:23,900 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6toys2cm', purging
2023-05-29 07:00:23,900 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hh7n9fxk', purging
2023-05-29 07:00:23,901 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kt0_u3uq', purging
2023-05-29 07:00:23,901 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-09agqz42', purging
2023-05-29 07:00:23,901 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b6c48_g9', purging
2023-05-29 07:00:23,901 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rc99ciyo', purging
2023-05-29 07:00:23,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gsfkzlcw', purging
2023-05-29 07:00:23,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:23,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:23,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:23,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:24,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:24,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:24,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:24,230 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:24,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:24,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:24,757 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:24,757 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:24,802 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:24,802 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:24,973 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:24,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:25,461 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:25,489 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:25,834 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:26,221 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:26,245 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:26,443 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:26,489 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:26,674 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:27,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s39m7r5t', purging
2023-05-29 07:00:27,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3y8bwvmp', purging
2023-05-29 07:00:27,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3vgl67ek', purging
2023-05-29 07:00:27,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5qryw7qz', purging
2023-05-29 07:00:27,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-25vo9m8k', purging
2023-05-29 07:00:27,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-10z_mnfc', purging
2023-05-29 07:00:27,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2pqpp2rr', purging
2023-05-29 07:00:27,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9mdm1lz7', purging
2023-05-29 07:00:27,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:27,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:27,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:27,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:27,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:27,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:27,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:27,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:27,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:27,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:28,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:28,023 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:28,057 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:28,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:28,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:28,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:28,356 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:28,382 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:29,019 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-29 07:00:29,702 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:29,703 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-29 07:00:29,825 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k7422man', purging
2023-05-29 07:00:29,825 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6njm2hra', purging
2023-05-29 07:00:29,826 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vpc5kwsb', purging
2023-05-29 07:00:29,826 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m8ysfvck', purging
2023-05-29 07:00:29,826 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xk_ou00x', purging
2023-05-29 07:00:29,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e3hjm9xb', purging
2023-05-29 07:00:29,827 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8hv3l8vv', purging
2023-05-29 07:00:29,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:29,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:29,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3xqpbhm3', purging
2023-05-29 07:00:29,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:29,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:29,860 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:30,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:30,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:30,971 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:30,995 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:31,147 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cwvphatj', purging
2023-05-29 07:00:31,148 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0vc5bg2y', purging
2023-05-29 07:00:31,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:31,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:31,192 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-boh5ir7o', purging
2023-05-29 07:00:31,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:31,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:31,220 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:31,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:31,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:32,332 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:32,353 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:32,424 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-16jt5ea9', purging
2023-05-29 07:00:32,425 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b_5x1o84', purging
2023-05-29 07:00:32,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:32,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:32,453 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:32,453 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:32,536 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:32,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oxf7whry', purging
2023-05-29 07:00:32,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:32,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:33,523 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:33,547 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:33,725 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:33,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mi7t9u6a', purging
2023-05-29 07:00:33,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-24vjli_t', purging
2023-05-29 07:00:33,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_2ut1k65', purging
2023-05-29 07:00:33,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:33,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:33,801 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:33,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:34,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:34,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:34,865 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:34,893 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:35,007 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ci25x2ae', purging
2023-05-29 07:00:35,007 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3k4m7i3t', purging
2023-05-29 07:00:35,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:35,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:35,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:35,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:35,065 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:35,191 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7tk51q8m', purging
2023-05-29 07:00:35,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:35,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:36,089 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:36,128 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:36,283 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:36,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1nzmi4s7', purging
2023-05-29 07:00:36,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j4g3qu52', purging
2023-05-29 07:00:36,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m6tzg4x8', purging
2023-05-29 07:00:36,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:36,320 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:36,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:36,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:36,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:36,528 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:37,435 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:37,457 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:37,524 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1bsfufvo', purging
2023-05-29 07:00:37,524 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6tuvszw2', purging
2023-05-29 07:00:37,525 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:37,525 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:37,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:37,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:37,638 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:37,741 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g5zasayz', purging
2023-05-29 07:00:37,741 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:37,741 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:38,661 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:38,704 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:38,859 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h2h9n33e', purging
2023-05-29 07:00:38,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w91kpqv2', purging
2023-05-29 07:00:38,860 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hbxw2tqn', purging
2023-05-29 07:00:38,860 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:38,860 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:38,870 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:38,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:38,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:39,106 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:39,106 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:39,976 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:40,003 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:40,146 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-16_jt2vv', purging
2023-05-29 07:00:40,147 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hsc_1rl6', purging
2023-05-29 07:00:40,147 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7zbt6yz_', purging
2023-05-29 07:00:40,148 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:40,148 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:40,176 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:40,193 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:40,193 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:40,316 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:40,316 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:41,302 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:41,328 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:41,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2xyrl5ec', purging
2023-05-29 07:00:41,398 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1jwusk0n', purging
2023-05-29 07:00:41,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:41,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:41,438 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:41,438 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:41,499 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:41,598 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pvsy0gn9', purging
2023-05-29 07:00:41,599 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:41,599 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:42,526 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-29 07:00:42,706 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:42,811 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kml1f_7p', purging
2023-05-29 07:00:42,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5_krvydc', purging
2023-05-29 07:00:42,812 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qdmjzq1a', purging
2023-05-29 07:00:42,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:42,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:42,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:42,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:42,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:42,942 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:43,926 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:43,953 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:43,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tfpke_m9', purging
2023-05-29 07:00:43,993 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s9ozrevn', purging
2023-05-29 07:00:43,994 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:43,994 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:44,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:44,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:44,153 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:44,950 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:45,121 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:45,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gm7sl0ye', purging
2023-05-29 07:00:45,342 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lja_uwuw', purging
2023-05-29 07:00:45,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8iygmrgi', purging
2023-05-29 07:00:45,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:45,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:45,388 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:45,388 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:45,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:45,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:46,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:46,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:46,404 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:46,447 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:46,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uy5u1dlq', purging
2023-05-29 07:00:46,597 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hru29594', purging
2023-05-29 07:00:46,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:46,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:46,631 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:47,418 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:47,592 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:47,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1b0u6vn5', purging
2023-05-29 07:00:47,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-39m0ahbs', purging
2023-05-29 07:00:47,853 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u6i4gutb', purging
2023-05-29 07:00:47,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:47,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:47,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:47,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:48,100 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:48,100 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:48,832 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:48,832 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:48,941 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:48,968 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:49,016 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vqg53hse', purging
2023-05-29 07:00:49,017 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rp355fdp', purging
2023-05-29 07:00:49,017 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:49,017 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:49,167 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:49,943 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:50,110 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:50,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-urdbc5ew', purging
2023-05-29 07:00:50,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9hg7agpa', purging
2023-05-29 07:00:50,338 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dj9pwl9p', purging
2023-05-29 07:00:50,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:50,338 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:50,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:50,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:50,609 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:50,610 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:51,338 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:51,375 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:51,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fqkfxbuy', purging
2023-05-29 07:00:51,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n9754k2v', purging
2023-05-29 07:00:51,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:51,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:51,514 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:51,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:51,624 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:52,417 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:52,578 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:52,775 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x_9o6_pb', purging
2023-05-29 07:00:52,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_nmkdef0', purging
2023-05-29 07:00:52,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5bfyainf', purging
2023-05-29 07:00:52,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:52,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:52,821 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:52,821 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:53,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:53,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:53,814 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:53,814 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:53,875 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:53,900 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:54,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j7n1pscm', purging
2023-05-29 07:00:54,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6i1qz4oo', purging
2023-05-29 07:00:54,011 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:54,011 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:54,096 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:54,883 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:55,047 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:55,293 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zgzonz87', purging
2023-05-29 07:00:55,293 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kk7q59nt', purging
2023-05-29 07:00:55,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ugy5rkji', purging
2023-05-29 07:00:55,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:55,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:55,334 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:55,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:55,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:55,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:56,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:56,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:56,364 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:56,399 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:56,518 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xxd7kw5w', purging
2023-05-29 07:00:56,519 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pejty202', purging
2023-05-29 07:00:56,519 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:56,519 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:56,601 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:57,392 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:57,557 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:57,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mcy9gj5m', purging
2023-05-29 07:00:57,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ak4xgux', purging
2023-05-29 07:00:57,784 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-79cdks5u', purging
2023-05-29 07:00:57,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:57,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:57,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:57,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:58,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:58,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:58,822 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:58,822 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:58,868 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:58,893 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:58,987 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zznx066v', purging
2023-05-29 07:00:58,988 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b5eacnmf', purging
2023-05-29 07:00:58,988 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:00:58,988 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:00:59,094 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:00:59,826 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:00:59,982 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:00,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9aej9dq_', purging
2023-05-29 07:01:00,281 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-za9ug0wt', purging
2023-05-29 07:01:00,282 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x1ot5shp', purging
2023-05-29 07:01:00,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:00,282 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:00,285 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:00,285 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:00,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:00,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:01,261 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:01,261 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:01,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wz0lv6uc', purging
2023-05-29 07:01:01,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:01,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:01,447 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:01,482 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:01,645 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:01,952 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:02,235 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:02,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hsw8j2r6', purging
2023-05-29 07:01:02,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w7adoh0h', purging
2023-05-29 07:01:02,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s0la582k', purging
2023-05-29 07:01:02,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0vld3w48', purging
2023-05-29 07:01:02,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:02,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:02,882 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:02,882 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:03,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:03,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:03,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:03,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:03,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:03,655 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:04,132 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:04,160 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:04,313 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:04,491 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:04,650 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:05,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hmnzsj9y', purging
2023-05-29 07:01:05,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7aarwtyh', purging
2023-05-29 07:01:05,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q7iiyr6l', purging
2023-05-29 07:01:05,505 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fu4fk3l8', purging
2023-05-29 07:01:05,505 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sr2_slsq', purging
2023-05-29 07:01:05,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:05,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:05,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:05,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:05,750 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:05,750 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:05,950 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:05,950 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:06,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:06,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:06,928 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:06,954 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:06,996 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:07,182 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:07,362 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:08,401 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9dluvxqa', purging
2023-05-29 07:01:08,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i0zg8wj6', purging
2023-05-29 07:01:08,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1pagamc', purging
2023-05-29 07:01:08,402 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gseid356', purging
2023-05-29 07:01:08,403 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-im34252r', purging
2023-05-29 07:01:08,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:08,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:08,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:08,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:08,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:08,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:08,656 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:08,656 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:08,712 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:08,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:09,905 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:09,929 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:09,967 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:09,995 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:10,151 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:11,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6hv8relw', purging
2023-05-29 07:01:11,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7g4kgmwe', purging
2023-05-29 07:01:11,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_g8uoj3', purging
2023-05-29 07:01:11,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aglslrij', purging
2023-05-29 07:01:11,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6agi_cps', purging
2023-05-29 07:01:11,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:11,374 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:11,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:11,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:11,377 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:11,377 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:11,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:11,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:11,524 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:11,524 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:12,886 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:12,908 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:12,938 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:12,957 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:13,114 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:14,298 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hp6v442n', purging
2023-05-29 07:01:14,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7c2hd6oe', purging
2023-05-29 07:01:14,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p66y1sce', purging
2023-05-29 07:01:14,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mcpq2uq7', purging
2023-05-29 07:01:14,299 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ir4y671w', purging
2023-05-29 07:01:14,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:14,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:14,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:14,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:14,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:14,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:14,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:14,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:14,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:14,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:15,818 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:15,872 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:15,895 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:15,920 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:16,092 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:17,278 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-257ib_m9', purging
2023-05-29 07:01:17,278 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-obvjn7xg', purging
2023-05-29 07:01:17,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gclr2zie', purging
2023-05-29 07:01:17,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qdvl32fq', purging
2023-05-29 07:01:17,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n4r7_2oy', purging
2023-05-29 07:01:17,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:17,280 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:17,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:17,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:17,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:17,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:17,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:17,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:17,544 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:17,544 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:18,796 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:18,824 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:18,859 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:18,888 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:19,048 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:20,264 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s5itr6mo', purging
2023-05-29 07:01:20,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-59e5e4lb', purging
2023-05-29 07:01:20,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nnq0tpfx', purging
2023-05-29 07:01:20,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u2381zot', purging
2023-05-29 07:01:20,266 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2n707wig', purging
2023-05-29 07:01:20,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:20,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:20,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:20,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:20,310 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:20,311 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:20,356 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:20,356 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:20,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:20,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:21,758 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:21,798 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:21,827 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:21,861 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:22,022 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:23,203 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ftce1dy4', purging
2023-05-29 07:01:23,203 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zielwu8b', purging
2023-05-29 07:01:23,203 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-upr3szkl', purging
2023-05-29 07:01:23,204 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-58a3tpd8', purging
2023-05-29 07:01:23,204 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_woa64tg', purging
2023-05-29 07:01:23,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:23,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:23,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:23,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:23,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:23,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:23,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:23,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:23,408 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:23,408 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:24,704 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:24,755 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:24,780 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:24,802 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:24,961 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:26,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b4jlfp5g', purging
2023-05-29 07:01:26,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qvqhruxp', purging
2023-05-29 07:01:26,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7fjy4bxd', purging
2023-05-29 07:01:26,186 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-osnjojln', purging
2023-05-29 07:01:26,187 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sfuxf72e', purging
2023-05-29 07:01:26,187 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:26,187 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:26,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:26,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:26,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:26,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:26,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:26,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:26,330 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:26,330 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:27,738 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:27,763 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:27,797 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:27,826 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:27,987 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:29,210 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2syrb0ry', purging
2023-05-29 07:01:29,210 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vwr8b7po', purging
2023-05-29 07:01:29,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c7r2lw8a', purging
2023-05-29 07:01:29,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_u3_755u', purging
2023-05-29 07:01:29,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kg6rr866', purging
2023-05-29 07:01:29,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:29,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:29,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:29,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:29,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:29,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:29,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:29,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:29,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:29,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:30,697 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:30,750 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:30,775 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:30,798 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:30,960 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:32,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5zfdwvw', purging
2023-05-29 07:01:32,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pwre7yfn', purging
2023-05-29 07:01:32,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8zcn3he7', purging
2023-05-29 07:01:32,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_3uqcrat', purging
2023-05-29 07:01:32,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lv5jn31b', purging
2023-05-29 07:01:32,145 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:32,145 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:32,146 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:32,146 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:32,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:32,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:32,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:32,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:32,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:32,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:33,649 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:33,693 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:33,726 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:33,749 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:33,901 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:35,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2wvch7fx', purging
2023-05-29 07:01:35,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5plex8t7', purging
2023-05-29 07:01:35,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j0dgb627', purging
2023-05-29 07:01:35,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o7q98wi_', purging
2023-05-29 07:01:35,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6z6_zfoq', purging
2023-05-29 07:01:35,114 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:35,114 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:35,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:35,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:35,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:35,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:35,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:35,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:35,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:35,270 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:36,622 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:36,673 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:36,686 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:36,710 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:36,880 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:38,071 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ljws8n55', purging
2023-05-29 07:01:38,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qkc4ins3', purging
2023-05-29 07:01:38,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gkriq2tg', purging
2023-05-29 07:01:38,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gyk26chv', purging
2023-05-29 07:01:38,072 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tn0q7kym', purging
2023-05-29 07:01:38,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:38,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:38,119 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:38,119 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:38,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:38,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:38,198 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:38,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:38,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:38,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:39,602 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:39,622 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-29 07:01:39,696 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:39,839 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:41,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uen1v0_u', purging
2023-05-29 07:01:41,000 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ka4kp_ql', purging
2023-05-29 07:01:41,001 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aznfnmlw', purging
2023-05-29 07:01:41,001 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mgzzp5rx', purging
2023-05-29 07:01:41,001 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a0i5a7ya', purging
2023-05-29 07:01:41,002 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:41,002 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:41,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:41,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:41,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:41,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:41,232 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:41,232 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:42,237 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:42,283 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:42,305 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:42,473 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:43,697 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_vzwuas5', purging
2023-05-29 07:01:43,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-27f5llla', purging
2023-05-29 07:01:43,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d958s2j7', purging
2023-05-29 07:01:43,698 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7b1m47ah', purging
2023-05-29 07:01:43,699 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:43,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:43,711 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:43,711 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:43,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:43,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:43,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:43,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:44,958 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:45,006 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:45,027 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:45,186 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:46,392 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-437bqnd2', purging
2023-05-29 07:01:46,393 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ntt624jo', purging
2023-05-29 07:01:46,393 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mc5h7hjb', purging
2023-05-29 07:01:46,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-he33iw6u', purging
2023-05-29 07:01:46,395 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:46,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:46,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:46,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:46,446 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:46,446 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:46,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:46,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:47,678 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:47,724 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:47,747 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:47,903 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:49,110 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rx7ldmsi', purging
2023-05-29 07:01:49,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mlunb3xq', purging
2023-05-29 07:01:49,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nq14529a', purging
2023-05-29 07:01:49,111 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ul34xcd', purging
2023-05-29 07:01:49,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:49,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:49,134 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:49,134 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:49,159 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:49,159 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:49,354 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:49,354 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:50,395 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:50,442 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:50,465 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:50,640 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:51,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-42wko8cq', purging
2023-05-29 07:01:51,780 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_bm2s_ej', purging
2023-05-29 07:01:51,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a26yi3vd', purging
2023-05-29 07:01:51,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ej0crq5a', purging
2023-05-29 07:01:51,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:51,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:51,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:51,826 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:51,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:51,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:52,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:52,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:53,079 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:53,104 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:53,138 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:53,299 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:54,486 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zu0pnwkc', purging
2023-05-29 07:01:54,486 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-suxs2wvx', purging
2023-05-29 07:01:54,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fvi5nzmp', purging
2023-05-29 07:01:54,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wxe6eqw', purging
2023-05-29 07:01:54,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:54,488 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:54,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:54,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:54,511 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:54,511 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:54,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:54,698 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:55,782 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:55,813 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:55,832 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:56,002 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:57,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j2_ox2ax', purging
2023-05-29 07:01:57,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5fuijkjl', purging
2023-05-29 07:01:57,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-asz2yr8c', purging
2023-05-29 07:01:57,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-thyuktsn', purging
2023-05-29 07:01:57,201 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:57,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:57,238 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:57,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:57,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:57,243 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:57,430 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:57,430 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:01:58,473 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:58,508 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:58,541 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:58,715 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:01:59,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3rw18zwp', purging
2023-05-29 07:01:59,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2ndsdiu', purging
2023-05-29 07:01:59,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-42cf7lc7', purging
2023-05-29 07:01:59,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9m3pnu88', purging
2023-05-29 07:01:59,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:59,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:59,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:59,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:01:59,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:01:59,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:00,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:00,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:01,132 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:01,177 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:01,197 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:01,358 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:02,556 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rq5h63et', purging
2023-05-29 07:02:02,556 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-13fol06d', purging
2023-05-29 07:02:02,557 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-shdqv5fh', purging
2023-05-29 07:02:02,557 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-90wv7rj_', purging
2023-05-29 07:02:02,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:02,558 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:02,577 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:02,577 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:02,579 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:02,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:02,735 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:02,735 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:03,827 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:03,863 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:03,895 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:04,054 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:05,250 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-__9vz7nb', purging
2023-05-29 07:02:05,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-si40s_29', purging
2023-05-29 07:02:05,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uhdflrk3', purging
2023-05-29 07:02:05,251 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i8jae4zz', purging
2023-05-29 07:02:05,252 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:05,252 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:05,260 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:05,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:05,282 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:05,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:05,460 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:05,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:06,547 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:06,571 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:06,593 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:06,775 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:07,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eogm9v9d', purging
2023-05-29 07:02:07,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5yusl6x4', purging
2023-05-29 07:02:07,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r2y5da88', purging
2023-05-29 07:02:07,934 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dkhcwf29', purging
2023-05-29 07:02:07,935 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:07,935 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:07,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:07,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:07,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:07,998 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:08,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:08,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:09,188 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:09,231 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:09,266 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:09,427 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:10,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ote7xfb', purging
2023-05-29 07:02:10,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-772hsji7', purging
2023-05-29 07:02:10,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r_yj46xe', purging
2023-05-29 07:02:10,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hm2si3sw', purging
2023-05-29 07:02:10,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:10,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:10,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:10,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:10,671 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:10,671 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:10,843 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:10,843 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:11,875 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:11,918 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:11,941 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:12,100 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:13,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p_662z_p', purging
2023-05-29 07:02:13,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n962smzj', purging
2023-05-29 07:02:13,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-niuky_8c', purging
2023-05-29 07:02:13,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3m1tug3s', purging
2023-05-29 07:02:13,338 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:13,338 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:13,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:13,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:13,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:13,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:13,478 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:13,478 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:14,620 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:14,653 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:14,670 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:14,828 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:16,049 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ng3a_y3', purging
2023-05-29 07:02:16,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_zl0s39x', purging
2023-05-29 07:02:16,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h7dp73g4', purging
2023-05-29 07:02:16,050 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xk2gxc4p', purging
2023-05-29 07:02:16,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:16,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:16,054 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:16,054 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:16,056 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:16,057 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:16,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:16,246 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:17,354 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:17,378 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:17,404 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:17,556 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:18,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m9gmca8_', purging
2023-05-29 07:02:18,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9u5gmhr', purging
2023-05-29 07:02:18,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-11c940_i', purging
2023-05-29 07:02:18,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q9lc3una', purging
2023-05-29 07:02:18,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:18,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:18,774 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:18,774 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:18,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:18,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:18,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:18,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:20,021 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:20,056 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:20,079 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:20,259 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:21,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5q9dwvz', purging
2023-05-29 07:02:21,455 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eics05qm', purging
2023-05-29 07:02:21,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-edut1i00', purging
2023-05-29 07:02:21,456 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-68xm48es', purging
2023-05-29 07:02:21,457 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:21,457 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:21,493 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:21,493 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:21,496 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:21,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:21,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:21,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:22,732 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:22,778 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:22,811 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:22,965 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:24,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-32dpdeue', purging
2023-05-29 07:02:24,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3fkmvrh4', purging
2023-05-29 07:02:24,143 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_j28rqqt', purging
2023-05-29 07:02:24,144 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hce2dre4', purging
2023-05-29 07:02:24,144 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:24,144 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:24,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:24,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:24,217 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:24,217 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:24,370 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:24,370 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:25,424 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:25,459 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:25,487 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:25,648 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:26,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d2mbrokf', purging
2023-05-29 07:02:26,850 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9p20zphy', purging
2023-05-29 07:02:26,850 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nqntlys8', purging
2023-05-29 07:02:26,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3vtblo8z', purging
2023-05-29 07:02:26,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:26,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:26,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:26,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:26,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:26,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:27,061 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:27,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:28,164 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:28,186 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:28,216 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:28,384 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:29,566 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hqvx2n9l', purging
2023-05-29 07:02:29,567 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n9stbfqd', purging
2023-05-29 07:02:29,567 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sbdrfl5m', purging
2023-05-29 07:02:29,567 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u5iehjm8', purging
2023-05-29 07:02:29,568 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:29,568 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:29,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:29,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:29,646 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:29,646 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:29,763 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:29,763 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:30,824 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:30,873 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:30,897 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:31,075 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:32,277 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tewianhy', purging
2023-05-29 07:02:32,278 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uf9innex', purging
2023-05-29 07:02:32,278 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g13scgm2', purging
2023-05-29 07:02:32,279 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n8p4tak3', purging
2023-05-29 07:02:32,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:32,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:32,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:32,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:32,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:32,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:32,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:32,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:33,640 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:33,665 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:33,701 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:33,865 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:35,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5f5wpej_', purging
2023-05-29 07:02:35,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z8ov0zmh', purging
2023-05-29 07:02:35,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ozx_if7d', purging
2023-05-29 07:02:35,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x8ns7xrp', purging
2023-05-29 07:02:35,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:35,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:35,078 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:35,078 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:35,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:35,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:35,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:35,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:36,290 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:36,335 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:36,353 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:36,522 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:37,707 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b0sdvbry', purging
2023-05-29 07:02:37,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0uws3_on', purging
2023-05-29 07:02:37,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1ywns6aj', purging
2023-05-29 07:02:37,708 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n209bd_x', purging
2023-05-29 07:02:37,709 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:37,709 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:37,720 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:37,720 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:37,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:37,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:37,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:37,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:38,979 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:39,008 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:39,028 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:39,214 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:40,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a5hephrc', purging
2023-05-29 07:02:40,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r3wp_zd0', purging
2023-05-29 07:02:40,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-heoenilo', purging
2023-05-29 07:02:40,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bedldv1v', purging
2023-05-29 07:02:40,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:40,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:40,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:40,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:40,409 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:40,409 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:40,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:40,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:41,650 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:41,699 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:41,722 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:41,896 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:43,095 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gh6o6d9z', purging
2023-05-29 07:02:43,095 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pqp_z9sr', purging
2023-05-29 07:02:43,096 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-06d2n60t', purging
2023-05-29 07:02:43,096 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e__ksje_', purging
2023-05-29 07:02:43,097 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:43,097 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:43,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:43,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:43,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:43,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:43,319 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:43,319 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:44,355 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:44,400 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:44,440 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:44,600 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:45,776 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yiqfc4o2', purging
2023-05-29 07:02:45,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pyflsxk9', purging
2023-05-29 07:02:45,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-weq5x4td', purging
2023-05-29 07:02:45,777 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0k1d3r_5', purging
2023-05-29 07:02:45,778 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:45,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:45,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:45,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:45,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:45,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:45,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:45,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:47,046 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:47,120 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:47,122 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:47,287 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:48,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_6yz7f4o', purging
2023-05-29 07:02:48,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9jzt9cwt', purging
2023-05-29 07:02:48,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hpvldie7', purging
2023-05-29 07:02:48,482 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b9fjh3f6', purging
2023-05-29 07:02:48,482 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:48,482 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:48,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:48,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:48,558 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:48,559 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:48,714 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:48,714 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:49,790 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:49,819 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:49,839 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:50,004 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:51,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:51,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_lqtx_6_', purging
2023-05-29 07:02:51,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:51,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w1hkcr31', purging
2023-05-29 07:02:51,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-enpaebw7', purging
2023-05-29 07:02:51,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7s286223', purging
2023-05-29 07:02:51,216 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:51,216 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:51,231 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:51,231 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:51,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:51,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:52,476 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:52,507 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:52,545 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:52,708 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:53,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_xkp07gu', purging
2023-05-29 07:02:53,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j1q9iz76', purging
2023-05-29 07:02:53,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-co8fwb30', purging
2023-05-29 07:02:53,931 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3yio6rcz', purging
2023-05-29 07:02:53,931 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:53,931 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:53,941 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:53,941 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:53,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:53,997 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:54,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:54,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:55,199 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:55,246 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:55,283 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:55,435 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:56,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hv43ch90', purging
2023-05-29 07:02:56,639 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qs44chd_', purging
2023-05-29 07:02:56,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ff3ln2h_', purging
2023-05-29 07:02:56,640 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-igj1abdz', purging
2023-05-29 07:02:56,641 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:56,641 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:56,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:56,648 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:56,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:56,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:56,857 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:56,857 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:02:57,943 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:57,990 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:58,014 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:58,174 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:02:59,371 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1qb6qmgo', purging
2023-05-29 07:02:59,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ludxl9x5', purging
2023-05-29 07:02:59,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i31wtoia', purging
2023-05-29 07:02:59,372 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eofjxtsy', purging
2023-05-29 07:02:59,373 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:59,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:59,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:59,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:59,418 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:59,418 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:02:59,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:02:59,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:00,688 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:00,713 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:00,736 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:00,898 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:02,065 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hxyntpm8', purging
2023-05-29 07:03:02,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nwy61aev', purging
2023-05-29 07:03:02,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ufoedqax', purging
2023-05-29 07:03:02,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4p2wlg70', purging
2023-05-29 07:03:02,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:02,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:02,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:02,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:02,132 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:02,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:02,299 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:02,299 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:03,360 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:03,394 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:03,424 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:03,615 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:04,768 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kviy1i93', purging
2023-05-29 07:03:04,768 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m3_8arfw', purging
2023-05-29 07:03:04,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ss5ialx_', purging
2023-05-29 07:03:04,769 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5t4oelgx', purging
2023-05-29 07:03:04,769 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:04,769 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:04,777 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:04,777 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:04,786 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:04,786 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:05,007 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:05,007 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:06,009 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:06,039 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:06,070 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:06,229 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:07,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n422p48_', purging
2023-05-29 07:03:07,373 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7rm78shi', purging
2023-05-29 07:03:07,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s3if1fhi', purging
2023-05-29 07:03:07,374 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t9j6fy08', purging
2023-05-29 07:03:07,374 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:07,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:07,455 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:07,455 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:07,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:07,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:07,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:07,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:08,640 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:08,686 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:08,714 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:08,872 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:10,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iqrkh_hy', purging
2023-05-29 07:03:10,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r1b_cqov', purging
2023-05-29 07:03:10,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sasklkxc', purging
2023-05-29 07:03:10,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rmwjtd74', purging
2023-05-29 07:03:10,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:10,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:10,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:10,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:10,150 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:10,150 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:10,250 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:10,251 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:11,401 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:11,429 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:11,452 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:11,622 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:12,848 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2v2z0qe_', purging
2023-05-29 07:03:12,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9nsz7ada', purging
2023-05-29 07:03:12,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mz8vc3kb', purging
2023-05-29 07:03:12,849 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5_2b8p0z', purging
2023-05-29 07:03:12,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:12,850 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:12,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:12,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:12,873 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:12,873 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:12,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:12,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:14,115 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:14,156 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:14,179 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:14,340 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:15,526 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b28mcl4m', purging
2023-05-29 07:03:15,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-feg7axwd', purging
2023-05-29 07:03:15,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hvh4wf7c', purging
2023-05-29 07:03:15,527 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hvlgclft', purging
2023-05-29 07:03:15,528 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:15,528 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:15,569 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:15,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:15,572 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:15,572 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:15,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:15,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:16,805 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:16,837 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:16,861 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:17,042 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:18,196 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lfilahev', purging
2023-05-29 07:03:18,196 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ve_g8bwx', purging
2023-05-29 07:03:18,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-exaxty92', purging
2023-05-29 07:03:18,197 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wl3sayvt', purging
2023-05-29 07:03:18,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:18,198 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:18,226 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:18,226 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:18,259 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:18,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:18,435 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:18,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:19,459 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:19,498 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:19,521 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:19,704 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:20,868 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-41xvbh4n', purging
2023-05-29 07:03:20,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3mh92afe', purging
2023-05-29 07:03:20,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yx1hggmy', purging
2023-05-29 07:03:20,869 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6r0kil6h', purging
2023-05-29 07:03:20,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:20,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:20,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:20,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:20,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:20,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:21,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:21,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:22,139 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:22,191 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:22,207 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:22,400 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:23,540 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-02bm850k', purging
2023-05-29 07:03:23,541 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e_9rb6v4', purging
2023-05-29 07:03:23,541 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vlzagaxe', purging
2023-05-29 07:03:23,541 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pkwlt5vz', purging
2023-05-29 07:03:23,542 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:23,542 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:23,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:23,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:23,617 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:23,617 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:23,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:23,839 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:24,824 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:24,854 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:24,877 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:25,052 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:26,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a6bbpwv4', purging
2023-05-29 07:03:26,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pswz3gtx', purging
2023-05-29 07:03:26,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ldf9mja', purging
2023-05-29 07:03:26,272 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-66j2crpx', purging
2023-05-29 07:03:26,273 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:26,273 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:26,277 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:26,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:26,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:26,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:26,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:26,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:27,670 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:27,711 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:27,749 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:27,911 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:29,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:29,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d6iavc08', purging
2023-05-29 07:03:29,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:29,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04dnof2n', purging
2023-05-29 07:03:29,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dr66ahb6', purging
2023-05-29 07:03:29,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-af3nr51j', purging
2023-05-29 07:03:29,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:29,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:29,175 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:29,175 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:29,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:29,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:30,388 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:30,432 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:30,456 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:30,639 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:31,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-km3hzsec', purging
2023-05-29 07:03:31,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-90nkwg5b', purging
2023-05-29 07:03:31,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3p_g2w0g', purging
2023-05-29 07:03:31,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vn5mcq1r', purging
2023-05-29 07:03:31,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:31,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:31,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:31,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:31,898 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:31,898 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:32,045 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:32,045 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:33,086 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:33,161 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:33,162 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:33,323 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:34,459 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4kybdfw1', purging
2023-05-29 07:03:34,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c28uuwak', purging
2023-05-29 07:03:34,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pdluwkux', purging
2023-05-29 07:03:34,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l905zpm7', purging
2023-05-29 07:03:34,461 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:34,461 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:34,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:34,582 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:34,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:34,607 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:34,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:34,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:35,715 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:35,752 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:35,799 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:35,955 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:37,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ceat_d3a', purging
2023-05-29 07:03:37,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m2jutdtf', purging
2023-05-29 07:03:37,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d01f9s_u', purging
2023-05-29 07:03:37,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-csb5or6a', purging
2023-05-29 07:03:37,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:37,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:37,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:37,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:37,181 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:37,181 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:37,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:37,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:38,415 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:38,458 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:38,485 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:38,657 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:39,824 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dqd53u0m', purging
2023-05-29 07:03:39,824 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c96oulyq', purging
2023-05-29 07:03:39,825 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_s_ouue5', purging
2023-05-29 07:03:39,825 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e61c15hn', purging
2023-05-29 07:03:39,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:39,825 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:39,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:39,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:39,905 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:39,905 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:40,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:40,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:41,099 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:41,138 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:41,161 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:41,319 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:42,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nko_fyod', purging
2023-05-29 07:03:42,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4njdiitg', purging
2023-05-29 07:03:42,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uy13qm6p', purging
2023-05-29 07:03:42,503 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y2zv4v0w', purging
2023-05-29 07:03:42,504 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:42,504 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:42,515 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:42,515 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:42,569 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:42,569 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:42,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:42,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:43,753 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:43,802 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:43,824 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:43,996 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:45,189 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e44ibj72', purging
2023-05-29 07:03:45,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mv8bwyes', purging
2023-05-29 07:03:45,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tr8sk1g8', purging
2023-05-29 07:03:45,190 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-plbd3bhm', purging
2023-05-29 07:03:45,191 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:45,191 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:45,215 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:45,215 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:45,218 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:45,218 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:45,369 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:45,369 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:46,467 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:46,499 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:46,514 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:46,672 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:47,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4tcvpuhv', purging
2023-05-29 07:03:47,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qhjrq96v', purging
2023-05-29 07:03:47,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-elp88wed', purging
2023-05-29 07:03:47,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xx0hvfox', purging
2023-05-29 07:03:47,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:47,892 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:47,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:47,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:47,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:47,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:48,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:48,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:49,165 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:49,190 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:49,227 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:49,390 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:50,559 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kcez33u0', purging
2023-05-29 07:03:50,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-21h9y18b', purging
2023-05-29 07:03:50,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04fi92pi', purging
2023-05-29 07:03:50,560 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4vlfyc6p', purging
2023-05-29 07:03:50,561 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:50,561 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:50,602 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:50,602 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:50,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:50,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:50,795 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:50,795 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:51,815 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:51,861 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:51,882 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:52,041 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:53,200 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-me5pl9gu', purging
2023-05-29 07:03:53,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-icqa_nx7', purging
2023-05-29 07:03:53,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04gsyrlf', purging
2023-05-29 07:03:53,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ciq381yx', purging
2023-05-29 07:03:53,202 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:53,202 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:53,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:53,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:53,283 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:53,283 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:53,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:53,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:54,487 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:54,519 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:54,543 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:54,700 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:55,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5rpv1bkt', purging
2023-05-29 07:03:55,873 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5fk_gjsy', purging
2023-05-29 07:03:55,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u_lh42st', purging
2023-05-29 07:03:55,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lbfcs522', purging
2023-05-29 07:03:55,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:55,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:55,904 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:55,904 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:55,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:55,936 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:56,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:56,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:57,176 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:57,196 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:57,230 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:57,387 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:58,603 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-msl5tgsc', purging
2023-05-29 07:03:58,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d79n5h7s', purging
2023-05-29 07:03:58,604 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-shi7xy4u', purging
2023-05-29 07:03:58,605 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bqify7q6', purging
2023-05-29 07:03:58,605 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:58,605 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:58,661 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:58,661 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:58,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:58,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:03:58,796 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:03:58,796 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:03:59,929 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:59,954 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:03:59,971 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:00,155 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:01,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qqp_xo7d', purging
2023-05-29 07:04:01,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-41m_939c', purging
2023-05-29 07:04:01,336 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r65dlqul', purging
2023-05-29 07:04:01,337 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a0ef3k4s', purging
2023-05-29 07:04:01,337 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:01,337 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:01,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:01,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:01,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:01,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:01,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:01,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:02,628 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:02,653 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:02,685 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:02,850 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:04,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g9dzypu_', purging
2023-05-29 07:04:04,025 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y8wcz6ka', purging
2023-05-29 07:04:04,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tra6u4lo', purging
2023-05-29 07:04:04,026 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2epoxa7k', purging
2023-05-29 07:04:04,027 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:04,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:04,070 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:04,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:04,108 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:04,108 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:04,259 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:04,260 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:05,308 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:05,337 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:05,356 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:05,532 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:06,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i58t0si8', purging
2023-05-29 07:04:06,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zyrtmf98', purging
2023-05-29 07:04:06,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0ajxhvd3', purging
2023-05-29 07:04:06,706 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a99veog_', purging
2023-05-29 07:04:06,706 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:06,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:06,733 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:06,733 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:06,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:06,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:06,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:06,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:07,962 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:08,013 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:08,030 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:08,183 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:09,379 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tyrglj00', purging
2023-05-29 07:04:09,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oucwkqw7', purging
2023-05-29 07:04:09,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v2pwd1lw', purging
2023-05-29 07:04:09,380 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cec3xlm7', purging
2023-05-29 07:04:09,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:09,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:09,416 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:09,416 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:09,423 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:09,423 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:09,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:09,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:10,663 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:10,700 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:10,723 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:10,882 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:12,030 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-52ruqzip', purging
2023-05-29 07:04:12,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mu49cgyo', purging
2023-05-29 07:04:12,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6720tkxq', purging
2023-05-29 07:04:12,031 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-utuct3cj', purging
2023-05-29 07:04:12,032 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:12,032 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:12,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:12,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:12,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:12,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:12,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:12,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:13,300 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:13,325 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:13,353 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:13,511 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:14,713 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o0f247vp', purging
2023-05-29 07:04:14,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jisg4t1k', purging
2023-05-29 07:04:14,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jzmaqx_x', purging
2023-05-29 07:04:14,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f5j6ipbz', purging
2023-05-29 07:04:14,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:14,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:14,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:14,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:14,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:14,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:14,877 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:14,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:15,979 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:16,029 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:16,046 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:16,206 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:17,383 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6nxkl58q', purging
2023-05-29 07:04:17,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0stibkso', purging
2023-05-29 07:04:17,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2k_d83_g', purging
2023-05-29 07:04:17,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5puh34mu', purging
2023-05-29 07:04:17,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:17,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:17,444 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:17,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:17,445 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:17,445 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:17,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:17,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:18,653 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:18,679 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:18,713 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:18,884 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:20,051 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-005bice2', purging
2023-05-29 07:04:20,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t2d0264u', purging
2023-05-29 07:04:20,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ri1frgce', purging
2023-05-29 07:04:20,052 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e4uiybj5', purging
2023-05-29 07:04:20,053 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:20,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:20,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:20,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:20,136 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:20,136 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:20,312 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:20,312 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:21,320 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:21,353 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:21,381 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:21,539 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:22,741 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m296qbse', purging
2023-05-29 07:04:22,741 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8u_tj5sf', purging
2023-05-29 07:04:22,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ed9j4i17', purging
2023-05-29 07:04:22,742 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-52myjrje', purging
2023-05-29 07:04:22,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:22,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:22,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:22,753 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:22,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:22,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:22,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:22,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:24,020 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:24,038 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:24,076 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:24,251 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:25,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-quz9ilzk', purging
2023-05-29 07:04:25,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sq0lxkk4', purging
2023-05-29 07:04:25,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-92h_3c_h', purging
2023-05-29 07:04:25,436 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:25,436 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ju9hdjrh', purging
2023-05-29 07:04:25,436 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:25,437 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:25,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:25,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:25,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:25,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:25,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:26,720 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:26,741 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:26,772 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:26,934 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:28,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f9i4328a', purging
2023-05-29 07:04:28,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6gg3z_v2', purging
2023-05-29 07:04:28,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ojt866kg', purging
2023-05-29 07:04:28,124 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zty2zmgu', purging
2023-05-29 07:04:28,124 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:28,124 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:28,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:28,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:28,188 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:28,188 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:28,350 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:28,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:29,408 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:29,435 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:29,467 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:29,637 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:30,850 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-48_8atrb', purging
2023-05-29 07:04:30,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hxx2nfw5', purging
2023-05-29 07:04:30,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cpddvw00', purging
2023-05-29 07:04:30,851 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qc118pzc', purging
2023-05-29 07:04:30,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:30,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:30,859 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:30,859 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:30,888 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:30,888 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:31,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:31,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:32,134 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:32,151 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:32,186 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:32,351 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:33,539 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rkzmpr2y', purging
2023-05-29 07:04:33,539 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-otxkmifh', purging
2023-05-29 07:04:33,539 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cl7knocj', purging
2023-05-29 07:04:33,540 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j__2nuuj', purging
2023-05-29 07:04:33,541 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:33,541 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:33,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:33,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:33,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:33,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:33,750 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:33,750 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:34,810 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:34,854 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:34,885 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:35,038 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:36,248 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-flxupbtx', purging
2023-05-29 07:04:36,248 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0tdtxsqz', purging
2023-05-29 07:04:36,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_f75cau9', purging
2023-05-29 07:04:36,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_227w_px', purging
2023-05-29 07:04:36,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:36,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:36,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:36,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:36,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:36,268 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:36,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:36,449 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:37,545 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:37,584 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:37,607 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:37,771 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:38,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y3cbh_wo', purging
2023-05-29 07:04:38,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bs3p2gvj', purging
2023-05-29 07:04:38,929 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u5xy54wj', purging
2023-05-29 07:04:38,930 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t62_onqn', purging
2023-05-29 07:04:38,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:38,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:38,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:38,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:38,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:38,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:39,156 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:39,156 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:40,207 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:40,236 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:40,273 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:40,452 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:41,624 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wkv865oq', purging
2023-05-29 07:04:41,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ytbsls84', purging
2023-05-29 07:04:41,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-42xam75s', purging
2023-05-29 07:04:41,625 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ic7v6wji', purging
2023-05-29 07:04:41,626 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:41,626 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:41,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:41,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:41,628 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:41,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:41,856 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:41,856 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:42,922 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:42,937 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:42,974 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:43,127 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:44,340 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eycmxpex', purging
2023-05-29 07:04:44,341 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-snpor10v', purging
2023-05-29 07:04:44,341 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i9on1t3p', purging
2023-05-29 07:04:44,341 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a978svtk', purging
2023-05-29 07:04:44,342 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:44,342 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:44,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:44,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:44,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:44,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:44,497 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:44,497 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:45,624 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:45,663 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:45,677 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:45,837 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:47,006 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-43ckc55d', purging
2023-05-29 07:04:47,006 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_oezrmzv', purging
2023-05-29 07:04:47,007 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n0iiyl1a', purging
2023-05-29 07:04:47,007 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7egejvb0', purging
2023-05-29 07:04:47,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:47,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:47,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:47,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:47,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:47,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:47,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:47,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:48,262 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:48,301 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:48,326 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:48,500 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:49,650 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fypm37bj', purging
2023-05-29 07:04:49,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pdamahy4', purging
2023-05-29 07:04:49,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nbej759b', purging
2023-05-29 07:04:49,651 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d3k5hn7_', purging
2023-05-29 07:04:49,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:49,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:49,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:49,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:49,748 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:49,748 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:49,872 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:49,872 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:50,916 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:50,967 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:50,981 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:51,156 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:52,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qeptykkj', purging
2023-05-29 07:04:52,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hvyi7tga', purging
2023-05-29 07:04:52,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-26gxafnf', purging
2023-05-29 07:04:52,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-it8w1q0h', purging
2023-05-29 07:04:52,358 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:52,358 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:52,368 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:52,368 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:52,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:52,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:52,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:52,586 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:53,657 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:53,687 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:53,719 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:53,876 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:55,061 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-56tzcls8', purging
2023-05-29 07:04:55,062 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2d5iuww', purging
2023-05-29 07:04:55,062 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m7huzymu', purging
2023-05-29 07:04:55,062 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uf8s8d_l', purging
2023-05-29 07:04:55,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:55,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:55,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:55,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:55,110 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:55,110 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:55,281 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:55,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:56,361 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:56,385 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:56,418 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:56,571 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:57,752 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c21g7tm1', purging
2023-05-29 07:04:57,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ebxvc_bg', purging
2023-05-29 07:04:57,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3pnownf4', purging
2023-05-29 07:04:57,753 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dthaoqzk', purging
2023-05-29 07:04:57,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:57,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:57,789 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:57,789 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:57,818 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:57,818 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:04:57,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:04:57,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:04:59,033 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:59,081 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:59,098 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:04:59,286 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:00,470 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7kihi5vr', purging
2023-05-29 07:05:00,470 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k7ihwz_d', purging
2023-05-29 07:05:00,470 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w9dovxhl', purging
2023-05-29 07:05:00,471 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mqnyg0tp', purging
2023-05-29 07:05:00,471 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:00,471 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:00,484 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:00,484 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:00,500 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:00,500 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:00,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:00,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:01,746 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:01,793 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:01,826 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:01,980 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:03,210 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gmyhb26w', purging
2023-05-29 07:05:03,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ntnka7v2', purging
2023-05-29 07:05:03,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-po7g_f_1', purging
2023-05-29 07:05:03,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:03,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:03,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rq4chtnk', purging
2023-05-29 07:05:03,212 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:03,212 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:03,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:03,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:03,419 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:03,419 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:04,504 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:04,541 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:04,568 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:04,740 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:05,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yakox2_w', purging
2023-05-29 07:05:05,912 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sw01433w', purging
2023-05-29 07:05:05,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eun1eykh', purging
2023-05-29 07:05:05,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ktmdoqrj', purging
2023-05-29 07:05:05,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:05,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:05,947 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:05,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:05,975 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:05,975 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:06,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:06,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:07,203 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:07,248 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:07,271 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:07,444 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:08,627 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o90qqupy', purging
2023-05-29 07:05:08,627 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3apxxy18', purging
2023-05-29 07:05:08,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:08,628 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:08,628 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wjd8_7v2', purging
2023-05-29 07:05:08,628 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cmzna4vh', purging
2023-05-29 07:05:08,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:08,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:08,723 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:08,723 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:08,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:08,867 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:09,890 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:09,942 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:09,960 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:10,124 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:11,292 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pp339mqn', purging
2023-05-29 07:05:11,293 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-emz_o41c', purging
2023-05-29 07:05:11,293 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ctxc1_y6', purging
2023-05-29 07:05:11,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n_r9cs4g', purging
2023-05-29 07:05:11,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:11,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:11,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:11,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:11,329 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:11,329 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:11,530 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:11,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:12,543 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:12,585 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-29 07:05:12,781 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:13,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ho4rr0k0', purging
2023-05-29 07:05:13,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ckzgd_lx', purging
2023-05-29 07:05:13,939 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kof4xvd4', purging
2023-05-29 07:05:13,940 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_m2kaje8', purging
2023-05-29 07:05:13,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:13,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:13,946 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:13,947 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:14,154 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:14,154 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:15,004 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:15,050 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:15,209 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:16,358 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3x0nuux2', purging
2023-05-29 07:05:16,359 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x8ck9bnt', purging
2023-05-29 07:05:16,359 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fpnr9104', purging
2023-05-29 07:05:16,360 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:16,360 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:16,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:16,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:16,567 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:16,567 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:17,410 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:17,462 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:17,624 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:18,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mon7t91r', purging
2023-05-29 07:05:18,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_a61ryga', purging
2023-05-29 07:05:18,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8ztkm2un', purging
2023-05-29 07:05:18,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:18,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:18,831 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:18,831 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:19,015 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:19,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:19,825 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:19,846 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:20,024 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:21,165 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cp5sww66', purging
2023-05-29 07:05:21,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wpgpsg3g', purging
2023-05-29 07:05:21,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-na01rykz', purging
2023-05-29 07:05:21,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:21,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:21,197 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:21,197 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:21,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:21,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:22,195 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:22,234 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:22,409 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:23,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dbvu7m46', purging
2023-05-29 07:05:23,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ilmkty_q', purging
2023-05-29 07:05:23,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g88jnkd8', purging
2023-05-29 07:05:23,575 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:23,575 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:23,576 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:23,576 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:23,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:23,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:24,604 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:24,642 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:24,804 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:25,968 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7ovwrioy', purging
2023-05-29 07:05:25,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k46rj4se', purging
2023-05-29 07:05:25,969 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0j0sfbt8', purging
2023-05-29 07:05:25,970 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:25,970 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:26,009 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:26,009 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:26,174 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:26,174 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:27,010 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:27,049 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:27,207 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:28,386 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v499hkcg', purging
2023-05-29 07:05:28,386 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0m5qctz3', purging
2023-05-29 07:05:28,386 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_m881nzx', purging
2023-05-29 07:05:28,387 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:28,387 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:28,396 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:28,396 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:28,621 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:28,621 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:29,433 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:29,463 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:29,624 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:30,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sut0m9r_', purging
2023-05-29 07:05:30,809 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2kqibkhm', purging
2023-05-29 07:05:30,809 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4t_xl6__', purging
2023-05-29 07:05:30,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:30,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:30,825 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:30,826 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:30,976 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:30,976 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:31,843 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:31,871 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:32,044 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:33,201 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_9xzslaa', purging
2023-05-29 07:05:33,202 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x_5euru7', purging
2023-05-29 07:05:33,202 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rwlf7d7q', purging
2023-05-29 07:05:33,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:33,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:33,224 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:33,224 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:33,434 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:33,435 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:34,240 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:34,267 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:34,434 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:35,599 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-70y8gs02', purging
2023-05-29 07:05:35,599 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-scrh0p4k', purging
2023-05-29 07:05:35,600 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6uod1yi5', purging
2023-05-29 07:05:35,600 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:35,600 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:35,690 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:35,690 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:35,835 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:35,835 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:36,643 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:36,683 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:36,852 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:38,010 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03z8dtvo', purging
2023-05-29 07:05:38,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-do6ps4ke', purging
2023-05-29 07:05:38,011 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rhf6ox5l', purging
2023-05-29 07:05:38,012 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:38,012 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:38,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:38,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:38,223 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:38,223 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:39,062 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:39,077 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:39,238 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:40,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fa3aumv4', purging
2023-05-29 07:05:40,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ccsn9p0i', purging
2023-05-29 07:05:40,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jpwep43o', purging
2023-05-29 07:05:40,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:40,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:40,449 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:40,450 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:40,613 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:40,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:41,499 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:41,522 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:41,681 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:42,885 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bh_5xhxl', purging
2023-05-29 07:05:42,885 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mxexggj5', purging
2023-05-29 07:05:42,886 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uytnjzx_', purging
2023-05-29 07:05:42,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:42,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:42,934 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:42,934 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:43,062 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:43,062 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:43,950 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:43,981 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:44,142 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:45,325 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h5vqqjgh', purging
2023-05-29 07:05:45,326 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hw1mekga', purging
2023-05-29 07:05:45,326 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q50j_8v3', purging
2023-05-29 07:05:45,327 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:45,327 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:45,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:45,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:45,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:45,546 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:46,392 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:46,429 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:46,580 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:47,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u030pv31', purging
2023-05-29 07:05:47,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zhlbuvj7', purging
2023-05-29 07:05:47,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3xtppcel', purging
2023-05-29 07:05:47,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:47,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:47,834 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:47,834 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:47,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:47,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:48,822 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:48,844 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:49,017 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:50,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aw_dj6d2', purging
2023-05-29 07:05:50,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rdffzehr', purging
2023-05-29 07:05:50,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t5h9zxch', purging
2023-05-29 07:05:50,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:50,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:50,207 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:50,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:50,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:50,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:51,199 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:51,225 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:51,397 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:52,581 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jeflsee0', purging
2023-05-29 07:05:52,581 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yb4c30o8', purging
2023-05-29 07:05:52,582 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hlxg5nnp', purging
2023-05-29 07:05:52,582 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:52,582 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:52,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:52,588 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:52,758 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:52,758 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:53,612 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:53,646 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:53,825 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:54,962 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h70680ul', purging
2023-05-29 07:05:54,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4hz29fv5', purging
2023-05-29 07:05:54,963 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8fd6d5nx', purging
2023-05-29 07:05:54,964 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:54,964 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:54,999 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:54,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:55,216 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:55,216 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:56,006 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:56,028 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:56,213 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:57,363 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r5ejcj_0', purging
2023-05-29 07:05:57,364 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rqa3vhg8', purging
2023-05-29 07:05:57,364 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gni0jz8x', purging
2023-05-29 07:05:57,365 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:57,365 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:57,407 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:57,407 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:57,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:57,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:05:58,400 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:58,425 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:58,597 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:05:59,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tbiyi2jh', purging
2023-05-29 07:05:59,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-73k0r32y', purging
2023-05-29 07:05:59,803 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9doni8bj', purging
2023-05-29 07:05:59,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:59,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:05:59,849 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:05:59,849 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:00,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:00,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:00,866 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:00,903 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:01,074 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:02,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_wb_2044', purging
2023-05-29 07:06:02,220 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bjd8ttc2', purging
2023-05-29 07:06:02,221 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v9xcrkxw', purging
2023-05-29 07:06:02,221 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:02,221 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:02,307 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:02,307 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:02,437 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:02,437 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:03,220 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:03,261 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:03,435 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:04,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-slrtcrt9', purging
2023-05-29 07:06:04,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3lj68sgh', purging
2023-05-29 07:06:04,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-18bxmsp5', purging
2023-05-29 07:06:04,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:04,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:04,664 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:04,665 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:04,824 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:04,824 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:05,639 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:05,672 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:05,829 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:07,088 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7gdwr0p0', purging
2023-05-29 07:06:07,089 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y5d4osi1', purging
2023-05-29 07:06:07,089 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mjs9j9d0', purging
2023-05-29 07:06:07,090 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:07,090 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:07,107 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:07,107 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:07,192 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:07,192 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:08,141 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:08,175 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:08,329 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:09,535 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lxbrfo_t', purging
2023-05-29 07:06:09,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rw9w21lb', purging
2023-05-29 07:06:09,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j6gy0jp6', purging
2023-05-29 07:06:09,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:09,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:09,545 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:09,545 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:09,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:09,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:10,623 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:10,624 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:10,783 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:12,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f_qb6715', purging
2023-05-29 07:06:12,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x83_zhoe', purging
2023-05-29 07:06:12,003 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-43zqld7d', purging
2023-05-29 07:06:12,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:12,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:12,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:12,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:12,158 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:12,159 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:13,029 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:13,061 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:13,239 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:14,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6e4odg_a', purging
2023-05-29 07:06:14,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9wbqm9zy', purging
2023-05-29 07:06:14,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zpk8q3b7', purging
2023-05-29 07:06:14,385 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:14,385 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:14,420 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:14,420 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:14,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:14,638 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:15,434 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:15,464 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:15,648 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:16,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pwprepny', purging
2023-05-29 07:06:16,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t00vnmob', purging
2023-05-29 07:06:16,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fpiyl3vx', purging
2023-05-29 07:06:16,816 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:16,816 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:16,879 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:16,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:17,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:17,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:17,860 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:17,893 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:18,060 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:19,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-03e47fgk', purging
2023-05-29 07:06:19,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q2u1zp6w', purging
2023-05-29 07:06:19,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-it6e_61p', purging
2023-05-29 07:06:19,250 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:19,250 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:19,293 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:19,293 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:19,475 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:19,475 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:20,315 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:20,345 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:20,529 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:21,687 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-blajhp4m', purging
2023-05-29 07:06:21,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3f0qyhgh', purging
2023-05-29 07:06:21,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-udz3zgb8', purging
2023-05-29 07:06:21,688 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:21,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:21,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:21,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:21,929 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:21,929 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:22,829 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:22,852 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:23,022 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:24,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6i4mznl', purging
2023-05-29 07:06:24,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fj0kxgby', purging
2023-05-29 07:06:24,142 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qcakalfv', purging
2023-05-29 07:06:24,143 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:24,143 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:24,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:24,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:24,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:24,442 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:25,204 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:25,242 - distributed.nanny - WARNING - Restarting worker
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:25,478 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:26,616 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cb7u9rm2', purging
2023-05-29 07:06:26,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rxzebxn1', purging
2023-05-29 07:06:26,617 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o9knvdac', purging
2023-05-29 07:06:26,618 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:26,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:26,627 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:26,627 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:26,827 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:26,827 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:27,680 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:27,703 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:27,864 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:29,057 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rhd1x5pp', purging
2023-05-29 07:06:29,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xc2wp8bb', purging
2023-05-29 07:06:29,058 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jkhcjs8l', purging
2023-05-29 07:06:29,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:29,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:29,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:29,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:29,270 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:29,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:30,125 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:30,160 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:30,316 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:31,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-43gge0e0', purging
2023-05-29 07:06:31,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hlrnr7vl', purging
2023-05-29 07:06:31,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jgm0u3g3', purging
2023-05-29 07:06:31,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:31,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:31,551 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:31,551 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:31,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:31,705 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:32,556 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:32,584 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:32,767 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:33,966 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p43z9ee3', purging
2023-05-29 07:06:33,967 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qc6uzs2u', purging
2023-05-29 07:06:33,967 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_fjbxymp', purging
2023-05-29 07:06:33,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:33,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:33,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:33,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:34,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:34,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:35,030 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:35,056 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:35,223 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:36,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-54p3gc4p', purging
2023-05-29 07:06:36,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0qp_ovdj', purging
2023-05-29 07:06:36,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pl6u5kqf', purging
2023-05-29 07:06:36,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:36,415 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:36,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:36,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:36,637 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:36,637 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:37,460 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:37,493 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:37,656 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:38,875 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hzufirjc', purging
2023-05-29 07:06:38,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7y5q7dm2', purging
2023-05-29 07:06:38,876 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d7aahl1b', purging
2023-05-29 07:06:38,876 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:38,877 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:38,886 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:38,886 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:39,026 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:39,026 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:39,940 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:39,983 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:40,150 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:41,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gsqfjplz', purging
2023-05-29 07:06:41,339 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n4mc6j5d', purging
2023-05-29 07:06:41,340 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hfu4417z', purging
2023-05-29 07:06:41,340 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:41,340 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:41,341 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:41,341 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:41,536 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:41,536 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:42,399 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:42,450 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:42,604 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:43,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3b5revsx', purging
2023-05-29 07:06:43,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ijv0lo5n', purging
2023-05-29 07:06:43,808 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gwz3e1ya', purging
2023-05-29 07:06:43,809 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:43,809 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:43,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:43,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:44,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:44,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:44,849 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:44,883 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:45,058 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:46,212 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rtwj12i5', purging
2023-05-29 07:06:46,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ltchyt96', purging
2023-05-29 07:06:46,213 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n1qmhvoa', purging
2023-05-29 07:06:46,213 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:46,213 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:46,279 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:46,279 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:46,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:46,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:47,355 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:47,386 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:47,547 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:48,730 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5wkm__b_', purging
2023-05-29 07:06:48,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nexe3bip', purging
2023-05-29 07:06:48,731 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9rg5xhqt', purging
2023-05-29 07:06:48,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:48,731 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:48,804 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:48,805 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:48,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:48,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:49,784 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:49,803 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:49,990 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:51,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7brgq246', purging
2023-05-29 07:06:51,166 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ml7pki0q', purging
2023-05-29 07:06:51,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-meaxnfb0', purging
2023-05-29 07:06:51,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:51,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:51,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:51,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:51,329 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:51,330 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:52,203 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:52,244 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:52,397 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:53,555 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1kj3m51n', purging
2023-05-29 07:06:53,555 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4mkdqdzm', purging
2023-05-29 07:06:53,555 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hc0smfpl', purging
2023-05-29 07:06:53,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:53,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:53,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:53,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:53,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:53,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:54,589 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:54,626 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:54,790 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:55,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8v5o8jst', purging
2023-05-29 07:06:55,966 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iy2_meid', purging
2023-05-29 07:06:55,966 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5ofyrq7o', purging
2023-05-29 07:06:55,967 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:55,967 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:56,000 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:56,000 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:56,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:56,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:57,006 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:57,042 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:57,210 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:58,384 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5wtn63ha', purging
2023-05-29 07:06:58,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rg3iln1c', purging
2023-05-29 07:06:58,385 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xajmcj79', purging
2023-05-29 07:06:58,386 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:58,386 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:58,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:58,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:06:58,578 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:06:58,578 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:06:59,415 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:59,445 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:06:59,635 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:00,799 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qm4v6por', purging
2023-05-29 07:07:00,800 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n0iv6zvu', purging
2023-05-29 07:07:00,800 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3yvw269x', purging
2023-05-29 07:07:00,800 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:00,801 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:00,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:00,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:01,025 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:01,025 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:01,870 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:01,902 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:02,055 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:03,242 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o9d6qqlq', purging
2023-05-29 07:07:03,242 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u5hyssha', purging
2023-05-29 07:07:03,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k47iq505', purging
2023-05-29 07:07:03,243 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:03,243 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:03,300 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:03,300 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:03,426 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:03,426 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:04,364 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:04,395 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:04,558 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:05,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rfvh6pk9', purging
2023-05-29 07:07:05,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-161efotn', purging
2023-05-29 07:07:05,745 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ir7q06ll', purging
2023-05-29 07:07:05,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:05,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:05,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:05,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:05,940 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:05,940 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:06,820 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:06,845 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:07,018 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:08,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dsp160kn', purging
2023-05-29 07:07:08,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oox_cyvv', purging
2023-05-29 07:07:08,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-660k756o', purging
2023-05-29 07:07:08,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:08,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:08,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:08,238 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:08,400 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:08,400 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:09,197 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:09,242 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:09,412 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:10,590 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-psjv8_zc', purging
2023-05-29 07:07:10,590 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a8zj6_v9', purging
2023-05-29 07:07:10,590 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1uy50jg8', purging
2023-05-29 07:07:10,591 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:10,591 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:10,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:10,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:10,812 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:10,812 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:11,659 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:11,684 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:11,845 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:13,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mjbmustm', purging
2023-05-29 07:07:13,067 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vpxc1rj1', purging
2023-05-29 07:07:13,068 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-il4pkl73', purging
2023-05-29 07:07:13,068 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:13,068 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:13,081 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:13,081 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:13,240 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:13,240 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:14,135 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:14,160 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:14,320 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:15,522 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zbq_uz0s', purging
2023-05-29 07:07:15,523 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pf94x5yf', purging
2023-05-29 07:07:15,523 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-txcmxufu', purging
2023-05-29 07:07:15,523 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:15,523 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:15,556 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:15,556 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:15,713 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:15,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:16,583 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:16,610 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:16,767 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:17,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7tv_id2w', purging
2023-05-29 07:07:17,989 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hv0gwuz8', purging
2023-05-29 07:07:17,990 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bzz87un5', purging
2023-05-29 07:07:17,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:17,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:18,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:18,013 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:18,133 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:18,133 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:19,054 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:19,077 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:19,238 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:20,424 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v_vp1ssl', purging
2023-05-29 07:07:20,424 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e4in37t8', purging
2023-05-29 07:07:20,424 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tzqats99', purging
2023-05-29 07:07:20,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:20,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:20,427 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:20,427 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:20,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:20,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:21,447 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:21,486 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:21,661 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:22,831 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lxq32brb', purging
2023-05-29 07:07:22,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-grcph_eg', purging
2023-05-29 07:07:22,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-joreoqba', purging
2023-05-29 07:07:22,833 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:22,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:22,856 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:22,856 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:23,000 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:23,000 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:23,872 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:23,896 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:24,067 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:25,288 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hiyocmh9', purging
2023-05-29 07:07:25,288 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yt9v6zt0', purging
2023-05-29 07:07:25,288 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zqxb6ogl', purging
2023-05-29 07:07:25,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:25,289 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:25,301 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:25,301 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:25,410 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:25,411 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:26,358 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:26,393 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:26,548 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:27,743 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e7yp4wbn', purging
2023-05-29 07:07:27,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q0tfoe2a', purging
2023-05-29 07:07:27,744 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eanzmz33', purging
2023-05-29 07:07:27,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:27,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:27,785 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:27,785 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:27,942 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:27,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:28,782 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:28,811 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:28,984 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:30,218 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pzg900ih', purging
2023-05-29 07:07:30,218 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lf4aon0a', purging
2023-05-29 07:07:30,219 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-um5h8vn0', purging
2023-05-29 07:07:30,219 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:30,219 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:30,259 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:30,259 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:30,413 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:30,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:31,264 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:31,302 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:31,473 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:32,665 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e72mta8v', purging
2023-05-29 07:07:32,665 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8p0ql0q', purging
2023-05-29 07:07:32,666 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mobpz4aw', purging
2023-05-29 07:07:32,666 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:32,666 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:32,680 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:32,680 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:32,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:32,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:33,705 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:33,740 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:33,914 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:35,125 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yrut4rkr', purging
2023-05-29 07:07:35,126 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m512ixao', purging
2023-05-29 07:07:35,126 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o6tbnein', purging
2023-05-29 07:07:35,126 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:35,126 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:35,142 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:35,142 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:35,253 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:35,253 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:36,143 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:36,169 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:36,344 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:37,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cw07v0do', purging
2023-05-29 07:07:37,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-al7jxoyb', purging
2023-05-29 07:07:37,534 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q6bkotn4', purging
2023-05-29 07:07:37,534 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:37,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:37,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:37,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:37,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:37,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:38,566 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:38,608 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:38,774 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:39,923 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q6285ucy', purging
2023-05-29 07:07:39,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_1r4x0cs', purging
2023-05-29 07:07:39,924 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5v632ayq', purging
2023-05-29 07:07:39,925 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:39,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:40,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:40,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:40,170 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:40,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:40,996 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:41,010 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:41,174 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:42,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lxbwyy3s', purging
2023-05-29 07:07:42,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xee5_71_', purging
2023-05-29 07:07:42,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-feuok9fk', purging
2023-05-29 07:07:42,383 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:42,383 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:42,399 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:42,399 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:42,581 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:42,581 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:43,443 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:43,496 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:43,651 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:44,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q5rx4ol0', purging
2023-05-29 07:07:44,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hvdmqghk', purging
2023-05-29 07:07:44,867 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h8qsa5c5', purging
2023-05-29 07:07:44,868 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:44,868 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:44,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:44,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:45,068 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:45,068 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:45,907 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:45,942 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:46,120 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:47,293 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h774j_8w', purging
2023-05-29 07:07:47,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-td6zy4nw', purging
2023-05-29 07:07:47,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nepbc6k3', purging
2023-05-29 07:07:47,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:47,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:47,335 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:47,335 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:47,510 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:47,510 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:48,355 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:48,396 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:48,557 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:49,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n98jb6b9', purging
2023-05-29 07:07:49,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9z95wb3y', purging
2023-05-29 07:07:49,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qw6gdvpz', purging
2023-05-29 07:07:49,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:49,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:49,753 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:49,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:49,939 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:49,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:50,776 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:50,818 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:50,975 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:52,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rtlvhulq', purging
2023-05-29 07:07:52,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ho1mm5ih', purging
2023-05-29 07:07:52,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xca9rmtn', purging
2023-05-29 07:07:52,169 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:52,169 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:52,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:52,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:52,349 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:52,349 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:53,234 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:53,249 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:53,417 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:54,607 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lgpgiy5t', purging
2023-05-29 07:07:54,607 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dupmxuit', purging
2023-05-29 07:07:54,608 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9wgmldo3', purging
2023-05-29 07:07:54,608 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:54,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:54,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:54,644 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:54,819 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:54,819 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:55,661 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:55,694 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:55,864 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:57,032 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vpmuta4c', purging
2023-05-29 07:07:57,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pq0fd_0k', purging
2023-05-29 07:07:57,033 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fbdyiawj', purging
2023-05-29 07:07:57,033 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:57,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:57,087 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:57,087 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:57,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:57,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:07:58,071 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:58,116 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:58,270 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:07:59,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-idzce20q', purging
2023-05-29 07:07:59,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r24u44m8', purging
2023-05-29 07:07:59,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-69f95acs', purging
2023-05-29 07:07:59,440 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:59,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:59,487 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:59,487 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:07:59,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:07:59,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:00,518 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:00,532 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:00,690 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:01,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tgs292wt', purging
2023-05-29 07:08:01,896 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f3lp8sgm', purging
2023-05-29 07:08:01,897 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iuxghmzh', purging
2023-05-29 07:08:01,897 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:01,897 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:01,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:01,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:02,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:02,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:02,963 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:03,005 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:03,159 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:04,348 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ifx3khu2', purging
2023-05-29 07:08:04,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-77vsvdhd', purging
2023-05-29 07:08:04,349 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g3nt1j6t', purging
2023-05-29 07:08:04,350 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:04,350 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:04,401 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:04,402 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:04,557 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:04,557 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:05,399 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:05,422 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:05,603 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:06,781 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-udtajkc_', purging
2023-05-29 07:08:06,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zwjzj998', purging
2023-05-29 07:08:06,782 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xd3281tk', purging
2023-05-29 07:08:06,783 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:06,783 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:06,838 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:06,838 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:06,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:06,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:07,852 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:07,877 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:08,050 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:09,248 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-70l7iuy0', purging
2023-05-29 07:08:09,248 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-44k0jxtn', purging
2023-05-29 07:08:09,249 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-s7zt8e8b', purging
2023-05-29 07:08:09,249 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:09,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:09,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:09,275 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:09,440 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:09,440 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:10,300 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:10,343 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:10,516 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:11,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2wppa46c', purging
2023-05-29 07:08:11,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p2au3r5h', purging
2023-05-29 07:08:11,688 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2gd08wog', purging
2023-05-29 07:08:11,689 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:11,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:11,737 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:11,737 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:11,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:11,871 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:12,757 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:12,783 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:12,946 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:14,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q_lzandg', purging
2023-05-29 07:08:14,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-162ocs8v', purging
2023-05-29 07:08:14,180 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fr00f6d2', purging
2023-05-29 07:08:14,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:14,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:14,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:14,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:14,313 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:14,313 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:15,260 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:15,288 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:15,455 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:16,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ez_dh4z8', purging
2023-05-29 07:08:16,658 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ccn9vjd0', purging
2023-05-29 07:08:16,659 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9o5iiblz', purging
2023-05-29 07:08:16,659 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:16,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:16,717 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:16,717 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:16,861 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:16,861 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:17,719 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:17,745 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:17,923 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:19,096 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cv0buvbo', purging
2023-05-29 07:08:19,097 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4v8qpg1s', purging
2023-05-29 07:08:19,097 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hy5834b5', purging
2023-05-29 07:08:19,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:19,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:19,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:19,127 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:19,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:19,320 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:20,140 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:20,171 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:20,367 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:21,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nr4cx4a2', purging
2023-05-29 07:08:21,516 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ei1clo8_', purging
2023-05-29 07:08:21,517 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qezhoe19', purging
2023-05-29 07:08:21,517 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:21,517 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:21,560 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:21,560 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:21,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:21,751 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:22,584 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:22,619 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:22,795 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:23,952 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bn7gr1l_', purging
2023-05-29 07:08:23,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sh103qux', purging
2023-05-29 07:08:23,953 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b31lsztn', purging
2023-05-29 07:08:23,954 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:23,954 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:24,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:24,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:24,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:24,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:25,019 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:25,043 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:25,223 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:26,391 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h6p1f8m4', purging
2023-05-29 07:08:26,392 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-97hoqgpv', purging
2023-05-29 07:08:26,392 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d0697lr_', purging
2023-05-29 07:08:26,393 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:26,393 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:26,403 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:26,403 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:26,612 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:26,612 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:27,427 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:27,464 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:27,625 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:28,801 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-him_fkyf', purging
2023-05-29 07:08:28,802 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uu21u5zz', purging
2023-05-29 07:08:28,802 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xi6sjl1u', purging
2023-05-29 07:08:28,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:28,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:28,853 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:28,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:29,034 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:29,034 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:29,853 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:29,887 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:30,056 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:31,240 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zpbtovzr', purging
2023-05-29 07:08:31,240 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-utv1t17j', purging
2023-05-29 07:08:31,241 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xwtm8xp6', purging
2023-05-29 07:08:31,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:31,241 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:31,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:31,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:31,441 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:31,441 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:32,301 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:32,331 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:32,515 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:33,701 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tc7h6or3', purging
2023-05-29 07:08:33,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ro9x0xjx', purging
2023-05-29 07:08:33,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k1bf22h6', purging
2023-05-29 07:08:33,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:33,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:33,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:33,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:33,865 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:33,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:34,772 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:34,811 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:34,966 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:36,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jwfox2pn', purging
2023-05-29 07:08:36,175 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sdpl3jb2', purging
2023-05-29 07:08:36,176 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-h93wc70i', purging
2023-05-29 07:08:36,176 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:36,176 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:36,184 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:36,184 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:36,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:36,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:37,223 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:37,261 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:37,422 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:38,614 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yxnb_km9', purging
2023-05-29 07:08:38,615 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0bu03x9j', purging
2023-05-29 07:08:38,615 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p0f06kfh', purging
2023-05-29 07:08:38,615 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:38,615 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:38,658 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:38,659 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:38,826 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:38,826 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:39,682 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:39,735 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:39,901 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:41,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pmtuiev9', purging
2023-05-29 07:08:41,047 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-re9nazab', purging
2023-05-29 07:08:41,048 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4nvtzq2p', purging
2023-05-29 07:08:41,048 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:41,048 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:41,135 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:41,135 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:41,297 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:41,297 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:42,123 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:42,147 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:42,311 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:43,530 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pjx82gko', purging
2023-05-29 07:08:43,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-btih7swc', purging
2023-05-29 07:08:43,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-omomv3n2', purging
2023-05-29 07:08:43,531 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:43,531 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:43,532 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:43,532 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:43,695 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:43,695 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:44,606 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:44,608 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:44,783 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:45,958 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-decd8b_d', purging
2023-05-29 07:08:45,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yoagirzz', purging
2023-05-29 07:08:45,959 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3vowme7v', purging
2023-05-29 07:08:45,960 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:45,960 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:46,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:46,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:46,194 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:46,194 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:47,039 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:47,067 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:47,245 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:48,458 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sd51hcif', purging
2023-05-29 07:08:48,458 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6q3kntuu', purging
2023-05-29 07:08:48,459 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m39swfkw', purging
2023-05-29 07:08:48,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:48,459 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:48,481 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:48,481 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:48,662 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:48,662 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:49,509 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:49,549 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:49,712 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:50,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pgy8pwgt', purging
2023-05-29 07:08:50,894 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zr4pinuv', purging
2023-05-29 07:08:50,895 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hp7jjqoq', purging
2023-05-29 07:08:50,895 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:50,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:50,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:50,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:51,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:51,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:51,937 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:51,967 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:52,151 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:53,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-io8afv0a', purging
2023-05-29 07:08:53,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-545z5dr0', purging
2023-05-29 07:08:53,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bovqsyk1', purging
2023-05-29 07:08:53,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:53,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:53,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:53,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:53,491 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:53,491 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:54,398 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:54,432 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:54,610 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:55,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-56y7pz_2', purging
2023-05-29 07:08:55,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6zp50r6f', purging
2023-05-29 07:08:55,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-04bqe1ym', purging
2023-05-29 07:08:55,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:55,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:55,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:55,863 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:56,017 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:56,018 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:56,838 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:56,870 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:57,048 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:58,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qywtknoe', purging
2023-05-29 07:08:58,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-glvbhtqr', purging
2023-05-29 07:08:58,228 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8m37uo38', purging
2023-05-29 07:08:58,229 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:58,229 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:58,248 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:58,249 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:08:58,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:08:58,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:08:59,270 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:59,298 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:08:59,478 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:00,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bn_ne3_l', purging
2023-05-29 07:09:00,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e2hcg9sf', purging
2023-05-29 07:09:00,656 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ub3kmyqj', purging
2023-05-29 07:09:00,657 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:00,657 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:00,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:00,688 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:00,863 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:00,863 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:01,705 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:01,738 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:01,915 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:03,078 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fkjpga_2', purging
2023-05-29 07:09:03,079 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o_3e_nhy', purging
2023-05-29 07:09:03,079 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fpomnxu7', purging
2023-05-29 07:09:03,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:03,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:03,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:03,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:03,315 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:03,315 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:04,122 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:04,162 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:04,321 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:05,531 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ubvte1x3', purging
2023-05-29 07:09:05,532 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dvw_3_sk', purging
2023-05-29 07:09:05,532 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zawfqrky', purging
2023-05-29 07:09:05,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:05,533 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:05,580 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:05,580 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:05,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:05,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:06,620 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:06,638 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:06,796 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:07,977 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lyw0mnl4', purging
2023-05-29 07:09:07,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0n34boc1', purging
2023-05-29 07:09:07,978 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dk8tuj68', purging
2023-05-29 07:09:07,978 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:07,978 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:08,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:08,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:08,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:08,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:09,005 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:09,047 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:09,216 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:10,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-di_8wbs4', purging
2023-05-29 07:09:10,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-18ukznba', purging
2023-05-29 07:09:10,365 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8la7yaf8', purging
2023-05-29 07:09:10,366 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:10,366 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:10,432 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:10,432 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:10,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:10,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:11,409 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:11,430 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:11,629 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:12,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kkgx8a7i', purging
2023-05-29 07:09:12,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2cv7hya2', purging
2023-05-29 07:09:12,787 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gsd8f7if', purging
2023-05-29 07:09:12,788 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:12,788 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:12,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:12,803 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:13,008 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:13,008 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:13,814 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:13,848 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:14,009 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:15,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-o_vhpdrb', purging
2023-05-29 07:09:15,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2hbgcaal', purging
2023-05-29 07:09:15,185 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rp6rmm6y', purging
2023-05-29 07:09:15,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:15,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:15,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:15,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:15,394 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:15,395 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:16,240 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:16,285 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:16,442 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:17,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c0_1zlm_', purging
2023-05-29 07:09:17,633 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-93yex5w7', purging
2023-05-29 07:09:17,634 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a16ex55y', purging
2023-05-29 07:09:17,634 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:17,634 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:17,645 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:17,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:17,828 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:17,828 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:18,709 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:18,747 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:18,915 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:20,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wns5mu3g', purging
2023-05-29 07:09:20,100 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wo5ys_xl', purging
2023-05-29 07:09:20,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-drysdyvc', purging
2023-05-29 07:09:20,101 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:20,101 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:20,186 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:20,186 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:20,345 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:20,345 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:21,158 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:21,192 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:21,352 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:22,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3l098cc_', purging
2023-05-29 07:09:22,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5htxu9mz', purging
2023-05-29 07:09:22,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ajpazgi9', purging
2023-05-29 07:09:22,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:22,564 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:22,570 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:22,570 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:22,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:22,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:23,636 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:23,638 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:23,797 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:25,059 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:25,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qpg4jg33', purging
2023-05-29 07:09:25,059 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:25,059 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-shapwc3p', purging
2023-05-29 07:09:25,060 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fmqgtuv0', purging
2023-05-29 07:09:25,060 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:25,060 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:25,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:25,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:26,131 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:26,150 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:26,352 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:27,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n8ml8t0o', purging
2023-05-29 07:09:27,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dhh8bj4g', purging
2023-05-29 07:09:27,484 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8v5gouiu', purging
2023-05-29 07:09:27,485 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:27,485 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:27,546 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:27,546 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:27,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:27,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:28,556 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:28,579 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:28,759 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:29,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zt3m7gzo', purging
2023-05-29 07:09:29,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fogbun9v', purging
2023-05-29 07:09:29,965 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jnolnewk', purging
2023-05-29 07:09:29,966 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:29,966 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:29,969 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:29,969 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:30,112 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:30,112 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:31,037 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:31,061 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:31,231 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:32,419 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_7dlzvck', purging
2023-05-29 07:09:32,420 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-u2g9yib3', purging
2023-05-29 07:09:32,420 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p5_n8cnw', purging
2023-05-29 07:09:32,421 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:32,421 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:32,447 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:32,447 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:32,625 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:32,625 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:33,460 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:33,491 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:33,658 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:34,836 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-svs9ii19', purging
2023-05-29 07:09:34,836 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2i6xlx6u', purging
2023-05-29 07:09:34,836 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gc2pmxgn', purging
2023-05-29 07:09:34,837 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:34,837 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:34,854 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:34,854 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:35,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:35,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:35,888 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:35,940 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:36,092 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:37,317 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hjdnbz4b', purging
2023-05-29 07:09:37,317 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-74stdop1', purging
2023-05-29 07:09:37,317 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rz038z5o', purging
2023-05-29 07:09:37,318 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:37,318 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:37,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:37,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:37,454 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:37,454 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:38,370 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:38,396 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:38,566 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:39,763 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9u8zc87p', purging
2023-05-29 07:09:39,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e3f5y141', purging
2023-05-29 07:09:39,764 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fluiqit8', purging
2023-05-29 07:09:39,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:39,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:39,765 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:39,765 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:39,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:39,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:40,802 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:40,847 - distributed.nanny - WARNING - Restarting worker

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-29 07:09:42,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uz5ovr9w', purging
2023-05-29 07:09:42,161 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yv7ady4y', purging
2023-05-29 07:09:42,162 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1mwtignx', purging
2023-05-29 07:09:42,162 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:42,162 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:42,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:42,177 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:43,003 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:43,163 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:44,356 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n5meb67p', purging
2023-05-29 07:09:44,357 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xacp1t2u', purging
2023-05-29 07:09:44,357 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:44,357 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:44,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:44,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:45,204 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:45,377 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:46,551 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mimf6ray', purging
2023-05-29 07:09:46,552 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-og5s4tsa', purging
2023-05-29 07:09:46,552 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:46,552 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:46,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:46,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:47,379 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:47,541 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:48,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-gmiuq1g6', purging
2023-05-29 07:09:48,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-j44iy1i1', purging
2023-05-29 07:09:48,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:48,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:48,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:48,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:49,603 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:49,772 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:51,004 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6s_iq0xe', purging
2023-05-29 07:09:51,005 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-99pkosjf', purging
2023-05-29 07:09:51,006 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:51,006 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:51,167 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:51,167 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:51,844 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:52,012 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:53,202 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pg8lcwcg', purging
2023-05-29 07:09:53,202 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yqt8tnrw', purging
2023-05-29 07:09:53,203 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:53,203 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:53,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:53,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:54,048 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:54,211 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:55,416 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-je10_5b6', purging
2023-05-29 07:09:55,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zuuwbd2e', purging
2023-05-29 07:09:55,417 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:55,417 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:55,555 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:55,555 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:56,243 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:56,414 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:57,588 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l40hn5l9', purging
2023-05-29 07:09:57,589 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m3vd96s1', purging
2023-05-29 07:09:57,589 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:57,589 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:57,756 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:57,756 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:09:58,445 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:58,614 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:09:59,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p4z_2e12', purging
2023-05-29 07:09:59,798 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pbw8gh2z', purging
2023-05-29 07:09:59,799 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:59,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:09:59,955 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:09:59,955 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:00,639 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:00,815 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:02,018 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fz2knhje', purging
2023-05-29 07:10:02,018 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-koua1dpv', purging
2023-05-29 07:10:02,019 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:02,019 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:02,204 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:02,204 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:02,869 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:03,033 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:04,207 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uw0o79sh', purging
2023-05-29 07:10:04,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xi5ww8pt', purging
2023-05-29 07:10:04,208 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:04,208 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:04,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:04,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:05,122 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:05,277 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:06,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-278wc61e', purging
2023-05-29 07:10:06,504 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-odjqx5yt', purging
2023-05-29 07:10:06,505 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:06,505 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:06,620 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:06,620 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:07,357 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:07,522 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:08,718 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lvsnl2xi', purging
2023-05-29 07:10:08,718 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_y6i_k0z', purging
2023-05-29 07:10:08,719 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:08,719 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:08,870 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:08,870 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:09,558 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:09,730 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:10,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-v6mkhtag', purging
2023-05-29 07:10:10,913 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rkvtotqf', purging
2023-05-29 07:10:10,914 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:10,914 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:11,079 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:11,079 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:11,759 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:11,914 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:13,146 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8kenkjth', purging
2023-05-29 07:10:13,146 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kx1vammv', purging
2023-05-29 07:10:13,147 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:13,147 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:13,280 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:13,281 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:13,988 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:14,146 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:15,358 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5e9gwhae', purging
2023-05-29 07:10:15,358 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8dhtsfzx', purging
2023-05-29 07:10:15,359 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:15,359 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:15,494 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:15,494 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:16,184 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:16,339 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:17,546 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bped0e1y', purging
2023-05-29 07:10:17,547 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2aekxs31', purging
2023-05-29 07:10:17,547 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:17,547 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:17,685 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:17,685 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:18,393 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:18,552 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:19,770 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-44d1dmsj', purging
2023-05-29 07:10:19,771 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n6ku0x5b', purging
2023-05-29 07:10:19,771 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:19,771 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:19,909 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:19,909 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:20,621 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:20,785 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:21,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vyq2my3n', purging
2023-05-29 07:10:21,973 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ds_c08o9', purging
2023-05-29 07:10:21,974 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:21,974 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:22,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:22,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:22,845 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:23,020 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:24,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zj92wcag', purging
2023-05-29 07:10:24,253 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ese2ufys', purging
2023-05-29 07:10:24,254 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:24,254 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:24,380 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:24,380 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:25,091 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:25,276 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:26,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zomkklq_', purging
2023-05-29 07:10:26,468 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7e4x6wdz', purging
2023-05-29 07:10:26,469 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:26,469 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:26,606 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:26,606 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:27,324 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:27,489 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:28,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-b2k0l71v', purging
2023-05-29 07:10:28,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-t663_x8n', purging
2023-05-29 07:10:28,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:28,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:28,844 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:28,844 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:29,539 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:29,697 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:30,905 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lscydjhl', purging
2023-05-29 07:10:30,905 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k38me9tm', purging
2023-05-29 07:10:30,906 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:30,906 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:31,080 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:31,080 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:31,760 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:31,921 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:33,140 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ym6wsgl0', purging
2023-05-29 07:10:33,141 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4ivmvqru', purging
2023-05-29 07:10:33,141 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:33,141 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:33,290 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:33,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:33,969 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:34,130 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:35,351 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f5ipx0vy', purging
2023-05-29 07:10:35,352 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dzew7cye', purging
2023-05-29 07:10:35,352 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:35,352 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:35,498 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:35,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:36,214 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:36,381 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:37,564 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ltrzgf2e', purging
2023-05-29 07:10:37,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7r0g1vga', purging
2023-05-29 07:10:37,565 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:37,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:37,728 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:37,728 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:38,394 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:38,569 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:39,746 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d2p8e4dq', purging
2023-05-29 07:10:39,747 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tofpqsvb', purging
2023-05-29 07:10:39,747 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:39,747 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:39,901 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:39,901 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:40,588 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:40,752 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:41,932 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zjkw1f89', purging
2023-05-29 07:10:41,933 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-m0wrv_kd', purging
2023-05-29 07:10:41,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:41,933 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:42,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:42,102 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:42,765 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:42,934 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:44,117 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0usf7ze8', purging
2023-05-29 07:10:44,117 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ay16voxr', purging
2023-05-29 07:10:44,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:44,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:44,284 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:44,284 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:44,952 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:45,126 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:46,293 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5g2h4fcf', purging
2023-05-29 07:10:46,294 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3vtmx1hn', purging
2023-05-29 07:10:46,294 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:46,294 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:46,474 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:46,474 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:47,118 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:47,302 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:48,460 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-haraibmo', purging
2023-05-29 07:10:48,461 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cxaqv107', purging
2023-05-29 07:10:48,462 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:48,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:48,651 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:48,651 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:49,301 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:49,473 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:50,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_uwi_044', purging
2023-05-29 07:10:50,647 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2uqz4_a3', purging
2023-05-29 07:10:50,648 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:50,648 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:50,829 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:50,829 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:51,487 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:51,651 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:52,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x5fxmg7o', purging
2023-05-29 07:10:52,874 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ggxuajuc', purging
2023-05-29 07:10:52,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:52,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:53,013 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:53,014 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:53,724 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:53,895 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:55,122 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-brb7h2jg', purging
2023-05-29 07:10:55,123 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2wahegtn', purging
2023-05-29 07:10:55,123 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:55,123 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:55,267 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:55,267 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:55,972 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:56,138 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:57,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kw3c_e39', purging
2023-05-29 07:10:57,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bdhvdc6s', purging
2023-05-29 07:10:57,321 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:57,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:57,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:57,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:10:58,163 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:58,330 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:10:59,507 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7f8n46_j', purging
2023-05-29 07:10:59,507 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-59vj7kaj', purging
2023-05-29 07:10:59,508 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:59,508 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:10:59,683 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:10:59,683 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:00,342 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:00,509 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:01,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1zzpziut', purging
2023-05-29 07:11:01,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lgtra4bc', purging
2023-05-29 07:11:01,722 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:01,722 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:01,845 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:01,845 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:02,584 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:02,747 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:03,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vhhk90sg', purging
2023-05-29 07:11:03,927 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8voqsq_2', purging
2023-05-29 07:11:03,928 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:03,928 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:04,095 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:04,095 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:04,756 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:04,927 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:06,084 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d0tk75l5', purging
2023-05-29 07:11:06,085 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dxlo_097', purging
2023-05-29 07:11:06,085 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:06,085 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:06,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:06,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:06,928 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:07,095 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:08,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wqkp75eu', purging
2023-05-29 07:11:08,265 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wsh1gvzx', purging
2023-05-29 07:11:08,266 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:08,266 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:08,425 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:08,425 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:09,086 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:09,250 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:10,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y12ljwza', purging
2023-05-29 07:11:10,413 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x52bi5h1', purging
2023-05-29 07:11:10,414 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:10,414 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:10,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:10,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:11,233 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:11,390 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:12,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wy2ym638', purging
2023-05-29 07:11:12,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-905w6_jz', purging
2023-05-29 07:11:12,566 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:12,566 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:12,713 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:12,713 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:13,401 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:13,563 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:14,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-787wiu8z', purging
2023-05-29 07:11:14,739 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1k7xohaz', purging
2023-05-29 07:11:14,740 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:14,740 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:14,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:14,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:15,560 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:15,731 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:16,909 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c4wabm8l', purging
2023-05-29 07:11:16,909 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f79oe_yf', purging
2023-05-29 07:11:16,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:16,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:17,073 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:17,073 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:17,735 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:17,904 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:19,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xcbvd7c6', purging
2023-05-29 07:11:19,093 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-iybc9znv', purging
2023-05-29 07:11:19,094 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:19,094 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:19,239 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:19,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:19,922 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:20,079 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:21,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-r6y7x1ib', purging
2023-05-29 07:11:21,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lyk62c4q', purging
2023-05-29 07:11:21,272 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:21,272 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:21,424 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:21,424 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:22,114 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:22,280 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:23,472 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_2xuvula', purging
2023-05-29 07:11:23,472 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5f5p_30a', purging
2023-05-29 07:11:23,473 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:23,473 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:23,593 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:23,593 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:24,291 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:24,457 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:25,628 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-chlx9n_j', purging
2023-05-29 07:11:25,628 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i7v7b094', purging
2023-05-29 07:11:25,629 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:25,629 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:25,772 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:25,772 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:26,477 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:26,647 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:27,865 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2nphjyo2', purging
2023-05-29 07:11:27,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8dy6sxso', purging
2023-05-29 07:11:27,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:27,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:27,989 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:27,989 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:28,715 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:28,874 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:30,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-skll4ucq', purging
2023-05-29 07:11:30,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pw591x_1', purging
2023-05-29 07:11:30,074 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:30,075 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:30,214 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:30,214 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:30,901 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:31,073 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:32,277 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-swdnkz6t', purging
2023-05-29 07:11:32,278 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dqikpm8w', purging
2023-05-29 07:11:32,278 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:32,278 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:32,439 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:32,439 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:33,112 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:33,267 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:34,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-emf97h5c', purging
2023-05-29 07:11:34,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3b_2ketj', purging
2023-05-29 07:11:34,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:34,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:34,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:34,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:35,342 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:35,526 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:36,720 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-46ng5die', purging
2023-05-29 07:11:36,721 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kssffhaf', purging
2023-05-29 07:11:36,721 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:36,721 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:36,885 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:36,885 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:37,554 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:37,728 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:38,899 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-yi5v3tin', purging
2023-05-29 07:11:38,900 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5l5rthru', purging
2023-05-29 07:11:38,900 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:38,900 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:39,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:39,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:39,737 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:39,907 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:41,083 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6527dfse', purging
2023-05-29 07:11:41,083 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qzt7c9le', purging
2023-05-29 07:11:41,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:41,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:41,241 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:41,241 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:41,913 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:42,081 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:43,270 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1e88ywrg', purging
2023-05-29 07:11:43,271 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ddmov5jq', purging
2023-05-29 07:11:43,271 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:43,271 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:43,458 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:43,458 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:44,111 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:44,286 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:45,439 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mjeumgis', purging
2023-05-29 07:11:45,440 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sukrpr6b', purging
2023-05-29 07:11:45,440 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:45,440 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:45,652 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:45,652 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:46,246 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:46,415 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:47,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1hqe4xcf', purging
2023-05-29 07:11:47,602 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-0vc5acc5', purging
2023-05-29 07:11:47,603 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:47,603 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:47,745 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:47,745 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:48,436 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:48,598 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:49,790 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7vvwyp78', purging
2023-05-29 07:11:49,791 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_19xtc81', purging
2023-05-29 07:11:49,791 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:49,791 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:49,959 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:49,959 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:50,625 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:50,799 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:51,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-exson87k', purging
2023-05-29 07:11:51,964 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y2jvklzp', purging
2023-05-29 07:11:51,965 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:51,965 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:52,137 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:52,137 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:52,809 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:52,969 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:54,156 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-83msvn2d', purging
2023-05-29 07:11:54,156 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7akkwuy0', purging
2023-05-29 07:11:54,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:54,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:54,296 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:54,296 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:55,000 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:55,158 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:56,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-axq85xpw', purging
2023-05-29 07:11:56,343 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-z141w69z', purging
2023-05-29 07:11:56,344 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:56,344 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:56,477 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:56,477 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:57,200 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:57,360 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:58,532 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-dooulhkm', purging
2023-05-29 07:11:58,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4khlyefg', purging
2023-05-29 07:11:58,533 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:58,534 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:11:58,725 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:11:58,725 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:11:59,378 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:11:59,545 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:00,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5lpbflag', purging
2023-05-29 07:12:00,729 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ezbc0dyf', purging
2023-05-29 07:12:00,730 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:00,730 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:00,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:00,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:01,565 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:01,731 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:02,898 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-32x41udx', purging
2023-05-29 07:12:02,899 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vd2rvwfp', purging
2023-05-29 07:12:02,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:02,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:03,052 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:03,053 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:03,710 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:03,882 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:05,023 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9zjckiv4', purging
2023-05-29 07:12:05,023 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-a_rx2i9_', purging
2023-05-29 07:12:05,023 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:05,024 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:05,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:05,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:05,841 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:06,012 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:07,164 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-680t1bvy', purging
2023-05-29 07:12:07,164 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-eoz83lpi', purging
2023-05-29 07:12:07,165 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:07,165 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:07,362 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:07,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:07,987 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:08,152 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:09,346 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-3y2xcio1', purging
2023-05-29 07:12:09,347 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-in5kxg47', purging
2023-05-29 07:12:09,347 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:09,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:09,492 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:09,492 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:10,189 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:10,348 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:11,536 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-l7vmr3mu', purging
2023-05-29 07:12:11,537 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nyc_e7oq', purging
2023-05-29 07:12:11,537 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:11,537 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:11,703 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:11,703 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:12,368 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:12,540 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:13,690 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-sruyjxfl', purging
2023-05-29 07:12:13,690 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6a2ls5hn', purging
2023-05-29 07:12:13,691 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:13,691 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:13,910 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:13,910 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:14,511 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:14,685 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:15,877 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qy7lws22', purging
2023-05-29 07:12:15,878 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wgbpclgt', purging
2023-05-29 07:12:15,878 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:15,878 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:16,029 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:16,029 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:16,724 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:16,879 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:18,069 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_2a5m0eu', purging
2023-05-29 07:12:18,070 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w6iufxu0', purging
2023-05-29 07:12:18,070 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:18,070 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:18,245 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:18,245 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:18,892 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:19,068 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:20,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rgqq7sc6', purging
2023-05-29 07:12:20,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ytzgxer', purging
2023-05-29 07:12:20,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:20,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:20,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:20,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:21,038 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:21,200 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:22,381 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xgbu7g1b', purging
2023-05-29 07:12:22,382 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zmf65aog', purging
2023-05-29 07:12:22,382 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:22,382 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:22,512 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:22,513 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:23,207 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:23,373 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:24,547 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_3nuu6x_', purging
2023-05-29 07:12:24,547 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9_lgdg7d', purging
2023-05-29 07:12:24,548 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:24,548 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:24,687 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:24,687 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:25,387 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:25,554 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:26,759 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kzqb82er', purging
2023-05-29 07:12:26,760 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-2ihkv2rn', purging
2023-05-29 07:12:26,761 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:26,761 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:26,907 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:26,907 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:27,609 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:27,784 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:28,968 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-oartkm3d', purging
2023-05-29 07:12:28,968 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-p7wpcc77', purging
2023-05-29 07:12:28,968 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:28,968 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:29,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:29,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:29,818 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:29,979 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:31,178 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-8wdpr_mv', purging
2023-05-29 07:12:31,179 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-i1zt7roy', purging
2023-05-29 07:12:31,179 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:31,179 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:31,363 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:31,363 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:32,037 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:32,204 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:33,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_5n9mzcr', purging
2023-05-29 07:12:33,397 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-spiez_cu', purging
2023-05-29 07:12:33,398 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:33,398 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:33,564 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:33,565 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:34,240 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:34,410 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:35,585 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ni5mhnzo', purging
2023-05-29 07:12:35,586 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-cnqf7wsm', purging
2023-05-29 07:12:35,586 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:35,586 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:35,736 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:35,736 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:36,400 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:36,564 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:37,714 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xnzn7wjn', purging
2023-05-29 07:12:37,715 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uphxq9om', purging
2023-05-29 07:12:37,715 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:37,715 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:37,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:37,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:38,540 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:38,712 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:39,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mqec5jvd', purging
2023-05-29 07:12:39,863 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fla79eou', purging
2023-05-29 07:12:39,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:39,864 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:40,084 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:40,084 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:40,663 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:40,835 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:41,984 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-q8rr7x1g', purging
2023-05-29 07:12:41,984 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-vug4mbq0', purging
2023-05-29 07:12:41,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:41,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:42,180 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:42,180 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:42,810 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:42,982 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:44,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7r56i4hr', purging
2023-05-29 07:12:44,127 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-lz17t5co', purging
2023-05-29 07:12:44,127 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:44,128 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:44,332 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:44,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:44,939 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:45,127 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:46,319 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-5n8_alnv', purging
2023-05-29 07:12:46,320 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-di82vsmr', purging
2023-05-29 07:12:46,320 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:46,321 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:46,479 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:46,479 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:47,176 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:47,335 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:48,541 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7epzl66c', purging
2023-05-29 07:12:48,542 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-f6wyxukw', purging
2023-05-29 07:12:48,542 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:48,542 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:48,679 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:48,679 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:49,370 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:49,542 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:50,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ckxqjzyo', purging
2023-05-29 07:12:50,723 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-pozwaly3', purging
2023-05-29 07:12:50,724 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:50,724 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:50,864 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:50,865 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:51,562 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:51,728 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:52,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bh3_y3k0', purging
2023-05-29 07:12:52,919 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ceyd11to', purging
2023-05-29 07:12:52,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:52,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:53,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:53,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:53,755 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:53,930 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:55,112 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-7io13ilm', purging
2023-05-29 07:12:55,113 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-_5v4994v', purging
2023-05-29 07:12:55,113 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:55,113 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:55,295 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:55,295 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:55,979 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:56,142 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:57,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-qflzq_vl', purging
2023-05-29 07:12:57,332 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mb2ibyae', purging
2023-05-29 07:12:57,333 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:57,333 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:57,459 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:57,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:12:58,149 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:58,313 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:12:59,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bmjam1hw', purging
2023-05-29 07:12:59,502 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ubxyu_3f', purging
2023-05-29 07:12:59,503 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:59,503 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:12:59,644 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:12:59,645 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:00,329 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:00,498 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:01,680 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xqtxmtrv', purging
2023-05-29 07:13:01,680 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9jejtxvu', purging
2023-05-29 07:13:01,681 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:01,681 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:13:01,808 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:01,808 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:02,549 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:02,708 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:03,891 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9f1skn6b', purging
2023-05-29 07:13:03,892 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-d07g4kro', purging
2023-05-29 07:13:03,892 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:03,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:13:04,086 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:04,086 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:04,737 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:04,893 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:06,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-9ylsfn8s', purging
2023-05-29 07:13:06,066 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-uz1_98n_', purging
2023-05-29 07:13:06,067 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:06,067 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:13:06,237 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:06,237 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:06,888 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:07,059 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:08,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zxwsnqky', purging
2023-05-29 07:13:08,243 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-odzxloiw', purging
2023-05-29 07:13:08,244 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:08,244 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:13:08,389 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:08,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:09,062 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:09,236 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:10,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-42vj53js', purging
2023-05-29 07:13:10,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-74cs584y', purging
2023-05-29 07:13:10,429 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:10,429 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-05-29 07:13:10,595 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:10,595 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 857, in _wait_until_connected
    msg = self.init_result_q.get_nowait()
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 135, in get_nowait
    return self.get(False)
  File "/opt/conda/envs/gdf/lib/python3.9/multiprocessing/queues.py", line 116, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 549, in _on_worker_exit
    await self.instantiate()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 442, in instantiate
    result = await self.process.start()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 718, in start
    msg = await self._wait_until_connected(uid)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 859, in _wait_until_connected
    await asyncio.sleep(self._init_msg_interval)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 652, in sleep
    return await future
asyncio.exceptions.CancelledError
2023-05-29 07:13:11,505 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:12,805 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aw1huwly', purging
2023-05-29 07:13:12,805 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bsbzsmt9', purging
2023-05-29 07:13:12,806 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:12,806 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:13,580 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:14,882 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zcoblnwc', purging
2023-05-29 07:13:14,883 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:14,883 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:15,641 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:16,942 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-1dck6eot', purging
2023-05-29 07:13:16,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:16,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:17,701 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:19,002 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bmt0l9ee', purging
2023-05-29 07:13:19,003 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:19,003 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:19,783 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:21,087 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-089f01dw', purging
2023-05-29 07:13:21,088 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:21,088 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:21,857 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:23,177 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-zwggpwe2', purging
2023-05-29 07:13:23,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:23,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:23,961 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:25,274 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-nm24io04', purging
2023-05-29 07:13:25,274 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:25,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
2023-05-29 07:13:26,031 - distributed.nanny - WARNING - Restarting worker
2023-05-29 07:13:27,323 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mzcqwm2x', purging
2023-05-29 07:13:27,324 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-05-29 07:13:27,324 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/opt/conda/envs/gdf/bin/python: symbol lookup error: /opt/conda/envs/gdf/lib/ucx/libuct_ib.so.0: undefined symbol: ibv_reg_dmabuf_mr
/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 801 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
