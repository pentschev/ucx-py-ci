[dgx13:84446:0:84446] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  84446) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f8e7773deed]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c0e4) [0x7f8e7773e0e4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c2aa) [0x7f8e7773e2aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f8f30021420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f8e777bf577]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f8e777e7d5d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2086f) [0x7f8e776f686f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a48) [0x7f8e776f9a48]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f8e77747639]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f8e776f8b5d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f8e777bc47a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f8e778835fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55c0471c16fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0471bd094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55c0471ce519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0471be5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0471ce7c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55c0471dbe83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55c0472e6b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55c047178d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55c0471c57f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55c0471c3929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0471ce7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0471be5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0471ce7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0471be5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0471ce7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0471be5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0471ce7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0471be5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0471bd094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55c0471ce519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55c0471bf128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0471bd094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55c0471dbccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55c0471dc44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55c04729f10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55c0471c677c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55c0471c16fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0471ce7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55c0471dbdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55c0471c16fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0471ce7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0471be5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0471bd094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55c0471ce519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55c0471be5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55c0471ce7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55c0471be312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0471bd094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55c0471ce519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55c0471bf128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55c0471bd094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55c0471bcd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55c0471bcd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55c04726a07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55c047296fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55c047293353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55c04728b16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55c04728b05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55c04728a297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55c04725df07]
=================================
2023-10-03 07:37:12,085 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37965 -> ucx://127.0.0.1:58461
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fed7934a100, tag: 0x37b0b99b6b8bae45, nbytes: 800000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:12,180 - distributed.nanny - WARNING - Restarting worker
[dgx13:84432:0:84432] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  84432) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f17e38deeed]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c0e4) [0x7f17e38df0e4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c2aa) [0x7f17e38df2aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f188a1ba420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f17e3960577]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f17e3988d5d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2086f) [0x7f17e389786f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a48) [0x7f17e389aa48]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f17e38e8639]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f17e3899b5d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f17e395d47a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f17e3a245fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x56195cd316fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56195cd2d094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56195cd3e519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56195cd2e5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1e3162) [0x56195cde1162]
17  /opt/conda/envs/gdf/lib/python3.9/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so(+0x81e9) [0x7f180ab8a1e9]
18  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56195cd3677c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x56195cce8d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x56195cd357f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x56195cd33929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56195cd3e7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56195cd2e5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56195cd3e7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56195cd2e5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56195cd3e7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56195cd2e5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56195cd3e7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56195cd2e5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56195cd2d094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56195cd3e519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x56195cd2f128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56195cd2d094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x56195cd4bccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x56195cd4c44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x56195ce0f10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x56195cd3677c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x56195cd316fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56195cd3e7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x56195cd4bdac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x56195cd316fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56195cd3e7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56195cd2e5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56195cd2d094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56195cd3e519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x56195cd2e5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x56195cd3e7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x56195cd2e312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56195cd2d094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x56195cd3e519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x56195cd2f128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x56195cd2d094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x56195cd2cd68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56195cd2cd19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56195cdda07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x56195ce06fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x56195ce03353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x56195cdfb16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x56195cdfb05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x56195cdfa297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x56195cdcdf07]
=================================
[dgx13:84443:0:84443] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  84443) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fef91fc9eed]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c0e4) [0x7fef91fca0e4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c2aa) [0x7fef91fca2aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7ff03a8c6420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fefa8071577]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7fefa8099d5d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2086f) [0x7fef91f8286f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a48) [0x7fef91f85a48]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fef91fd3639]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fef91f84b5d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fefa806e47a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7fefa81355fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55aee32136fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aee320f094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55aee3220519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aee32105c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aee32207c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55aee322de83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55aee3338b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55aee31cad05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55aee32177f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55aee3215929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aee32207c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aee32105c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aee32207c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aee32105c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aee32207c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aee32105c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aee32207c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aee32105c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aee320f094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55aee3220519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55aee3211128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aee320f094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55aee322dccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55aee322e44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55aee32f110e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55aee321877c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55aee32136fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aee32207c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55aee322ddac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55aee32136fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aee32207c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aee32105c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aee320f094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55aee3220519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55aee32105c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55aee32207c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55aee3210312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aee320f094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55aee3220519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55aee3211128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55aee320f094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55aee320ed68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55aee320ed19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55aee32bc07b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55aee32e8fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55aee32e5353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55aee32dd16a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55aee32dd05c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55aee32dc297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55aee32aff07]
=================================
2023-10-03 07:37:12,766 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37965 -> ucx://127.0.0.1:53587
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fed7934a140, tag: 0x5ae59a4ee1092350, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:12,765 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60823 -> ucx://127.0.0.1:48599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcc73280140, tag: 0xec0070542b59e574, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:12,766 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fed7934a1c0, tag: 0x6e1a57df4d240bce, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fed7934a1c0, tag: 0x6e1a57df4d240bce, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-03 07:37:12,766 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53587
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7fe171bfd280, tag: 0x3ea56c8aa9858a4f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7fe171bfd280, tag: 0x3ea56c8aa9858a4f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-03 07:37:12,766 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53587
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7f7f152be180, tag: 0xd013022ded71b41c, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7f7f152be180, tag: 0xd013022ded71b41c, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-03 07:37:12,767 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53587
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fed7934a200, tag: 0xbb4bbc8571b98ad5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fed7934a200, tag: 0xbb4bbc8571b98ad5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-03 07:37:12,767 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7fe171bfd1c0, tag: 0x26211ca25c528de5, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7fe171bfd1c0, tag: 0x26211ca25c528de5, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-03 07:37:12,768 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fcc732801c0, tag: 0x7aa6745c1576be16, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fcc732801c0, tag: 0x7aa6745c1576be16, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-03 07:37:12,768 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53587
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #000] ep: 0x7fcc73280240, tag: 0x56c06d9552dfee67, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #000] ep: 0x7fcc73280240, tag: 0x56c06d9552dfee67, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-03 07:37:12,774 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:48599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f7f152be100, tag: 0x3e0e1f467584da9f, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f7f152be100, tag: 0x3e0e1f467584da9f, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-03 07:37:12,815 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46091 -> ucx://127.0.0.1:48599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f7f152be280, tag: 0xf5951fbcd9e5a7db, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:12,847 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:53587
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2849, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1626, in connect
    return connect_attempt.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1516, in _connect
    comm = await connect(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CancelledError()
2023-10-03 07:37:12,876 - distributed.nanny - WARNING - Restarting worker
[dgx13:84437:0:84437] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15b81)
==== backtrace (tid:  84437) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7fb19ca1ceed]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c0e4) [0x7fb19ca1d0e4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c2aa) [0x7fb19ca1d2aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7fb23d171420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fb19ca9e577]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7fb19cac6d5d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2086f) [0x7fb19c9d586f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a48) [0x7fb19c9d8a48]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fb19ca26639]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7fb19c9d7b5d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7fb19ca9b47a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7fb19cb625fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x5608aae1f6fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5608aae1b094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5608aae2c519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5608aae1c5c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5608aae2c7c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x5608aae39e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x5608aaf44b2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x5608aadd6d05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x5608aae237f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x5608aae21929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5608aae2c7c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5608aae1c5c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5608aae2c7c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5608aae1c5c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5608aae2c7c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5608aae1c5c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5608aae2c7c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5608aae1c5c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5608aae1b094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5608aae2c519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x5608aae1d128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5608aae1b094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x5608aae39ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x5608aae3a44c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x5608aaefd10e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x5608aae2477c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x5608aae1f6fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5608aae2c7c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x5608aae39dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x5608aae1f6fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5608aae2c7c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5608aae1c5c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5608aae1b094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5608aae2c519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x5608aae1c5c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x5608aae2c7c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x5608aae1c312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5608aae1b094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x5608aae2c519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x5608aae1d128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x5608aae1b094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x5608aae1ad68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x5608aae1ad19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x5608aaec807b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x5608aaef4fca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x5608aaef1353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x5608aaee916a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x5608aaee905c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x5608aaee8297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x5608aaebbf07]
=================================
2023-10-03 07:37:12,977 - distributed.nanny - WARNING - Restarting worker
2023-10-03 07:37:13,192 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46091 -> ucx://127.0.0.1:59605
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7f7f152be3c0, tag: 0xd4e557186384c03f, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:13,192 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37965 -> ucx://127.0.0.1:59605
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fed7934a3c0, tag: 0x37c905135629959a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:13,192 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60823 -> ucx://127.0.0.1:59605
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fcc732803c0, tag: 0x39fca3c8b3560f2, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:13,192 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:36707 -> ucx://127.0.0.1:59605
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fe171bfd3c0, tag: 0x84b970fbddbc570e, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:13,193 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37965 -> ucx://127.0.0.1:48599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7fed7934a100, tag: 0x6451e70cc1698c59, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:13,193 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59605
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7f7f152be140, tag: 0x9d00bc0000f6f263, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7f7f152be140, tag: 0x9d00bc0000f6f263, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-10-03 07:37:13,193 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59605
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 354, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fcc73280300, tag: 0xdf2c90cf0e5f26d1, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 372, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fcc73280300, tag: 0xdf2c90cf0e5f26d1, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-10-03 07:37:13,193 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59605
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fe171bfd300, tag: 0x6a6311f438831b9d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fe171bfd300, tag: 0x6a6311f438831b9d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-10-03 07:37:13,193 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:59605
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 396, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fed7934a240, tag: 0xd266bb261f747b8d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 402, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fed7934a240, tag: 0xd266bb261f747b8d, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Connection reset by remote peer")
2023-10-03 07:37:13,193 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:36707 -> ucx://127.0.0.1:48599
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fe171bfd140, tag: 0xafa8b3def1fb61ed, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:13,194 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:36707 -> ucx://127.0.0.1:53587
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fe171bfd100, tag: 0xfc1bea1ba8a39528, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:13,270 - distributed.nanny - WARNING - Restarting worker
[dgx13:84604:0:84604] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x450)
==== backtrace (tid:  84604) ====
 0  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2fd) [0x7f6f03ef4eed]
 1  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c0e4) [0x7f6f03ef50e4]
 2  /opt/conda/envs/gdf/lib/libucs.so.0(+0x2c2aa) [0x7f6f03ef52aa]
 3  /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x14420) [0x7f6fd0698420]
 4  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f6f03f76577]
 5  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x65d) [0x7f6f03f9ed5d]
 6  /opt/conda/envs/gdf/lib/libuct.so.0(+0x2086f) [0x7f6f3002e86f]
 7  /opt/conda/envs/gdf/lib/libuct.so.0(+0x23a48) [0x7f6f30031a48]
 8  /opt/conda/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f6f03efe639]
 9  /opt/conda/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7d) [0x7f6f30030b5d]
10  /opt/conda/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x5a) [0x7f6f03f7347a]
11  /opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/_libs/ucx_api.cpython-39-x86_64-linux-gnu.so(+0x3a5fa) [0x7f6f300845fa]
12  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b18fd786fb]
13  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b18fd74094]
14  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b18fd85519]
15  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b18fd755c6]
16  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b18fd857c2]
17  /opt/conda/envs/gdf/bin/python(+0x14de83) [0x55b18fd92e83]
18  /opt/conda/envs/gdf/bin/python(+0x258b2c) [0x55b18fe9db2c]
19  /opt/conda/envs/gdf/bin/python(+0xead05) [0x55b18fd2fd05]
20  /opt/conda/envs/gdf/bin/python(+0x1377f3) [0x55b18fd7c7f3]
21  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x59f9) [0x55b18fd7a929]
22  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b18fd857c2]
23  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b18fd755c6]
24  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b18fd857c2]
25  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b18fd755c6]
26  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b18fd857c2]
27  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b18fd755c6]
28  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b18fd857c2]
29  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b18fd755c6]
30  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b18fd74094]
31  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b18fd85519]
32  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b18fd76128]
33  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b18fd74094]
34  /opt/conda/envs/gdf/bin/python(+0x14dccb) [0x55b18fd92ccb]
35  /opt/conda/envs/gdf/bin/python(PyObject_Call+0xbc) [0x55b18fd9344c]
36  /opt/conda/envs/gdf/bin/python(+0x21110e) [0x55b18fe5610e]
37  /opt/conda/envs/gdf/bin/python(_PyObject_MakeTpCall+0x2ec) [0x55b18fd7d77c]
38  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b18fd786fb]
39  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b18fd857c2]
40  /opt/conda/envs/gdf/bin/python(+0x14ddac) [0x55b18fd92dac]
41  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x37cb) [0x55b18fd786fb]
42  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b18fd857c2]
43  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b18fd755c6]
44  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b18fd74094]
45  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b18fd85519]
46  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x696) [0x55b18fd755c6]
47  /opt/conda/envs/gdf/bin/python(+0x1407c2) [0x55b18fd857c2]
48  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3e2) [0x55b18fd75312]
49  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b18fd74094]
50  /opt/conda/envs/gdf/bin/python(_PyFunction_Vectorcall+0xd9) [0x55b18fd85519]
51  /opt/conda/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11f8) [0x55b18fd76128]
52  /opt/conda/envs/gdf/bin/python(+0x12f094) [0x55b18fd74094]
53  /opt/conda/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x48) [0x55b18fd73d68]
54  /opt/conda/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55b18fd73d19]
55  /opt/conda/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55b18fe2107b]
56  /opt/conda/envs/gdf/bin/python(+0x208fca) [0x55b18fe4dfca]
57  /opt/conda/envs/gdf/bin/python(+0x205353) [0x55b18fe4a353]
58  /opt/conda/envs/gdf/bin/python(PyRun_StringFlags+0x9a) [0x55b18fe4216a]
59  /opt/conda/envs/gdf/bin/python(PyRun_SimpleStringFlags+0x3c) [0x55b18fe4205c]
60  /opt/conda/envs/gdf/bin/python(Py_RunMain+0x267) [0x55b18fe41297]
61  /opt/conda/envs/gdf/bin/python(Py_BytesMain+0x37) [0x55b18fe14f07]
=================================
2023-10-03 07:37:15,012 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:37965 -> ucx://127.0.0.1:44871
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fed7934a100, tag: 0xb9479c0acd6acba3, nbytes: 99986296, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:15,054 - distributed.core - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-10-03 07:37:15,055 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2852, in get_data_from_worker
    response = await send_recv(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1106, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 377, in read
    frames = [
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 378, in <listcomp>
    device_array(each_size) if is_cuda else host_array(each_size)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 171, in device_array
    return rmm.DeviceBuffer(size=n)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded
2023-10-03 07:37:15,058 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:46091 -> ucx://127.0.0.1:44871
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 294, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-10-03 07:37:15,101 - distributed.worker - WARNING - Compute Failed
Key:       ('merge_chunk-adccb87e3fee0e0ff9c5206a34e9fe09', 1)
Function:  subgraph_callable-72606c88-f287-43b9-997d-e85cc26d
args:      (               key   payload
shuffle                     
0           743221  72410523
0           202941  50156777
0           928952  93919479
0           160290  94514679
0           729862  41804014
...            ...       ...
7        799597084  71017777
7        799543488  21447669
7        799697696  99605475
7        799571127  56989644
7        799544957  31700291

[100005187 rows x 2 columns],                  key   payload
704        506307232  49982907
707        404312834  26767254
32465      865432947  86548380
102920     822176035   5389970
32479      108282325   8947738
...              ...       ...
99999177    91594759  31095048
99999184  1503958943  66186395
99999192  1548912090  21717024
99999193  1559292689  50061947
99999196   595409287  71273171

[99996328 rows x 2 columns], 'simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 'simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2')
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-10-03 07:37:15,102 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:60823 -> ucx://127.0.0.1:44871
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #008] ep: 0x7fcc73280300, tag: 0x53aa7cf2b58ea4a2, nbytes: 100029936, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:15,118 - distributed.nanny - WARNING - Restarting worker
2023-10-03 07:37:15,123 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 2)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           796129  67873394
0           769972   8608058
0           166629  34591412
0           740819   5147430
0           732035  87006049
...            ...       ...
0        799762464  97839864
0        799865524  49174145
0        799767609  86139977
0        799925843  77404343
0        799990764  12517295

[12497244 rows x 2 columns],                key   payload
shuffle                     
1           457419  57122837
1           132488  68650553
1           459862  95075118
1           232934  40721003
1           436818  92933959
...            ...       ...
1        799705892  92493014
1        799590045  15416676
1        799756060  50048689
1        799847217  37241946
1        799757474  74218037

[12500558 rows x 2 columns],                key   payload
shuffle                     
2           293679  72578521
2            29953  65568823
2            33105  86369518
2           320670  81112697
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-10-03 07:37:15,124 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:36707 -> ucx://127.0.0.1:44871
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 338, in write
    await self.ep.send(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7fe171bfd100, tag: 0xe441eba5d07b8c80, nbytes: 100007144, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Connection reset by remote peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1782, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 803, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/ucx.py", line 342, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-10-03 07:37:15,180 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-84a0276e6a854cf0d6c4324869a61d39', 0)
Function:  _concat
args:      ([                key   payload
713       818444294  96281941
733       840311156   4179948
32449     834831972  99071451
102913    835105082   1470023
32464     804945770  19145670
...             ...       ...
99983359  703544055  51781847
99983296  838236986  87280008
99983310  403751758  87761402
99983322  310877566  66069118
99983323  860388759  24849709

[12497168 rows x 2 columns],                 key   payload
131777    954625776  81429196
131786    958977101  80372872
131793    901740566  97189023
32387     519123305  15269314
64238     956740106  34787297
...             ...       ...
99981788  623546755  81664825
99981729  930237165  96209592
99981741  619995648  14877885
99981753  964260176  45560849
99981759  412648306  37850735

[12502889 rows x 2 columns],                  key   payload
39104     1038502112  79177772
39113     1026446215  69095853
105027     732988924  94542168
144038    1035369491  41864477
39119      333311701  87598133
...              ...       ...
9
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-10-03 07:37:15,181 - distributed.worker - ERROR - 'int' object is not subscriptable
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2059, in gather_dep
    response = await get_data_from_worker(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2861, in get_data_from_worker
    status = response["status"]
TypeError: 'int' object is not subscriptable
2023-10-03 07:37:15,183 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 4)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           903333  80867643
0           780592  77014012
0           129706   6880341
0           920773   7954190
0           898736  85274478
...            ...       ...
0        799755356  74453437
0        799977659  64702692
0        799710884  86170309
0        799955096  32333323
0        799830436  35863549

[12503392 rows x 2 columns],                key   payload
shuffle                     
1           560132  11126172
1           299003  79056138
1           517739    632180
1           161620   4538416
1           464989  30709615
...            ...       ...
1        799611112  33899716
1        799873818  48877844
1        799838686  59670138
1        799773430  69855763
1        799710387   1018193

[12500389 rows x 2 columns],                key   payload
shuffle                     
2           373892  95723258
2           339531  87576428
2           303398  77601798
2            77200  54607817
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-10-03 07:37:15,456 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 3)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           738576  73449216
0           787741  49912978
0           147550  27810953
0           822703  89157623
0           733148   8187688
...            ...       ...
0        799848381   1932727
0        799884995  29853250
0        799882718  22703620
0        799973011  11657616
0        799996494  88961563

[12497076 rows x 2 columns],                key   payload
shuffle                     
1           438519  99768294
1           155955  48097833
1           464014  74422212
1           274915  71503266
1           574038   6588771
...            ...       ...
1        799645755  35109257
1        799695047  17178155
1        799606330   2068489
1        799765857  35296834
1        799738506  34099333

[12501362 rows x 2 columns],                key   payload
shuffle                     
2           417011  79129530
2            15714   5424892
2           158709  63933244
2          1002280   7712996
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-10-03 07:37:15,760 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 5)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           730536  14363694
0           238158  48811852
0           967285  76779786
0           182958  74985524
0           219307  14856483
...            ...       ...
0        799708834  78915404
0        799936212  55671895
0        799866726  28022069
0        799923331  79414771
0        799847138  86793328

[12502296 rows x 2 columns],                key   payload
shuffle                     
1           521437  40987644
1           149773  16882596
1           577243  63880902
1           165729  92340084
1           565976  82534303
...            ...       ...
1        799829317  63901915
1        799823724  16585966
1        799879481  35491780
1        799728360  77490114
1        799914762  70843093

[12499115 rows x 2 columns],                key   payload
shuffle                     
2           379454  62957980
2           389695  16352681
2           417376   9403671
2           290310  71595985
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

2023-10-03 07:37:15,894 - distributed.worker - WARNING - Compute Failed
Key:       ('simple-shuffle-b0648aa7f9e27a40d5f4d39e31c5b5a2', 7)
Function:  _concat
args:      ([               key   payload
shuffle                     
0           813916  68945483
0           724865  58157340
0           230629    350786
0           763689  24386096
0           820116  91118279
...            ...       ...
0        799856538  12637976
0        799904498  21285826
0        799674370  91674136
0        799866476  76457864
0        799690856  68267042

[12498151 rows x 2 columns],                key   payload
shuffle                     
1           402563  50780830
1           235334  76449596
1           458849  43392750
1           481356  76175514
1           486473  74531765
...            ...       ...
1        799863600  13730152
1        799757968  61822937
1        799857554  69644391
1        799695612  83351426
1        799727769   7946433

[12498591 rows x 2 columns],                key   payload
shuffle                     
2           315344  92345181
2            24995  15576828
2            10066  59347774
2           297696  78339701
2         
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/envs/gdf/include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')"

/opt/conda/envs/gdf/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
